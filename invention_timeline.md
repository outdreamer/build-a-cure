### example posts containing inventions or unique points/jokes that were copied by other people
		- first mention of insight paths on social media
			- https://twitter.com/alienbot123/status/1137526990339170306
		- I explained the concept of insight paths to identify insights automatically
			- https://twitter.com/alienbot123/status/339106387219079169
			- https://twitter.com/alienbot123/status/339106565825126400
			- https://twitter.com/alienbot123/status/339106672620482560
			- https://twitter.com/alienbot123/status/339106893605789696
			- https://twitter.com/alienbot123/status/339107097155358722
			- https://twitter.com/alienbot123/status/339107234690764800
			- https://twitter.com/alienbot123/status/339107451452399616
			- https://twitter.com/alienbot123/status/339107650606350336
				- the post above also mentions the variables of a process/function (that can be used to automate problem-solving by identifying the next insight in an insight path, when applied to a particular context like a field/domain of science), which is the first mention of function attributes that are useful for problem-solving automation
		- truth types (indicating 'alternate routes' to access the truth)
			- https://twitter.com/alienbot123/status/636694507224989696
		- earliest mentions of function indexing attributes on my twitter
			- mentions indexing function by abstraction, indicating intent to create interface queries
				- https://twitter.com/alienbot123/status/367796753371627520
			- https://twitter.com/alienbot123/status/670087598312919040
			- https://twitter.com/alienbot123/status/735892668287492096
			- https://twitter.com/alienbot123/status/789953895934095360
			- https://twitter.com/alienbot123/status/850786694974590977
			- https://twitter.com/alienbot123/status/873001704568082433
			- https://twitter.com/alienbot123/status/903697129058783233
			- https://twitter.com/alienbot123/status/903693738765148160
			- https://twitter.com/alienbot123/status/928530789112995840
		- earliest mentions of problem-solving automation specifically on my twitter
			- https://twitter.com/alienbot123/status/368896666847301633
			- https://twitter.com/alienbot123/status/368896961409077248
			- https://twitter.com/alienbot123/status/550407946749091840
			- https://twitter.com/alienbot123/status/550408623982403584
			- https://twitter.com/alienbot123/status/550409968525250561
			- https://twitter.com/alienbot123/status/802885493453103108
				- https://github.com/outdreamer/finder/tree/master/objects
			- https://twitter.com/alienbot123/status/829197235384700928
		- earliest mentions of interfaces (as 'perspectives' or 'lenses' as 'filters') on my twitter
			- https://twitter.com/alienbot123/status/211271391662714880
			- https://twitter.com/alienbot123/status/211271546478665729
		- idea/conceptual markets
			- https://twitter.com/alienbot123/status/208398749272248321
			- https://twitter.com/alienbot123/status/215465108023943168
		- applying structures like 'combine' to concepts:
			- https://twitter.com/alienbot123/status/254062162119651328
		- abstract network (a structure on the 'abstract interface')
			- https://twitter.com/alienbot123/status/268223098522832896
		- first mention of the meaning interface on twitter
			- https://twitter.com/alienbot123/status/367801507636207616
		- perspective-switching (interface query)
			- https://twitter.com/alienbot123/status/367813951561547776
			- https://twitter.com/alienbot123/status/647373077827993600
			- https://twitter.com/alienbot123/status/647380929237925888
			- https://twitter.com/alienbot123/status/682709026921025536
		- graph of interface layers
			- https://twitter.com/alienbot123/status/1016179939371085825
		- earliest mentions of the usefulness of the 'intent' interface on twitter
			- https://twitter.com/alienbot123/status/1334480685722046464
			- https://twitter.com/alienbot123/status/735893657484689408
		- earliest mentions of structures on the 'concept' interface on twitter
			- https://twitter.com/alienbot123/status/1334480696597889026
		- earliest mention of solution metadata like solution types
			- https://twitter.com/alienbot123/status/550408877087666177
		- I identified the possibility of math operations on concepts (conceptual math) & other structural math operations on other interfaces
			- https://twitter.com/alienbot123/status/1043549108261281793
		- math automation (finding/deriving/generating new solution methods to solve math problems)
			- Lattice multiplication method automation
				- https://github.com/outdreamer/build-a-cure/tree/master/docs/specific_problem_analysis/math/multiplication.md
			- Integration method automation
				- https://github.com/outdreamer/build-a-cure/tree/master/docs/objects/problem_space.svg
			- Eigenvector/eigenvalue relationship derivation automation
				- https://twitter.com/alienbot123/status/1154930391012167680
				- https://github.com/outdreamer/build-a-cure/tree/master/docs/specific_problem_analysis/math/automate_math_proof_example.md
			- Set generation automation (or solving a related problem, like deriving conversion functions between objects in a set to identify set operations)
				- using a similar method as this example of attribute/function combination, generate all possible sets:
				  - https://twitter.com/alienbot123/status/1245950414278627328

	- other useful insights identified/explained, some of which are in this repo, my finder repo, or my online emails/messages/posts/blogs
		
		- I identified:
			- that some functions were inherent to all processes & were interchangeable (find, build, apply, mean, derive)
			- that some structures were interchangeable as methods of generating other useful structures (useful structures like 'input-output sequences' could be used to generate solution automation workflows)
			- useful attributes like 'interactivity' of structures
			- that there were multiple solution automation workflows that could solve any problem & identified their variables & core interaction functions to generate them
			- how to automate inventing (with math examples & other examples)
			- the core structures/functions/attributes that most systems could be broken into & used to generate them
			- the format of mixing interface components to graph a system
			- useful cross-interface structures like interaction layers that could deconstruct a system quickly to generate quick understanding
			- that no one had automated any kind of system analysis like automatically identifying efficiencies in a system
			- important alternatives interfaces on which any problem could be solved
			- a new way to structure these objects in a way that enables connecting problems & solutions automatically
			- that its an interface that everything can be standardized to
			- that other interfaces exist, or identify that all problems can be solved by standardizing to the physics interface or another core interface
			- that system components like efficiency & incentives are also useful in solving all problems, and physics just implements these components in a physical/measurable way
			- that all problems & solutions are structural and their formats can be connected in relatively simple & quick ways like interface queries
			- the patterns in your workflows, or abstract, structure, & automate your workflows & thoughts
			- the importance of 'meaning' and 'relevance' and 'interactivity' to integrate structures & predict their interactions
			- that they're abstractable, structurible, & automatable, or identify that there is no function to even identify the inefficiencies in any system
			- that structures like 'filters, symmetries, standards, perspectives, bases, etc' all had something in common
			- that there were useful structures like general functions (find/apply/build/derive/mean) that were interchangeable
			- all the primary interfaces on which any problem could be solved
			- how to filter trillions of objects to identify the rare useful ones that would work to automate problem-solving
			- how to come up with a new method to automate problem-solving (a new 'solution automation workflow') whenever I want

		- I explained how to solve problems by explaining:
			- dictators/war/human nature to governments so they wouldnt have to go to war anymore, specifically how to connect perspectives across conflicts like wars in a way that doesnt invalidate either side - because if you dont connect them, conflicts will continue
			- how they could identify new viruses/species by applying changes to known species based on common change types/functions
			- that people should use known methods to design drugs that are non-addictive
				- https://phys.org/news/2021-07-addictive-opioids-chemistry.html
			- that all problems are structural, which no one even noticed until I pointed it out
			- that cell communication is a fundamental property that can be used to cure cancer, and so can my stressor/change supply & demand model
			- that poverty costs more than it would take to end it
			- how to fix biased AI algorithms
			- why symmetries (which I convert to the term 'interfaces') are useful for automating problem-solving & then they started using them in ML algorithms
			- that there are other useful structures that just data sets to solve a problem, like concepts/cause/intent, like how you can use facts or logic to prove a point, and both arent necessary

### summary of invention timeline
		
		- I was taught that:
			- problems could be solved in multiple ways
				- trial & error
					- if there was a way to apply trial & error to some problems, why not other problems?
				- addressing problem cause vs. problem itself (how vs. why)
				- solving a problem using logic vs. using facts
					- identified by how I know someone is lying bc it's obvious given how logic works and how they reveal their intentions, even though it's not provable with facts (info interface) because there arent tools to measure that specific information generated by logic & intentions without better brain activity triggering & measuring tools, to find out what info is stored in which brain structures & what activities indicate which computations on that info, but statistics offers an alternative method of approximation (clustering, prediction tools, probability analysis, similarity scores)
			- problems could be solved using rules
				- math problems could be solved using rules, so why not other problems?
		
		- I identified the following in:
			- 2008:
				- 'abstract network' (abstract interface) of irreducible cross-system concepts, when I began building the story/setting for my book Outdreamer, which is when I began cataloguing concepts to identify the most concise & useful set of them
				- 'perspective' structure (interface structure) when I began to examine priorities & documented the perspective structure (a filter with priorities) and realized there were multiple perspectives that were useful for solving a problem, and that these perspectives had structure, because when I was writing the story, I had to create structures to connect abstract concepts in the abstract network, and these connections followed rules of their own which had definitions/structure on the logic interface ('jumping to conclusions')
				- I wanted to automate basic tasks at school that took longer than they should have given how simple they were, like finding insights or good lines in a book quickly without reading the whole thing
			- sometime in between 2008 - 2012:
				- 'insight path' structure when I noticed patterns in innovations across systems when reading science news (& spark notes cheat sheets) when I was researching cancer & how vaccines were invented (it was made obvious by pure random accident bc the info was focused on given the inventor's perspective) & looking for ways to speed up science discoveries, and realized 'trial & error' was an example of this structure
			- 2012:
				- barclays libor rate 'insider information' news story is when I identified the structures of an information problem that made a solution possible to solve with information structures (information position, information barrier, information asymmetry) that were not the same as physical structures ('agents who know information') and how to connect those structures
					- this is the first example I can remember that made it clear that:
						- there were important & useful structures other than just functions/variables in problem-solving
						- information had absolute structure ('lies' and 'intent' were derivable using information structures & logic structures), rather than being subjective or nebulous concepts with changeable structure only as defined by humans
						- information problems could be solved with the information perspective using information structures (like 'distributing information' to resolve an 'information asymmetry')
			- 2013:
				- pitched function metadata at work (Cybernetics) in an email
				- pitched solution machine at work (Morinteresting) in a word document
			- between 2013 - 2015
				- started pitching function metadata & problem-solving structures like 'shape index' (structure interface) on social media
					- https://twitter.com/alienbot123/status/736605879093633025
			- 2015
				- pitched function-generation at work (NJI Media) in an email
			- 2016
				- pitched problem-solving tool Solvr at work (Booz Allen)
			- 2017
				- pitched these at work (Accenture, Capital One)

### detailed invention timeline

		- I decided to try to automate problem-solving once I saw patterns in the rules people used to solve problems, and once I found an example proof of concept, I pursued it. Alternatively, if you don't have human thoughts like that, or if you don't have human sources of joy/motivation, such as caring about protecting good people enough to try, or intellectual curiousity, or believing in yourself, you can try some caffeine.
		- I discovered concepts first in books & movies, then insights linking them while building the abstract network for my book in 2008, then I identified interfaces as useful objects to frame other objects on, given their patterns of change.
		- I first realized the fundamental object of insight paths when I realized people used methods to solve problems, which I realized at college. The probability problems I examined were framed in a way with patterns in the missing information, and the method to retrieve or generate it.
		- Here's an example of why insight paths are useful:
			- you could try to spot a liar by checking every fact, which is an implementation of the method of trial & error, and is very fragile given its dependence on data.
			- or you could try to spot a liar by checking the output of people's choices, given the intended output (output like reactions) and figuring out why they might want that output (to see what they can get away with to check their social status, etc) - a method based on understanding that is relatively independent of data.
			- the insight paths there are 'trial & error', 'look up information in a database', 'derive intent' - of those, the intent-derivation method is clearly more robust & accurate
			- another insight path involves identifying those robust insight paths: how would you identify the insights that are more powerful than others?
				- this insight path involves identifying the important objects on the relevant structures (like object interaction layers, such as the layer where objects like intent/patterns/rules/decisions interact) determining a problem of differentiating a lie from a fact, given that people lie for a reason, and the reason/intent is an important object determining the variation in the lie object
				- once you've identified that intent is the important object to the lie differentiation problem, you can build an insight path to detect intent from actual/intended outputs of the decision (the insight path above, the 'intent-derivation' method)
			- then even without knowing the intent-derivation method, you could derive it by doing queries on that structure for the important objects, and determine those objects' relationships relevant to the lie-differentiating problem - and youd have a good method of solving the problem, that was more efficient & accurate than standard methods, with just a general problem-solving insight path, in the form of a structural query (like 'find relevant objects in this structure').
		- dimensions: thinking about other dimensions was what led to identifying perspectives as important, after which I realized perspectives were like filters
		- interfaces: the term 'application programming interface' made me focus a little more than average on the term 'interface' (given its abstraction), which I initially stored in my head as a 'way/place for two different programs to communicate, like a language, applying a standardizing transform'. Eventually I realized that these interfaces were similar in function to filters.
			- I realized certain interfaces also acted like foundations where types of change developed (cause, potential, information, structure interfaces), and that some types of change were not only explanatory across all systems but were inherently related (structures like balance & abstractions like equality).
		- math-language map: I think about unit cases often, so I realized the standard operation of division was like applying the lower number as a standardizing transform on the upper number. Once I realized that division was a standardizing operation, I realized it had similarities to interfaces, which are more indexable as a semantic (linguistic) object than a structural one. I explored the concept of meaning in relation to these objects, and arrived at a structural definition of meaning: 
			- the 'meaning' of an object included the structures of that object in a relevant system, possibly aligning across multiple related systems
				- like how the answer to the question 'yes this fact is true, but what does it mean' is asking 'how does this fact fit into a system of related facts, and what impact does that have on other systems like cause/logic/change/potential'?
				- or specifically 'yes they had a kilo of cocaine, but what does that mean?' which in the absence of system context (fit of the fact into a system) is meaningless, but once you add other information like whether they were aware they were transporting it, it begins to have meaning. Once you add information about cause (responsibility/uniqueness/inevitability) of their decisions (is this a decision commonly produced by society/laws/incentives, did they work hard to get to a place where they could make this decision, did they have other options, and was it a decision at all), and objects on other interfaces (like 'does this align with the concept of fairness'), the original fact has additional meaning. The structure of an aligning slice of these systems may look like a street signpost in its most basic form.
				- another example would be debating the granular isolated/context-less question of "if a person who sends ransomware is completely evil", or whether (once you fit that fact into a system context) the meaning of their decision across systems is that "their structures of lack driving their decisions are completely evil". this is another example of how some systems (like intent & structure) are inherently related: some intents are only malicious in a particular system context, and some structures are only negative when used for a particular malicious intent.
				- the 'meaning' in my system is the interface query output, where the query is the meaning generator.
				- I realized this fatal disadvantage of isolated information when I started examining statistics, which frames variable relationships based on a snapshot of a set of variables, without really digging into what a variable is (a change type), how they develop & aggregate into other variables (like types & concepts), whether patterns of change across variable types/networks could be used to strengthen prediction functions against bias, where/how randomness develops in complex systems, whether bases/subsets were better structures to begin analysis from than averages, the causal structures like position of the variables, and other fundamental questions that seemed to be ignored from the statistical perspective.
				- you can frame this tool (or its network of interfaces, as a meaning interface) as meaning detection/generation automation.
				- meaning can take several forms in different systems:
					- the fit of an object in a system (position/structure)
						- the fit of an object in a particular system like the interface system (which relevant objects align across the interface systems)
					- the relevant structuress of an object:
						- a subset of the context, including related objects that are important for understanding, like a good explanation has
						- its most reduced form, like a rule that can generate the info you need to remember
					- the structures of importance (one attribute of a definition of meaning), like equivalence (similarity, balance) & power (hubs, inputs, catalysts)
				- the meaning is the answer to the question of 'why is this important or relevant', where other interfaces answer questions like 'why' (intent), 'how' (structure), 'when' (cause), 'where' (in what system context), and 'whether' (potential).
				- meaning can help you identify answers to questions like 'what is the important object' or 'what is the better priority', such as:

		- this insight about isolated analysis converged with another insight about the isolation of optimizations, either in priority or other relevant structures to the concept of optimization
			- optimization metrics: another important insight was the realization that having one winning system or metric was itself a sub-optimal system in most cases; a 'win-based perspective' narrows the focus too much toward one set of optimal (definition, metric, etc) when theres usually a combination structure of optimals (multiple government types, rules, metrics).
				- example: capitalism produces tech debt between companies that need to copy each other to compete, which is sub-optimal for almost everyone bc it requires repeated work, so a free market allowing competition should be used in certain cases (fair fight between different perspectives on how to implement an important product idea) to get the benefits of that system (quick innovation)
		- detachment: another reason I'm successful at thinking is that I don't allow myself to be biased - that means not letting myself get attached to conclusions (assumption bias), not letting myself over-prioritize my own interpretations (self bias), not letting myself over-focus on work that is similar to mine (similarity bias), not letting myself avoid conclusions that are painful or which make me afraid (pain-avoidance bias), not letting myself over-use existing methods just because I already understand them (understanding bias), etc.
			- this detachment allowed me to examine the inefficiencies in current solutions from a systematic perspective - allowing me to see why some problems were solved at all (curiosity, boredom), why some were solved inefficiently (lack of resources/oversight/incentives), why some were solved by markets/science (high impact, high incentive to solve in the form of a profit opportunity), why some went unsolved (low impact, high complexity), why some problems were solved eventually but in a way that maximized work rather than automating the solution (to create jobs)
			- i also saw patterns in problems, patterns that seemed to be unaddressed with current solutions - like common error types (dependency/version mismatch) & security incidents (misaligned permissionss with intents) or unnecessary work (manual learning of correct parameters to use in an ml model, without understanding).
			- these patterns made me realize how structural these problems were, and I knew that structurable information was automatable. I applied abstract analysis to find the important objects in these spaces (like the objects 'expectations' or 'intentions' and the 'expectation-intention mismatch' for the security space).
			- I began to think more about information formats, and how to format information about a problem in a way that you could query for the solution. A default information object I knew about was an 'info asymmetry' (where info on one side could be used to generate/derive info on the other side, but not in reverse - an info-lossy relationship), which was related to an 'info imbalance', where one agent had an information advantage over other agents, like with insider trading, which I knew about from the news, for example like the Barclay's incident. I thought about how to solve an 'info imbalance' (by distributing the info, keeping it local, keeping it accessible only by people who wanted to execute approved tasks with that info, etc) and I realized these solutions were generatable.
			- Then the task became not 'how to format information to make solutions queryable' but 'how to translate a problem into a format where the solutions could be fit to the problem & tested for solution metric fulfillment'.
				- I realized problems were formattable as various shapes which came down to a set of vectors: arranging vectors as solution steps, for the problem formats of filling a shape, reducing a shape, matching a shape, or mapping a problem as a trajectory shape in a network shape - the structural interface being what I used to call the 'shape index'.
			- This was followed by the articulation of the invention of the interface network, followed by the question of 'which formats were better for which interfaces', followed by the idea of interface operations like applying one interface to another (applying structure interface to each interface, to generate core interface objects like causal networks), and then fitting analysis specific to each interface (like the difference between related objects on an interface, such as intent & priorities) to those structures, which I used to call the 'physics' of logic/information/truth, to refer to the set of rules specific to those interfaces.
		- intent: one of the reasons I identified intent as an important object was that I usually have multiple reasons for decisions, like a decision to post a quote could have multiple intents (to get criticized given the quote metadata like who it quoted, to draw attention to an insight, to inspire copying behavior to see who is watching, etc), so I realized intents were not only an abundant source of variation, but an object that could be derived for functions. Then I thought about how to map intents to core functions, and I realized you could map high-level function intents like retrieve data to operations on granular intents like check.
		- math automation: how did I realize that math insights were automatable? The first clues were that it had core functions, like other automatable systems - then another clue that certain operations had default intents associated (there were reasons to apply certain operations, similar to incentives), and the related system objects you'd expect to see were there (efficiencies, like adjacent transformations that made certain calculations quicker). It was also clear that if functions had attributes, these attributes were connected to structure & were therefore automatable, especially once I derived the insight path to produce the cryptocurrency invention, which is a structure with conceptual attributes like 'trustless'.
		- looking back, I think some objects were clues to this trajectory, which could be structures that you could use to generate this (mandela, detachment from the Bhagavad Gita, the psychic instrument from His Dark Materials, the signpost from the Phantom Tollbooth, the 'abstractions as islands' trope in fiction, the time-traveling trope in fiction or conflicts between the church & state alerting me to different perspectives) but I can't point to one structure that I focused on through the years except the abstract network that I used for my book, which I realized was real somewhere after thinking about how certain concepts seemed to have rules they followed, like how power seems to gather in certain places. I began to think of an abstract city where these concepts could change, in conceptual time, and thought about how they might change in their interactions if not their structure, since they didn't seem changeable in this dimension set, but instead seemed to cascade down to structural dimensions, like a form of light.
		- why did I wait until last year to patent it? Partly bc I was keeping some pieces of the invention private in case I got a pitch meeting, partly bc I was busy with work/health/thinking of new ideas in specific problem spaces,  partly bc of the 1-year limit on public disclosures of inventions in the current outdated legal framework, partly bc of the difficulty/cost of the patent process which I thought the people who stole my inventions would inevitably interfere with, and partly bc I knew patents were public and if a large company copied it by reading my patent, I would find it difficult to bring them to justice, and partly bc I decided to figure out the mechanics/implementation of pieces of it later, once I arrived at & verified the initial proof of concept (later meaning once I got a pitch meeting).

- isnt your invention just another combination of words, like anything else?

		- words like problems, concepts, attributes, language, information, & a connection between math & language did in fact already exist by the tiem I used them to automate problem-solving
			- I did not invent the ideas of concepts, attributes, language, or information - I also did not invent problems.
			- you're aware of objects like intentions & problems because they're built in to social interaction & the language & theyre also important objects that you encounter frequently
			- existing concepts & systems like 'physics' are connected to everything else, and I did not invent physics (because it's a truth that can be discovered, not an invention using truth in useful ways reflecting truths)
			- being taught a problem-solving method like 'apply physics or biology or machine learning when you dont know the answer' is not the same as identifying even one method to solve all problems, let alone a method to generate all of the problem-solving methods that can solve all problems
				- everyone already knows methods like 'break a problem into sub-problems to solve the problem' and everyone follows rules in a workflow to solve problems, but stating that you have been taught a problem-solving workflow based on rules everyone knows is not problem-solving automation, it is just stating the problem of problem-solving workflows not currently being automated & repeating a workflow you were taught or that everyone would identify, rather than stating a solution of how to implement a method to automate all problem-solving, given that one workflow doesn't necessarily cover all problems and none of these workflows are currently automated.
				- other problem-solving workflows involve steps that are sometimes faster than others, such as 'find the interaction layer where the high-impact variation occurs & solve the problem there' is sometimes faster than 'break a problem into sub-problems', and more specific & structural, enabling it to be automated faster as well - as an example of why merely knowing a particular workflow to solve problems with very general or abstract steps such as 'break a problem into sub-problems' is not equivalent to 'problem-solving automation'.
			- 'other people have applied physics, neuroscience, & other sciences to ml before, someone would have thought of this eventually'
				- other people can read, but their egos tend to make them stupid, preventing them from ever identifying that they could be automated, so they wouldn't try to automate their work.
				- other people had decades & strong incentives to solve their problems and didnt

		- this tool is not equal to problems, concepts, attributes, language, & information - it's a way to automate deriving a solution for a problem (automating the trajectory from problem definition, to solution objects like meaning, cause, & insights).
				
		- I struggle to believe that no one else would have thought of a 'method to update the weights of variables & their interactions & versions after checking if the previous weights were accurate' which is the core structure that machine-learning is based on, so machine-learning shouldn't be seen as an esoteric invention that is out of reach of most people's brains, but rather a default invention that most people would have thought of if they had basic math understanding/education & tried to solve the problem of automating 'finding a prediction function' in a way that didn't involve regression or other known methods & scaled to high-dimensional spaces.
		
		- I also struggle to believe that someone would have thought of my invention, given how many hundreds of millions of people had the info necessary to come up with it but didn't, though it would be nice if I was living in a world full of other geniuses, it's just hard to believe given the information that people keep proving. If most people tried to automate problem-solving, they would come up with a solution that adjacently used existing technologies, like 'apply machine learning whenever you dont know something' or 'store solutions in a rules/solutions database', because those are easy solutions and people generally come up with easy solutions.
