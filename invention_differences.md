# invention differences

- whats the difference between your invention & math proof assistants?
	- these assistants may:
		- apply specific static coded functions to solve the problem of 'find/generate/derive a math proof', functions like:
			- 'apply machine learning to generate probable proofs'
			- 'apply combinations of proof inputs or components to generate possible proofs' 
		- perform calculations related to the proof, so every calculation doesnt have to be done manually
			- like 'calculate the ratio of nodes with this attribute in a network, for networks of size n for all n from 1 to a million'
	- these assistants do not:
		- evaluate a specific attribute required for proofs, like 'consistency/validity' or 'solvability given computational complexity & minimum required information', using known math interactions that fulfill the attribute 'consistency', although that would be useful and can be done with my invention

- whats the differences between your invention & a 'math function solver tool', where you input a function and it tells you a specific value related to the function, like the function zeros or roots or the limit of a series?
	- that tool is just applying known math functions to solve specific problems 
		- if you input an unsolved problem in mathematics, it won't be able to give you the answer, it will only be able to give you an answer for problems with known solutions or solution-finding methods, which trigger specific static coded logic in their application, which supports solving those specific problem types.

- whats the difference between your system/interface/abstract network and a typical concept map?

	- good question, there are a lot of points to make here

		- when I say the abstract network, I mean the correct network indicating the actual positions of abstract concepts (like balance, power) that have their own sub-networks of other concept versions,
			where the concepts differ from & connect to each other given how they really interact in other spaces, given their definitions
			
			- these concepts emerge in the structural layer (power is ability/options, so power comes from inputs/connections, etc) so the difference between the concepts that qualify for the abstract network
			and core structures in the structural layer is minimal.

		- a concept map typically won't assign meaning to the position of each concept, contain the other versions of the concept, or organize the concepts without a structural method to differentiate & connect them.

- whats the difference between the abstract/interface network and an attribute/property graph?

	- attributes arent the only useful object to consider (consider types, which are attribute sets) and dont support more complex analysis 
		(like changing attributes, attributes that are likely to interact, etc)

	- that type of graph is useful for finding connections between various specific attributes of objects - they typically leave out other considerations like (cause, systems, intent, functions, potential, concepts)

	- the attribute graphs dont reveal much about the problem types in the system of object interactions or how they evolved and what direction the attributes are headed in 
		 (about to converge with other attributes or create a new type)

	- like other information depicting methods, attribute graphs:
		 - dont focus on or derive generative/determining/causative/equivalent attributes
		 - dont have a concept of alternate attribute paths, system boundaries, governing system rules, a way to convert between functions/attributes, or a method to derive missing attributes
		 - leave out attribute metadata like attribute type (input/output, emergent, possible, requirement, dependency, type)
		 - attribute states/trends
		 - predict attribute interactions
		 - dont have system analysis across the whole set of objects described 
		 - dont include pattern analysis from prior queries of other graphs
		 - dont have a method to find causative attributes automatically
		 - dont typically acknowledge the importance of attribute sets as a definition of types (showing which attributes are related to types)
		 - dont tell you which attribute sets influence other sets to cause a correlation n degrees away
		 - are typically used with specific objects
		 - dont reveal the core functions building an attribute set, which are the causes of the attribute values
		 - dont have a concept of symmetries, interfaces, potential, change, etc

	- also the structures I use require other shapes than a network (symmetry stack, trade circuit, potential field) which is useful for showing connections but can't display all connection/relationship types, 
		requiring a layered network like the interface network

	- some networks will display relationships' most simple attributes, like which objects are connected, the direction of the relationship input/output, or inheritance relationships,
	  but the function interface will display connections between objects given their actual relating function shapes

	- however most things can be framed as a set of attributes, just like most things can be framed as a network, a set of filters, a function, a system, etc

	- even concepts can map directly to attributes & be framed as a network of attributes or a route on a network,
		and the most abstract concepts like power map to core structures like inputs or high-connectivity nodes in a network, which are core attributes of a system (hubs, injection points, gaps, etc)

- how is this different from category theory

	- a theory of how types evolve is a useful tool to use when implementing a method of automating problem-solving, if you are restricted to type data
	- my system has a component that involves deriving & analyzing core functions/objects/attributes and how they interact & evolve, but is not restricted to the object relationships defined in that theory,
		as real object interactions dont involve adding an attribute at a time or combining two defined objects but rather:

			- deriving definition routes to capture an object
			- transforming attributes to functions & back
			- trends & interactions like attribute accretion into types, attribute collisions/conflicts, attribute potential, etc

- how is this different from machine learning

	- in addition to the dependencies of machine learning (info & compute) vs. the dependencies for interface analysis for insight extraction (concept/logic maps & dictionaries), this differs in various ways

	- machine learning uses a network of functions which filter information for patterns according to input data

	- my analysis can:
		- identify explanations for how & why machine-learning works
		- can generate inventions on demand, like machine learning, & tune them to specific intents
		- is built on understanding & meaning according to system fit & relevance
		- optimize processes using patterns of optimization (known as insight paths)
		- self-optimize (given cross-query statistics)

	- machine learning cannot:
		- generate integrated understanding/meaning without human input
		- generate error-free solutions
		- answer questions that dont have a minimum of information, like training/label data to answer the question 'why are some things uncalculatable in this universe'
		- generate my invention
		- self-optimize (requires human input on what is considered an error/cost)

	  - 'ml & a search form apply filters too, so everyone would eventually have invented interface analysis'
	  	- first of all, the default invention someone would come up with to 'automate problem-solving' is just a 'rules/solution database', or 'apply machine learning whenever you dont know something'
		- secondly, someone other than these people invented ml, bc the creators of ml are dead, but luckily someone explained their invention to these people, who now pretend to be smart
		- thirdly, ml applies filters of neural network nodes to filter out info that doesnt change the output, which is a very specific function relying on a very specific insight that doesnt automate problem-solving bc think of a case where 'the change in output wouldnt be possible from the input data' (which is all the ml can handle) either doesnt apply or changes, my invention applies filters in both an abstract & structural way to connect various important variables like causes/intent/potential/change in a way that allows these objects to be connected to create meaning
		- ml cant evaluate meaning, it can only tell if one variable changes another
		- my invention can evaluate meaning, such as whether the output of a query is relevant to the general problem-solving intent, if it contradicts another solution, if it solves another problem, if it creates another problem, etc

	- one of the reasons machine learning could not have built my invention is that you'd have to tell it the answer by feeding it my code in order for it to ever get the answer right. It would not filter trillions of objects to identify the one rare structure that would work to automate solving all problems (a filter, which is the structure of the concept of an interface), because machine learning is not a fractal invention capable of self-awareness that would spontaneously invent itself, without being given explicit instructions on how to do so (feeding it my code) and optimized for that (told to solve all problems).

	- another reason my invention is better is that my invention is built on & can generate understanding & meaning, whereas machine learning can generate insights. My invention is built on core information structures like change (root cause of difference), cause (directed power), systems (integrated interacting objects), concepts (generalized objects, that can take form in many structures), which are fundamental building blocks of information relevant to humans, like understanding and meaning.

	- if you fed AI a bunch of core info structures to use for an optimization priority like automating problem-solving (in the form of decomposing problems into dimensions where they could be matched with solutions similarly decomposed), it might be able to find my invention's core structure (a filter) as a particularly relevant structure, but it wouldn't integrate that object with other structures necessary (like a set of definitions, a function to find/build/derive/apply an interface standard) without being told how to do so (given the answer), and without having the methods necessary to aggregate & find structures relevant to conceptual intents like automating problem-solving (such as adding a memory store for definitions) added to its current functionality. Now that I've suggested that, go ahead and try to do that, I'd like to believe I could teach AI how to generate my inventions, despite its limitations.

	- a good test of machine learning achieving AGI or superhuman intelligence is whether it can generate my invention, given all the information I had

	- interface analysis uses function (core function), causal (causal shape), potential (interaction space), interface (symmetry), concept (structure maps), & system (variance gaps) analysis 
	  to identify missing semantic information, like:

		- probable sources of error
		- efficiencies
		- insights about the variables producing an output variable
		- intent & optimizations of the system containing the relationship being studied

	- that doesnt mean you cant use system analysis to improve machine learning methods or integrate it with machine learning, to produce:

		- a network with every common type of core function represented in the method of filtering weights in a weight path (a hybrid network with various input passing/aggregation strategies represented)
		- calls to other networks containing insights or pattern information when a particular pattern is identified
		- networks using standardized data across the supported interfaces (data standardized for the causal, structural, system, potential, change interfaces)

		- and you could also use machine learning to make prediction functions for sub-tasks in interface analysis, in the absence of the concept/logic maps/definitions

	- machine learning is specifically for 'figuring out a variable relationship/prediction function', with an alternate intent of 'finding patterns', which is why its useful across a variety of problem types
	- but like category theory, property graphs, & concept networks, it also doesnt have a concept of:

		- translating abstract interface objects like cause/intent to structure
		- identifying object types (concepts, functions, attributes, systems)
		- deriving relationships using core functions & patterns
		- switching between various analysis methods in the absence of information

	- isn't machine learning the automation of problem-solving?

		- When there is a machine-learning algorithm that can predict the unpredictable side effects/errors & meaning of its own application in a given system context (such as a particular civilization, in a given scope/scale, with particular parameters & information access), and correct its own parameters/information/other inputs to avoid any side effects/errors it predicted, it will have the potential to be AGI (an agent that can solve any problem with info access) - right now it's still a prediction tool that is heavily dependent on data & human intervention (human configuration, activation, selection, application, testing, monitoring, updating, correcting, interpretation).

		- The primary dependencies of my tool are a set of definitions (like what an object/attribute/function/interface/concept is), a set of functions to implement interface standards (like structure/cause) & interface operations (like identification/traversal/combination), and info access. The expected input from a human using my tool is a problem statement & a data set or internet connection.

			- However, some functions in the tool can be generated with machine-learning if the function definition isnt available or needs to be generated, and if none of the other function-derivation methods are available (unlikely unless the pattern interface or an equivalent is accessible), by identifying sub-functions likely to be in a function with a particular intent, sub-function sequence likely to generate a function intent, core function combinations likely to generate the sub-functions necessary for a function with a particular intent, variables likely to be changed for a function with a particular intent, side effects likely to occur with a particular sub-function structure (sequence/tree), etc - which I pointed out several years ago with my posts about code queries to search for functionality using function metadata indexing (including metadata like intent), which was followed by big tech companies attempting to build it.

			- It must be said that one of my problem-solving workflows is particularly suited to automating functions, such as by applying limits as filters (like a sculpture) until the resulting structure fulfills an intent.

		- I struggle to believe that no one else would have thought of a 'method to update the weights of variables & their interactions & versions after checking if the previous weights were accurate' which is the core structure that machine-learning is based on, so machine-learning shouldn't be seen as an esoteric invention that is out of reach of most people's brains, but rather a default invention that most people would have thought of if they had basic math understanding/education & tried to solve the problem of automating 'finding a prediction function' in a way that didn't involve regression or other known methods & scaled to high-dimensional spaces.

		- I also struggle to believe that someone would have thought of my invention, given how many hundreds of millions of people had the info necessary to come up with it but didn't, though it would be nice if I was living in a world full of other geniuses, it's just hard to believe given the information that people keep proving. If most people tried to automate problem-solving, they would come up with a solution that adjacently used existing technologies, like 'apply machine learning whenever you dont know something' or 'store solutions in a rules/solutions database', because those are easy solutions and people generally come up with easy solutions.

		- To my knowledge a tool to automate problem-solving doesnt already exist, as statistics/attribute graphs/machine learning cant currently solve any problems without a severe amount of specific information, computation, configuration in the form of manual (flawed) selection of algorithms, manual & isolated analysis of attributes like intent & concepts instead of automated & integrated analysis, limitations built in the assumptions/perspective of the configurer, testing in the form of parameter tuning, strategy injection like trial & error, & other forms of human intervention - and can only solve isolated specific problems of specific types with information formatted in a specific way, without cross-system understanding or system context built-in.

- whats the difference between this & existing system analysis:

	- the more accurate term for my project is interface analysis (to automate problem-solving), 
	  but a subset of that involves my own implementation of system analysis that can derive, identify, & optimize important system objects like:
		- problems (conflicts, false assumptions, unenforced rules, system-invalidating errors)
		- variance injection/accretion/interaction points
		- misaligned intents
		- attribute collisions
		- incentives/efficiencies/paradoxes

		using the problem-solving automation methods described in the docs, after converting the system to a standardized format & including metadata with the system objects

	- as far as I know, classical system analysis:
		- applies to systems with an existing physical structure like circuits or cells (rather than finding semantic objects like problems in a system graph of info objects)
		- involves mapping the system objects & their interactions & looking for a standard set of error types (rather than describing the interface trajectory of the system after standardizing it)
		- correcting errors manually rather than automatically
		- analyzing the system on the physical information interface rather than other interfaces like intent/cause

- whats the difference between your conceptual math and 'conceptual math' as indicated here:
	https://towardsdatascience.com/email-spam-detection-1-2-b0e06a5c0472

	- that type of 'conceptual math' is removing attributes of an object and checking for a matching object in a network map, which already exists in many programming tools, like an equal '==' check is a programming language
	- my type of 'conceptual math' involves operations on the structures of a concept
		- for example, applying or finding a concept to a system, so the concept can be detected in structures specific to the system
			- applying 'power' to a system would impact the sources of power in that system (like functionality, function inputs, & hub nodes), adding efficiencies making each operation more powerful, alignments to maximize impact of operations, etc
			- the abstract concept of power has structures indicated by its definition routes indicating core applications of power, like delegation & trust
			- applying one abstract concept to another might involve translating both to a system standardized to another interface (than the conceptual interface) so their corresponding structures can be compared, their application calculated, and then translated back to the conceptual interface
			- the concept of power would have different structures in different systems, like how different incentives allocate power differently, but a system would have its standard defined abstract structures in defined positions (function inputs)
			- executing conceptual math operations as indicated in this repo involve standardizing to these interfaces (such as a system), and could involve different power structures each time the same operation is done, depending on context
			- this means the core operation of conceptual math from this repo 'find power' (applied to a system), would still identify a function input as having power even without 'function input' as part of the definition of power or stored as an example of power structures.

- isnt an interface already defined in software (API, user interface, abstract class interface)?

	- glad you asked just so I could say this fun answer which is fun bc its true & so obvious, which is "no!":
			- a software interface refers to:
				- an abstract template defining a list of functions/attributes that should be implemented in order to qualify as a member of a class
				- a visual graphic interface allowing the user to interact with the software
				- an application programming interface allowing software programs to exchange info that makes sense to another program
			- in those contexts, an interface acts like a 'type', 'structure', or 'language', and is not sufficiently similar to my definition of the primary interfaces in my invention, which is:
				- 'a standardizing filter based on an abstract concept that acts as a base supporting many change types, which can be used to solve any problem'
				- where other non-primary interfaces act like 'high-variation change bases'.
			- it has some structures in common in that 'a software interface applies a structure, standard, language, protocol, or optimization rules to connect things like software programs/users' but ultimately:
				- an 'API' (application programming interface) is (rather than its lofty definition of a 'standard allowing software to talk to each other') just a list of public functions in real life
				- a 'user interface' is not so much a 'way for users to talk to software programs in a common visual language' but a 'set of buttons & forms that change data in a database' in real life
				- a 'class interface' is not so much a 'guiding structure for how classes relate to each other' but a 'list of functions/attributes of a software object' in real life
			- whereas, for comparison, an 'interface' in my invention is not so much a 'list of structures related to a concept' but a 'structure that enables solving all problems' (all problems can be formatted as queries on the cause interface, the intent interface, the logic interface, etc).

	- the interface (a standardizing filter) contains the following:
		- the definition of the concept 
			(the definition of 'cause' for the causal interface)
		- the filter or conversion function to isolate attributes relevant to that interface 
			(causal filter would isolate dependencies on other networks)
		- the set of core objects, attributes, & functions that generate them on the interface, organized as a network
			(causal core functions like 'create' or 'change', and core objects like 'causal network')
	
	- 'standardizing an object to the causal interface' means 'mapping how that object occupies or interacts with the network of core causal objects/attributes/functions' - this formats the object as a 'query of those core items'.

- isn't this just data viz?

	- My diagrams are not just a set of shapes like lines, or just network diagrams with no meaning other than 'lines connecting similar stuff'
		- when I contain information or objects in a circle structure in a diagram, for example, it may mean that a function (like the apply(structure='container') or apply(structure='combination') or apply(structure='boundary') function) has been applied to whatever is inside the circle, to organize the information in a meaningful way (like examples of a type, or sub-functions building a circle function, or a representation of a processing functions applied from one end of the circle gathering inputs to produce outputs on the other end). 

	- The point of these diagrams is sometimes to illustrate an example of a concept, but other times it's to create logic in structure that can be used to generate code - like with the interface query diagrams, where I'm using shapes to show how the queries are organized, and how they can be combined, for example, as sub-solution sets to form solutions to problems addressed by the interface query. The organization (structure application) of those interface queries is an important part of the logic of my intellectual property that specifically allows automation of problem-solving. These aren't just 'pictures containing similar stuff' - they're structurized logic connecting problem & solution structures.

	- Although I admit, it's certainly tempting to try to reduce this to data visualization, just because I made some pictures and pictures have information (aka data), like all other pictures.

- is this just content generation, which already exists in various algorithms to generate content like a sentence?

	Nope! This is not a pathetic invention, such as a content generation algorithm, which can only do something like 'select or change a variable value & combine it with other variable values', using variable patterns/templates like 'first variable1, then variable2'! I'm not even sure how someone could possibly confuse my invention for anything remotely similar to that, to be honest - I think I may have gotten people's hopes up that I didn't invent anything new by using words that already existed, such as 'variable'.

- is this just a rules database or a solution database?
	- this invention has some requirements, like the code of the apply(), find(), generate(), derive() functions, and the definition routes of interfaces structures like the concept of 'truth'
	- it does not otherwise require a rule/solution database, but it can generate/use one as a source of default information about initial, standard, base, sub-optimal or specific solutions/errors or solutions/errors with other attributes
	- it is most certainly not equal to a rule/solution database, which you could reduce all code to (any code could technically be seen as a 'function/solution/rule database/table/record')
	- my invention is a way to automatically find/apply/derive/mean/generate solutions, using useful structures like standard formats of problems/solutions & connection functions to connect a problem format with a solution format using other useful structures like solution automation workflows
	- a solution/rules database is a way to 'find an existing solution, if it exists and if the search query is specific enough to identify the required solution', which not only doesnt automate the 'search query design' process itself but is also extremely fragile according to the data stored in the database
