## FAQ

	1. whats the need for mapping information problems to structure (math) problems? for example, isnt an information asymmetry already structural?

		- yes and no. 

			the problemm is already captured on a layer of abstraction above the agent layer (what you could call 3-d space or physical reality), 
		which is what I sometimes mean when I say the structural/math layer though I should really say the physical information layer, 
		where most problems should be transformed to unless you have existing solutions or a complete interface map so you can query for a solution on other interfaces.

			but the information asymmetry is an abstract problem has many solutions, and applying each solution would look different between different problem spaces.

			one way to solve it is by distributing all information to all agents - another way is by splitting hte information and sharing it equally - another way is removing the information.

			these solutions would look different depending on the problem space - distributing all information or removing it may not be possible depending on what resources you have.

			but once you have the problem matched to these solution structures, you can apply the solution structures to 3-d space, looking for objects that could fulfill the definition of solution terms.

			what does 'distribute' mean for a particular problem space? these are the questions that can be answered on the 3-d space layer.

				if you have info tech, you can distribute information that way, at risk of the info being hacked
				if you have social networks, you can distribute it that way, at risk of distorting it

			different solutions comes with different intents & problems like risks, and these objects are also automatically identifiable once the solution is applied

			distributing information may give conflicting agents power over each other - but only one of them may use it - thats an information problem as well, which can also be framed as an info asymmetry.

			whats the solution that causes the fewest risks & subsequent info asymmetries? that depends on the problem space.


	2. does every object need to be mapped to a common shape (like a square or circle) with your system?

		- that strategy can be used to compare attribute sets that match these common structures, to find structural solutions that can then be applied to the original problem 

		- in the absence of other problem-solving methods, finding structures with problem-solution matches already indexed can be an efficient method of solving the original problem.

		- that doesnt mean there arent cases where finding a new structure (like a core function combination circle layer system or a function system) isnt useful for depicting information in ways that will reveal problem cause & other important info, even revealing solutions if the information is organized in the right structure


	3. whats the difference between your system/interface/abstract network and a typical concept map?

		- good question, there are a lot of points to make here

			- when I say the abstract network, I mean the correct network indicating the actual positions of abstract concepts (like balance, power) that have their own sub-networks of other concept versions,
				where the concepts differ from & connect to each other given how they really interact in other spaces, given their definitions
				
				- these concepts emerge in the structural layer (power is ability/options, so power comes from inputs/connections, etc) so the difference between the concepts that qualify for the abstract network
				and core structures in the structural layer is minimal.

			- a concept map typically won't assign meaning to the position of each concept, contain the other versions of the concept, or organize the concepts without a structural method to differentiate & connect them.


	4. whats the difference between the abstract/interface network and an attribute/property graph?

		- attributes arent the only useful object to consider (consider types, which are attribute sets) and dont support more complex analysis 
			(like changing attributes, attributes that are likely to interact, etc)

		- that type of graph is useful for finding connections between various specific attributes of objects - they typically leave out other considerations like 
			- cause
			- system structures (boundaries, sub-systems)
			- intent
			- function (functionality building or emerging from attributes)
			- potential (interaction space)
			- concepts (trajectory on abstract network used by system)

		- the attribute graphs dont reveal much about the problem types in the system of object interactions or how they evolved and what direction the attributes are headed in 
			 (about to converge with other attributes or create a new type)

		- like other information depicting methods, attribute graphs:
			 - dont focus on or derive generative/determining/causative/equivalent attributes
			 - dont have a concept of alternate attribute paths, system boundaries, governing system rules, a way to convert between functions/attributes, or a method to derive missing attributes
			 - leave out attribute metadata like attribute type (input/output, emergent, possible, requirement, dependency, type)
			 - attribute states/trends
			 - predict attribute interactions
			 - dont have system analysis across the whole set of objects described 
			 - dont include pattern analysis from prior queries of other graphs
			 - dont have a method to find causative attributes automatically
			 - dont typically acknowledge the importance of attribute sets as a definition of types (showing which attributes are related to types)
			 - dont tell you which attribute sets influence other sets to cause a correlation n degrees away
			 - are typically used with specific objects
			 - dont reveal the core functions building an attribute set, which are the causes of the attribute values
			 - dont have a concept of symmetries, interfaces, potential, change, etc


		- also the structures I use require other shapes than a network (symmetry stack, trade circuit, potential field) which is useful for showing connections but can't display all connection/relationship types, 
			requiring a layered network like the interface network

		- some networks will display relationships' most simple attributes, like which objects are connected, the direction of the relationship input/output, or inheritance relationships,
		  but the function interface will display connections between objects given their actual relating function shapes

		- however most things can be framed as a set of attributes, just like most things can be framed as a network, a set of filters, a function, a system, etc

		- even concepts can map directly to attributes & be framed as a network of attributes or a route on a network,
			and the most abstract concepts like power map to core structures like inputs or high-connectivity nodes in a network, which are core attributes of a system (hubs, injection points, gaps, etc)


	5. how is this different from category theory

		- a theory of how types evolve is a useful tool to use when implementing a method of automating problem-solving, if you are restricted to type data
		- my system has a component that involves deriving & analyzing core functions/objects/attributes and how they interact & evolve, but is not restricted to the object relationships defined in that theory,
			as real object interactions dont involve adding an attribute at a time or combining two defined objects but rather:

				- deriving definition routes to capture an object
				- transforming attributes to functions & back
				- trends & interactions like attribute accretion into types, attribute collisions/conflicts, attribute potential, etc


	6. how is this different from machine learning

		- in addition to the dependencies of machine learning (info & compute) vs. the dependencies for interface analysis for insight extraction (concept/logic maps & dictionaries), this differs in various ways

		- machine learning uses a network of functions which filter information for patterns according to input data

		- interface analysis uses function (core function), causal (causal shape), potential (interaction space), interface (symmetry), concept (structure maps), & system (variance gaps) analysis 
		  to identify missing semantic information, like:

			- probable sources of error
			- efficiencies
			- insights about the variables producing an output variable
			- intent & optimizations of the system containing the relationship being studied

		- that doesnt mean you cant use system analysis to improve machine learning methods or integrate it with machine learning, to produce:

			- a network with every common type of core function represented in the method of filtering weights in a weight path (a hybrid network with various input passing/aggregation strategies represented)
			- calls to other networks containing insights or pattern information when a particular pattern is identified
			- networks using standardized data across the supported interfaces (data standardized for the causal, structural, system, potential, change interfaces)

			- and you could also use machine learning to make prediction functions for sub-tasks in interface analysis, in the absence of the concept/logic maps/definitions

		- machine learning is specifically for 'figuring out a variable relationship/prediction function', with an alternate intent of 'finding patterns', which is why its useful across a variety of problem types
		- but like category theory, property graphs, & concept networks, it also doesnt have a concept of:

			- translating abstract interface objects like cause/intent to structure
			- identifying object types (concepts, functions, attributes, systems)
			- deriving relationships using core functions & patterns
			- switching between various analysis methods in the absence of information


	7. whats the difference between this & existing system analysis:

		- the more accurate term for my project is interface analysis (to automate problem-solving), 
		  but a subset of that involves my own implementation of system analysis that can derive, identify, & optimize important system objects like:
			- problems (conflicts, false assumptions, unenforced rules, system-invalidating errors)
			- variance injection/accretion/interaction points
			- misaligned intents
			- attribute collisions
			- incentives/efficiencies/paradoxes

			using the problem-solving automation methods described in the docs, after converting the system to a standardized format & including metadata with the system objects

		- as far as I know, classical system analysis:
			- applies to systems with an existing physical structure like circuits or cells (rather than finding semantic objects like problems in a system graph of info objects)
			- involves mapping the system objects & their interactions & looking for a standard set of error types (rather than describing the interface trajectory of the system after standardizing it)
			- correcting errors manually rather than automatically
			- analyzing the system on the physical information interface rather than other interfaces like intent/cause


	8. whats the difference between this and simulations of agent-based games

		- some of my methods involve making changes to object positions & assessing the impact of that change, which is where the similarity ends
		- simulating info object (incentive, question, problem, system) combination types (merge, collide, compete, inject, etc) is not the same as simulating the combination of physical objects
		- my methods to find the cause of a phenomenon impacting various objects (like deriving that a bottle was the source of contamination causing an illness) involves using cross-system insight paths
			(like those found below, including finding the "attribute alignment" and "high-connectivity hub nodes"), which determine most emergent interaction patterns that occur in the physical world
		- my system analyzes agent position based on info & physical assets rather than just physical assets


	9. whats the difference between your conceptual math and 'conceptual math' as indicated here:
		https://towardsdatascience.com/email-spam-detection-1-2-b0e06a5c0472

		- that type of 'conceptual math' is removing attributes of an object and checking for a matching object in a network map
		- my type of 'conceptual math' involves operations on the structures of a concept
			- for example, applying or finding a concept to a system, so the concept can be detected in structures specific to the system
				- applying 'power' to a system would impact the sources of power in that system (like functionality, function inputs, & hub nodes), adding efficiencies making each operation more powerful, alignments to maximize impact of operations, etc
				- the abstract concept of power has structures indicated by its definition routes indicating core applications of power, like delegation & trust
				- applying one abstract concept to another might involve translating both to a system standardized to another interface (than the conceptual interface) so their corresponding structures can be compared, their application calculated, and then translated back to the conceptual interface
				- the concept of power would have different structures in different systems, like how different incentives allocate power differently, but a system would have its standard defined abstract structures in defined positions (function inputs)
				- executing conceptual math operations as indicated in this repo involve standardizing to these interfaces (such as a system), and could involve different power structures each time the same operation is done, depending on context
				- this means the core operation of conceptual math from this repo 'find power' (applied to a system), would still identify a function input as having power even without 'function input' as part of the definition of power or stored as an example of power structures.


	10. that (a problem/a language map/a math-language mapping/an attribute graph/a set of filters) already exists!

		- yes, problems, concepts, attributes, language, information, & a connection between math & language already existed - which is why its weird that no one came up with a tool to automate information derivation, specifically to solve information problems - I did not invent the ideas of concepts, attributes, language, or information - I also did not invent problems.

		- This tool is not problems, concepts, attributes, language, & information - it's a way to automate deriving a solution for a problem (automating the trajectory from problem definition, to solution objects like meaning, cause, & insights), which to my knowledge doesnt exist, as statistics/attribute graphs/machine learning cant currently solve problems without a severe amount of specific information, computation, configuration in the form of manual (flawed) selection of algorithms, manual & isolated analysis of attributes like intent & concepts instead of automated & integrated analysis, limitations built in the assumptions/perspective of the configurer, testing in the form of parameter tuning, strategy injection like trial & error, & other forms of human intervention - and can only solve isolated specific problems of specific types with information formatted in a specific way, without cross-system understanding or system context built-in.

		10.a. isn't machine learning the automation of problem-solving?

			- When there is a machine-learning algorithm that can predict the unpredictable side effects/errors & meaning of its own application in a given system context (such as a particular civilization, in a given scope/scale, with particular parameters & information access), and correct its own parameters/information/other inputs to avoid any side effects/errors it predicted, it will have the potential to be AGI (an agent that can solve any problem with info access) - right now it's still a prediction tool that is heavily dependent on data & human intervention (human configuration, activation, selection, application, testing, monitoring, updating, correcting, interpretation).

			- The primary dependencies of my tool are a set of definitions (like what an object/attribute/function/interface/concept is), a set of functions to implement interface standards (like structure/cause) & interface operations (like identification/traversal/combination), and info access. The expected input from a human using my tool is a problem statement & a data set or internet connection.

				- However, some functions in the tool can be generated with machine-learning if the function definition isnt available or needs to be generated, and if none of the other function-derivation methods are available (unlikely unless the pattern interface or an equivalent is accessible), by identifying sub-functions likely to be in a function with a particular intent, sub-function sequence likely to generate a function intent, core function combinations likely to generate the sub-functions necessary for a function with a particular intent, variables likely to be changed for a function with a particular intent, side effects likely to occur with a particular sub-function structure (sequence/tree), etc - which I pointed out several years ago with my posts about code queries to search for functionality using function metadata indexing (including metadata like intent), which was followed by big tech companies attempting to build it.

				- It must be said that one of my problem-solving workflows is particularly suited to automating functions, such as by applying limits as filters (like a sculpture) until the resulting structure fulfills an intent.

		10.b. aren't you scared of all the people who are mad that you came up with this?

			- First of all, the best way to understand the human interface is to understand that it's based on the crazy interface, which is generated by the structural interface (bio system, evolution, physics, etc). If you assume that everyone is a psychopath, you'll not only be a lot happier, you'll also survive all their attempts to kill you for being happier than them.

			- Second, you have to understand that this interface base & combination produces some particularly crazy basic needs for humans (such as intents like 'being right', 'being liked', 'being smart', 'being unique', 'being important', etc) which fulfill the functions of the ego, which can motivate people to get resources (get resources to feel right/liked/smart). There are other ways to self-motivate than avoiding costs/moving toward resources to fulfill those intents - ways such as deriving logic to help other people get resources. If you want to be superhuman, you need to not need these things - and if you love yourself enough, you will not need them & will outgrow the human interface.

			- Third, the best way to handle having too much power is to distribute it, which is one of the reasons I post anything publicly at all - I can teach people how to think if they're lacking, and they will not need to copy or otherwise attack me, because they'll be able to solve their own problems.

				- The best way to handle having a particular power from a unique contribution like problem-solving automation is to share how you came up with it, and let them figure out that they could have done so as well, if they had the same information, intents, & other attributes like perserverance as you, all of which is theoretically possible, with our current understanding of free will & physics. I could use my power to push everyone into their default psychopathy, but why not give them the option of pushes toward becoming independent, in case they want to grow?

			- Fourth, I have other problems to solve like time dynamics & universe manipulation, & more to contribute like implementation strategies & new interfaces, and I have made that clear enough that people who attack me seem to have achieved a dim awareness of it, so they have extra reasons not to attack me.

			- Fifth, I enjoy watching people try to take credit for my inventions even while it is tragic, because an intelligent mind can see the humor in the absence of meaning, and it reminds me that I have a lot of people (who might not be what they seem) to help, who can give my life meaning if I find a way to love them, even if they appear to be trying to prevent me from doing so, though an intelligent mind can also consider the possibility that everything is an illusion.

			- Sixth, fear is a boring way to live, even if it did give me an extra reason to become good at predicting the behavior of complex systems, as if I needed more.

			- Lastly, a good tactic when you're not finding meaning elsewhere is to question everything - Im capable of coming up with alternate explanations, so I can conceive of a universe where what appears to be real isn't the whole story. Maybe people are ego monsters created by physics, but maybe there are adjacent conditions for independence I can find to set them free - or maybe the agent who configured this universe is asking us for help optimization its parameters - or maybe there is another universe searching for potential that is using them as a portal, and I need to help that universe find it in themselves - or maybe this universe is used as a method of calculating what information (such as universe position) a life form can derive - or this universe is where space-times get stuck sometimes when they stop holding a level of potential change - or this universe is about to be a hub universe where other universes interact, and if someone maintains the potential here to avoid pre-determination, it can become that.


	11. is this too abstract to be useful? how would you implement this?

		- the fact that we can imagine what a concept is means it can have structure, & interfaces act like standardizing filters:
		  while they are abstract terms, they have intrinsic physical attributes & map to structures even when they are abstract enough to have few physical attributes

		- the docs for some implementation strategies are here:
			https://github.com/outdreamer/build-a-cure/blob/master/docs/core_analysis/derivation_methods.md
			https://github.com/outdreamer/build-a-cure/blob/master/docs/workflow/problem_solving_matching.md

		- most of my implementation strategies vary on:

			- the starting point of the analysis (which interface the query starts from)
			- the structures relevant (which structures or type of graphing method to use)
			- the intent (create a prediction function, reduce solution space, compare solutions, or match problem with solution)
			- the core abstract function represented (is it a find method, an apply method, a combination)
			- the models used (object model, interface query)

		- but they have in common:
			- using core objects & patterns
			- using info objects like problems/incentives/sub-systems/efficiencies & definitions & concepts like probability/relevance to create defined structures like prediction functions
			- applying structure to unstructured information


	12. can this really be used to automate math insights? that requires complex thought that cant be automated.

		- whoever told you that is full of

			Lattice multiplication method automation
				- https://github.com/outdreamer/build-a-cure/tree/master/docs/specific_problem_analysis/multiplication.md

			Integration method automation
				- https://github.com/outdreamer/build-a-cure/tree/master/docs/objects/problem_space.svg

			Eigenvector/eigenvalue relationship derivation automation
				- https://twitter.com/alienbot123/status/1154930391012167680
				- https://github.com/outdreamer/build-a-cure/tree/master/docs/specific_problem_analysis/automate_math_proof_example.md

			Set generation automation
				- using a similar method as this example of attribute/function combination, generate all possible sets:
				  https://twitter.com/alienbot123/status/1245950414278627328
				  <img src="https://github.com/outdreamer/build-a-cure/tree/master/docs/specific_problem_analysis/predict_pathogen_species.png" />

			- more evidence of damnation - come get your poison:

				- Problem solving automation workflow identifying structure implementing the concept of randomness, which can be used to generate functions with conceptual properties like high ratio of 'calculatability of answer' to 'verification of answer' (which can also be used to identify structure as an interface that can capture non-structured information like concepts)
					https://github.com/outdreamer/build-a-cure/tree/master/docs/workflow/problem_solving_matching.md

				- Linking relevant concepts to randomness such as average and balance/equality using definition routes as a method of identifying a probability distribution with randomness built-in (distribution with equal probability distributed across outcomes, or alternatively a distribution where each outcome has the same averaged probability value)

				- Generating the symmetry concept as a combination of objects/attributes/functions like 'reversible changes without losing information', using core component combination analysis
					https://github.com/outdreamer/build-a-cure/tree/master/find_existing_solutions/system_analysis/core_analysis.py

				- Identifying bases & other structures as an origin of a prediction function, rather than data sets alone, as alternate routes to a prediction function
					https://github.com/outdreamer/build-a-cure/tree/master/docs/tasks/problem_workflow_example.md

				- generate a function with certain attributes using net intent of structural component operations

					- to generate a function with ambiguity in input/output relationships (as in multiple inputs produce the same output), introduce an exponent in the dependent variable (like how x^2 + y^2 removes the concept of 'uniqueness' from the input/output relationship, given how exponents use repetition of the same base (x as a base, multiplied by itself), and using how combining different types of repetition can remove 'uniqueness' from the input/output relationship, and using how different pairs of inputs can generate the same outputs with a squaring operation (making squaring the unit operation to fulfills intents like "generate the 'ambiguity' attribute" or "remove the 'uniqueness' attribute")

				- kernel trick: 

					- the intent is to 'differentiate shapes on a graph with a straight line' (shapes indicating clusters belonging to different data categories)
					
					- in its standard definition routes, 'differentiating' can take the form of:
						- 'maximizing difference'
						- 'isolating difference'
						- 'producing difference'
					
					- 'maximizing difference' can take the form of 'adding a difference' rather than 'maximizing an existing difference'
					
					- if there is a difference, but it's not defined by a straight line, the difference boundary can be used to indicate a group of data that should have a different added attribute value (like height) than the other points
					
					- 'adding a difference' between shapes can translate to the structures:
						- 'adding a dimension'
						- 'changing the difference definition'
						- 'adding a difference of an existing type (scalar in current dimension)'
					
					- now that you have a specific structure ('add a difference in the form of a dimension') to achieve this general intent ('differentiate shapes'), apply that structure to the problem:
				      
				      - structural intent: find a function that maximizes differences between shapes on a graph
				        
				        - find the differentiating boundary on the current graph if there is one

					        1. identify a function that would create different values on either side of the boundary (minimizing values on one side, maximizing values on the other side)
					          - example: 
					          	- functions like x^2 have low outputs for low inputs and proportionately higher outputs for slightly higher inputs, so if you align the boundary with the position where the input/output proportion changes, you'll align low inputs with low outputs and slightly higher inputs with high outputs
					          	- 'aligning low inputs' means arranging the axes so the low axis values near zero overlap with the shape positions that should have low outputs
					          		- so 'alignment' here consists of centering/shifting the axes so that:
					          			- low/high values occur in the right positions
					          			- the difference where low outputs change into high outputs aligns with the differentiating boundary
					       
					       	2. alternatively, find the direction of change (from one shape to another) that could be mapped to a direction of growth in a function
					        	- 'direction of change' = 'outward from center of shape', so growth in value (from zero up) should align with the outward direction (align origin with center of shape)
					        		- <img src="https://en.wikipedia.org/wiki/Kernel_method#/media/File:Kernel_trick_idea.svg"/>
					        
					        3. alternatively, identify that the shape-differentiating boundary is the important object, and that this boundary should also be the separator in low/high outputs from whatever function is chosen
					        
					        - 1, 2, & 3 are just different starting points/formats of the same trajectory ('aligning inputs/outputs across differentiating boundary', 'differentiating outputs for different group inputs', 'align direction of group change with direction of increasing change')

					      - then apply this differentiating function to add a dimension of change
					      - then test if the new low outputs & relatively higher inputs are different enough to clearly separate them with a line (the unit separator)
					      - if not, try another function to maximize differences in outputs between shapes, with other structures that definitions (like 'adding a difference' or 'maximizing difference') can map to

					    - if there isnt a differentiating boundary, find a differentiating attribute between data groups, such as numbers that are square roots/primes/integers
					    	- then apply the same procedure as above, to find a function that differentiates numbers with that attribute from numbers without it

					- so from the origin intent 'differentiate shapes', we:

						- pulled definitions relevant to that intent
						
						- iterated through definitions
						
						- applied definitions to a system to get their structure in that system (answering the question, "what form would 'maximize difference' take in the graph system"), with answers like ('add a change type' and 'maximize change')
						
						- applying the structures retrieved by that definition application to the system (apply 'add a change type' by pulling types of change, iterating & applying them) in a way that aligns with origin intent

							- apply 'add a change type' (specifically a dimension of change) in a way that aligns with intent 'differentiating shapes'

								- this application involves first pulling core or important change types in this system:
									- change type 'input difference', in group membership
									- change type 'output difference', across inputs of different types
									- change type 'output difference thresshold', where outputs begin to change from one change type (linear, like 1^2 = 1) to another (quadratic, like 2^2 = 4)
									- change type 'attribute difference', in attributes of a data point
									- change type 'value difference', in various values of an attribute across different data points

								- then mapping these as inputs generating the group differences, which have their own input/output relationship already defined (input data::output group label)

								- formatting/arranging the change types in a structure that generates the group difference implies a function linking inputs & outputs, across the difference trajectory:
									
									- origin group A: origin group B difference
									
									- origin position attribute similarity (low values of A are similar to low values of B)
									
									- target position attribute difference (low values of A are different from low values of B)
										- meaning converted low values of A are lower/higher than converted low values of B
									
										- to get a difference in an attribute (like position), you can apply a conversion to maximize differences within that attribute, or add an attribute that offers another type of position difference, so that the attribute as defined in another space/system (3-d as opposed to 2-d) is differentiated
									
								- the origin position attribute similarity can be converted into the target position attribute difference with a function:

									- if there is a similarity between the threshold structure within a function output, and the threshold structure differentiating groups, that could make the input-output relationship generating function align with the overall 'differentiating shapes' intent

										- inject a similarity in that position, taking advantage of the existing similarity in structures (output threshold & group boundary both being examples of the 'differentiating limit' structure), by aligning group membership and threshold side

									- now you can search for a function that would align inputs/outputs across this threshold, starting your search with functions having an attribute of volatility (similar inputs produce very different outputs)

										- with the restrictions that:

											- it should have one major change in output change type, like x^2 has one major change from semi-linear to very nonlinear change
											- this major change should occur at relatively low values, for standardization & the fact that there isnt much room in the center shape for growth types

										- other functions maximizing difference would include a wave where adjacent inputs produce positive/negative values, but that implies other groups or alternating groups beyond the two categories


						- you have various starting points to automate finding the solution:

							- find the structure missing the solution first (derive solution structure, then fill it in with a solution)
								- find the structure of the input/output relationship that needs to occur
								- then fill it in with a function producing that input/output relationship

							- combine solution components first & apply limits/tests/filters to check if it matches solution metrics (build & refine solution)
								- find functions likely to produce difference across inputs
								- then check if they produce the right difference, and refine it (by centering/scaling) until it matches the difference you need

							- this solution is an example implementation of the structure-intent interface combination, with a specific implementation of the 'change' interface within that interface combination


						- this method can be generalized to a method of finding functions for an intent like 'reduce computation' or 'differentiate with a line'


	13. what is an interface 

		- its a standard for comparison - in my system its a standard that reduces systems so they can be compared


	14. what is a problem space

		- its the space where youd graph all the info relevant to a problem - I often use tech as a key determinant of a problem space bc which tech you have often determines which strategies you can use 
		  but it includes all the other resources you might have access to (info, potential, energy, physical assets, etc)


	15. why improve problem-solving at all?

		- the problems with current solution methods:

			- solutions that are slow to implement, static, not shared, not organized, not generalized, & include repeated work
			- solutions often dont use prior knowledge (insights/patterns) to inform new solutions
			- known/discoverable systems with known/discoverable rules are treated as unknowns
			- errors are found with common known or easily derived rules ("change/remove assumptions") or causes ("misaligned attributes")
			- problems of the same type persist across systems
			- problems can be standardized to info/structural problems, which have associated solutions, and can be used as building blocks of solutions
			- work devoted to repeating a solution could be work devoted to innovating problem-solving
			- problem-solving isnt automated
		
		- current methods are focused heavily on information - if people become too focused on information (what is true at a given time), they'll never change again & time will end,
			they'll just calculate everything from the point that they find a way to do so

			- instead of focusing on information as the priority, they need to focus on preserving variance potential, so there are still questions to answer

			- outrunning the onset of the information calculation singularity involves:

				- creating self-sustaining variance sources & protecting existing ones (maintaining ambiguity/alternative options)
				- automating what can be & also automating the update of automation tools
				- evaluating information on the basis of change/potential
				- analyzing reason/cause rather than information
				- this means avoiding optimizing everything
				- there should always be at least two comparable alternatives so a decision is difficult & not certain
					- at least two systems, at least two perspectives, at least two metrics, at least two intents, etc - the ark requires differentiation to sustain potential


	16. what do you mean by 'using potential as a base rather than time'

		- time as a base for assessing change is useful in solving information problems
		- time occurs when there are no symmetries allowing for reversibility - in order for something to be reversible, symmetries have to align to allow for efficient organization of energy flow so a system can form to be a platform for the change
		- potential is the ability to change, time is the realization of change
		- im using potential as a proxy for the time variable, just like using the derivative rather than the function
		- potential is an important input of time - if there is potential for change, time can occur 
		- focusing on time over-focuses on information, which is the result of a measurement, and measurements have unintended side effects like over-dependence on the measurement
		- potential also captures a lot of potential information:
			- whether something is about to happen (whether a function is about to change)
			- whether something is possible or unverifiably possible
			- whether something deviates from or complies with known patterns (whether it's likely to be new or not)
			- how similar something is to output of known generators (adjacence to functions as a analytical metric, rather than the prediction function itself)
			- possibilities & ambiguities (where information is lost like in a black hole or uncalculatable like where there are too many alternatives) 
		- evaluating change with respect to potential measures whether you're increasing the number of possibilities (enabling information to occur as time passes) or decreasing them
		- if you make a decision that closes too many doors, potential, change, & time will be permanently lost, if the door goes with it (if it's irreversible)
		- other types of time are useful to evaluate change 
			- whether youve changed in conceptual time, causal time, potential time, or information time, & whether the change is absolute/specific - did you change everyone's time or just yours?
			- these metrics differ in how other types of time pass
		- rather than asking 'is this resource needed at a given location' - we can ask questions like 'did we enable people in that location to solve a resource deficit?'


	17. what does the interface actually contain?

		- the interface (a standardizing filter) is the following:
			- the definition of the concept 
				(the definition of 'cause' for the causal interface)
			- the filter or conversion function to isolate attributes relevant to that interface 
				(causal filter would isolate dependencies on other networks)
			- the set of core objects, attributes, & functions that generate them on the interface, organized as a network
				(causal core functions like 'create' or 'change', and core objects like 'causal network')

		- standardizing an object to the causal interface means mapping how that object occupies or interacts with the network of core causal objects/attributes/functions - this means a query or traversal of those core items


	18. what is the actual workflow to use this?

		- the general program steps include the following:

			1. check pre-existing output of the program (pattern indexes, concept definitions, etc) to see if it can be used as an input filter for a new problem (the system filters below are some of the outputs of this program) to break the problem into solved problems

			2. if it isn't composable with solved problems, but the problem type is still identifiable, then select a solution strategy & starting point

			3. then select threshold metrics to switch between strategies 

			4. then execute the solution strategies, checking at various threshold points for problem-solution match

			5. if no match found for one strategy, switch to other strategies

			6. if no matches found across all strategies, switch to uncertainty description patterns & methods

			7. output either insights found, problem-solution match, or uncertainties that need to be resolved (gather more data, answer this question, etc)

			8. store any info objects found that arent already in indexes (insights, patterns, problem-solution matches, interfaces, functions)


	19. how come youre the only person who identified that automating problem-solving was even possible, let alone the only person who came up with a method to do it in all of human history?

		- I decided to try to automate problem-solving once I saw patterns in the rules people used to solve problems, and once I found an example proof of concept, I pursued it. Alternatively, if you don't have human thoughts like that, or if you don't have human sources of joy/motivation, such as caring about protecting good people enough to try, or intellectual curiousity, or believing in yourself, you can try some caffeine.

		- I discovered concepts first in books & movies, then insights linking them while building the abstract network for my book in 2008, then I identified interfaces as useful objects to frame other objects on, given their patterns of change.

		- I first realized the fundamental object of insight paths when I realized people used methods to solve problems, which I realized at college. The probability problems I examined were framed in a way with patterns in the missing information, and the method to retrieve or generate it.

		- Here's an example of why insight paths are useful:
			- you could try to spot a liar by checking every fact, which is an implementation of the method of trial & error, and is very fragile given its dependence on data.
			- or you could try to spot a liar by checking the output of people's choices, given the intended output (output like reactions) and figuring out why they might want that output (to see what they can get away with to check their social status, etc) - a method based on understanding that is relatively independent of data.
			- the insight paths there are:
				- trial & error
				- look up information
				- intent-derivation method, given actual & intended outputs of a decision
			- the intent-derivation method is clearly more robust & accurate
			- another insight path involves identifying those robust insight paths: how would you identify the insights that are more powerful than others?
				- this insight path involves identifying the important objects on the relevant structures (like object interaction layers, such as the layer where objects like intent/patterns/rules/decisions interact) determining a problem of differentiating a lie from a fact, given that people lie for a reason, and the reason/intent is an important object determining the variation in the lie object
				- once you've identified that intent is the important object to the lie differentiation problem, you can build an insight path to detect intent from actual/intended outputs of the decision (the insight path above, the 'intent-derivation' method)
			- then even without knowing the intent-derivation method, you could derive it by doing queries on that structure for the important objects, and determine those objects' relationships relevant to the lie-differentiating problem - and youd have a good method of solving the problem, that was more efficient & accurate than standard methods, with just a general problem-solving insight path, in the form of a structural query (like 'find relevant objects in this structure').

		- dimensions: thinking about other dimensions was what led to identifying perspectives as important, after which I realized perspectives were like filters

		- interfaces: the term 'application programming interface' made me focus a little more than average on the term 'interface' (given its abstraction), which I initially stored in my head as a 'way/place for two different programs to communicate, like a language, applying a standardizing transform'. Eventually I realized that these interfaces were similar in function to filters.

			- I realized certain interfaces also acted like foundations where types of change developed (cause, potential, information, structure interfaces), and that some types of change were not only explanatory across all systems but were inherently related (structures like balance & abstractions like equality).

		- math-language map: I think about unit cases often, so I realized the standard operation of division was like applying the lower number as a standardizing transform on the upper number. Once I realized that division was a standardizing operation, I realized it had similarities to interfaces, which are more indexable as a semantic (linguistic) object than a structural one. I explored the concept of meaning in relation to these objects, and arrived at a structural definition of meaning: 

			- the 'meaning' of an object included the structures of that object in a relevant system, possibly aligning across multiple related systems
				
				- like how the answer to the question 'yes this fact is true, but what does it mean' is asking 'how does this fact fit into a system of related facts, and what impact does that have on other systems like cause/logic/change/potential'?
				
				- or specifically 'yes they had a kilo of cocaine, but what does that mean?' which in the absence of system context (fit of the fact into a system) is meaningless, but once you add other information like whether they were aware they were transporting it, it begins to have meaning. Once you add information about cause (responsibility/uniqueness/inevitability) of their decisions (is this a decision commonly produced by society/laws/incentives, did they work hard to get to a place where they could make this decision, did they have other options, and was it a decision at all), and objects on other interfaces (like 'does this align with the concept of fairness'), the original fact has additional meaning. The structure of an aligning slice of these systems may look like a street signpost in its most basic form.

				- another example would be debating the granular isolated/context-less question of "if a person who sends ransomware is completely evil", or whether (once you fit that fact into a system context) the meaning of their decision across systems is that "their structures of lack driving their decisions are completely evil". this is another example of how some systems (like intent & structure) are inherently related: some intents are only malicious in a particular system context, and some structures are only negative when used for a particular malicious intent.

				- the 'meaning' in my system is the interface query output, where the query is the meaning generator.

				- I realized this fatal disadvantage of isolated information when I started examining statistics, which frames variable relationships based on a snapshot of a set of variables, without really digging into what a variable is (a change type), how they develop & aggregate into other variables (like types & concepts), whether patterns of change across variable types/networks could be used to strengthen prediction functions against bias, where/how randomness develops in complex systems, whether bases/subsets were better structures to begin analysis from than averages, the causal structures like position of the variables, and other fundamental questions that seemed to be ignored from the statistical perspective.

				- you can frame this tool (or its network of interfaces, as a meaning interface) as meaning detection/generation automation.

				- meaning can take several forms in different systems:
					
					- the fit of an object in a system (position/structure)
						- the fit of an object in a particular system like the interface system (which relevant objects align across the interface systems)
					
					- the relevant structuress of an object:
						- a subset of the context, including related objects that are important for understanding, like a good explanation has
						- its most reduced form, like a rule that can generate the info you need to remember

					- the structures of importance (one attribute of a definition of meaning), like equivalence (similarity, balance) & power (hubs, inputs, catalysts)

				- the meaning is the answer to the question of 'why is this important or relevant', where other interfaces answer questions like 'why' (intent), 'how' (structure), 'when' (cause), 'where' (in what system context), and 'whether' (potential).

				- meaning can help you identify answers to questions like 'what is the important object' or 'what is the better priority', such as:
					
					- question: "what concept is explanatory or prioritized in society" (specifically the question "is society about truth or teamwork?" for a person raised by wolves trying to understand society quickly to survive)
						
						- how would you derive the answer "teamwork is a good default, except when the team succumbs to negative group dynamics, at which point individuals/other teams external to the group need to be in position to criticize it", given the thousands of objects that could explain the function of 'optimizing society'
						
						- there are many interface traversals to gather output to derive the answer:

							- insight: 
								- 'over-focus on facts makes arguments & potential restrictive', 'teamwork is good for risk distribution for robust populations'
								- 'given that information is necessarily existing in the past according to the observer, and that information doesnt exist according to an observer outside the space-time, does this apply to the information system of math - is there information forming or possible information that can be captured by future number types which are gathering, where existing math is the observer looking backward'
							
							- system: 
								- 'teamwork has built-in incentive alignment with whats best for other people'
							
							- interface: 
								- 'truth is one interface, but teamwork is applicable across many'
							
							- function: 
								- 'teamwork is an important concept by default because it is related to a core function type, which is interaction functions'
							
							- concept-structure: 
								- 'teamwork as a structurized concept is based on the core structures of checking if other team members have what they need to benefit the team & maintain the team advantage, which is based on the concept of balance'
								- 'teamwork involves a network subset with aligned incentives'
							
							- concept
								- 'truth is related to the concept of state'
								- 'teamwork involves the concept of a group'
								- 'facts are ignored by many groups which find their trade loops more efficient without that information - the concept of a cult'
							
							- pattern: 
								- 'patterns of state changes are often more useful for their predictive power than state information'
							
							- meaning:
								- the information from the other interface traversals can help build the meaning of the priority ranking relationship between these two concepts:
									- 'facts dont mean anything to a group unless they help the group'
									- 'teams that dont assimilate the important facts quickly enough may become irrelevant enough to seem false or not real to other groups'
									- 'if an observer sees a group problem, they can save the group, and they have an incentive to, if the group is beneficial to other groups'

								- this is the meaning bc its the structure relevant to the initial concern, which was the question asked
						
						- now the observer can quickly figure out what to prioritize, rather than waiting for someone to explain it to them

							- vertices:
								- determinative/generative/power: does truth determine teamwork or the other way around?
								- differentiating: what is truth that teamwork is not and vice versa?

							- vertices like generative/hub/differentiating variables can shorten the distance from lack of understanding to understanding, similar to the insight paths associated with the vertices

						- other examples of high-value use cases (other than identifying important concepts):

							- identifying the important base to frame changes on (identifying new interfaces)
							- identifying the right interaction level to focus on (identifying the change-maximizing layer of a system to examine a particular relationship)
							- identifying the right perspective to filter with (like 'identifying whether the legal/scientific/progressive perspective is most useful for an intent')
							- identifying the right context/position for an object (derive context when it's missing or fit an object to a system)
							- identifying the most causative function set (like identifying core functions, or the most misused functionss, or the most change-causing functions)
							- identifying important differentiating types (like function types indexed by intent & structure types, like boundary/change functions)

		- this insight about isolated analysis converged with another insight about the isolation of optimizations, either in priority or other relevant structures to the concept of optimization

			- optimization metrics: another important insight was the realization that having one winning system or metric was itself a sub-optimal system in most cases; a 'win-based perspective' narrows the focus too much toward one set of optimal (definition, metric, etc) when theres usually a combination structure of optimals (multiple government types, rules, metrics).

				- example: capitalism produces tech debt between companies that need to copy each other to compete, which is sub-optimal for almost everyone bc it requires repeated work, so a free market allowing competition should be used in certain cases (fair fight between different perspectives on how to implement an important product idea) to get the benefits of that system (quick innovation)

		- detachment: another reason I'm successful at thinking is that I don't allow myself to be biased - that means not letting myself get attached to conclusions (assumption bias), not letting myself over-prioritize my own interpretations (self bias), not letting myself over-focus on work that is similar to mine (similarity bias), not letting myself avoid conclusions that are painful or which make me afraid (pain-avoidance bias), not letting myself over-use existing methods just because I already understand them (understanding bias), etc.

			- this detachment allowed me to examine the inefficiencies in current solutions from a systematic perspective - allowing me to see why some problems were solved at all (curiosity, boredom), why some were solved inefficiently (lack of resources/oversight/incentives), why some were solved by markets/science (high impact, high incentive to solve in the form of a profit opportunity), why some went unsolved (low impact, high complexity), why some problems were solved eventually but in a way that maximized work rather than automating the solution (to create jobs)

			- i also saw patterns in problems, patterns that seemed to be unaddressed with current solutions - like common error types (dependency/version mismatch) & security incidents (misaligned permissionss with intents) or unnecessary work (manual learning of correct parameters to use in an ml model, without understanding).

			- these patterns made me realize how structural these problems were, and I knew that structurable information was automatable. I applied abstract analysis to find the important objects in these spaces (like the objects 'expectations' or 'intentions' and the 'expectation-intention mismatch' for the security space).

			- I began to think more about information formats, and how to format information about a problem in a way that you could query for the solution. A default information object I knew about was an 'info asymmetry' (where info on one side could be used to generate/derive info on the other side, but not in reverse - an info-lossy relationship), which was related to an 'info imbalance', where one agent had an information advantage over other agents, like with insider trading, which I knew about from the news, for example like the Barclay's incident. I thought about how to solve an 'info imbalance' (by distributing the info, keeping it local, keeping it accessible only by people who wanted to execute approved tasks with that info, etc) and I realized these solutions were generatable.

			- Then the task became not 'how to format information to make solutions queryable' but 'how to translate a problem into a format where the solutions could be fit to the problem & tested for solution metric fulfillment'.

				- I realized problems were formattable as various shapes which came down to a set of vectors: arranging vectors as solution steps, for the problem formats of filling a shape, reducing a shape, matching a shape, or mapping a problem as a trajectory shape in a network shape - the structural interface being what I used to call the 'shape index'.

			- This was followed by the articulation of the invention of the interface network, followed by the question of 'which formats were better for which interfaces', followed by the idea of interface operations like applying one interface to another (applying structure interface to each interface, to generate core interface objects like causal networks), and then fitting analysis specific to each interface (like the difference between related objects on an interface, such as intent & priorities) to those structures, which I used to call the 'physics' of logic/information/truth, to refer to the set of rules specific to those interfaces.

		- intent: one of the reasons I identified intent as an important object was that I usually have multiple reasons for decisions, like a decision to post a quote could have multiple intents (to get criticized given the quote metadata like who it quoted, to draw attention to an insight, to inspire copying behavior to see who is watching, etc), so I realized intents were not only an abundant source of variation, but an object that could be derived for functions. Then I thought about how to map intents to core functions, and I realized you could map high-level function intents like retrieve data to operations on granular intents like check.

		- math automation: how did I realize that math insights were automatable? The first clues were that it had core functions, like other automatable systems - then another clue that certain operations had default intents associated (there were reasons to apply certain operations, similar to incentives), and the related system objects you'd expect to see were there (efficiencies, like adjacent transformations that made certain calculations quicker). It was also clear that if functions had attributes, these attributes were connected to structure & were therefore automatable, especially once I derived the insight path to produce the cryptocurrency invention, which is a structure with conceptual attributes like 'trustless'.

		- looking back, I think some objects were clues to this trajectory, which could be structures that you could use to generate this (mandela, detachment from the Bhagavad Gita, the psychic instrument from His Dark Materials, the signpost from the Phantom Tollbooth, the 'abstractions as islands' trope in fiction, the time-traveling trope in fiction or conflicts between the church & state alerting me to different perspectives) but I can't point to one structure that I focused on through the years except the abstract network that I used for my book, which I realized was real somewhere after thinking about how certain concepts seemed to have rules they followed, like how power seems to gather in certain places. I began to think of an abstract city where these concepts could change, in conceptual time, and thought about how they might change in their interactions if not their structure, since they didn't seem changeable in this dimension set, but instead seemed to cascade down to structural dimensions, like a form of light.

		- why did I wait until this year to patent it? Partly bc I was keeping some pieces of the invention private in case I got a pitch meeting, partly bc I was busy with work/health/thinking of new ideas in specific problem spaces, and partly bc of the 1-year limit on public disclosures of inventions in the current outdated legal framework, and partly bc I decided to figure out the mechanics/implementation of pieces of it later, once I arrived at & verified the initial proof of concept (later meaning once I got a pitch meeting).

		- Not everyone has a built-in reason to automate problem-solving (like if they don't have serious problems to solve relevant to them, like the well-being of good people), but once I realized automation of problem-solving was possible, that gave me extra drive to get there, so I didn't need other reasons past that point, though luckily I had them just in case.


	20. is all value created? are there any problems left to chase? what problems cant be solved with this?

		- this system can solve problems where information is calculatable (like on the math interface) or where information is retrievable/testable (where you have data you can find & retrieve).
			- it can identify new interfaces on which problem-solving automation is possible, as they develop or become measurable
			- it can integrate new problems & new problem types into the system
		
		- it cant solve problems where information isnt measurable or calculatable - that means:
			- problems that are not solvable in this host system (a universe with these laws of physics):
				- problems that require more computation than we have computing power for
				- problems regarding information that is not retrievable or derivable (destroyed information, like historical information or information inside black holes)
				- problems regarding structures we dont have the understanding to organize information queries for, or retrieve information for (if there is a physics or math insight that is so foreign to our understanding that we don't even know to look for it, that may not be solvable with this tool, but it should be able to point understanding & information retrieval in that direction if not reach the destination structure). This would happen if the analysis isn't comprehensive enough when generating different perspectives, to identify new interfaces & new structures on them not adjacently derivable with existing interfaces.
					- maybe there's an object that generates so much randomness that we cant ever capture enough information about it to derive it
					- maybe there's a mechanism preventing necessary computation time to derive the mechanism from gathering around certain structures capable of hosting sentient life
					- maybe information has a built-in expiration in physics, and if it's not used, it decays - maybe this is how math develops, around efficiency energy organization that is allocated according to incentives & aligned with meaningful intent based on usage
			- these are examples I can come up with, which means my system can also come up with them - but you can see how non-standard assumptions can generate a high level of difference, to come up with alternative explanations originating from very different but still possible systems.


