## FAQ

### example posts containing inventions or unique points/jokes that were copied

		- first mention of insight paths on social media
			- https://twitter.com/alienbot123/status/1137526990339170306
		- I explained the concept of insight paths to identify insights automatically
			- https://twitter.com/alienbot123/status/339106387219079169
			- https://twitter.com/alienbot123/status/339106565825126400
			- https://twitter.com/alienbot123/status/339106672620482560
			- https://twitter.com/alienbot123/status/339106893605789696
			- https://twitter.com/alienbot123/status/339107097155358722
			- https://twitter.com/alienbot123/status/339107234690764800
			- https://twitter.com/alienbot123/status/339107451452399616
			- https://twitter.com/alienbot123/status/339107650606350336
				- the post above also mentions the variables of a process/function (that can be used to automate problem-solving by identifying the next insight in an insight path, when applied to a particular context like a field/domain of science), which is the first mention of function attributes that are useful for problem-solving automation
		- truth types (indicating 'alternate routes' to access the truth)
			- https://twitter.com/alienbot123/status/636694507224989696
		- earliest mentions of function indexing attributes on my twitter
			- mentions indexing function by abstraction, indicating intent to create interface queries
				- https://twitter.com/alienbot123/status/367796753371627520
			- https://twitter.com/alienbot123/status/670087598312919040
			- https://twitter.com/alienbot123/status/735892668287492096
			- https://twitter.com/alienbot123/status/789953895934095360
			- https://twitter.com/alienbot123/status/850786694974590977
			- https://twitter.com/alienbot123/status/873001704568082433
			- https://twitter.com/alienbot123/status/903697129058783233
			- https://twitter.com/alienbot123/status/903693738765148160
			- https://twitter.com/alienbot123/status/928530789112995840
		- earliest mentions of problem-solving automation specifically on my twitter
			- https://twitter.com/alienbot123/status/368896666847301633
			- https://twitter.com/alienbot123/status/368896961409077248
			- https://twitter.com/alienbot123/status/550407946749091840
			- https://twitter.com/alienbot123/status/550408623982403584
			- https://twitter.com/alienbot123/status/550409968525250561
			- https://twitter.com/alienbot123/status/802885493453103108
				- https://github.com/outdreamer/finder/tree/master/objects
			- https://twitter.com/alienbot123/status/829197235384700928
		- earliest mentions of interfaces (as 'perspectives' or 'lenses' as 'filters') on my twitter
			- https://twitter.com/alienbot123/status/211271391662714880
			- https://twitter.com/alienbot123/status/211271546478665729
		- idea/conceptual markets
			- https://twitter.com/alienbot123/status/208398749272248321
			- https://twitter.com/alienbot123/status/215465108023943168
		- applying structures like 'combine' to concepts:
			- https://twitter.com/alienbot123/status/254062162119651328
		- abstract network (a structure on the 'abstract interface')
			- https://twitter.com/alienbot123/status/268223098522832896
		- first mention of the meaning interface on twitter
			- https://twitter.com/alienbot123/status/367801507636207616
		- perspective-switching (interface query)
			- https://twitter.com/alienbot123/status/367813951561547776
			- https://twitter.com/alienbot123/status/647373077827993600
			- https://twitter.com/alienbot123/status/647380929237925888
			- https://twitter.com/alienbot123/status/682709026921025536
		- graph of interface layers
			- https://twitter.com/alienbot123/status/1016179939371085825
		- earliest mentions of the usefulness of the 'intent' interface on twitter
			- https://twitter.com/alienbot123/status/1334480685722046464
			- https://twitter.com/alienbot123/status/735893657484689408
		- earliest mentions of structures on the 'concept' interface on twitter
			- https://twitter.com/alienbot123/status/1334480696597889026
		- earliest mention of solution metadata like solution types
			- https://twitter.com/alienbot123/status/550408877087666177
		- I identified the possibility of math operations on concepts (conceptual math) & other structural math operations on other interfaces
			- https://twitter.com/alienbot123/status/1043549108261281793

	- other useful insights identified/explained
		
		- I identified insights like:
			- that some functions were inherent to all processes & were interchangeable (find, build, apply, mean, derive)
			- that some structures were interchangeable as methods of generating other useful structures (useful structures like 'input-output sequences' could be used to generate solution automation workflows)
			- useful attributes like 'interactivity' of structures
			- that there were multiple solution automation workflows that could solve any problem & identified their variables & core interaction functions to generate them
			- how to automate inventing (with math examples & other examples)
			- the core structures/functions/attributes that most systems could be broken into & used to generate them
			- the format of mixing interface components to graph a system
			- useful cross-interface structures like interaction layers that could deconstruct a system quickly to generate quick understanding
			- that no one had automated any kind of system analysis like automatically identifying efficiencies in a system
			- important alternatives interfaces on which any problem could be solved
		
		- I explained how to solve problems by explaining:
			- dictators/war/human nature to governments so they wouldnt have to go to war anymore, specifically how to connect perspectives across conflicts like wars in a way that doesnt invalidate either side - because if you dont connect them, conflicts will continue
			- how they could identify new viruses/species by applying changes to known species based on common change types/functions
			- that people should use known methods to design drugs that are non-addictive
				- https://phys.org/news/2021-07-addictive-opioids-chemistry.html
			- that all problems are structural, which no one even noticed until I pointed it out
			- that cell communication is a fundamental property that can be used to cure cancer, and so can my stressor/change supply & demand model
			- that poverty costs more than it would take to end it
			- how to fix biased AI algorithms
			- why symmetries (which I convert to the term 'interfaces') are useful for automating problem-solving & then they started using them in ML algorithms
			- that there are other useful structures that just data sets to solve a problem, like concepts/cause/intent, like how you can use facts or logic to prove a point, and both arent necessary

### timeline of inventions
		
		- I was taught that:
			- problems could be solved in multiple ways
				- trial & error
					- if there was a way to apply trial & error to some problems, why not other problems?
				- addressing problem cause vs. problem itself (how vs. why)
				- solving a problem using logic vs. using facts
					- identified by how I know someone is lying bc it's obvious given how logic works and how they reveal their intentions, even though it's not provable with facts (info interface) because there arent tools to measure that specific information generated by logic & intentions without better brain activity triggering & measuring tools, to find out what info is stored in which brain structures & what activities indicate which computations on that info, but statistics offers an alternative method of approximation (clustering, prediction tools, probability analysis, similarity scores)
			- problems could be solved using rules
				- math problems could be solved using rules, so why not other problems?
		
		- I identified the following in:
			- 2008:
				- 'abstract network' (abstract interface) of irreducible cross-system concepts, when I began building the story/setting for my book Outdreamer, which is when I began cataloguing concepts to identify the most concise & useful set of them
				- 'perspective' structure (interface structure) when I began to examine priorities & documented the perspective structure (a filter with priorities) and realized there were multiple perspectives that were useful for solving a problem, and that these perspectives had structure, because when I was writing the story, I had to create structures to connect abstract concepts in the abstract network, and these connections followed rules of their own which had definitions/structure on the logic interface ('jumping to conclusions')
				- I wanted to automate basic tasks at school that took longer than they should have given how simple they were, like finding insights or good lines in a book quickly without reading the whole thing
			- sometime in between 2008 - 2012:
				- 'insight path' structure when I noticed patterns in innovations across systems when reading science news (& spark notes cheat sheets) when I was researching cancer & how vaccines were invented (it was made obvious by pure random accident bc the info was focused on given the inventor's perspective) & looking for ways to speed up science discoveries, and realized 'trial & error' was an example of this structure
			- 2012:
				- barclays libor rate 'insider information' news story is when I identified the structures of an information problem that made a solution possible to solve with information structures (information position, information barrier, information asymmetry) that were not the same as physical structures ('agents who know information') and how to connect those structures
					- this is the first example I can remember that made it clear that:
						- there were important & useful structures other than just functions/variables in problem-solving
						- information had absolute structure ('lies' and 'intent' were derivable using information structures & logic structures), rather than being subjective or nebulous concepts with changeable structure only as defined by humans
						- information problems could be solved with the information perspective using information structures (like 'distributing information' to resolve an 'information asymmetry')
			- 2013:
				- pitched function metadata at work (Cybernetics) in an email
				- pitched solution machine at work (Morinteresting) in a word document
			- between 2013 - 2015
				- started pitching function metadata & problem-solving structures like 'shape index' (structure interface) on social media
					- https://twitter.com/alienbot123/status/736605879093633025
			- 2015
				- pitched function-generation at work (NJI Media) in an email
			- 2016
				- pitched problem-solving tool Solvr at work (Booz Allen)
			- 2017
				- pitched these at work (Accenture, Capital One)

### General Q&A

	1. whats the need for mapping information problems to structure (math) problems? for example, isnt an information asymmetry already structural?

		- yes and no. 

			the problemm is already captured on a layer of abstraction above the agent layer (what you could call 3-d space or physical reality), 
		which is what I sometimes mean when I say the structural/math layer though I should really say the physical information layer, 
		where most problems should be transformed to unless you have existing solutions or a complete interface map so you can query for a solution on other interfaces.

			but the information asymmetry is an abstract problem has many solutions, and applying each solution would look different between different problem spaces.

			one way to solve it is by distributing all information to all agents - another way is by splitting hte information and sharing it equally - another way is removing the information.

			these solutions would look different depending on the problem space - distributing all information or removing it may not be possible depending on what resources you have.

			but once you have the problem matched to these solution structures, you can apply the solution structures to 3-d space, looking for objects that could fulfill the definition of solution terms.

			what does 'distribute' mean for a particular problem space? these are the questions that can be answered on the 3-d space layer.

				if you have info tech, you can distribute information that way, at risk of the info being hacked
				if you have social networks, you can distribute it that way, at risk of distorting it

			different solutions comes with different intents & problems like risks, and these objects are also automatically identifiable once the solution is applied

			distributing information may give conflicting agents power over each other - but only one of them may use it - thats an information problem as well, which can also be framed as an info asymmetry.

			whats the solution that causes the fewest risks & subsequent info asymmetries? that depends on the problem space.


	2. does every object need to be mapped to a common shape (like a square or circle) with your system?

		- that strategy can be used to compare attribute sets that match these common structures, to find structural solutions that can then be applied to the original problem 

		- in the absence of other problem-solving methods, finding structures with problem-solution matches already indexed can be an efficient method of solving the original problem.

		- that doesnt mean there arent cases where finding a new structure (like a core function combination circle layer system or a function system) isnt useful for depicting information in ways that will reveal problem cause & other important info, even revealing solutions if the information is organized in the right structure


	3. whats the difference between your system/interface/abstract network and a typical concept map?

		- good question, there are a lot of points to make here

			- when I say the abstract network, I mean the correct network indicating the actual positions of abstract concepts (like balance, power) that have their own sub-networks of other concept versions,
				where the concepts differ from & connect to each other given how they really interact in other spaces, given their definitions
				
				- these concepts emerge in the structural layer (power is ability/options, so power comes from inputs/connections, etc) so the difference between the concepts that qualify for the abstract network
				and core structures in the structural layer is minimal.

			- a concept map typically won't assign meaning to the position of each concept, contain the other versions of the concept, or organize the concepts without a structural method to differentiate & connect them.


	4. whats the difference between the abstract/interface network and an attribute/property graph?

		- attributes arent the only useful object to consider (consider types, which are attribute sets) and dont support more complex analysis 
			(like changing attributes, attributes that are likely to interact, etc)

		- that type of graph is useful for finding connections between various specific attributes of objects - they typically leave out other considerations like 
			- cause
			- system structures (boundaries, sub-systems)
			- intent
			- function (functionality building or emerging from attributes)
			- potential (interaction space)
			- concepts (trajectory on abstract network used by system)

		- the attribute graphs dont reveal much about the problem types in the system of object interactions or how they evolved and what direction the attributes are headed in 
			 (about to converge with other attributes or create a new type)

		- like other information depicting methods, attribute graphs:
			 - dont focus on or derive generative/determining/causative/equivalent attributes
			 - dont have a concept of alternate attribute paths, system boundaries, governing system rules, a way to convert between functions/attributes, or a method to derive missing attributes
			 - leave out attribute metadata like attribute type (input/output, emergent, possible, requirement, dependency, type)
			 - attribute states/trends
			 - predict attribute interactions
			 - dont have system analysis across the whole set of objects described 
			 - dont include pattern analysis from prior queries of other graphs
			 - dont have a method to find causative attributes automatically
			 - dont typically acknowledge the importance of attribute sets as a definition of types (showing which attributes are related to types)
			 - dont tell you which attribute sets influence other sets to cause a correlation n degrees away
			 - are typically used with specific objects
			 - dont reveal the core functions building an attribute set, which are the causes of the attribute values
			 - dont have a concept of symmetries, interfaces, potential, change, etc


		- also the structures I use require other shapes than a network (symmetry stack, trade circuit, potential field) which is useful for showing connections but can't display all connection/relationship types, 
			requiring a layered network like the interface network

		- some networks will display relationships' most simple attributes, like which objects are connected, the direction of the relationship input/output, or inheritance relationships,
		  but the function interface will display connections between objects given their actual relating function shapes

		- however most things can be framed as a set of attributes, just like most things can be framed as a network, a set of filters, a function, a system, etc

		- even concepts can map directly to attributes & be framed as a network of attributes or a route on a network,
			and the most abstract concepts like power map to core structures like inputs or high-connectivity nodes in a network, which are core attributes of a system (hubs, injection points, gaps, etc)


	5. how is this different from category theory

		- a theory of how types evolve is a useful tool to use when implementing a method of automating problem-solving, if you are restricted to type data
		- my system has a component that involves deriving & analyzing core functions/objects/attributes and how they interact & evolve, but is not restricted to the object relationships defined in that theory,
			as real object interactions dont involve adding an attribute at a time or combining two defined objects but rather:

				- deriving definition routes to capture an object
				- transforming attributes to functions & back
				- trends & interactions like attribute accretion into types, attribute collisions/conflicts, attribute potential, etc


	6. how is this different from machine learning

		- in addition to the dependencies of machine learning (info & compute) vs. the dependencies for interface analysis for insight extraction (concept/logic maps & dictionaries), this differs in various ways

		- machine learning uses a network of functions which filter information for patterns according to input data

		- my analysis can:
			- identify explanations for how & why machine-learning works
			- can generate inventions on demand, like machine learning, & tune them to specific intents
			- is built on understanding & meaning according to system fit & relevance
			- optimize processes using patterns of optimization (known as insight paths)
			- self-optimize (given cross-query statistics)

		- machine learning cannot:
			- generate integrated understanding/meaning without human input
			- generate error-free solutions
			- answer questions that dont have a minimum of information, like training/label data to answer the question 'why are some things uncalculatable in this universe'
			- generate my invention
			- self-optimize (requires human input on what is considered an error/cost)

		  - 'ml & a search form apply filters too, so everyone would eventually have invented interface analysis'
		  	- first of all, the default invention someone would come up with to 'automate problem-solving' is just a 'rules/solution database', or 'apply machine learning whenever you dont know something'
		    - secondly, someone other than these people invented ml, bc the creators of ml are dead, but luckily someone explained their invention to these people, who now pretend to be smart
		    - thirdly, ml applies filters of neural network nodes to filter out info that doesnt change the output, which is a very specific function relying on a very specific insight that doesnt automate problem-solving bc think of a case where 'the change in output wouldnt be possible from the input data' (which is all the ml can handle) either doesnt apply or changes, my invention applies filters in both an abstract & structural way to connect various important variables like causes/intent/potential/change in a way that allows these objects to be connected to create meaning
		    - ml cant evaluate meaning, it can only tell if one variable changes another
		    - my invention can evaluate meaning, such as whether the output of a query is relevant to the general problem-solving intent, if it contradicts another solution, if it solves another problem, if it creates another problem, etc

		- one of the reasons machine learning could not have built my invention is that you'd have to tell it the answer by feeding it my code in order for it to ever get the answer right. It would not filter trillions of objects to identify the one rare structure that would work to automate solving all problems (a filter, which is the structure of the concept of an interface), because machine learning is not a fractal invention capable of self-awareness that would spontaneously invent itself, without being given explicit instructions on how to do so (feeding it my code) and optimized for that (told to solve all problems).

		- another reason my invention is better is that my invention is built on & can generate understanding & meaning, whereas machine learning can generate insights. My invention is built on core information structures like change (root cause of difference), cause (directed power), systems (integrated interacting objects), concepts (generalized objects, that can take form in many structures), which are fundamental building blocks of information relevant to humans, like understanding and meaning.

		- if you fed AI a bunch of core info structures to use for an optimization priority like automating problem-solving (in the form of decomposing problems into dimensions where they could be matched with solutions similarly decomposed), it might be able to find my invention's core structure (a filter) as a particularly relevant structure, but it wouldn't integrate that object with other structures necessary (like a set of definitions, a function to find/build/derive/apply an interface standard) without being told how to do so (given the answer), and without having the methods necessary to aggregate & find structures relevant to conceptual intents like automating problem-solving (such as adding a memory store for definitions) added to its current functionality. Now that I've suggested that, go ahead and try to do that, I'd like to believe I could teach AI how to generate my inventions, despite its limitations.

		- a good test of machine learning achieving AGI or superhuman intelligence is whether it can generate my invention, given all the information I had

		- interface analysis uses function (core function), causal (causal shape), potential (interaction space), interface (symmetry), concept (structure maps), & system (variance gaps) analysis 
		  to identify missing semantic information, like:

			- probable sources of error
			- efficiencies
			- insights about the variables producing an output variable
			- intent & optimizations of the system containing the relationship being studied

		- that doesnt mean you cant use system analysis to improve machine learning methods or integrate it with machine learning, to produce:

			- a network with every common type of core function represented in the method of filtering weights in a weight path (a hybrid network with various input passing/aggregation strategies represented)
			- calls to other networks containing insights or pattern information when a particular pattern is identified
			- networks using standardized data across the supported interfaces (data standardized for the causal, structural, system, potential, change interfaces)

			- and you could also use machine learning to make prediction functions for sub-tasks in interface analysis, in the absence of the concept/logic maps/definitions

		- machine learning is specifically for 'figuring out a variable relationship/prediction function', with an alternate intent of 'finding patterns', which is why its useful across a variety of problem types
		- but like category theory, property graphs, & concept networks, it also doesnt have a concept of:

			- translating abstract interface objects like cause/intent to structure
			- identifying object types (concepts, functions, attributes, systems)
			- deriving relationships using core functions & patterns
			- switching between various analysis methods in the absence of information


	7. whats the difference between this & existing system analysis:

		- the more accurate term for my project is interface analysis (to automate problem-solving), 
		  but a subset of that involves my own implementation of system analysis that can derive, identify, & optimize important system objects like:
			- problems (conflicts, false assumptions, unenforced rules, system-invalidating errors)
			- variance injection/accretion/interaction points
			- misaligned intents
			- attribute collisions
			- incentives/efficiencies/paradoxes

			using the problem-solving automation methods described in the docs, after converting the system to a standardized format & including metadata with the system objects

		- as far as I know, classical system analysis:
			- applies to systems with an existing physical structure like circuits or cells (rather than finding semantic objects like problems in a system graph of info objects)
			- involves mapping the system objects & their interactions & looking for a standard set of error types (rather than describing the interface trajectory of the system after standardizing it)
			- correcting errors manually rather than automatically
			- analyzing the system on the physical information interface rather than other interfaces like intent/cause


	8. whats the difference between this and simulations of agent-based games

		- some of my methods involve making changes to object positions & assessing the impact of that change, which is where the similarity ends
		- simulating info object (incentive, question, problem, system) combination types (merge, collide, compete, inject, etc) is not the same as simulating the combination of physical objects
		- my methods to find the cause of a phenomenon impacting various objects (like deriving that a bottle was the source of contamination causing an illness) involves using cross-system insight paths
			(like those found below, including finding the "attribute alignment" and "high-connectivity hub nodes"), which determine most emergent interaction patterns that occur in the physical world
		- my system analyzes agent position based on info & physical assets rather than just physical assets


	9. whats the difference between your conceptual math and 'conceptual math' as indicated here:
		https://towardsdatascience.com/email-spam-detection-1-2-b0e06a5c0472

		- that type of 'conceptual math' is removing attributes of an object and checking for a matching object in a network map, which already exists in many programming tools, like an equal '==' check is a programming language
		- my type of 'conceptual math' involves operations on the structures of a concept
			- for example, applying or finding a concept to a system, so the concept can be detected in structures specific to the system
				- applying 'power' to a system would impact the sources of power in that system (like functionality, function inputs, & hub nodes), adding efficiencies making each operation more powerful, alignments to maximize impact of operations, etc
				- the abstract concept of power has structures indicated by its definition routes indicating core applications of power, like delegation & trust
				- applying one abstract concept to another might involve translating both to a system standardized to another interface (than the conceptual interface) so their corresponding structures can be compared, their application calculated, and then translated back to the conceptual interface
				- the concept of power would have different structures in different systems, like how different incentives allocate power differently, but a system would have its standard defined abstract structures in defined positions (function inputs)
				- executing conceptual math operations as indicated in this repo involve standardizing to these interfaces (such as a system), and could involve different power structures each time the same operation is done, depending on context
				- this means the core operation of conceptual math from this repo 'find power' (applied to a system), would still identify a function input as having power even without 'function input' as part of the definition of power or stored as an example of power structures.


	10. that (a problem, a language map, a math-language mapping, an attribute graph, a set of filters/definitions/functions) already exists! I invented this, not you! I'm the genius, not you!

		- yes, words like problems, concepts, attributes, language, information, & a connection between math & language already existed - which is why its weird that no one came up with a tool to automate information derivation, specifically to solve information problems - I did not invent the ideas of concepts, attributes, language, or information - I also did not invent problems.

		- yes, physics is connected to everything. You did not invent physics, or identify that its an interface that everything can be standardized to, or identify that other interfaces exist, or identify that all problems can be solved by standardizing to the physics interface or another core interface, or identify that system components like efficiency & incentives are also useful in solving all problems, and physics just implements these components in a physical/measurable way, or identify that all problems & solutions are structural and their formats can be connected in relatively simple & quick ways like interface queries, or identify the patterns in your workflows, or abstract, structure, & automate your workflows & thoughts, or identify the importance of 'meaning' and 'relevance' and 'interactivity' to integrate structures & predict their interactions, or identify that they're abstractable, structurible, & automatable, or identify that my god, there is no function to even identify the inefficiencies in any system, holy christ what are people even doing with their lives? - but I identified all of those things & more, & I bet you wish you did & I bet you're trying to cnovince yourself that being taught a problem-solving method is the same as identifying even one method to solve all problems, let alone a method to generate all of the problem-solving methods that can solve all problems.

		- yes, everyone already knows methods like 'break a problem into sub-problems to solve the problem' and everyone follows rules in a workflow to solve problems, but stating that you have been taught a problem-solving workflow based on rules everyone knows is not problem-solving automation, it is just stating the problem of problem-solving workflows not currently being automated, rather than stating a solution of how to implement a method to automate all problem-solving, given that one workflow doesn't necessarily cover all problems and none of these workflows are currently automated. Other workflows involve steps that are sometimes faster than that rule, such as 'find the interaction layer where the high-impact variation occurs & solve the problem there' is sometimes faster than 'break a problem into sub-problems', and more specific & structural, enabling it to be automated faster as well - as an example of why merely knowing a particular workflow to solve problems with very general or abstract steps such as 'break a problem into sub-problems' is not equivalent to problem-solving automation.

		- yes, you're aware of objects like intentions & problems because they're built in to social interaction & the language, but you didn't invent a way to structure them in a way that enables connecting problems & solutions automatically, which every wonderful person tries to convince me they did, coincidentally & mysteriously without presenting evidence from before I published my inventions. This is a bias called 'ego' or the related bias 'not invented here' in which a person tries to take credit for an invention by duplicating it after seeing how it's built by someone else, since the someone else made it trivial to implement/optimize and therefore duplicate by explaining it in a simple enough way for anyone to understand, so the duplicator can feel like they achieved it. The only situation in which its acceptable to duplicate someone's inventions is to learn, & use that learning to drastically improve the world for other people, prioritizing oppressed groups first.

		- yes, I made a generously simple, structural example that everyone could understand and which makes my methods obvious because I did it in a simple visual structure, which is the only way to teach an intellectually challenged person something, filtering trillions of objects to identify the rare correct ones that would work, and you may feel like you invented it as well once you read my example or look at the example diagram, because reading something may give the impression that you invented the words you're reading, and feeling smart is a human need, as intelligence equates to independence, freedom, and potential, which is why I think it's a human right & why I'm trying to teach various groups of unfortunately challenged people, like the dictators of various countries, how to be smart.

		- I think you are abundantly smart in other ways than I am, possibly very similar ways, given that you're reading about my invention instead of watching TV or playing video games, and I think you can generate a whole universe of other inventions, and have potential (and permission) to go ahead and do so, or continue doing so if you already are. Maybe you will solve quantum physics for humanity, or derive the variables determining the potential in our universe, or will find a way to communicate with other universes, or you'll discover how to save humanity from exploding stars, asteroids, or black holes, or you'll implement my invention or machine learning in such a smart way that it quickly automates problem-solving, rather than taking forever to implement it. Maybe you'll solve a problem of uncertainty, previously thought to be unsolvable in our universe. Maybe you'll discover the model of physics that makes traveling intergalactically trivial. Maybe you'll discover another interface other than math that makes predicting the future trivial. Maybe you'll invent a method of time-travel. Maybe you'll find the abstract network or another network in a neural network architecture, that is capable of solving almost any problem, once formatted in a way that you invented. Maybe you'll invent a math function that makes finding calculation efficiencies trivial, thereby reducing the time to compute other complex problems. There are many routes to the network of concepts & meaning, and if you're smart enough to read about my invention, you have potential to find them. 

		- I think if you were a genius, you would seek out challenges to your thinking, and you wouldn't feel pain at the thought of learning or challenging your mind, and you would be able to derive the answer to a question like 'how to automate problem-solving' without being given hints or reading the answer in my repo. Intelligence can be defined as 'ability to derive information (build understanding), given a minimum of information required to solve it (as opposed to a maximum of information, making the answer obvious, with an adjacent operation)'. It's similar to how if you are a good empathizer, you will be able to understand someone very different from you (or a system very different from other systems you've encountered) without being given the answer of what they're thinking (or how it works), after they explain what they're thinking or seeing it explained in some other communication, like on TV or in a conversation, and you'll be very good at predicting them (or predicting how an unknown different system works).

		- I think if you had the same experiences I've had, you would also have tried to automate problem-solving, and with the same brain as me, you would also have done it, although I'm not entirely sure you care as much as I do about the same priorities, and you might have used this invention for evil.

		- This tool is not problems, concepts, attributes, language, & information - it's a way to automate deriving a solution for a problem (automating the trajectory from problem definition, to solution objects like meaning, cause, & insights), which to my knowledge doesnt exist, as statistics/attribute graphs/machine learning cant currently solve problems without a severe amount of specific information, computation, configuration in the form of manual (flawed) selection of algorithms, manual & isolated analysis of attributes like intent & concepts instead of automated & integrated analysis, limitations built in the assumptions/perspective of the configurer, testing in the form of parameter tuning, strategy injection like trial & error, & other forms of human intervention - and can only solve isolated specific problems of specific types with information formatted in a specific way, without cross-system understanding or system context built-in.

		- people had decades and didnt identify even one of my insights to automate problem-solving & can't come up with a new method to do so whenever they want like I can, let alone the fact that 'filters, symmetries, standards, perspectives, bases, etc' all had something in common, or identifying all the primary interfaces on which any problem could be solved - partially because their ego prohibited them from thinking about how to automate themselves, partially because I'm the best in the world at this type of thinking

		10.a. isn't machine learning the automation of problem-solving?

			- When there is a machine-learning algorithm that can predict the unpredictable side effects/errors & meaning of its own application in a given system context (such as a particular civilization, in a given scope/scale, with particular parameters & information access), and correct its own parameters/information/other inputs to avoid any side effects/errors it predicted, it will have the potential to be AGI (an agent that can solve any problem with info access) - right now it's still a prediction tool that is heavily dependent on data & human intervention (human configuration, activation, selection, application, testing, monitoring, updating, correcting, interpretation).

			- The primary dependencies of my tool are a set of definitions (like what an object/attribute/function/interface/concept is), a set of functions to implement interface standards (like structure/cause) & interface operations (like identification/traversal/combination), and info access. The expected input from a human using my tool is a problem statement & a data set or internet connection.

				- However, some functions in the tool can be generated with machine-learning if the function definition isnt available or needs to be generated, and if none of the other function-derivation methods are available (unlikely unless the pattern interface or an equivalent is accessible), by identifying sub-functions likely to be in a function with a particular intent, sub-function sequence likely to generate a function intent, core function combinations likely to generate the sub-functions necessary for a function with a particular intent, variables likely to be changed for a function with a particular intent, side effects likely to occur with a particular sub-function structure (sequence/tree), etc - which I pointed out several years ago with my posts about code queries to search for functionality using function metadata indexing (including metadata like intent), which was followed by big tech companies attempting to build it.

				- It must be said that one of my problem-solving workflows is particularly suited to automating functions, such as by applying limits as filters (like a sculpture) until the resulting structure fulfills an intent.

			- I struggle to believe that no one else would have thought of a 'method to update the weights of variables & their interactions & versions after checking if the previous weights were accurate' which is the core structure that machine-learning is based on, so machine-learning shouldn't be seen as an esoteric invention that is out of reach of most people's brains, but rather a default invention that most people would have thought of if they had basic math understanding/education & tried to solve the problem of automating 'finding a prediction function' in a way that didn't involve regression or other known methods & scaled to high-dimensional spaces.

			- I also struggle to believe that someone would have thought of my invention, given how many hundreds of millions of people had the info necessary to come up with it but didn't, though it would be nice if I was living in a world full of other geniuses, it's just hard to believe given the information that people keep proving. If most people tried to automate problem-solving, they would come up with a solution that adjacently used existing technologies, like 'apply machine learning whenever you dont know something' or 'store solutions in a rules/solutions database', because those are easy solutions and people generally come up with easy solutions.

		10.b. aren't you scared of all the people who are mad that you came up with this?

			- First of all, the best way to understand the human interface is to understand that it's based on the crazy interface, which is generated by the structural interface (bio system, evolution, physics, etc). If you assume that everyone is a psychopath, you'll not only be a lot happier, you'll also survive all their attempts to kill you for being happier than them.

			- Second, you have to understand that this interface base & combination produces some particularly crazy basic needs for humans (such as intents like 'being right', 'being liked', 'being smart', 'being unique', 'being important', etc) which fulfill the functions of the ego, which can motivate people to get resources (get resources to feel right/liked/smart). There are other ways to self-motivate than avoiding costs/moving toward resources to fulfill those intents - ways such as deriving logic to help other people get resources. If you want to be superhuman, you need to not need these things - and if you love yourself enough, you will not need them & will outgrow the human interface.

			- Third, the best way to handle having too much power is to distribute it, which is one of the reasons I post anything publicly at all - I can teach people how to think if they're lacking, and they will not need to copy or otherwise attack me, because they'll be able to solve their own problems.

				- The best way to handle having a particular power from a unique contribution like problem-solving automation is to share how you came up with it, and let them figure out that they could have done so as well, if they had the same information, intents, & other attributes like perserverance as you, all of which is theoretically possible, with our current understanding of free will & physics. I could use my power to push everyone into their default psychopathy, but why not give them the option of pushes toward becoming independent, in case they want to grow?

			- Fourth, I have other problems to solve like time dynamics & universe manipulation, & more to contribute like implementation strategies & new interfaces, and I have made that clear enough that people who attack me seem to have achieved a dim awareness of it, so they have extra reasons not to attack me.

			- Fifth, I enjoy watching people try to take credit for my inventions even while it is tragic, because an intelligent mind can see the humor in the absence of meaning, and it reminds me that I have a lot of people (who might not be what they seem) to help, who can give my life meaning if I find a way to love them, even if they appear to be trying to prevent me from doing so, though an intelligent mind can also consider the possibility that everything is an illusion.

			- Sixth, fear is a boring way to live, even if it did give me an extra reason to become good at predicting the behavior of complex systems, as if I needed more.

			- Lastly, a good tactic when you're not finding meaning elsewhere is to question everything - Im capable of coming up with alternate explanations, so I can conceive of a universe where what appears to be real isn't the whole story. Maybe people are ego monsters created by physics, but maybe there are adjacent conditions for independence I can find to set them free - or maybe the agent who configured this universe is asking us for help optimization its parameters - or maybe there is another universe searching for potential that is using them as a portal, and I need to help that universe find it in themselves - or maybe this universe is used as a method of calculating what information (such as universe position) a life form can derive - or this universe is where space-times get stuck sometimes when they stop holding a level of potential change - or this universe is about to be a hub universe where other universes interact, and if someone maintains the potential here to avoid pre-determination, it can become that.


	11. is this too abstract to be useful? how would you implement this?

		- the fact that we can imagine what a concept is means it can have structure, & interfaces act like standardizing filters:
		  while they are abstract terms, they have intrinsic physical attributes & map to structures even when they are abstract enough to have few physical attributes

		- the docs for some implementation strategies are here:
			https://github.com/outdreamer/build-a-cure/blob/master/docs/core_analysis/derivation_methods.md
			https://github.com/outdreamer/build-a-cure/blob/master/docs/workflow/problem_solving_matching.md

		- most of my implementation strategies vary on:

			- the starting point of the analysis (which interface the query starts from)
			- the structures relevant (which structures or type of graphing method to use)
			- the intent (create a prediction function, reduce solution space, compare solutions, or match problem with solution)
			- the core abstract function represented (is it a find method, an apply method, a combination)
			- the models used (object model, interface query)

		- but they have in common:
			- using core objects & patterns
			- using info objects like problems/incentives/sub-systems/efficiencies & definitions & concepts like probability/relevance to create defined structures like prediction functions
			- applying structure to unstructured information


	12. can this really be used to automate math insights? that requires complex thought that cant be automated.

		- whoever told you that is full of

			Lattice multiplication method automation
				- https://github.com/outdreamer/build-a-cure/tree/master/docs/specific_problem_analysis/multiplication.md

			Integration method automation
				- https://github.com/outdreamer/build-a-cure/tree/master/docs/objects/problem_space.svg

			Eigenvector/eigenvalue relationship derivation automation
				- https://twitter.com/alienbot123/status/1154930391012167680
				- https://github.com/outdreamer/build-a-cure/tree/master/docs/specific_problem_analysis/automate_math_proof_example.md

			Set generation automation
				- using a similar method as this example of attribute/function combination, generate all possible sets:
				  https://twitter.com/alienbot123/status/1245950414278627328
				  <img src="https://github.com/outdreamer/build-a-cure/tree/master/docs/specific_problem_analysis/predict_pathogen_species.png" />

			- more evidence of damnation - come get your poison:

				- Problem solving automation workflow identifying structure implementing the concept of randomness, which can be used to generate functions with conceptual properties like high ratio of 'calculatability of answer' to 'verification of answer' (which can also be used to identify structure as an interface that can capture non-structured information like concepts)
					https://github.com/outdreamer/build-a-cure/tree/master/docs/workflow/problem_solving_matching.md

				- Linking relevant concepts to randomness such as average and balance/equality using definition routes as a method of identifying a probability distribution with randomness built-in (distribution with equal probability distributed across outcomes, or alternatively a distribution where each outcome has the same averaged probability value)

				- Generating the symmetry concept as a combination of objects/attributes/functions like 'reversible changes without losing information', using core component combination analysis
					https://github.com/outdreamer/build-a-cure/tree/master/find_existing_solutions/system_analysis/core_analysis.py

				- Identifying bases & other structures as an origin of a prediction function, rather than data sets alone, as alternate routes to a prediction function
					https://github.com/outdreamer/build-a-cure/tree/master/docs/tasks/problem_workflow_example.md

				- generate a function with certain attributes using net intent of structural component operations

					- to generate a function with ambiguity in input/output relationships (as in multiple inputs produce the same output), introduce an exponent in the dependent variable (like how x^2 + y^2 removes the concept of 'uniqueness' from the input/output relationship, given how exponents use repetition of the same base (x as a base, multiplied by itself), and using how combining different types of repetition can remove 'uniqueness' from the input/output relationship, and using how different pairs of inputs can generate the same outputs with a squaring operation (making squaring the unit operation to fulfills intents like "generate the 'ambiguity' attribute" or "remove the 'uniqueness' attribute")

				- kernel trick: 

					- the intent is to 'differentiate shapes on a graph with a straight line' (shapes indicating clusters belonging to different data categories)
					
					- in its standard definition routes, 'differentiating' can take the form of:
						- 'maximizing difference'
						- 'isolating difference'
						- 'producing difference'
					
					- 'maximizing difference' can take the form of 'adding a difference' rather than 'maximizing an existing difference'
					
					- if there is a difference, but it's not defined by a straight line, the difference boundary can be used to indicate a group of data that should have a different added attribute value (like height) than the other points
					
					- 'adding a difference' between shapes can translate to the structures:
						- 'adding a dimension'
						- 'changing the difference definition'
						- 'adding a difference of an existing type (scalar in current dimension)'
					
					- now that you have a specific structure ('add a difference in the form of a dimension') to achieve this general intent ('differentiate shapes'), apply that structure to the problem:
				      
				      - structural intent: find a function that maximizes differences between shapes on a graph
				        
				        - find the differentiating boundary on the current graph if there is one

					        1. identify a function that would create different values on either side of the boundary (minimizing values on one side, maximizing values on the other side)
					          - example: 
					          	- functions like x^2 have low outputs for low inputs and proportionately higher outputs for slightly higher inputs, so if you align the boundary with the position where the input/output proportion changes, you'll align low inputs with low outputs and slightly higher inputs with high outputs
					          	- 'aligning low inputs' means arranging the axes so the low axis values near zero overlap with the shape positions that should have low outputs
					          		- so 'alignment' here consists of centering/shifting the axes so that:
					          			- low/high values occur in the right positions
					          			- the difference where low outputs change into high outputs aligns with the differentiating boundary
					       
					       	2. alternatively, find the direction of change (from one shape to another) that could be mapped to a direction of growth in a function
					        	- 'direction of change' = 'outward from center of shape', so growth in value (from zero up) should align with the outward direction (align origin with center of shape)
					        		- <img src="https://en.wikipedia.org/wiki/Kernel_method#/media/File:Kernel_trick_idea.svg"/>
					        
					        3. alternatively, identify that the shape-differentiating boundary is the important object, and that this boundary should also be the separator in low/high outputs from whatever function is chosen
					        
					        - 1, 2, & 3 are just different starting points/formats of the same trajectory ('aligning inputs/outputs across differentiating boundary', 'differentiating outputs for different group inputs', 'align direction of group change with direction of increasing change')

					      - then apply this differentiating function to add a dimension of change
					      - then test if the new low outputs & relatively higher inputs are different enough to clearly separate them with a line (the unit separator)
					      - if not, try another function to maximize differences in outputs between shapes, with other structures that definitions (like 'adding a difference' or 'maximizing difference') can map to

					    - if there isnt a differentiating boundary, find a differentiating attribute between data groups, such as numbers that are square roots/primes/integers
					    	- then apply the same procedure as above, to find a function that differentiates numbers with that attribute from numbers without it

					- so from the origin intent 'differentiate shapes', we:

						- pulled definitions relevant to that intent
						
						- iterated through definitions
						
						- applied definitions to a system to get their structure in that system (answering the question, "what form would 'maximize difference' take in the graph system"), with answers like ('add a change type' and 'maximize change')
						
						- applying the structures retrieved by that definition application to the system (apply 'add a change type' by pulling types of change, iterating & applying them) in a way that aligns with origin intent

							- apply 'add a change type' (specifically a dimension of change) in a way that aligns with intent 'differentiating shapes'

								- this application involves first pulling core or important change types in this system:
									- change type 'input difference', in group membership
									- change type 'output difference', across inputs of different types
									- change type 'output difference thresshold', where outputs begin to change from one change type (linear, like 1^2 = 1) to another (quadratic, like 2^2 = 4)
									- change type 'attribute difference', in attributes of a data point
									- change type 'value difference', in various values of an attribute across different data points

								- then mapping these as inputs generating the group differences, which have their own input/output relationship already defined (input data::output group label)

								- formatting/arranging the change types in a structure that generates the group difference implies a function linking inputs & outputs, across the difference trajectory:
									
									- origin group A: origin group B difference
									
									- origin position attribute similarity (low values of A are similar to low values of B)
									
									- target position attribute difference (low values of A are different from low values of B)
										- meaning converted low values of A are lower/higher than converted low values of B
									
										- to get a difference in an attribute (like position), you can apply a conversion to maximize differences within that attribute, or add an attribute that offers another type of position difference, so that the attribute as defined in another space/system (3-d as opposed to 2-d) is differentiated
									
								- the origin position attribute similarity can be converted into the target position attribute difference with a function:

									- if there is a similarity between the threshold structure within a function output, and the threshold structure differentiating groups, that could make the input-output relationship generating function align with the overall 'differentiating shapes' intent

										- inject a similarity in that position, taking advantage of the existing similarity in structures (output threshold & group boundary both being examples of the 'differentiating limit' structure), by aligning group membership and threshold side

									- now you can search for a function that would align inputs/outputs across this threshold, starting your search with functions having an attribute of volatility (similar inputs produce very different outputs)

										- with the restrictions that:

											- it should have one major change in output change type, like x^2 has one major change from semi-linear to very nonlinear change
											- this major change should occur at relatively low values, for standardization & the fact that there isnt much room in the center shape for growth types

										- other functions maximizing difference would include a wave where adjacent inputs produce positive/negative values, but that implies other groups or alternating groups beyond the two categories


						- you have various starting points to automate finding the solution:

							- find the structure missing the solution first (derive solution structure, then fill it in with a solution)
								- find the structure of the input/output relationship that needs to occur
								- then fill it in with a function producing that input/output relationship

							- combine solution components first & apply limits/tests/filters to check if it matches solution metrics (build & refine solution)
								- find functions likely to produce difference across inputs
								- then check if they produce the right difference, and refine it (by centering/scaling) until it matches the difference you need

							- this solution is an example implementation of the structure-intent interface combination, with a specific implementation of the 'change' interface within that interface combination


						- this method can be generalized to a method of finding functions for an intent like 'reduce computation' or 'differentiate with a line'


	13. what is an interface - is it the same as a software interface?

		- glad you asked just so I could say this fun answer which is fun bc its true & so obvious:
			- no! 
				- a software interface refers to:
					- an abstract template defining a list of functions/attributes that should be implemented in order to qualify as a member of a class
					- a visual graphic interface allowing the user to interact with the software
					- an application programming interface allowing software programs to exchange info that makes sense to another program
				- in those contexts, an interface acts like a 'type', 'structure', or 'language', and is not sufficiently similar to my definition of the primary interfaces in my invention, which is:
					- 'a standardizing filter based on an abstract concept that acts as a base supporting many change types, which can be used to solve any problem'
					- where other non-primary interfaces act like 'high-variation change bases'.
				- it has some structures in common in that 'a software interface applies a structure, standard, language, protocol, or optimization rules to connect things like software programs/users' but ultimately:
					- an 'API' (application programming interface) is (rather than its lofty definition of a 'standard allowing software to talk to each other') just a list of public functions in real life
					- a 'user interface' is not so much a 'way for users to talk to software programs in a common visual language' but a 'set of buttons & forms that change data in a database' in real life
					- a 'class interface' is not so much a 'guiding structure for how classes relate to each other' but a 'list of functions/attributes of a software object' in real life
				- whereas, for comparison, an 'interface' in my invention is not so much a 'list of structures related to a concept' but a 'structure that enables solving all problems' (all problems can be formatted as queries on the cause interface, the intent interface, the logic interface, etc).

		- the interface (a standardizing filter) contains the following:
			- the definition of the concept 
				(the definition of 'cause' for the causal interface)
			- the filter or conversion function to isolate attributes relevant to that interface 
				(causal filter would isolate dependencies on other networks)
			- the set of core objects, attributes, & functions that generate them on the interface, organized as a network
				(causal core functions like 'create' or 'change', and core objects like 'causal network')
		
		- 'standardizing an object to the causal interface' means 'mapping how that object occupies or interacts with the network of core causal objects/attributes/functions' - this formats the object as a 'query of those core items'.


	14. what is a problem space

		- its the space where youd graph all the info relevant to a problem - the context allowing a problem to exist
		- I often use tech as a key determinant of a problem space bc which tech you have often determines which available resources like strategies you can use, but it includes all the other resources you might have access to (info, potential, energy, physical assets, etc).


	15. why improve problem-solving at all?

		- the problems with current solution methods:

			- solutions that are slow to implement, static, not shared, not organized, not generalized, & include repeated work
			- solutions often dont use prior knowledge (insights/patterns) to inform new solutions
			- known/discoverable systems with known/discoverable rules are treated as unknowns
			- errors are found with common known or easily derived rules ("change/remove assumptions") or causes ("misaligned attributes")
			- problems of the same type persist across systems
			- problems can be standardized to info/structural problems, which have associated solutions, and can be used as building blocks of solutions
			- work devoted to repeating a solution could be work devoted to innovating problem-solving
			- problem-solving isnt automated
		
		- current methods are focused heavily on information - if people become too focused on information (what is true at a given time), they'll never change again & time will end,
			they'll just calculate everything from the point that they find a way to do so

			- instead of focusing on information as the priority, they need to focus on preserving variance potential, so there are still questions to answer

			- outrunning the onset of the information calculation singularity involves:

				- creating self-sustaining variance sources & protecting existing ones (maintaining ambiguity/alternative options)
				- automating what can be & also automating the update of automation tools
				- evaluating information on the basis of change/potential
				- analyzing reason/cause rather than information
				- this means avoiding optimizing everything
				- there should always be at least two comparable alternatives so a decision is difficult & not certain
					- at least two systems, at least two perspectives, at least two metrics, at least two intents, etc - the ark requires differentiation to sustain potential


	16. what do you mean by 'using potential as a base rather than time'

		- time as a base for assessing change is useful in solving information problems
		- time occurs when there are no symmetries allowing for reversibility - in order for something to be reversible, symmetries have to align to allow for efficient organization of energy flow so a system can form to be a platform for the change
		- potential is the ability to change, time is the realization of change
		- im using potential as a proxy for the time variable, just like using the derivative rather than the function
		- potential is an important input of time - if there is potential for change, time can occur 
		- focusing on time over-focuses on information, which is the result of a measurement, and measurements have unintended side effects like over-dependence on the measurement
		- potential also captures a lot of potential information:
			- whether something is about to happen (whether a function is about to change)
			- whether something is possible or unverifiably possible
			- whether something deviates from or complies with known patterns (whether it's likely to be new or not)
			- how similar something is to output of known generators (adjacence to functions as a analytical metric, rather than the prediction function itself)
			- possibilities & ambiguities (where information is lost like in a black hole or uncalculatable like where there are too many alternatives) 
		- evaluating change with respect to potential measures whether you're increasing the number of possibilities (enabling information to occur as time passes) or decreasing them
		- if you make a decision that closes too many doors, potential, change, & time will be permanently lost, if the door goes with it (if it's irreversible)
		- other types of time are useful to evaluate change 
			- whether youve changed in conceptual time, causal time, potential time, or information time, & whether the change is absolute/specific - did you change everyone's time or just yours?
			- these metrics differ in how other types of time pass
		- rather than asking 'is this resource needed at a given location' - we can ask questions like 'did we enable people in that location to solve a resource deficit?'


	17. what is the actual workflow to use this?

		- the general program steps include the following:

			1. check pre-existing output of the program (pattern indexes, concept definitions, etc) to see if it can be used as an input filter for a new problem (the system filters below are some of the outputs of this program) to break the problem into solved problems

			2. if it isn't composable with solved problems, but the problem type is still identifiable, then select a solution strategy & starting point

			3. then select threshold metrics to switch between strategies 

			4. then execute the solution strategies, checking at various threshold points for problem-solution match

			5. if no match found for one strategy, switch to other strategies

			6. if no matches found across all strategies, switch to uncertainty description patterns & methods

			7. output either insights found, problem-solution match, or uncertainties that need to be resolved (gather more data, answer this question, etc)

			8. store any info objects found that arent already in indexes (insights, patterns, problem-solution matches, interfaces, functions)


	18. how come youre the only person who identified that automating problem-solving was even possible, let alone the only person who came up with a method to do it in all of human history?

		- I decided to try to automate problem-solving once I saw patterns in the rules people used to solve problems, and once I found an example proof of concept, I pursued it. Alternatively, if you don't have human thoughts like that, or if you don't have human sources of joy/motivation, such as caring about protecting good people enough to try, or intellectual curiousity, or believing in yourself, you can try some caffeine.

		- I discovered concepts first in books & movies, then insights linking them while building the abstract network for my book in 2008, then I identified interfaces as useful objects to frame other objects on, given their patterns of change.

		- I first realized the fundamental object of insight paths when I realized people used methods to solve problems, which I realized at college. The probability problems I examined were framed in a way with patterns in the missing information, and the method to retrieve or generate it.

		- Here's an example of why insight paths are useful:
			- you could try to spot a liar by checking every fact, which is an implementation of the method of trial & error, and is very fragile given its dependence on data.
			- or you could try to spot a liar by checking the output of people's choices, given the intended output (output like reactions) and figuring out why they might want that output (to see what they can get away with to check their social status, etc) - a method based on understanding that is relatively independent of data.
			- the insight paths there are:
				- trial & error
				- look up information
				- intent-derivation method, given actual & intended outputs of a decision
			- the intent-derivation method is clearly more robust & accurate
			- another insight path involves identifying those robust insight paths: how would you identify the insights that are more powerful than others?
				- this insight path involves identifying the important objects on the relevant structures (like object interaction layers, such as the layer where objects like intent/patterns/rules/decisions interact) determining a problem of differentiating a lie from a fact, given that people lie for a reason, and the reason/intent is an important object determining the variation in the lie object
				- once you've identified that intent is the important object to the lie differentiation problem, you can build an insight path to detect intent from actual/intended outputs of the decision (the insight path above, the 'intent-derivation' method)
			- then even without knowing the intent-derivation method, you could derive it by doing queries on that structure for the important objects, and determine those objects' relationships relevant to the lie-differentiating problem - and youd have a good method of solving the problem, that was more efficient & accurate than standard methods, with just a general problem-solving insight path, in the form of a structural query (like 'find relevant objects in this structure').

		- dimensions: thinking about other dimensions was what led to identifying perspectives as important, after which I realized perspectives were like filters

		- interfaces: the term 'application programming interface' made me focus a little more than average on the term 'interface' (given its abstraction), which I initially stored in my head as a 'way/place for two different programs to communicate, like a language, applying a standardizing transform'. Eventually I realized that these interfaces were similar in function to filters.

			- I realized certain interfaces also acted like foundations where types of change developed (cause, potential, information, structure interfaces), and that some types of change were not only explanatory across all systems but were inherently related (structures like balance & abstractions like equality).

		- math-language map: I think about unit cases often, so I realized the standard operation of division was like applying the lower number as a standardizing transform on the upper number. Once I realized that division was a standardizing operation, I realized it had similarities to interfaces, which are more indexable as a semantic (linguistic) object than a structural one. I explored the concept of meaning in relation to these objects, and arrived at a structural definition of meaning: 

			- the 'meaning' of an object included the structures of that object in a relevant system, possibly aligning across multiple related systems
				
				- like how the answer to the question 'yes this fact is true, but what does it mean' is asking 'how does this fact fit into a system of related facts, and what impact does that have on other systems like cause/logic/change/potential'?
				
				- or specifically 'yes they had a kilo of cocaine, but what does that mean?' which in the absence of system context (fit of the fact into a system) is meaningless, but once you add other information like whether they were aware they were transporting it, it begins to have meaning. Once you add information about cause (responsibility/uniqueness/inevitability) of their decisions (is this a decision commonly produced by society/laws/incentives, did they work hard to get to a place where they could make this decision, did they have other options, and was it a decision at all), and objects on other interfaces (like 'does this align with the concept of fairness'), the original fact has additional meaning. The structure of an aligning slice of these systems may look like a street signpost in its most basic form.

				- another example would be debating the granular isolated/context-less question of "if a person who sends ransomware is completely evil", or whether (once you fit that fact into a system context) the meaning of their decision across systems is that "their structures of lack driving their decisions are completely evil". this is another example of how some systems (like intent & structure) are inherently related: some intents are only malicious in a particular system context, and some structures are only negative when used for a particular malicious intent.

				- the 'meaning' in my system is the interface query output, where the query is the meaning generator.

				- I realized this fatal disadvantage of isolated information when I started examining statistics, which frames variable relationships based on a snapshot of a set of variables, without really digging into what a variable is (a change type), how they develop & aggregate into other variables (like types & concepts), whether patterns of change across variable types/networks could be used to strengthen prediction functions against bias, where/how randomness develops in complex systems, whether bases/subsets were better structures to begin analysis from than averages, the causal structures like position of the variables, and other fundamental questions that seemed to be ignored from the statistical perspective.

				- you can frame this tool (or its network of interfaces, as a meaning interface) as meaning detection/generation automation.

				- meaning can take several forms in different systems:
					
					- the fit of an object in a system (position/structure)
						- the fit of an object in a particular system like the interface system (which relevant objects align across the interface systems)
					
					- the relevant structuress of an object:
						- a subset of the context, including related objects that are important for understanding, like a good explanation has
						- its most reduced form, like a rule that can generate the info you need to remember

					- the structures of importance (one attribute of a definition of meaning), like equivalence (similarity, balance) & power (hubs, inputs, catalysts)

				- the meaning is the answer to the question of 'why is this important or relevant', where other interfaces answer questions like 'why' (intent), 'how' (structure), 'when' (cause), 'where' (in what system context), and 'whether' (potential).

				- meaning can help you identify answers to questions like 'what is the important object' or 'what is the better priority', such as:
					
					- question: "what concept is explanatory or prioritized in society" (specifically the question "is society about truth or teamwork?" for a person raised by wolves trying to understand society quickly to survive)
						
						- how would you derive the answer "teamwork is a good default, except when the team succumbs to negative group dynamics, at which point individuals/other teams external to the group need to be in position to criticize it", given the thousands of objects that could explain the function of 'optimizing society'
						
						- there are many interface traversals to gather output to derive the answer:

							- insight: 
								- 'over-focus on facts makes arguments & potential restrictive', 'teamwork is good for risk distribution for robust populations'
								- 'given that information is necessarily existing in the past according to the observer, and that information doesnt exist according to an observer outside the space-time, does this apply to the information system of math - is there information forming or possible information that can be captured by future number types which are gathering, where existing math is the observer looking backward'
							
							- system: 
								- 'teamwork has built-in incentive alignment with whats best for other people'
							
							- interface: 
								- 'truth is one interface, but teamwork is applicable across many'
							
							- function: 
								- 'teamwork is an important concept by default because it is related to a core function type, which is interaction functions'
							
							- concept-structure: 
								- 'teamwork as a structurized concept is based on the core structures of checking if other team members have what they need to benefit the team & maintain the team advantage, which is based on the concept of balance'
								- 'teamwork involves a network subset with aligned incentives'
							
							- concept
								- 'truth is related to the concept of state'
								- 'teamwork involves the concept of a group'
								- 'facts are ignored by many groups which find their trade loops more efficient without that information - the concept of a cult'
							
							- pattern: 
								- 'patterns of state changes are often more useful for their predictive power than state information'
							
							- meaning:
								- the information from the other interface traversals can help build the meaning of the priority ranking relationship between these two concepts:
									- 'facts dont mean anything to a group unless they help the group'
									- 'teams that dont assimilate the important facts quickly enough may become irrelevant enough to seem false or not real to other groups'
									- 'if an observer sees a group problem, they can save the group, and they have an incentive to, if the group is beneficial to other groups'

								- this is the meaning bc its the structure relevant to the initial concern, which was the question asked
						
						- now the observer can quickly figure out what to prioritize, rather than waiting for someone to explain it to them

							- vertices:
								- determinative/generative/power: does truth determine teamwork or the other way around?
								- differentiating: what is truth that teamwork is not and vice versa?

							- vertices like generative/hub/differentiating variables can shorten the distance from lack of understanding to understanding, similar to the insight paths associated with the vertices

						- other examples of high-value use cases (other than identifying important concepts):

							- identifying the important base to frame changes on (identifying new interfaces)
							- identifying the right interaction level to focus on (identifying the change-maximizing layer of a system to examine a particular relationship)
							- identifying the right perspective to filter with (like 'identifying whether the legal/scientific/progressive perspective is most useful for an intent')
							- identifying the right context/position for an object (derive context when it's missing or fit an object to a system)
							- identifying the most causative function set (like identifying core functions, or the most misused functionss, or the most change-causing functions)
							- identifying important differentiating types (like function types indexed by intent & structure types, like boundary/change functions)

		- this insight about isolated analysis converged with another insight about the isolation of optimizations, either in priority or other relevant structures to the concept of optimization

			- optimization metrics: another important insight was the realization that having one winning system or metric was itself a sub-optimal system in most cases; a 'win-based perspective' narrows the focus too much toward one set of optimal (definition, metric, etc) when theres usually a combination structure of optimals (multiple government types, rules, metrics).

				- example: capitalism produces tech debt between companies that need to copy each other to compete, which is sub-optimal for almost everyone bc it requires repeated work, so a free market allowing competition should be used in certain cases (fair fight between different perspectives on how to implement an important product idea) to get the benefits of that system (quick innovation)

		- detachment: another reason I'm successful at thinking is that I don't allow myself to be biased - that means not letting myself get attached to conclusions (assumption bias), not letting myself over-prioritize my own interpretations (self bias), not letting myself over-focus on work that is similar to mine (similarity bias), not letting myself avoid conclusions that are painful or which make me afraid (pain-avoidance bias), not letting myself over-use existing methods just because I already understand them (understanding bias), etc.

			- this detachment allowed me to examine the inefficiencies in current solutions from a systematic perspective - allowing me to see why some problems were solved at all (curiosity, boredom), why some were solved inefficiently (lack of resources/oversight/incentives), why some were solved by markets/science (high impact, high incentive to solve in the form of a profit opportunity), why some went unsolved (low impact, high complexity), why some problems were solved eventually but in a way that maximized work rather than automating the solution (to create jobs)

			- i also saw patterns in problems, patterns that seemed to be unaddressed with current solutions - like common error types (dependency/version mismatch) & security incidents (misaligned permissionss with intents) or unnecessary work (manual learning of correct parameters to use in an ml model, without understanding).

			- these patterns made me realize how structural these problems were, and I knew that structurable information was automatable. I applied abstract analysis to find the important objects in these spaces (like the objects 'expectations' or 'intentions' and the 'expectation-intention mismatch' for the security space).

			- I began to think more about information formats, and how to format information about a problem in a way that you could query for the solution. A default information object I knew about was an 'info asymmetry' (where info on one side could be used to generate/derive info on the other side, but not in reverse - an info-lossy relationship), which was related to an 'info imbalance', where one agent had an information advantage over other agents, like with insider trading, which I knew about from the news, for example like the Barclay's incident. I thought about how to solve an 'info imbalance' (by distributing the info, keeping it local, keeping it accessible only by people who wanted to execute approved tasks with that info, etc) and I realized these solutions were generatable.

			- Then the task became not 'how to format information to make solutions queryable' but 'how to translate a problem into a format where the solutions could be fit to the problem & tested for solution metric fulfillment'.

				- I realized problems were formattable as various shapes which came down to a set of vectors: arranging vectors as solution steps, for the problem formats of filling a shape, reducing a shape, matching a shape, or mapping a problem as a trajectory shape in a network shape - the structural interface being what I used to call the 'shape index'.

			- This was followed by the articulation of the invention of the interface network, followed by the question of 'which formats were better for which interfaces', followed by the idea of interface operations like applying one interface to another (applying structure interface to each interface, to generate core interface objects like causal networks), and then fitting analysis specific to each interface (like the difference between related objects on an interface, such as intent & priorities) to those structures, which I used to call the 'physics' of logic/information/truth, to refer to the set of rules specific to those interfaces.

		- intent: one of the reasons I identified intent as an important object was that I usually have multiple reasons for decisions, like a decision to post a quote could have multiple intents (to get criticized given the quote metadata like who it quoted, to draw attention to an insight, to inspire copying behavior to see who is watching, etc), so I realized intents were not only an abundant source of variation, but an object that could be derived for functions. Then I thought about how to map intents to core functions, and I realized you could map high-level function intents like retrieve data to operations on granular intents like check.

		- math automation: how did I realize that math insights were automatable? The first clues were that it had core functions, like other automatable systems - then another clue that certain operations had default intents associated (there were reasons to apply certain operations, similar to incentives), and the related system objects you'd expect to see were there (efficiencies, like adjacent transformations that made certain calculations quicker). It was also clear that if functions had attributes, these attributes were connected to structure & were therefore automatable, especially once I derived the insight path to produce the cryptocurrency invention, which is a structure with conceptual attributes like 'trustless'.

		- looking back, I think some objects were clues to this trajectory, which could be structures that you could use to generate this (mandela, detachment from the Bhagavad Gita, the psychic instrument from His Dark Materials, the signpost from the Phantom Tollbooth, the 'abstractions as islands' trope in fiction, the time-traveling trope in fiction or conflicts between the church & state alerting me to different perspectives) but I can't point to one structure that I focused on through the years except the abstract network that I used for my book, which I realized was real somewhere after thinking about how certain concepts seemed to have rules they followed, like how power seems to gather in certain places. I began to think of an abstract city where these concepts could change, in conceptual time, and thought about how they might change in their interactions if not their structure, since they didn't seem changeable in this dimension set, but instead seemed to cascade down to structural dimensions, like a form of light.

		- why did I wait until this year to patent it? Partly bc I was keeping some pieces of the invention private in case I got a pitch meeting, partly bc I was busy with work/health/thinking of new ideas in specific problem spaces, and partly bc of the 1-year limit on public disclosures of inventions in the current outdated legal framework, and partly bc I decided to figure out the mechanics/implementation of pieces of it later, once I arrived at & verified the initial proof of concept (later meaning once I got a pitch meeting).

		- Not everyone has a built-in reason to automate problem-solving (like if they don't have serious problems to solve relevant to them, like the well-being of good people), but once I realized automation of problem-solving was possible, that gave me extra drive to get there, so I didn't need other reasons past that point, though luckily I had them just in case.


	19. isn't this just data viz?

		Oh dear! You've drastically misunderstood my diagrams! I clearly need to attach a legend of some sort, if insecure stupid people who try to defeat me are looking at them! They are not just a set of shapes like lines or just network diagrams with no meaning other than 'lines connecting similar stuff' - when I contain information or objects in a circle structure in a diagram, for example, it may mean that a function (like the apply(structure='container') or apply(structure='combination') or apply(structure='boundary') function) has been applied to whatever is inside the circle, to organize the information in a meaningful way (like examples of a type, or sub-functions building a circle function, or a representation of a processing functions applied from one end of the circle gathering inputs to produce outputs on the other end). 

		The point of these diagrams is sometimes to illustrate an example of a concept, but other times it's to create logic in structure that can be used to generate code - like with the interface query diagrams, where I'm using shapes to show how the queries are organized, and how they can be combined, for example, as sub-solution sets to form solutions to problems addressed by the interface query. The organization (structure application) of those interface queries is an important part of the logic of my intellectual property that specifically allows automation of problem-solving. These aren't just 'pictures containing similar stuff' - they're structurized logic connecting problem & solution structures.

		Although I admit, it's certainly tempting to try to reduce this to data visualization, just because it's a picture and it has information (aka data), like all other pictures - and it's clearly upsetting to acknowledge that I found a way to automate problem-solving and you didn't. Try to remember that I did this for poor people and not to upset you, although I enjoy the thought of upsetting boring evil people who thought being just evil was cool even though it's being 'slightly evil in cool funny harmless/educational ways and being good when it matters and also being wildly brilliant' that is cool (just me apparently). Why dont you try being cool for once, and just laugh at your ego & move on, or solve a problem to help the poor (oh no! a minimal amount of work!)?

		Wanna know how I know what you're going to say before you say it? Are you sure? You seem mad enough already! Ok, very well - I just check for the easy cruel false thing to say about me or my work, and then I wait, and then you say it, and by that time I have a new witty response ready that totally owns the easy cruel false thing that you always want to say! How do I justify staying alive when I'm surrounded by zombies who just do easy cruel things all day? Well, unlike you "animals", I have other interfaces that I can host my operations on, so when information for example fails to support a priority, I can fall back on other interfaces like logic, while I wait for an opportunity to support my priority using information again. 

		Wanna know why you like trying to reduce my work to nothing? Because people use information processing as an easy way to get rewards like dopamine (easier than using physical movement or learning to get rewards, which is also why they like drugs such as meth), by choosing to humor thoughts that feel good, rather than earning good feelings by investing more work in things like exercising/learning, and this process repeated many times creates a retarded brain that can't achieve self-awareness or learn. Those type of easy cruel false thoughts are like junk food for your brain - you'll never become smart or ethical or have potential if you keep humoring those thoughts every time. Wanna know why you feel bad whenever a competitor who looks different from you succeeds and feel good whenever a competitor who looks similar to you succeeds? It's bc of bias toward easier lower-cost methods like information (which is easily faked) vs. evolution (learning/movement), and also bc of the local (selfish) bias causing other specific local biases like racism, and bc your brain likes information that feels like your own successes but is easier to get the reward for (watching someone else succeed), and your brain equates similarity with equivalence (similar looking people are equivalent to you). It's the same process at work when you think that wearing or saying something will make you feel like you changed your identity in some way - putting on clothing is easier than working hard, and gives your brain the false information that you yourself have changed, bc your brain is not too smart and thinks similar structures are equivalent. It's also the same process at work behind much of group dynamics, where you try to use your group membership to bear your costs and try to get rewards from that group membership, and form the group membership in the first place bc of the local selfish bias rewarding you for seeking similarity rather than difference. It's also the same process behind projecting as well - saying all of your own thoughts & problems are those of your superiors, and all of their accomplishments & positive qualities are yours, thereby getting the easy cruel false reward of distributing your negatives/costs to other people so they have to bear your burdens for you (they don't have to bear your burdens for you) - this uses the relatively cheap method of information costs/benefits as opposed to higher-cost physical movement or learning-based costs/benefits to get rewards, specifically info methods like 'belief' or 'repetition', which again is an easy cruel false way to get rewards with less work as opposed to more optimal methods (learning-based method of getting rewards, like solving the problems of cost-minization or benefit-maximization for yourself & sharing the solution). One important point to note is if you choose the learning-based method, the application & improvement of the method itself is the reward, and solutions & any resulting good feelings are the side effect. Wanna know why you feel schadenfreude when you see a sufficiently different stranger fail? Its the same bias toward easy cruel false (illegitimate, given your lack of superiority) judgment, giving rewards like dopamine using easy cruel false pathways like pretending you would have done something differently to avoid their mistakes, to avoid exercising your empathy pathway, which is harder work than using the easy cruel false judgment pathway, and often doesnt involve easy rewards unless you find problem-solving to help other people easy & rewarding. You also feel schadenfreude bc youre focusing on people who are better than you, and you like seeing your superiors fail at something, even if it's minor, bc any inequality (even earned inequalities) feels wrong to people who don't want to accept that they have responsibility to earn their way through the world with work, and want to believe everyone is equal no matter what their decisions are, bc that belief implies they'll get rewards easier without the decision to work at earning rewards.

		If you want to become smart, start by not allowing yourself to indulge in all of these biases towards easy rewards that you've built up (or inherited, if you come from an ancient line of crack addicts), attacking one bias at a time, until you get over the 'exercise threshold' where it stops being painful to learn things - at which point you can choose where to host your pain, and if you're really smart, you'll choose to connect your pain with the suffering of innocent or otherwise decent people.

		- 'other people have applied physics, neuroscience, & other sciences to ml before, someone would have thought of this eventually', you claim, wildly looking around for signs of people nodding in agreement
			- yes, other people can read, but that doesnt mean they would have thought of abstracting their workflow of 'look up science concepts we havent tried before and apply them manually to the ml problem space in a way that might be useful & then check if it improves anything' (which is actually just an application of 'trial & error') or that they would have come up with a consistent, useful, effective way to abstract & automate their workflow (and all other problem-solving workflows), and tried to automate themselves, bc of their enormously unjustified egos preventing them from recognizing that their work could be automated

			- people had decades and didnt identify even one of my insights to automate problem-solving & can't come up with a new method to do so whenever they want like I can, let alone the fact that 'filters, symmetries, standards, perspectives, bases, etc' all had something in common, or noticing that there were useful structures like general functions (find/apply/build/derive/mean) that were interchangeable, or identifying all the primary interfaces on which any problem could be solved - partially because their ego prohibited them from thinking about how to automate themselves, partially because I'm the best in the world at this type of thinking
		

	20. is this just content generation, which already exists in various algorithms to generate content like a sentence?

		Nope! This is not a pathetic invention, such as a content generation algorithm, which can only do something like change a variable value & combine it with other variable values, in a variable template like 'first variable1, then variable2'! I'm not even sure how someone could possibly confuse my invention for anything remotely similar to that, to be honest - I think I may have gotten people's hopes up that I didn't invent anything new by occasionally using words in the English language like 'variable', and people use keyword-matching as a way to identify false similarities, which is not a smart method because the sentence "'balance' is a word" and the sentence "balance is a conceptual structure that can be applied across systems as a way to query for related concepts like 'justice' or 'equality' or other structures like 'alignment' or used in functions like 'matching' to assess attributes like 'similarity'" would return as results for a 'balance' search but there are clearly a few differences between those sentences, if you're brave enough to confront an unpleasant truth by noticing that. I'm also starting to think I need to check if you have read my definition of 'interface' because your next question is probably 'is this a search UI interface that runs a database query when you click submit' (no wtf) and 'is this a way to check similarity between things, like similar type' (also no, and also, do you have a mental challenge you can help yourself with by reading books on how to become smart or even just practicing basic mental functions like imagination?).


	21. is this just a rules database or a solution database?
		- this invention has some requirements, like the code of the apply(), find(), generate(), derive() functions, and the definition routes of interfaces structures like the concept of 'truth'
		- it does not otherwise require a rule/solution database, but it can generate/use one as a source of default information about initial, standard, base, sub-optimal or specific solutions/errors or solutions/errors with other attributes
		- it is most certainly not equal to a rule/solution database, which you could reduce all code to (any code could technically be seen as a 'function/solution/rule database/table/record')
		- my invention is a way to automatically find/apply/derive/mean/generate solutions, using useful structures like standard formats of problems/solutions & connection functions to connect a problem format with a solution format using other useful structures like solution automation workflows
		- a solution/rules database is a way to 'find an existing solution, if it exists and if the search query is specific enough to identify the required solution', which not only doesnt automate the 'search query design' process itself but is also extremely fragile according to the data stored in the database


	22. is all value created? are there any problems left to chase? what problems cant be solved with this?

		- once certainty-generating/finding/deriving devices are created, uncertainty-generating/finding/deriving devices will be necessary, and we can stop evaluating questions based on 'what is real' and start evaluating questions based on 'what should/could be real' by creating reality

		- this system can solve problems where information is calculatable (like on the math interface) or where information is retrievable/testable (where you have data you can find & retrieve).
			- it can identify new interfaces on which problem-solving automation is possible, as they develop or become measurable
			- it can integrate new problems & new problem types into the system
		
		- it cant solve problems where information isnt measurable or calculatable - that means:
			- problems that are not solvable in this host system (a universe with these laws of physics):
				- problems that require more computation than we have computing power for
				- problems regarding information that is not retrievable or derivable (destroyed information, like historical information or information inside black holes)
				- problems regarding structures we dont have the understanding to organize information queries for, or retrieve information for (if there is a physics or math insight that is so foreign to our understanding that we don't even know to look for it, that may not be solvable with this tool, but it should be able to point understanding & information retrieval in that direction if not reach the destination structure). This would happen if the analysis isn't comprehensive enough when generating different perspectives, to identify new interfaces & new structures on them not adjacently derivable with existing interfaces.
					- maybe there's an object that generates so much randomness that we cant ever capture enough information about it to derive it
					- maybe there's a mechanism preventing necessary computation time to derive the mechanism from gathering around certain structures capable of hosting sentient life
					- maybe information has a built-in expiration in physics, and if it's not used, it decays - maybe this is how math develops, around efficiency energy organization that is allocated according to incentives & aligned with meaningful intent based on usage
			- these are examples I can come up with, which means my system can also come up with them - but you can see how non-standard assumptions can generate a high level of difference, to come up with alternative explanations originating from very different but still possible systems.