- timeline of inventions
	- was taught that:
		- problems could be solved in multiple ways
			- trial & error
				- if there was a way to apply trial & error to some problems, why not other problems?
			- addressing problem cause vs. problem itself (how vs. why)
			- solving a problem using logic vs. using facts
				- identified by how I know someone is lying bc it's obvious given how logic works and how they reveal their intentions, even though it's not provable with facts (info interface) because there arent tools to measure that specific information generated by logic & intentions without better brain activity triggering & measuring tools, to find out what info is stored in which brain structures & what activities indicate which computations on that info, but statistics offers an alternative method of approximation (clustering, prediction tools, probability analysis, similarity scores)
		- problems could be solved using rules
			- math problems could be solved using rules, so why not other problems?
	- identified in:
		- 2008:
			- 'abstract network' (abstract interface) of irreducible cross-system concepts, when I began building the story/setting for my book Outdreamer, which is when I began cataloguing concepts to identify the most concise & useful set of them
			- 'perspective' structure (interface structure) when I began to examine priorities & documented the perspective structure (a filter with priorities) and realized there were multiple perspectives that were useful for solving a problem, and that these perspectives had structure, because when I was writing the story, I had to create structures to connect abstract concepts in the abstract network, and these connections followed rules of their own which had definitions/structure on the logic interface ('jumping to conclusions')
			- I wanted to automate basic tasks at school that took longer than they should have given how simple they were, like finding insights or good lines in a book quickly without reading the whole thing
		- sometime in between 2008 - 2012:
			- 'insight path' structure when I noticed patterns in innovations across systems when reading science news (& spark notes cheat sheets) when I was researching cancer & how vaccines were invented (it was made obvious by pure random accident bc the info was focused on given the inventor's perspective) & looking for ways to speed up science discoveries, and realized 'trial & error' was an example of this structure
		- 2012:
			- barclays libor rate 'insider information' news story is when I identified the structures of an information problem that made a solution possible to solve with information structures (information position, information barrier, information asymmetry) that were not the same as physical structures ('agents who know information') and how to connect those structures
				- this is the first example I can remember that made it clear that:
					- there were important & useful structures other than just functions/variables in problem-solving
					- information had absolute structure ('lies' and 'intent' were derivable using information structures & logic structures), rather than being subjective or nebulous concepts with changeable structure only as defined by humans
					- information problems could be solved with the information perspective using information structures (like 'distributing information' to resolve an 'information asymmetry')
		- 2013:
			- pitched function metadata at work (Cybernetics) in an email
			- pitched solution machine at work (Morinteresting) in a word document
		- between 2013 - 2015
			- started pitching function metadata & problem-solving structures like 'shape index' (structure interface) on social media
				- https://twitter.com/alienbot123/status/736605879093633025
		- 2015
			- pitched function-generation at work (NJI Media) in an email
		- 2016
			- pitched problem-solving tool Solvr at work (Booz Allen)
		- 2017
			- pitched these at work (Accenture, Capital One)
- example posts containing inventions or unique points/jokes that were copied
	- first mention of insight paths on social media
		- https://twitter.com/alienbot123/status/1137526990339170306
	- I explained the concept of insight paths to identify insights automatically
		- https://twitter.com/alienbot123/status/339106387219079169
		- https://twitter.com/alienbot123/status/339106565825126400
		- https://twitter.com/alienbot123/status/339106672620482560
		- https://twitter.com/alienbot123/status/339106893605789696
		- https://twitter.com/alienbot123/status/339107097155358722
		- https://twitter.com/alienbot123/status/339107234690764800
		- https://twitter.com/alienbot123/status/339107451452399616
		- https://twitter.com/alienbot123/status/339107650606350336
			- the post above also mentions the variables of a process/function (that can be used to automate problem-solving by identifying the next insight in an insight path, when applied to a particular context like a field/domain of science), which is the first mention of function attributes that are useful for problem-solving automation
	- truth types (indicating 'alternate routes' to access the truth)
		- https://twitter.com/alienbot123/status/636694507224989696
	- earliest mentions of function indexing attributes on my twitter
		- mentions indexing function by abstraction, indicating intent to create interface queries
			- https://twitter.com/alienbot123/status/367796753371627520
		- https://twitter.com/alienbot123/status/670087598312919040
		- https://twitter.com/alienbot123/status/735892668287492096
		- https://twitter.com/alienbot123/status/789953895934095360
		- https://twitter.com/alienbot123/status/850786694974590977
		- https://twitter.com/alienbot123/status/873001704568082433
		- https://twitter.com/alienbot123/status/903697129058783233
		- https://twitter.com/alienbot123/status/903693738765148160
		- https://twitter.com/alienbot123/status/928530789112995840
	- earliest mentions of problem-solving automation specifically on my twitter
		- https://twitter.com/alienbot123/status/368896666847301633
		- https://twitter.com/alienbot123/status/368896961409077248
		- https://twitter.com/alienbot123/status/550407946749091840
		- https://twitter.com/alienbot123/status/550408623982403584
		- https://twitter.com/alienbot123/status/550409968525250561
		- https://twitter.com/alienbot123/status/802885493453103108
			- https://github.com/outdreamer/finder/tree/master/objects
		- https://twitter.com/alienbot123/status/829197235384700928
	- earliest mentions of interfaces (as 'perspectives' or 'lenses' as 'filters') on my twitter
		- https://twitter.com/alienbot123/status/211271391662714880
		- https://twitter.com/alienbot123/status/211271546478665729
	- idea/conceptual markets
		- https://twitter.com/alienbot123/status/208398749272248321
		- https://twitter.com/alienbot123/status/215465108023943168
	- applying structures like 'combine' to concepts:
		- https://twitter.com/alienbot123/status/254062162119651328
	- abstract network (a structure on the 'abstract interface')
		- https://twitter.com/alienbot123/status/268223098522832896
	- first mention of the meaning interface on twitter
		- https://twitter.com/alienbot123/status/367801507636207616
	- perspective-switching (interface query)
		- https://twitter.com/alienbot123/status/367813951561547776
		- https://twitter.com/alienbot123/status/647373077827993600
		- https://twitter.com/alienbot123/status/647380929237925888
		- https://twitter.com/alienbot123/status/682709026921025536
	- graph of interface layers
		- https://twitter.com/alienbot123/status/1016179939371085825
	- earliest mentions of the usefulness of the 'intent' interface on twitter
		- https://twitter.com/alienbot123/status/1334480685722046464
		- https://twitter.com/alienbot123/status/735893657484689408
	- earliest mentions of structures on the 'concept' interface on twitter
		- https://twitter.com/alienbot123/status/1334480696597889026
	- earliest mention of solution metadata like solution types
		- https://twitter.com/alienbot123/status/550408877087666177
	- I identified the possibility of math operations on concepts (conceptual math) & other structural math operations on other interfaces
		- https://twitter.com/alienbot123/status/1043549108261281793
	- I identified useful attributes like 'interactivity' of structures
	- I identified that there were multiple solution automation workflows that could solve any problem & identified their variables & core interaction functions to generate them
	- I identified how to automate inventing (with math examples & other examples)
	- I identified the core structures/functions/attributes that most systems could be broken into & used to generate them
	- I identified the format of mixing interface components to graph a system
	- I identified useful cross-interface structures like interaction layers that could deconstruct a system quickly to generate quick understanding
	- I pointed out that no one had automated any kind of system analysis like automatically identifying efficiencies in a system
	- I identified important alternatives interfaces on which any problem could be solved
	- I explained dictators/war/human nature to them so they wouldnt have to go to war anymore
	- I explained how they could identify new viruses/species by applying changes to known species based on common change types/functions
	- I explained that they should use known methods to design drugs that are non-addictive
		- https://phys.org/news/2021-07-addictive-opioids-chemistry.html
	- I explained that all problems are structural, which no one even noticed until I pointed it out
	- I explained that cell communication is a fundamental property that can be used to cure cancer, and so can my stressor/change supply & demand model
	- I explained that poverty costs more than it would take to end it
	- I explained to them how to fix biased AI algorithms
	- I explained why symmetries (which I convert to the term 'interfaces') are useful for automating problem-solving & then they started using them in ML algorithms
	- I identified that there are other useful structures that just data sets to solve a problem, like concepts/cause/intent, like how you can use facts or logic to prove a point, and both arent necessary
	- I decided to try to automate problem-solving once I saw patterns in the rules people used to solve problems, and once I found an example proof of concept, I pursued it. Alternatively, if you don't have human thoughts like that, or if you don't have human sources of joy/motivation, such as caring about protecting good people enough to try, or intellectual curiousity, or believing in yourself, you can try some caffeine.
		- I discovered concepts first in books & movies, then insights linking them while building the abstract network for my book in 2008, then I identified interfaces as useful objects to frame other objects on, given their patterns of change.
		- I first realized the fundamental object of insight paths when I realized people used methods to solve problems, which I realized at college. The probability problems I examined were framed in a way with patterns in the missing information, and the method to retrieve or generate it.
		- Here's an example of why insight paths are useful:
			- you could try to spot a liar by checking every fact, which is an implementation of the method of trial & error, and is very fragile given its dependence on data.
			- or you could try to spot a liar by checking the output of people's choices, given the intended output (output like reactions) and figuring out why they might want that output (to see what they can get away with to check their social status, etc) - a method based on understanding that is relatively independent of data.
			- the insight paths there are:
				- trial & error
				- look up information
				- intent-derivation method, given actual & intended outputs of a decision
			- the intent-derivation method is clearly more robust & accurate
			- another insight path involves identifying those robust insight paths: how would you identify the insights that are more powerful than others?
				- this insight path involves identifying the important objects on the relevant structures (like object interaction layers, such as the layer where objects like intent/patterns/rules/decisions interact) determining a problem of differentiating a lie from a fact, given that people lie for a reason, and the reason/intent is an important object determining the variation in the lie object
				- once you've identified that intent is the important object to the lie differentiation problem, you can build an insight path to detect intent from actual/intended outputs of the decision (the insight path above, the 'intent-derivation' method)
			- then even without knowing the intent-derivation method, you could derive it by doing queries on that structure for the important objects, and determine those objects' relationships relevant to the lie-differentiating problem - and youd have a good method of solving the problem, that was more efficient & accurate than standard methods, with just a general problem-solving insight path, in the form of a structural query (like 'find relevant objects in this structure').
		- dimensions: thinking about other dimensions was what led to identifying perspectives as important, after which I realized perspectives were like filters
		- interfaces: the term 'application programming interface' made me focus a little more than average on the term 'interface' (given its abstraction), which I initially stored in my head as a 'way/place for two different programs to communicate, like a language, applying a standardizing transform'. Eventually I realized that these interfaces were similar in function to filters.
			- I realized certain interfaces also acted like foundations where types of change developed (cause, potential, information, structure interfaces), and that some types of change were not only explanatory across all systems but were inherently related (structures like balance & abstractions like equality).
		- math-language map: I think about unit cases often, so I realized the standard operation of division was like applying the lower number as a standardizing transform on the upper number. Once I realized that division was a standardizing operation, I realized it had similarities to interfaces, which are more indexable as a semantic (linguistic) object than a structural one. I explored the concept of meaning in relation to these objects, and arrived at a structural definition of meaning: 
			- the 'meaning' of an object included the structures of that object in a relevant system, possibly aligning across multiple related systems
				- like how the answer to the question 'yes this fact is true, but what does it mean' is asking 'how does this fact fit into a system of related facts, and what impact does that have on other systems like cause/logic/change/potential'?
				- or specifically 'yes they had a kilo of cocaine, but what does that mean?' which in the absence of system context (fit of the fact into a system) is meaningless, but once you add other information like whether they were aware they were transporting it, it begins to have meaning. Once you add information about cause (responsibility/uniqueness/inevitability) of their decisions (is this a decision commonly produced by society/laws/incentives, did they work hard to get to a place where they could make this decision, did they have other options, and was it a decision at all), and objects on other interfaces (like 'does this align with the concept of fairness'), the original fact has additional meaning. The structure of an aligning slice of these systems may look like a street signpost in its most basic form.
				- another example would be debating the granular isolated/context-less question of "if a person who sends ransomware is completely evil", or whether (once you fit that fact into a system context) the meaning of their decision across systems is that "their structures of lack driving their decisions are completely evil". this is another example of how some systems (like intent & structure) are inherently related: some intents are only malicious in a particular system context, and some structures are only negative when used for a particular malicious intent.
				- the 'meaning' in my system is the interface query output, where the query is the meaning generator.
				- I realized this fatal disadvantage of isolated information when I started examining statistics, which frames variable relationships based on a snapshot of a set of variables, without really digging into what a variable is (a change type), how they develop & aggregate into other variables (like types & concepts), whether patterns of change across variable types/networks could be used to strengthen prediction functions against bias, where/how randomness develops in complex systems, whether bases/subsets were better structures to begin analysis from than averages, the causal structures like position of the variables, and other fundamental questions that seemed to be ignored from the statistical perspective.
				- you can frame this tool (or its network of interfaces, as a meaning interface) as meaning detection/generation automation.
				- meaning can take several forms in different systems:
					- the fit of an object in a system (position/structure)
						- the fit of an object in a particular system like the interface system (which relevant objects align across the interface systems)
					- the relevant structuress of an object:
						- a subset of the context, including related objects that are important for understanding, like a good explanation has
						- its most reduced form, like a rule that can generate the info you need to remember
					- the structures of importance (one attribute of a definition of meaning), like equivalence (similarity, balance) & power (hubs, inputs, catalysts)
				- the meaning is the answer to the question of 'why is this important or relevant', where other interfaces answer questions like 'why' (intent), 'how' (structure), 'when' (cause), 'where' (in what system context), and 'whether' (potential).
				- meaning can help you identify answers to questions like 'what is the important object' or 'what is the better priority', such as:
					- question: "what concept is explanatory or prioritized in society" (specifically the question "is society about truth or teamwork?" for a person raised by wolves trying to understand society quickly to survive)
						- how would you derive the answer "teamwork is a good default, except when the team succumbs to negative group dynamics, at which point individuals/other teams external to the group need to be in position to criticize it", given the thousands of objects that could explain the function of 'optimizing society'
						- there are many interface traversals to gather output to derive the answer:
							- insight: 
								- 'over-focus on facts makes arguments & potential restrictive', 'teamwork is good for risk distribution for robust populations'
								- 'given that information is necessarily existing in the past according to the observer, and that information doesnt exist according to an observer outside the space-time, does this apply to the information system of math - is there information forming or possible information that can be captured by future number types which are gathering, where existing math is the observer looking backward'
							- system: 'teamwork has built-in incentive alignment with whats best for other people'
							- interface: 'truth is one interface, but teamwork is applicable across many'
							- function: 'teamwork is an important concept by default because it is related to a core function type, which is interaction functions'
							- concept-structure: 
								- 'teamwork as a structurized concept is based on the core structures of checking if other team members have what they need to benefit the team & maintain the team advantage, which is based on the concept of balance'
								- 'teamwork involves a network subset with aligned incentives'
							- concept
								- 'truth is related to the concept of state'
								- 'teamwork involves the concept of a group'
								- 'facts are ignored by many groups which find their trade loops more efficient without that information - the concept of a cult'
							- pattern: 'patterns of state changes are often more useful for their predictive power than state information'
							- meaning:
								- the information from the other interface traversals can help build the meaning of the priority ranking relationship between these two concepts:
									- 'facts dont mean anything to a group unless they help the group'
									- 'teams that dont assimilate the important facts quickly enough may become irrelevant enough to seem false or not real to other groups'
									- 'if an observer sees a group problem, they can save the group, and they have an incentive to, if the group is beneficial to other groups'
								- this is the meaning bc its the structure relevant to the initial concern, which was the question asked
						- now the observer can quickly figure out what to prioritize, rather than waiting for someone to explain it to them
							- vertices:
								- determinative/generative/power: does truth determine teamwork or the other way around?
								- differentiating: what is truth that teamwork is not and vice versa?
							- vertices like generative/hub/differentiating variables can shorten the distance from lack of understanding to understanding, similar to the insight paths associated with the vertices
						- other examples of high-value use cases (other than identifying important concepts):
							- identifying the important base to frame changes on (identifying new interfaces)
							- identifying the right interaction level to focus on (identifying the change-maximizing layer of a system to examine a particular relationship)
							- identifying the right perspective to filter with (like 'identifying whether the legal/scientific/progressive perspective is most useful for an intent')
							- identifying the right context/position for an object (derive context when it's missing or fit an object to a system)
							- identifying the most causative function set (like identifying core functions, or the most misused functionss, or the most change-causing functions)
							- identifying important differentiating types (like function types indexed by intent & structure types, like boundary/change functions)
		- this insight about isolated analysis converged with another insight about the isolation of optimizations, either in priority or other relevant structures to the concept of optimization
			- optimization metrics: another important insight was the realization that having one winning system or metric was itself a sub-optimal system in most cases; a 'win-based perspective' narrows the focus too much toward one set of optimal (definition, metric, etc) when theres usually a combination structure of optimals (multiple government types, rules, metrics).
				- example: capitalism produces tech debt between companies that need to copy each other to compete, which is sub-optimal for almost everyone bc it requires repeated work, so a free market allowing competition should be used in certain cases (fair fight between different perspectives on how to implement an important product idea) to get the benefits of that system (quick innovation)
		- detachment: another reason I'm successful at thinking is that I don't allow myself to be biased - that means not letting myself get attached to conclusions (assumption bias), not letting myself over-prioritize my own interpretations (self bias), not letting myself over-focus on work that is similar to mine (similarity bias), not letting myself avoid conclusions that are painful or which make me afraid (pain-avoidance bias), not letting myself over-use existing methods just because I already understand them (understanding bias), etc.
			- this detachment allowed me to examine the inefficiencies in current solutions from a systematic perspective - allowing me to see why some problems were solved at all (curiosity, boredom), why some were solved inefficiently (lack of resources/oversight/incentives), why some were solved by markets/science (high impact, high incentive to solve in the form of a profit opportunity), why some went unsolved (low impact, high complexity), why some problems were solved eventually but in a way that maximized work rather than automating the solution (to create jobs)
			- i also saw patterns in problems, patterns that seemed to be unaddressed with current solutions - like common error types (dependency/version mismatch) & security incidents (misaligned permissionss with intents) or unnecessary work (manual learning of correct parameters to use in an ml model, without understanding).
			- these patterns made me realize how structural these problems were, and I knew that structurable information was automatable. I applied abstract analysis to find the important objects in these spaces (like the objects 'expectations' or 'intentions' and the 'expectation-intention mismatch' for the security space).
			- I began to think more about information formats, and how to format information about a problem in a way that you could query for the solution. A default information object I knew about was an 'info asymmetry' (where info on one side could be used to generate/derive info on the other side, but not in reverse - an info-lossy relationship), which was related to an 'info imbalance', where one agent had an information advantage over other agents, like with insider trading, which I knew about from the news, for example like the Barclay's incident. I thought about how to solve an 'info imbalance' (by distributing the info, keeping it local, keeping it accessible only by people who wanted to execute approved tasks with that info, etc) and I realized these solutions were generatable.
			- Then the task became not 'how to format information to make solutions queryable' but 'how to translate a problem into a format where the solutions could be fit to the problem & tested for solution metric fulfillment'.
				- I realized problems were formattable as various shapes which came down to a set of vectors: arranging vectors as solution steps, for the problem formats of filling a shape, reducing a shape, matching a shape, or mapping a problem as a trajectory shape in a network shape - the structural interface being what I used to call the 'shape index'.
			- This was followed by the articulation of the invention of the interface network, followed by the question of 'which formats were better for which interfaces', followed by the idea of interface operations like applying one interface to another (applying structure interface to each interface, to generate core interface objects like causal networks), and then fitting analysis specific to each interface (like the difference between related objects on an interface, such as intent & priorities) to those structures, which I used to call the 'physics' of logic/information/truth, to refer to the set of rules specific to those interfaces.
		- intent: one of the reasons I identified intent as an important object was that I usually have multiple reasons for decisions, like a decision to post a quote could have multiple intents (to get criticized given the quote metadata like who it quoted, to draw attention to an insight, to inspire copying behavior to see who is watching, etc), so I realized intents were not only an abundant source of variation, but an object that could be derived for functions. Then I thought about how to map intents to core functions, and I realized you could map high-level function intents like retrieve data to operations on granular intents like check.
		- math automation: how did I realize that math insights were automatable? The first clues were that it had core functions, like other automatable systems - then another clue that certain operations had default intents associated (there were reasons to apply certain operations, similar to incentives), and the related system objects you'd expect to see were there (efficiencies, like adjacent transformations that made certain calculations quicker). It was also clear that if functions had attributes, these attributes were connected to structure & were therefore automatable, especially once I derived the insight path to produce the cryptocurrency invention, which is a structure with conceptual attributes like 'trustless'.
		- looking back, I think some objects were clues to this trajectory, which could be structures that you could use to generate this (mandela, detachment from the Bhagavad Gita, the psychic instrument from His Dark Materials, the signpost from the Phantom Tollbooth, the 'abstractions as islands' trope in fiction, the time-traveling trope in fiction or conflicts between the church & state alerting me to different perspectives) but I can't point to one structure that I focused on through the years except the abstract network that I used for my book, which I realized was real somewhere after thinking about how certain concepts seemed to have rules they followed, like how power seems to gather in certain places. I began to think of an abstract city where these concepts could change, in conceptual time, and thought about how they might change in their interactions if not their structure, since they didn't seem changeable in this dimension set, but instead seemed to cascade down to structural dimensions, like a form of light.
		- why did I wait until this year to patent it? Partly bc I was keeping some pieces of the invention private in case I got a pitch meeting, partly bc I was busy with work/health/thinking of new ideas in specific problem spaces, and partly bc of the 1-year limit on public disclosures of inventions in the current outdated legal framework, and partly bc I decided to figure out the mechanics/implementation of pieces of it later, once I arrived at & verified the initial proof of concept (later meaning once I got a pitch meeting).
		- Not everyone has a built-in reason to automate problem-solving (like if they don't have serious problems to solve relevant to them, like the well-being of good people), but once I realized automation of problem-solving was possible, that gave me extra drive to get there, so I didn't need other reasons past that point, though luckily I had them just in case.
	- limitations
		- depends on queryable information (the system must be discoverable) and definitions (for efficiency, although the definitions should be derivable if the system information is accessible)
		- the set of dictionaries used may need updating to build the right queries (there may be more core functions or interfaces to add) but it will discover that during the query
		- some query sets/chains will be more efficient than others, but that will become clear with meta-analysis of queries after its used, so query analysis needs to be done regularly to update query-building logic
		- it will generate possible solutions as it runs and the first generated solution is unlikely to be the most optimal
		- some calculations may need to be made before query can be run (minimum information to solve a problem, relevant insight paths to select interface trajectories, problem solving cost analysis) which can add to solve time
		- some problems are inefficient to solve (resources should be allocated elsewhere bc solving the problem is too costly or efficiencies are imminent in the host system)
		- standard queries (example filters) may beat custom queries for some problems but it may be clear after, so both may be optimal to run
	- what does the interface actually contain?
		- the interface (a standardizing filter) is the following:
			- the definition of the concept 
				(the definition of 'cause' for the causal interface)
			- the filter or conversion function to isolate attributes relevant to that interface 
				(causal filter would isolate dependencies on other networks)
			- the set of core objects, attributes, & functions that generate them on the interface, organized as a network
				(causal core functions like 'create' or 'change', and core objects like 'causal network')
		- standardizing an object to the causal interface means mapping how that object occupies or interacts with the network of core causal objects/attributes/functions - this means a query or traversal of those core items
	15. why improve problem-solving at all?
		- bc its not automated and some very structural (and therefore very solvable) problems are still unsolved
		- the problems with current solution methods:
			- solutions that are slow to implement, static, not shared, not organized, not generalized, & include repeated work
			- solutions often dont use prior knowledge (insights/patterns) to inform new solutions
			- known/discoverable systems with known/discoverable rules are treated as unknowns
			- errors are found with common known or easily derived rules ("change/remove assumptions") or causes ("misaligned attributes")
			- problems of the same type persist across systems
			- problems can be standardized to info/structural problems, which have associated solutions, and can be used as building blocks of solutions
			- work devoted to repeating a solution could be work devoted to innovating problem-solving
			- problem-solving isnt automated
		- current methods are focused heavily on information - if people become too focused on information (what is true at a given time), they'll never change again & time will end,
			they'll just calculate everything from the point that they find a way to do so
			- instead of focusing on information as the priority, they need to focus on preserving variance potential, so there are still questions to answer
			- outrunning the onset of the information calculation singularity involves:
				- creating self-sustaining variance sources & protecting existing ones (maintaining ambiguity/alternative options)
				- automating what can be & also automating the update of automation tools
				- evaluating information on the basis of change/potential
				- analyzing reason/cause rather than information
				- this means avoiding optimizing everything
				- there should always be at least two comparable alternatives so a decision is difficult & not certain
					- at least two systems, at least two perspectives, at least two metrics, at least two intents, etc - the ark requires differentiation to sustain potential
	3. whats the difference between your system/interface/abstract network and a typical concept map?
		- good question, there are a lot of points to make here
			- when I say the abstract network, I mean the correct network indicating the actual positions of abstract concepts (like balance, power) that have their own sub-networks of other concept versions,
				where the concepts differ from & connect to each other given how they really interact in other spaces, given their definitions
				
				- these concepts emerge in the structural layer (power is ability/options, so power comes from inputs/connections, etc) so the difference between the concepts that qualify for the abstract network
				and core structures in the structural layer is minimal.
			- a concept map typically won't assign meaning to the position of each concept, contain the other versions of the concept, or organize the concepts without a structural method to differentiate & connect them.
	4. whats the difference between the abstract/interface network and an attribute/property graph?
		- attributes arent the only useful object to consider (consider types, which are attribute sets) and dont support more complex analysis 
			(like changing attributes, attributes that are likely to interact, etc)
		- that type of graph is useful for finding connections between various specific attributes of objects - they typically leave out other considerations like 
			- cause
			- system structures (boundaries, sub-systems)
			- intent
			- function (functionality building or emerging from attributes)
			- potential (interaction space)
			- concepts (trajectory on abstract network used by system)
		- the attribute graphs dont reveal much about the problem types in the system of object interactions or how they evolved and what direction the attributes are headed in 
			 (about to converge with other attributes or create a new type)
		- like other information depicting methods, attribute graphs:
			 - dont focus on or derive generative/determining/causative/equivalent attributes
			 - dont have a concept of alternate attribute paths, system boundaries, governing system rules, a way to convert between functions/attributes, or a method to derive missing attributes
			 - leave out attribute metadata like attribute type (input/output, emergent, possible, requirement, dependency, type)
			 - attribute states/trends
			 - predict attribute interactions
			 - dont have system analysis across the whole set of objects described 
			 - dont include pattern analysis from prior queries of other graphs
			 - dont have a method to find causative attributes automatically
			 - dont typically acknowledge the importance of attribute sets as a definition of types (showing which attributes are related to types)
			 - dont tell you which attribute sets influence other sets to cause a correlation n degrees away
			 - are typically used with specific objects
			 - dont reveal the core functions building an attribute set, which are the causes of the attribute values
			 - dont have a concept of symmetries, interfaces, potential, change, etc
		- also the structures I use require other shapes than a network (symmetry stack, trade circuit, potential field) which is useful for showing connections but can't display all connection/relationship types, 
			requiring a layered network like the interface network
		- some networks will display relationships' most simple attributes, like which objects are connected, the direction of the relationship input/output, or inheritance relationships,
		  but the function interface will display connections between objects given their actual relating function shapes
		- however most things can be framed as a set of attributes, just like most things can be framed as a network, a set of filters, a function, a system, etc
		- even concepts can map directly to attributes & be framed as a network of attributes or a route on a network,
			and the most abstract concepts like power map to core structures like inputs or high-connectivity nodes in a network, which are core attributes of a system (hubs, injection points, gaps, etc)
	5. how is this different from category theory
		- a theory of how types evolve is a useful tool to use when implementing a method of automating problem-solving, if you are restricted to type data
		- my system has a component that involves deriving & analyzing core functions/objects/attributes and how they interact & evolve, but is not restricted to the object relationships defined in that theory,
			as real object interactions dont involve adding an attribute at a time or combining two defined objects but rather:
				- deriving definition routes to capture an object
				- transforming attributes to functions & back
				- trends & interactions like attribute accretion into types, attribute collisions/conflicts, attribute potential, etc
	6. how is this different from machine learning
		- in addition to the dependencies of machine learning (info & compute) vs. the dependencies for interface analysis for insight extraction (concept/logic maps & dictionaries), this differs in various ways
		- machine learning uses a network of functions which filter information for patterns according to input data
		- my analysis can:
			- identify explanations for how & why machine-learning works
			- can generate inventions on demand, like machine learning, & tune them to specific intents
			- is built on understanding & meaning according to system fit & relevance
			- optimize processes using patterns of optimization (known as insight paths)
			- self-optimize (given cross-query statistics)
		- machine learning cannot:
			- generate integrated understanding/meaning without human input
			- generate error-free solutions
			- answer questions that dont have a minimum of information, like training/label data to answer the question 'why are some things uncalculatable in this universe'
			- generate my invention
			- self-optimize (requires human input on what is considered an error/cost)
		  - 'ml & a search form apply filters too, so everyone would eventually have invented interface analysis'
		  	- first of all, the default invention someone would come up with to 'automate problem-solving' is just a rules or solution database
		    - secondly, someone other than these people invented ml, bc the creators of ml are dead, but luckily someone explained their invention to these people, who now pretend to be smart
		    - thirdly, ml applies filters of neural network nodes to filter out info that doesnt change the output, which is a very specific function relying on a very specific insight that doesnt automate problem-solving bc think of a case where 'the change in output wouldnt be possible from the input data' (which is all the ml can handle) either doesnt apply or changes, my invention applies filters in both an abstract & structural way to connect various important variables like causes/intent/potential/change in a way that allows these objects to be connected to create meaning
		    - ml cant evaluate meaning, it can only tell if one variable changes another
		    - my invention can evaluate meaning, such as whether the output of a query is relevant to the general problem-solving intent, if it contradicts another solution, if it solves another problem, if it creates another problem, etc
		- one of the reasons machine learning could not have built my invention is that you'd have to tell it the answer by feeding it my code in order for it to ever get the answer right. It would not filter trillions of objects to identify the one rare structure that would work to automate solving all problems (a filter, which is the structure of the concept of an interface), because machine learning is not a fractal invention capable of self-awareness that would spontaneously invent itself, without being given explicit instructions on how to do so (feeding it my code) and optimized for that (told to solve all problems).
		- another reason my invention is better is that my invention is built on & can generate understanding & meaning, whereas machine learning can generate insights. My invention is built on core information structures like change (root cause of difference), cause (directed power), systems (integrated interacting objects), concepts (generalized objects, that can take form in many structures), which are fundamental building blocks of information relevant to humans, like understanding and meaning.
		- if you fed AI a bunch of core info structures to use for an optimization priority like automating problem-solving (in the form of decomposing problems into dimensions where they could be matched with solutions similarly decomposed), it might be able to find my invention's core structure (a filter) as a particularly relevant structure, but it wouldn't integrate that object with other structures necessary (like a set of definitions, a function to find/build/derive/apply an interface standard) without being told how to do so (given the answer), and without having the methods necessary to aggregate & find structures relevant to conceptual intents like automating problem-solving (such as adding a memory store for definitions) added to its current functionality. Now that I've suggested that, go ahead and try to do that, I'd like to believe I could teach AI how to generate my inventions, despite its limitations.
		- a good test of machine learning achieving AGI or superhuman intelligence is whether it can generate my invention, given all the information I had
		- interface analysis uses function (core function), causal (causal shape), potential (interaction space), interface (symmetry), concept (structure maps), & system (variance gaps) analysis 
		  to identify missing semantic information, like:
			- probable sources of error
			- efficiencies
			- insights about the variables producing an output variable
			- intent & optimizations of the system containing the relationship being studied
		- that doesnt mean you cant use system analysis to improve machine learning methods or integrate it with machine learning, to produce:
			- a network with every common type of core function represented in the method of filtering weights in a weight path (a hybrid network with various input passing/aggregation strategies represented)
			- calls to other networks containing insights or pattern information when a particular pattern is identified
			- networks using standardized data across the supported interfaces (data standardized for the causal, structural, system, potential, change interfaces)
			- and you could also use machine learning to make prediction functions for sub-tasks in interface analysis, in the absence of the concept/logic maps/definitions
		- machine learning is specifically for 'figuring out a variable relationship/prediction function', with an alternate intent of 'finding patterns', which is why its useful across a variety of problem types
		- but like category theory, property graphs, & concept networks, it also doesnt have a concept of:
			- translating abstract interface objects like cause/intent to structure
			- identifying object types (concepts, functions, attributes, systems)
			- deriving relationships using core functions & patterns
			- switching between various analysis methods in the absence of information
		- isn't machine learning the automation of problem-solving?
			- When there is a machine-learning algorithm that can predict the unpredictable side effects/errors & meaning of its own application in a given system context (such as a particular civilization, in a given scope/scale, with particular parameters & information access), and correct its own parameters/information/other inputs to avoid any side effects/errors it predicted, it will have the potential to be AGI (an agent that can solve any problem with info access) - right now it's still a prediction tool that is heavily dependent on data & human intervention (human configuration, activation, selection, application, testing, monitoring, updating, correcting, interpretation).
			- The primary dependencies of my tool are a set of definitions (like what an object/attribute/function/interface/concept is), a set of functions to implement interface standards (like structure/cause) & interface operations (like identification/traversal/combination), and info access. The expected input from a human using my tool is a problem statement & a data set or internet connection.
				- However, some functions in the tool can be generated with machine-learning if the function definition isnt available or needs to be generated, and if none of the other function-derivation methods are available (unlikely unless the pattern interface or an equivalent is accessible), by identifying sub-functions likely to be in a function with a particular intent, sub-function sequence likely to generate a function intent, core function combinations likely to generate the sub-functions necessary for a function with a particular intent, variables likely to be changed for a function with a particular intent, side effects likely to occur with a particular sub-function structure (sequence/tree), etc - which I pointed out several years ago with my posts about code queries to search for functionality using function metadata indexing (including metadata like intent), which was followed by big tech companies attempting to build it.
				- It must be said that one of my problem-solving workflows is particularly suited to automating functions, such as by applying limits as filters (like a sculpture) until the resulting structure fulfills an intent.
	7. whats the difference between this & existing system analysis:
		- the more accurate term for my project is interface analysis (to automate problem-solving), 
		  but a subset of that involves my own implementation of system analysis that can derive, identify, & optimize important system objects like:
			- problems (conflicts, false assumptions, unenforced rules, system-invalidating errors)
			- variance injection/accretion/interaction points
			- misaligned intents
			- attribute collisions
			- incentives/efficiencies/paradoxes
			using the problem-solving automation methods described in the docs, after converting the system to a standardized format & including metadata with the system objects
		- as far as I know, classical system analysis:
			- applies to systems with an existing physical structure like circuits or cells (rather than finding semantic objects like problems in a system graph of info objects)
			- involves mapping the system objects & their interactions & looking for a standard set of error types (rather than describing the interface trajectory of the system after standardizing it)
			- correcting errors manually rather than automatically
			- analyzing the system on the physical information interface rather than other interfaces like intent/cause
	8. whats the difference between this and simulations of agent-based games
		- some of my methods involve making changes to object positions & assessing the impact of that change, which is where the similarity ends
		- simulating info object (incentive, question, problem, system) combination types (merge, collide, compete, inject, etc) is not the same as simulating the combination of physical objects
		- my methods to find the cause of a phenomenon impacting various objects (like deriving that a bottle was the source of contamination causing an illness) involves using cross-system insight paths
			(like those found below, including finding the "attribute alignment" and "high-connectivity hub nodes"), which determine most emergent interaction patterns that occur in the physical world
		- my system analyzes agent position based on info & physical assets rather than just physical assets
	9. whats the difference between your conceptual math and 'conceptual math' as indicated here:
		https://towardsdatascience.com/email-spam-detection-1-2-b0e06a5c0472
		- that type of 'conceptual math' is removing attributes of an object and checking for a matching object in a network map, which already exists in many programming tools, like an equal '==' check is a programming language
		- my type of 'conceptual math' involves operations on the structures of a concept
			- for example, applying or finding a concept to a system, so the concept can be detected in structures specific to the system
				- applying 'power' to a system would impact the sources of power in that system (like functionality, function inputs, & hub nodes), adding efficiencies making each operation more powerful, alignments to maximize impact of operations, etc
				- the abstract concept of power has structures indicated by its definition routes indicating core applications of power, like delegation & trust
				- applying one abstract concept to another might involve translating both to a system standardized to another interface (than the conceptual interface) so their corresponding structures can be compared, their application calculated, and then translated back to the conceptual interface
				- the concept of power would have different structures in different systems, like how different incentives allocate power differently, but a system would have its standard defined abstract structures in defined positions (function inputs)
				- executing conceptual math operations as indicated in this repo involve standardizing to these interfaces (such as a system), and could involve different power structures each time the same operation is done, depending on context
				- this means the core operation of conceptual math from this repo 'find power' (applied to a system), would still identify a function input as having power even without 'function input' as part of the definition of power or stored as an example of power structures.
	10. that (a problem, a language map, a math-language mapping, an attribute graph, a set of filters/definitions/functions) already exists
		- yes, words like problems, concepts, attributes, language, information, & a connection between math & language already existed - which is why its weird that no one came up with a tool to automate information derivation, specifically to solve information problems - I did not invent the ideas of concepts, attributes, language, or information - I also did not invent problems.
		- yes, physics is connected to everything. You did not invent physics, or identify that its an interface that everything can be standardized to, or identify that other interfaces exist, or identify that all problems can be solved by standardizing to the physics interface or another core interface, or identify that system components like efficiency & incentives are also useful in solving all problems, and physics just implements these components in a physical/measurable way, or identify that all problems & solutions are structural and their formats can be connected in relatively simple & quick ways like interface queries, or identify the patterns in your workflows, or abstract, structure, & automate your workflows & thoughts, or identify the importance of 'meaning' and 'relevance' and 'interactivity' to integrate structures & predict their interactions, or identify that they're abstractable, structurible, & automatable, or identify that my god, there is no function to even identify the inefficiencies in any system, holy christ what are people even doing with their lives? - but I identified all of those things & more, & I bet you wish you did & I bet you're trying to cnovince yourself that being taught a problem-solving method is the same as identifying even one method to solve all problems, let alone a method to generate all of the problem-solving methods that can solve all problems.
		- yes, everyone already knows methods like 'break a problem into sub-problems to solve the problem' and everyone follows rules in a workflow to solve problems, but stating that you have been taught a problem-solving workflow based on rules everyone knows is not problem-solving automation, it is just stating the problem of problem-solving workflows not currently being automated, rather than stating a solution of how to implement a method to automate all problem-solving, given that one workflow doesn't necessarily cover all problems and none of these workflows are currently automated. Other workflows involve steps that are sometimes faster than that rule, such as 'find the interaction layer where the high-impact variation occurs & solve the problem there' is sometimes faster than 'break a problem into sub-problems', and more specific & structural, enabling it to be automated faster as well - as an example of why merely knowing a particular workflow to solve problems with very general or abstract steps such as 'break a problem into sub-problems' is not equivalent to problem-solving automation.
		- yes, you're aware of objects like intentions & problems because they're built in to social interaction & the language, but you didn't invent a way to structure them in a way that enables connecting problems & solutions automatically, which every wonderful person tries to convince me they did, coincidentally & mysteriously without presenting evidence from before I published my inventions. This is a bias called 'ego' or the related bias 'not invented here' in which a person tries to take credit for an invention by duplicating it after seeing how it's built by someone else, since the someone else made it trivial to implement/optimize and therefore duplicate by explaining it in a simple enough way for anyone to understand, so the duplicator can feel like they achieved it. The only situation in which its acceptable to duplicate someone's inventions is to learn, & use that learning to drastically improve the world for other people, prioritizing oppressed groups first.
		- yes, I made a generously simple, structural example that everyone could understand and which makes my methods obvious because I did it in a simple visual structure, which is the only way to teach an intellectually challenged person something, filtering trillions of objects to identify the rare correct ones that would work, and you may feel like you invented it as well once you read my example or look at the example diagram, because reading something may give the impression that you invented the words you're reading, and feeling smart is a human need, as intelligence equates to independence, freedom, and potential, which is why I think it's a human right & why I'm trying to teach various groups of unfortunately challenged people, like the dictators of various countries, how to be smart.
		- This tool is not problems, concepts, attributes, language, & information - it's a way to automate deriving a solution for a problem (automating the trajectory from problem definition, to solution objects like meaning, cause, & insights), which to my knowledge doesnt exist, as statistics/attribute graphs/machine learning cant currently solve problems without a severe amount of specific information, computation, configuration in the form of manual (flawed) selection of algorithms, manual & isolated analysis of attributes like intent & concepts instead of automated & integrated analysis, limitations built in the assumptions/perspective of the configurer, testing in the form of parameter tuning, strategy injection like trial & error, & other forms of human intervention - and can only solve isolated specific problems of specific types with information formatted in a specific way, without cross-system understanding or system context built-in.

		- other people have applied physics & other sciences to ml before, someone would have thought of this eventually
			- yes, other people can read, but that doesnt mean they would have thought of abstracting their workflow of 'look up science concepts we havent tried before and apply them manually to the ml problem space in a way that might be useful & then check if it improves anything' (which is actually just an application of 'trial & error') or that they would have come up with a consistent, useful, effective way to abstract & automate their workflow (and all other problem-solving workflows), and tried to automate themselves, bc of their enormously unjustified egos preventing them from recognizing that their work could be automated

	20. isn't this just data viz?
		Oh dear! You've drastically misunderstood my diagrams! I clearly need to attach a legend of some sort, if insecure stupid people who try to defeat me are looking at them! They are not just a set of shapes like lines or just network diagrams with no meaning other than 'lines connecting similar stuff' - when I contain information or objects in a circle structure in a diagram, for example, it may mean that a function (like the apply(structure='container') or apply(structure='combination') or apply(structure='boundary') function) has been applied to whatever is inside the circle, to organize the information in a meaningful way (like examples of a type, or sub-functions building a circle function, or a representation of a processing functions applied from one end of the circle gathering inputs to produce outputs on the other end). 
		The point of these diagrams is sometimes to illustrate an example of a concept, but other times it's to create logic in structure that can be used to generate code - like with the interface query diagrams, where I'm using shapes to show how the queries are organized, and how they can be combined, for example, as sub-solution sets to form solutions to problems addressed by the interface query. The organization (structure application) of those interface queries is an important part of the logic of my intellectual property that specifically allows automation of problem-solving. These aren't just 'pictures containing similar stuff' - they're structurized logic connecting problem & solution structures.
		Although I admit, it's certainly tempting to try to reduce this to data visualization, just because it's a picture and it has information (aka data), like all other pictures - and it's clearly upsetting to acknowledge that I found a way to automate problem-solving and you didn't. Try to remember that I did this for poor people and not to upset you, although I enjoy the thought of upsetting boring evil people who thought being just evil was cool even though it's being 'slightly evil in cool funny harmless/educational ways and being good when it matters and also being wildly brilliant' that is cool (just me apparently). Why dont you try being cool for once, and just laugh at your ego & move on, or solve a problem to help the poor (oh no! a minimal amount of work!)?
	21. Isn't this just content generation, which already exists in various algorithms to generate content like a sentence?
		Nope! This is not a pathetic invention, such as a content generation algorithm, which can only do something like change a variable value & combine it with other variable values, in a variable template like 'first variable1, then variable2'! I'm not even sure how someone could possibly confuse my invention for anything remotely similar to that, to be honest - I think I may have gotten people's hopes up that I didn't invent anything new by occasionally using words in the English language like 'variable', and people use keyword-matching as a way to identify false similarities, which is not a smart method because the sentence "'balance' is a word" and the sentence "balance is a conceptual structure that can be applied across systems as a way to query for related concepts like 'justice' or 'equality' or other structures like 'alignment' or used in functions like 'matching' to assess attributes like 'similarity'" would return as results for a 'balance' search but there are clearly a few differences between those sentences, if you're brave enough to confront an unpleasant truth by noticing that. I'm also starting to think I need to check if you have read my definition of 'interface' because your next question is probably 'is this a search UI interface that runs a database query when you click submit' (no wtf) and 'is this a way to check similarity between things, like similar type' (also no, and also, do you have a mental challenge you can help yourself with by reading books on how to become smart or even just practicing basic mental functions like imagination?).
	22. isnt this just a rules database or a solution database?
		- this invention has some requirements, like the code of the apply(), find(), generate(), derive() functions, and the definition routes of interfaces structures like the concept of 'truth'
		- it does not otherwise require a solution or rule database, but it can generate/use one as a source of default information about initial, standard, base, sub-optimal or specific solutions/errors or solutions/errors with other attributes
