## Problem Object

  - attributes:

    - solvability: whether the problem space changes faster than existing tools can solve problems in that space

    - structures:
      - distance/gap
      - intersection
      - overlap
      - shapes (compounding problem dimensions)

    - core conflict
      - the core mismatch/imbalance creating the cascading mismatches/imbalances for agents in the problem space

    - stable state
      - whether the problem can solve itself if another problem is solved or if its left alone

    - minimum information

      - given different information, you can use different methods: some methods are immune to information but most require a clear minimum
      
      - vertices
          - in a system (set of rules & objects) the minimum information can be found with the system vertices
          - these vertices can be:
            - core/important/generative functions/variables
            - similar to moments of a distribution or divergence points in a voronoi diagram
            - the intersections between core functions/variables that either reduce the set of possible functions/variables to the actual set or generate them
        - with a line in a space, you have this information:
          - the type of change
          - the change rate
          - the angle compared to a standard, like an axis
          - its distance

  - antimetadata

      - given objects (rules) & their distorted/contextual versions (rule preventing an attribute from emerging) and the set of possible values of objects in the rule ('repetition' is a possible attribute), you can determine what's not prevented by the metadata defining an object's structure, by what common objects (or distortions of objects or object values) are allowed in the object, even if theyre not referenced in the object definition

      - example:

        - what could a problem be? (dependency, limit, lack, mismatch, conflict)

        - what is a problem definitely not?

          - interim objects that dont add to causation: enabling objects that allow other objects to exist but are not causative:
            - core functions that evolve in a system (caused by the system structure) that allow other functions to be built from them, but are not causative (the cause is the system structure)

          - an abstract concept without a particular contextual implementation/structure

    - questions (filters):
      
      - problem type prediction for a system: given a system structure, which problem types are likely to occur?

      - what problems are not solvable?

        - in the universe, if you deployed a perfect computer to every smallest unit of matter/energy/info, what could you not compute?
          - for example, you couldnt compute the optimal combinations of all the other units in each unit, because the computation would involve observing other units in a way that might require them to do no processing while being observed, and this might prevent the computation from being completed by each unit of matter containing a computation device, such as a superposition
        - are there systems in which that problem is solvable (if you adjusted variance cascade patterns, could the uncertainty be reduced enough for it to be solvable)
        - solvable: can be generated by a set of identifiable factors
        - what is solvable is limited by what is identifiable - when identifying tools change, how does solvability change?

      - what are the available & relevant solution tools of the problem space:
        - insight filter ("extract insight from data, selecting for variance cascades")
        - pattern finder ("find a pattern with intent x or output y")
        - pattern generator ("generate probable patterns using known or likely components to explain x")
        - pattern applier ("apply this pattern to this system", "apply this insight to this solution")
          - concept combiner ("combine this strategy with this power balance")
        - selecting strategies
        - property matching for sub-intents of exploit intent 
        - perspective switching/transforms

    - problem types:

      - conflicts

        - interaction objects
          - inputs/requirements/logic/incentives/assumptions/patterns/types/priorities/exploits/interfaces

        - types

          - mismatch 
            - incorrect position/structure/rule/direction
              - example: receptor fits the correct protein but also a hostile protein because its shape is too general (a conflict of mismatched scope)

          - competition (forces pulling in different directions, limited resources)

          - opposition (neutralizing functions)

            - misaligned incentives 
              - example: monitoring function not given reason to monitor the lib building the monitoring function

            - paradox: 

              - calculating something that doesnt seem directly calculatable from existing resources (https://en.wikipedia.org/wiki/Paradox)

              - attributes:

                - contradiction: a significant variable misrepresented as insignificant (like time)
                  - truth of axioms change according to timing of event, but if the event happens at all, its taken as an absolute contradiction when its really a time-dependent contradiction
                  - can occur with mutually exclusive states where conflicting directions are falsely associated (falsehood of an interpretation in a scope doesnt mean falsehood of the same interpretation in a different scope)

                - self-reference: a lack of information about options
                  - 'If "this sentence is false" is true, then it is false, but the sentence states that it is false, and if it is false, then it must be true, and so on.' https://en.wikipedia.org/wiki/Liar_paradox
                    - true in the sense of meaningful equivalence ('this sentence' equals 'false')
                    - false in the sense of consistency between extrapolated implications ('this sentence' equaling 'false' doesnt equal 'this sentence is false' equaling 'false'
                  - this is usually a lack of information (ambiguities) about scope & alternate variable values
                    - can truth exist on a spectrum
                    - can truth apply to different sentence attributes ('this sentence' object in the sentence, the whole sentence, & sentence implications

              - the paradox of a 'list that contains all lists' seems unsolvable (the list needs to contain itself to be a complete set) until you notice that the list of lists is complete even if its missing one because that can be derived from the variation in the other lists, which describes the variables that can change

                - similar to listing n - 1 boolean values of different category values instead of n boolean values
                - the list of all lists contains the list of all lists in itself, so its structure/variables/contents each describe itself, even if its not stored as an item in the list

              - these paradoxes are an opposite object to interfaces and involve the apparent impossibility of solving a problem without solving the problem from a system perspective (deriving all possible lists in a system) rather than in isolation (listing all things)


        - resolution configurations
            - one competitor winning & replacing the other
            - compromise:
              - sharing (sharing the resource)
              - delegation (cooperating to acquire the resource)
              - differentiation (developing different ways to get the resource, such as producing it themselves)
              - agent adaptation (changing what is demanded/prioritized so conflict is invalid)
            - forfeit
            - game adaptation 
            - variance overrides (new universal enemy aligns incentives of competitors to cooperate)

      - asymmetries

        - can be framed as a conflict/mismatch between supply & demand
        - resource asymmetries (misallocated info, cause, power, variance)
        - includes questions and other inequalities
        - emergent patterns created by imbalances in usage patterns

        - example asymmetries with different params:
          - asymmetry of info (distance between info sources, such as agents specialized for a particular function needing different information)
          - asymmetry of info across time (prediction, convergence of info sources)

        - symmetries as epicenters/organizers/distributers/filters of similarity/variance
          - limits as an output of symmetries - can you calculate all symmetries, and can you calculate all limits from the set of symmetries?
          - how do symmetries evolve in a system - do they provide a standard/interface for variance to coordinate efficiently?
          - how are symmetries related to efficiency?
          - quantum entanglement occurs around symmetries & other aggregators like similarity

        - resolution configurations
          - removing resource
          - balancing resource
          - replacing resource
          - deriving & distributing resource generator
          - variance/conflict injection

      - variance injections

        - unrestricted inputs (incentive/intent/expectation gaps)
        - unhandled error types

        - resolution configurations
          - adding barrier/filter to variance source
          - distributing variance to minimize impact (distributing stressor across surface area)
          - breaking variance into subsets that match existing variance handlers
          - combining variance handlers to match variance source
          - combining variance sources to match variance handlers


## Problem examples

- common task that is done in endless incorrect ways bc of lack of rule enforcement (like building & securing an api) when there's one clear way to do it:
  - generate api using latest patches against all known vulns, and adapt logic without adjusting security measures in generated code
  - even more secure is to generate code as user intents are identified & validated, so no code exists pre-runtime except:
    - intent-derivation & validation code
    - code to generate functions to supply resources for a valid intent
  - as valid intents are identified:
    - 'request data they have permission to access, which is also validated as relevant to them'
  - code is generated on-demand:
    - 'generate function to fetch data, using optimal data request function determined by intent-matching, or without that, determined by best manually determined algorithm & with latest manual patches'
  
- inefficiency problem
  - attributes:
    - granular/conflicting intent (only serves one intent optimally at sacrifice of another related intent that people often need together)
    - lack of clarity in cost/benefit structures (bc of abstraction, its not clear how a tool will provide a cost when interacting with another tool)
  - how do you minimize inefficiencies in workflow
    - translating task into clear requirements to reduce questions
    - identifying information gaps to distribute information where its relevant & needed

- problem-handling problem
  - what strategies do you use for anticipating problems (of a certain type & in general)
  - add error-generation
    - add diagrams for error types:
      - misalignment
      - assumptions without supporting logical/information links
      - incorrect position/function/structure/scope/limit/range/definition
    - examples:
      - p-hacking 
        - what range of significance levels do verified processes exhibit (when first noticed/converging/diverging/decaying)?
      - nearest neighbors hacking
  - give example of error types mapped to structural deficits

- planning problem
  - how much time do you invest in planning & what are your planning strategies to avoid having to solve problems later?

- learning problem

  - how do you educate yourself on inherent limitations of a tool 
    - if its designed for another intent
    - if its too new for advanced error handling
    - common problems with tool or third party tool integrations in forum posts/issues
    - corrections/features added by user request in version/release history (to address user identified problems or misunderstandings)


## Identify obvious errors possible in a solution

    - assumptions:
      - in a data visualization tool, an obvious error is data leakage (revealing data that shouldnt be shown to the user)
      - data that is retrievable is assumed to be relevant to the user

    - example:

      - if youre tracking the movement of particles in a square shaped container and two of your variables track the movements between opposite corners, their movement might seem directly related, but the reason theyre moving is not a variable relationship, but the shapes nearest to them determining their motion
        - this error (illusion of relationship) has the error stack:
          - mistaking correlation for similarity/equivalence/causation
          - misidentifying variables
            - there shouldnt be variables for the movement in each corner 
            - the variables should be the placement/other attributes of influential objects like corners if the shape isnt as simple as a clearly defined archetype like a square, or the function to generate the shapes having those influential objects
          - mistaking indirect cause for direct cause
            - the reason theyre related is a causal relationship they have in common (shape of corners) but its not a direct relationship (movement in corner A determines or is equivalent to movement in corner B)
        - this is an obvious error of the problem type 'determining movement between shapes' with the attribute:
          - 'shapes having multiple similar sub-objects like corners which can produce the illusion of relationships'
          - which is sub-type of the problem type: 'alignment isnt direct relevance'
        - how would you identify this obvious error in the above problem of predicting movement of particles within a shape container?
          1. you could start on a high level by looking for known error types (false positive) or error causes (false assumption)
          2. you could also start on a low level by generating the full set of different shape configuration data within a space & examining them for errors
            - you can generate the full set of different shape configurations using types, core functions, & interactions:
              - shape types (square, triangle)
              - shape core functions (transforms: scale, remove, expand)
              - shape interactions (combine, collide, oppose)
              - shape components (corners, inflection points, extremes, arcs, diagonals, angles, edges, centers)
            - and then examining them for error types & causes, given error type definitions
              - 'false positive' means 'something that looks like something else but isnt'
                - this can manifest in the problem space as:
                  - 'two different relationships seeming like the same or related relationship'
                    - which in this problem space could be the motion of particles in two similar sub-shapes like corners
          3. you could start with common errors in this & similar problem spaces or space stacks
            - given that a common problem is 'similarity implying relationship' in the stack of spaces (adjacent/causative dimensions), does that problem show up in this problem space, and if so, where is it likeliest to show up? (where are the similarities that could create a false correlation)
          4. you could derive the obvious errors using problem space metadata
            
