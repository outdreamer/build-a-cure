to do: organize into docs

  - methods of integrating solutions to sub-problems to build a solution for a global problem-solving intent
    - break problem into sub-problems
      - waiting till sub-solutions are fully formed to integrate in final operation, adjusting as needed to optimize global problem solution metrics
      - regularly checking alignment with global goal at intervals that allow a rate of deviation that fulfills adaptation intents
      - organizing sub-solutions by variation, making each sub-solution unique to avoid repeating work, building a function index to solve global problem
    - break problem into sequence of problems (interim solution, problem space-invalidating solution, etc)
      - building approximate interim solution that fulfills a subset of solution metrics, since optimizing on all metrics is likely to require future costs in updating solution regardless, so avoid optimizing on all metrics to minimize iterative solution update cost
    - break solution metrics into multiple subsets and build multiple solutions, for solution metric subsets
      - developing multiple alternative solutions and vacillating between them, as optimization metric subsets change
      - calculate important optimization metric subsets first, and build solutions for each of those 

  - example of applying interfaces to power dynamics: 
    - context applied to ethical objects: 
      - conditionally good (locally good)
    - matching related structures to generate prioritized concepts like balance: 
      - matching power with responsibility (access to global information means global responsibility)
      - combining information with independence-generating tools (product testing tool, truth assessment tools)
    - using tools with complexity as a side effect: integrating AI and algorithms into resource distribution so error complexity can provide a conduit for accidental resource transfers to oppressed groups
    - integrated analysis of decisions: 
      - with other decisions (local/global, economic/scientific)
      - with time (past/future states)
      - with decisions/time (decision history)
        - analyzing investment potential when calculating tax burden
      - with potential (limiting/expanding options)
    - applying intent to ai model networks: 
      - adding simulators & monitors to watch models that veer in one priority direction more, making them pass extra tests based on degree of distortion
    - applying alternatives:
      - find new interfaces & structures to reverse direction if a big interface is discovered and pivot faster to discoveries that dont invalidate current systems

    - example of aligning vectors to resolve conflicts (like debt/opportunity imbalances & reducing risks)
      - organizing debts & lawsuits to resolve unpaid debts
        - loaners on a debt chain can coordinate resource to sue borrowers who dont pay, reducing their risk of loss
          - loaners can also organize the debt so that losses accrue to the borrower if the borrower fails
            - example: if the borrower starts a business, loaners can require that they use suppliers already on the debt chain
              - if the borrower's business fails, they could either lose a key dependency to continue their business/achieve another goal, or gain an incentive to repay loans
              - this incentive could also be built in to the loan before business outcome is determined
                - people who the borrowers also owe money to, so the borrower has info that their loaners are sharing info, which increases their incentive to pay them back
                - other people who also owe the loaners money, so the loaner is likelier to be paid by the supplier

        - profit/learning opportunities & other resources like cost information, time, & responsibility can be traded between people on debt chains/loops, to resolve other inequalities
          - risk of default (responsibility for broken contract term) can be converted into a lawsuit opportunity & an opportunity for future contract/work with investment in education of defaulter
          - resources like information about profit opportunities & cost risks can be organized by loaners to help borrowers meet their goals
          - loaners on debt chains can invest in AI to predict success of business decisions and investments, to help borrowers avoid losses that will create losses for loaners
          - loaners can minimize their losses by using same AI to predict losses of other borrowers (they didnt personally lend to) & betting against borrowers making bad business decisions
          - loaners can reduce threats to borrowers' businesses by allocating the same risk or different opportunities to other/alternative interim technologies/businesses with lower profit potential, potentially anticompetitive behavior which can be spotted with AI or contradictory/aligning/alternative/equivalent vectors in a vectorized problem space
          - borrowers can pay with data if their business fails to train the AI to identify business risk & success probabilities
          - vectorized objects: crime, debt, contract, information (prediction, opportunity info, organization/alignment/efficiency info), work, time, profit, cost, interest, incentive, tax, value, risk, opportunity, litigation
            - all of these objects can be a resource (asset) to different positions
              - cost can be a resource in debt market suppliers (loaners) and legal market suppliers (lawyers)
              - risk is a resource in risk/prediction/investing/insurance markets, such as for short-sellers & insurers with more info about risks than buyers
              - crime is a resource in enforcement, labor, crime prevention, education & debt markets
              - inefficiencies in these markets occur with cross-market misalignments/gaps/imbalances, such as:
                - when info imbalances are allowed to persist (so info is concentrated on exploiters side), incentives may only be clear to exploited agents when its too high-cost to choose non-incentivized actions, so inequalities persist in other structures like opportunities

  - nn: example of applying the concept of 'health' to neural network architecture:

    - optimization for attributes
      - relevance
      - security
      - risk reduction
      - alternatives
    - optimization for functions
      - supporting alternative function inputs (like different energy sources)
      - having update mechanisms (evolution)
      - having a source of randomness to inject change in systems that are too static to handle stressors (mutations)
    - optimization for interfaces
      - organization by:
        - intent
          - functions with local/specific purposes are localized rather than global
          - functions with global usefulness are kept generic or abstract & distributed regularly
          - function search is built-in to certain mechanisms
        - cause
          - addressing cause at relevant/adjacent/root degree as needed
            - bio: mucosal lining addressing root cause of pathogen exposure as a first line of defense & other causes like system fragility as a backup
            - nn: identifying nodes causing various types/directness/degrees of error & deactivating them conditionally on input associated with error patterns
        - potential
          - bio: stem cells, cells that can re-generate or change type, telomere length, resource (energy/oxygen) usage efficiency, evolution/change/survival potential
          - nn: nodes that can change activation state/level, position/connection to other nodes (particularly frequently used nodes can be positioned to form sub-systems that incentivize error detection or prediction speed), type & other metadata, nodes that can create other nodes as they encounter feedback indicating extra decision complexity, nodes that can extend activation length as needed in conditions like when global system metrics indicate extra uncertainty or re-calculation of threshold values (different thresholds giving different answer accuracy for different input sub-systems & sub-types, which can be evaluated during training)
        - system
          - system backups
            - alternate systems to handle a function that is likely to be compromised at some point
          - system integration (cooperation)
            - common currencies
              - bio: energy/heat across systems
              - nn: information about 'explanatory feature'-finding success, information enabling extracting features from input information ('start search in a particular position or with a particular search pattern for features')
          - system organization
            - allocation of functionality/responsibility to systems (like immune or decision sub-systems) & positions (like organs, like max-pooling at certain positions)
        - information
          - proper memory management
            - dispose of resources like specific rules or abstractions as they become irrelevant
              - bio: old memory cell that is creating problems or repairing DNA based on copy of correct version stored in memory
              - nn: prior weights or inactive nodes
            - storing useful memory efficiently, optimized for access/usage/security, protected from attacks like unauthorized overwrites from structural damage and/or a pathogen
              - bio: cell surface proteins that dont bind to pathogen patterns
              - nn: organized memory according to usage intent, similarities like patterns, metadata to determine relevance like topics/types/systems
    - other health metrics 
      - inefficiencies/conflicts & other problem types dont cascade through the system
      - problem types (damage, hostile invasions) are identified on multiple structures like layers/networks/positions
      - solutions are allocated according to problem type & previous solution success history

  - current ways to lock people into/incentivize financial purchases or other resource transfers that help a business
    - contracts
    - loans
    - subscriptions
    - monopolies
    - guaranteed returns
    - predictions (of future value, in the form of profit/cost/automation/integration/regulation)
    - derivatives/options/stocks/bonds
    - optional discounts involving work to use (coupons, rebates, discount cards)
    - incentivized payment methods
      - credit card (incentivized purchases at partner businesses)
      - coins/currencies/tokens 
    - payment methods with benefits 
      - credit/loan interest rate
      - bond/investment yield rate
      - secure transactions 
      - guaranteed assets
      - withdrawal/transfer options
      - currency/liquidity conversion options
      - purchase ROI (points, cash back)
    - payment methods with costs 
      - cost of credit system includes defaults, enforcement
      - cost of crypto includes the criminal system 
      - cost of currency market includes variable currency value 
    - payment-platform dependencies
      - credit cards tied to tech platforms (apple card, apple pay) 
      - financial apps that work on or otherwise incentivize particular tech platforms & financial products
    - incentivized purchases 
      - bundled products 
      - dependent products
      - products with inefficiencies built in (designed to break or otherwise require other purchases or fixes)
      - products with complexities built in (designed to require purchases of other resources like reviews, which require resource investment of time to examine)
      - discounts 
      - subsidies

    - optimal products
      - require only a time investment in that users learn skills that make them independent
      - create efficiencies for the user, in the form of free time (no time required examining reviews, disposing of product, updating/replacing/returning/fixing product)
      - integrate with other optimal products to create combined & compounding efficiencies
      - incentivize positive business practices to improve health of the network of markets
      - help fund socially beneficial investments

    - ways to limit/enable purchases 
      - credit score/limit
      - taxes
      - exploitative pricing
      - profit re-investment in cost reduction (automation, integrated investments that benefit society & reduce costs for everyone, like for climate change or AI)

    - product value variables
      - exchange rates 
      - currency valuation insurance
      - regulation rates 
      - pricing & rating methods (rating bonds/stocks/currencies, rating products, selecting prices)
      - value of relative demand (potential position of currency in currency market)

    - questions

      - what impact should a positive payment history or payment potential have on the interfaces involved (currency/debt markets, investment interest, govt policies)
        - should one company's positive payment history create systemic change incentivizing their decisions/strategies, and rewarding people in debt who could contribute to their goals
        - should it steadily erode the idea of debt, so that transactions increasing general population debt are less incentivized than transactions reducing it 
        - should debt be recalculated historically & proportionally, to account for basic needs & actual contributions from uniquely good/high-impact/valuable decisions that few other people would have made in their situation, which indicates they are good at making financial decisions & should be making other financial decisions

      - should you calculate incentives, identify inefficiencies or bad incentives, and remove them from the financial system completely, or should they be allowed in edge cases for given net positive intents, like where:
        - an otherwise good company needs to charge exploitative pricing to make profits to fund socially beneficial investments
        - an otherwise good country needs to gang up with other countries on an exploitative country
      - should the financial system be rewired to incentivize exclusively socially beneficial investments to reduce costs for & dependence of everyone
      - should financial position be calculated based on ratio of problems solved/created and other metrics of integrated analysis

      - what specific interfaces are most useful to frame market decisions on?
        - value (with metrics like proportional/historical value)
        - markets (market for decisions, markets, pricing strategies, rating systems, currencies, etc)
        - potential (increasing opportunities through resource distribution)
        - one of the vertex variables in the market problem space is 'value', just like one of the vertex variables in the bio problem space is 'health', and a vertex variable in both is 'energy'

- applying a concept to a neural network to identify more error types & optimized network structure:

  - applying the concept of 'false':
    - allows calculations of combinations, with other existing concepts like:
      - 'false' + 'data'
        - 'static output data' (not changeable) permuted as 'dynamic input data' (changeable by an agent),
          - resulting from the decisions of an agent, who can have 'false'-related intents, like 'intentional falsehood'
            - in the format of: 'intent to fake data to get a particular output without the signals of validity'
              - by finding: 'false signals that are easily faked and are sufficient to get the target output'
        - 'fake data' having signals that may differ from valid data on the intent interface, bc fake data has a different intent:
          - "to get a 'true' output with lower cost"
      - which will help the network identify an error type it cant spot with its current algorithm, like:
        - 'combinations of low-cost signals without another semi-required high-cost signal, being identified as the "true" output'
      - which can have a structural fix of:
        - 'applying a hard requirement to the high-cost signal in the case where only low-cost signals are found in data'

  - which executes the following problem-solving workflow of applying a concept to a structure, to solve the problem of 'identifying all possible error types':
    - iterate concepts
      - apply concept (fake) to existing components (inputs like data, outputs like labels, input-output linking units like functions, input-output links like network structure)
        - identify differences caused by concept on different interfaces (different intent of fake data vs. valid data)
          - identify error types in differences (fake data that can look like valid data)
            - identify structures to identify error type (combination of low-cost signals without high-cost soft-required identifying signals)
              - identify structural solutions to error types (add hard requirement in case where error type structure occurs)
                - apply filter 'check structural solutions impact on existing solution metrics' (check for error types like false similarities in this solution, in the form of counterexamples)

  - solution filtering logic needs to generate counterexamples
  - 'false similarities' system problem type can also be applied instead of the conceptual route above
        
- example: frame a relevant insight to persuade a particular audience

  - insight: 'abusing power hurts society and occurs with a lack of intelligence'
  - query for the requirements of their perspective
  - frame the insight as a requirement-invalidator
    - example: 
      - to persuade a dictator to stop abusing their power
        - identify one of their requirements: feeling powerful
        - frame the insight as a requirement-invalidator: 
          - abusing power is actually a need rather than a power, bc it shows a lack of a different/greater power (intelligence, to form self-awareness/control)

  - query for their problems
  - frame the insight as a problem-solver
    - example: 
      - identify their problems:
        - a dictator has problems of understanding (understanding why they experience opposition) & safety (how to hand off power without being killed)
      - frame the insight as a problem-solver, linking the problem (experience opposition) to the cause (creating vs. fixing problems), enabling querying for solutions to that cause
        - they experience opposition bc their power handling strategies cause more problems for society than they solve, bc of their local bias, which is inefficient at organizing work to solve problems
        - they arent safe bc they havent fixed prior problems they caused
      - both of these problems are caused by lack of intelligence (formatted as organized work)

  - how would you format an insight to achieve a particular conclusion automatically:
    - the goal is to persuade an agent to move their position/change their state
      - in order to do that, they need to understand they are missing an efficient opportunity to improve their state
        - an efficient opportunity to move would be a clear set of steps
          - a set of steps such as understanding, linking one of their problems (like a requirement) to an adjacent solution that minimizes their work (apply organization to agencies/employees' work)
    
    - how would you identify 'an efficiently clear set of steps to improve their state' as a structural solution to achieve the intent of 'giving an agent motivation to change/move to a particular state/position'
      - apply the insights:
        - 'movement is likelier to occur on efficient (low-cost) paths'
        - 'understanding is a type of efficiency, bc it makes optimal solutions clearer to agents, rather than requiring them to build understanding & figure out which path to take'
        - 'requirement is a type of problem'
        - 'dictators have problems such as lack of intelligence, which takes the form of understanding'
        - 'dictators create more problems than they solve'
        - 'in order to create intelligence & solve problems, apply organization/structure to generate efficiencies in work allocation'

- interface analysis example with government components: 
    - democracy with an individual leader or group of elites/advisers/influencers which are treated as representatives of different population subsets is inherently contradictory - an alternative is in moving the leader to the same level as their adjacent advisers & other influencers, and giving them executive or majority/weighted/veto power over some decisions like whether to go to war, and the structure of the top advisers & the president would change according to needs
      - do they need a consensus? then make sure the network of advisers has an odd number
      - do they need an accurate resolution rather than an efficient one? then allow an even number & have regular re-calculations of votes until the issue is resolved
    - the application of different analysis methods in calculating the different probable & relevant perspectives on an issue & the optimal structure of the issue should be integrated as AI voters into human decision systems, as an independent third party that is biased in its incentives embedded in its learning algorithm (which can be selected for relevant issues, like a bias toward priorities like accuracy or efficiency depending on what type of decision is required) but not biased by financial incentives
    - a network or other structure of biases that is updated constantly is one way to counteract over-prioritization leading to a particular bias

- to handle intellectual property theft, offer IP/patents as a product/service (implemented as a licensed usage) to IP thieves at a lower cost than IP theft costs, where important IP like medical research is offered at a subsidized discount, to encourage different competitors trying to apply it the best/quickest

- offer extra data or future experiment participation options as a way of paying for experimental drugs

- drug pricing should be done based on difficulty of calculating/producing it with AI or other methods 

- taxing beneficiaries of lottery systems (crime lottery, with bail payouts to prison system & example payouts to politicians/media, given the occasional jackpot of an emotional imbalance that benefits them)

- the power structures of govt (structures to optimize to find an optimal govt structure)
  - functionality: ability to access function logic
  - permission: ability to call a function
  - value creation: ability to generate value, and distribute it to other functions
  - intelligence (in the form of freedom/potential, structured as an ability to move/change agent position, as in adapt/learn)
    - this ability to move requires detachment from a perspective, to be able to delete/edit/generate perspectives, and change between perspectives
  
  - we already have relevant structures:
    - permissions: basic rights & gaps in rule enforcement, which are sub-optimally enforced
    - functionality access: technology, products, education, information
    - value creation: resources like time & access to value-creation methods, or problems/conditions that adjacently (consistently) trigger value creation or value creation strategies
    - intelligence: in the form of optimizing/learning/adaptation functions
  
  - we dont have:
    - distributed resources (or resource-generators like intelligence, luck, permission, education, time)
    - automated permission/functionality correction/optimization/generation for a given system/intent (automatic program self-correction, like 'correct this problem in this network of AI models', which can be done with structural priorities to optimize or logic & test generation/automation)
    - automated value creation (can be done with independence machine, or proxies for components of it, with machines to filter water or plants engineered to perform those functions)


- organizing states/laws by market behaviors to generate laws on-demand & assigning them to entities organized by their market interactions
  - example: when x number of people participate as suppliers in this market, generate a law that protects them from attack types & prevents them from using above a ratio of attacks on other market demand participants

- example of applying interface analysis (core system layer graph) to generate new & useful applications of resources
  
  - tools:
    - AI/stats: prediction
    - interface analysis: understanding
    - automation: certainty
    - optimization: improving automatically

  - applications:
    - applying AI to select optimization algorithms
    - using optimization algorithms on AI parameters
    - applying AI to select network parameters for a task
    - AI as a conversion function, translating structures (data set to prediction function)

  - applying structures like 'combinations' to these components can help predict trend collisions & other problem types, as in the insurance example below
    - these components can be used in different formats (as objects & connecting/processing functions or interfaces):
      - using a prediction as an object:
        - a prediction object can be used as a target result, an input to a function, or a product in a market system
      - using a prediction as a function:
        - a prediction function can be applied to objects like technologies or other functions, or can be a product/target result, or a tool to achieve an intent
      - using a prediction as an interface:
        - once the other components are standardized to the prediction interface, other structures become clear, like:
          - the similarity of metadata between information & predictions (like usage or intent), meaning they can act as proxies for each other
          - the invalidation of prediction tools with cost-reduction tools like an appropriate optimization algorithm for a problem type

  - example of generating an idea using interface queries
    - idea: using single-purchase predictions as a cheap product that can add value to those without resources to train their own models (predictions for farmers about weather, water sources, market changes like demand/supply & competition/automation probabilities like 3-d printing or indoor farming tools)
    - define problem as 'agent doesnt know if the market/tech relevant to their business will change, or where to find inputs to their business like good weather, and has limited resources/access'
    - identify problem type: info imbalance
    - identify solution format: prediction, information
      - remove assumption 'agent has resource to train model'
      - identify 'resources that cant be purchased with agent resources, including AI predictions'
      - identify 'agent need to reduce uncertainty problem type, with information or predictions'
        - identify relevant resource 'prediction API'
          - identify version of relevant resource within agent limits (budget): 'call to prediction API' (applies 'subset' structure to prediction API resource)
            - identify resources necessary to use that relevant resource version: cell phone or access to someone with a cell phone, data, internet
              - apply check if the agent has or can borrow those required resources
        - identify relevant resource 'information'
          - identify version of relevant resource within agent limits (budget): communicate with business/agent with the information they need
            - identify resources necessary to use that relevant resource version: travel/communication expenses, tool to find entity with the required information, tool to differentiate false information or entity incentives to provide false information
              - apply check if the agent has or can borrow those required resources
    - identify secondary problem type: 'changing to alternate income source', with solutions like 'buying predictions/information and reselling to others in their previous position'

  - insurance
    - trends: quantifying trust as a tradable product across customers, customization of risk valuation, investment in tech for risk & cost-reduction to avoid costly claim payouts
    - integration (meaning) analysis can identify where these trends will collide, in various versions of implementations:
      - if trust is a currency, risk is customized with info tech like prediction functions, and insurance companies invest in cost-reduction tech, what will happen?
        - the value of trust depends on lack of info - otherwise if agents have all the relevant info, no trust is required
        - trustless transactions (guaranteed value) are an asset, with comparable value to trust (such as brand loyalty)
        - predictions can be an interface for manipulation - repeated predictions are likelier to be used as true information, and stakeholders are likely to make incentivized predictions seem or become true
        - info & proxies of it, like prediction function tech, is not equally distributed across all agents
        - insurance companies that invest in cost-reduction tech like AI or coordinating intents/optimizing systematic incentives are invalidating their product
        - invalidating their product builds trust with customers
        - they wont need their customers' trust if they also build optimized prediction tools at reduced cost, to distribute prediction tools equally across agents
        - at that point, the insurance company can profit from more expensive optimization & integration information/prediction products, like identifying market & regulatory optimizations to benefit their customers, which requires more resources than the prediction models their customers will have access to
        - optimization (such as cost-reduction) invalidates prediction markets (predicting value/costs) bc you dont need to predict costs if you have a tool (like an optimization algorithm) that reduces them enough
        - inference methods like interface analysis, as well as automation tech, reduce the relative value of all other products

- science

  - vitamin 3-d printer to print vitamins so that you can design your own multivitamin that:
    - fits your bio conditions & requirements
    - is released in the right order & timing
    - excludes interactions that are contradictory (antimicrobials & probiotics)

  - mask design can be optimized as a cover with one output flap like an esophagus preventing input on one nostril so the other can be used exclusively as an input with a filter 
    (better to sanitize at point-of-usage in environments with many unpredictable interactions like wind direction and interpersonal contact, which can get around most masks)

  - tool to make bacteria grow until detectable & then represent with AR

    - this closes the gap in information:
      - the information needed for the product (a testing & display tool) was insufficient
      - the mechanism to make the information sufficient is accessible (solutions to feed bacteria)
      - rather than make the measurement tool better, you can make the information more accessible (change the position of information rather than the position of the measurement tool)
      - the AR component would augment the size to make it displayable to users without using the measurement tool (microscope) or indicate size/type of pathogen with standard data visualization rules

      - applying the testing tool to hub nodes (then inputs/outputs of hub nodes, and adjacent objects to hub nodes) to check with increasing certainty whether surfaces were compromised
      - redistributing resources based on immunity/infection status to avoid cleaning, like distributing unchecked, unsanitized, or contaminated goods to consumers with immunity/infection 
      - keeping an animal likely to develop fast infections in buildings and then using air conditioner to distribute viral RNA when the building is unused and checking remotely if the animal shows symptoms to see if a building is safe is one way around the limitation to detect live copies of the virus, since the animal symptoms are easier to measure than a pathogen, so the problem becomes ensuring the animal will develop symptoms rather than immunity, and making sure the symptoms show up faster than a test done on hub nodes or quickened with enzymes/sugar/cells that help the pathogen replicate

- govt

  - depts of govt: 
    - optimization
    - research for existing/adjacent solutions
    - integrating intents/work/resources (cross-level, team, task, priority)
      - example: interim/imminent/adjacent/existing product analysis
  
  - with constantly updated opinion/priority/argument/reason/resource/problem data, you can have:
    - districts that choose their own voting algorithm & issues to vote on
    - calculated assignment of perspectives (opinion sets) to territories that can support those populations (as they grow in population, they can acquire more territory, and offer relocation assistance to people who want to live there)
      - perspectives can include priorities, focus of laws on certain topics (not regulating others), issues or decision methods (voting/optimization algorithms applied, automation applied)
        - socialist/libertarian perspective can have their own district
        - assignment of perspectives can be done manually by argument
        - guaranteed science jobs or jobs in local industries (according to climate or other resources)
          - guaranteed jobs can also take the form of offering relocation to places with jobs & education to get current/imminent jobs
        - jobs/industries/markets can be calculated by algorithm to determine jobs that add value to society as opposed to charging rent on positions (skills, information)
      - this applies competitive markets to perspectives 
        - if one perspective is successful & attracts citizens, it can have more resources
        - a perspective can be registered to compete if it has an answer to a set of common problems (what is the perspective's solution to war, jobs allocation, regulatory corruption)
      - optimization algorithms applied to voter data (opinion sets, voting metadata preferences like election frequency, resources, needs) & other data (neighboring district resources/opinions) to determine optimal position, interaction & state trajectory of the same
      - decisions on issues are based on scope & other metadata 
        - stakeholders vote on issues rather than objective third parties, the same information is given to all stakeholders
        - if a question cant be determined with science, its not eligible to be voted into law (cant vote religious issues into law)
      - weighted influence on decisions can be assigned to algorithms or systems (or attributes/functions of systems, like a particular priority) with a proven track record
        - smart people can have more influence on decisions, if theyre able to convince people to agree with them using an argument based on just facts & valid logic & have a history of successful decisions if this isnt their first public argument and if they can compete with an algorithm in terms of making better recommendations (based on past decision & decision simulation data), otherwise they dont have influence

    - the government or market can incentivize businesses to coordinate that could replace monopoly products (product-generation products to invalidate shopping/delivery services like medical/lab chemical printers, delivery/logistic products/services like drones, shopping/subscription/discount/purchase/shipping aggregation tool across multiple web sites (so they can make one order to multiple companies), similar to news aggregation/prioritization/merging, or structured content aggregation into a merged structure like a list/graph, product testing) without regulating monopolies themselves, but this may invalidate the potential profit incentive to develop those products in the first place, so should be used for non-essential products

    - monopoly

      - monopolistic products/industries/rules/priorities

        - products/industries/rules/priorities that can compete with, control, or replace all others
        - monopolies should be allowed to develop while their products are below an exploit ratio or are still improving/adding useful features, and while theyre contributing in other ways (research, open source, etc), and ended when theyre not

- automation

  - soon users will be able to select & add features to apps automatically, invalidating the app market
    - add a prepay option for features that can be built by a deadline if enough people prepay, as an alternative to monopoly abuse of power by not fulfilling user needs
  - automated product quality testing (to invalidate reviews & product endorsements from the platform) & faster delivery service as competition to amazon

  - browser optimizing web sites based on clear feature-execution mismatch created by malware or outdated code given origin code intent, a ratio of version/other change allowed, intent of site actions (not making changes that would break other functionality calculatable on the page)
    - browser configurations like versions/modes/settings applied for tabs

  - intent implemented on the web could look like approved workflows for accessing a site or across sites, where actions, requests or workflows can be pre-purchased and approved algorithmically 
      ('how to build a bomb' search isnt purchaseable with a 'purchase chemical' request or across purchase bundles)

  - product platform:
    - filters: predicting filters that will be used the most (features that differentiate products and alternate purchases the most)
    - products: product query language ('product with feature x and without component y')
    - supplies:
      - adjacent supply cost estimation ('adjacent product built from these suppliers would cost x')
      - estimate future demand & estimate cost of production methods (how many times will you need it? if above x, then its more cost effective to build it yourself, buy from these suppliers with price-lowering trends, buy this robot to make it regularly, or build a robot to do it - plus the timed sequence of those purchases for most cost effectiveness)
    - code as solutions:
      - code search (code as product solutions, like code to print a product or code to predict a compound or adjust vitamin combination as needed)
      - feature-to-code translation ('need a product with existing feature x and add new feature y')

  - multiple servers/processors in one computer with one-way data transfers, so one server can be for local communication, one can be for offline work, one can be for browsing internet, and local/offline can communicate to internet-browing processor but not the other way around

  - rules-to-code translation tool - translating domain-specific plain language rules to robot code can be short-term useful for automation of service industry tasks like:
    - converting recipes/flavor-mixing strategies to cooking robot code (chefs can use a tool like this to make money short-term or sell their rules, if they have unique strategies)
    - converting new plant designs to genome editing code
    - converting local social insights to global code (avoid personalities like this, use these tactics to persuade, make this argument to get them to an insight position, etc)
    - converting adaptation insights to change-attracting system adaptation code
    - converting routing mechanisms/optimizations to drone code (short-term human insights like 'avoiding a particular street bc of construction' that data isnt adequate for)
    - the general task of converting rule sets (systems) or human-made visuals (graphs, blueprints) to code

    - machine learning can be used for initial conversion, then tweaked with coded filters like priorities, logic, organization, output
    - system analysis can be used to optimize beyond those standard filters
    - this needs to identify existing rules (or specific versions of abstract rules, distorted versions of standard rules) & filter them out
    - this is an alternative & and an interim step to raw code-generation given a set of intents

- resources

  - https://phys.org/news/2020-11-digital-revolution-hundreds-millions-farmers.html
    - wifi trucks or wifi generating devices to deliver periodic or shared wifi if they cant afford the standard infrastructure
    - buying predictions/data from AI or api services that are received by mail or covered as part of basic mobile package, if they cant afford a cell phone/wifi/data bundle

- finance

  - pre-approved transactions on a schedule that give id service provider permission to update id
    - businesses contact id provider to check that id hasnt changed or get new id if its changed
    - then makes call to bank associated with id or updated id, which is expecting the transaction at that schedule & has already allocated/locked funds for that transaction
    - this means customers dont need to update card numbers or bank account numbers if prior numbers are compromised, but the id provider does need to track the original number & changes, and new numbers need to be unique across customers
    - transactions that are already configured/scheduled and havent been canceled are automatically approved
    - transactions that are implied/predicted (purchasing jacket if the weather is colder or moving to a colder location) have conditional pre-approval
    - customers can register their original id number with a particular business & optionally approve a budget with ratios of intents for transactions at that business/business type/product/product type, or range of transaction amounts, intents, types & other variables for their id number (by importing prior purchase histories or filling out new configurations or making new purchases) so transactions outside of that range arent allowed or have extra security intent layers applied
    - intents can be used to add validation to purchases (what are you buying this for? for event x coming up, which the calendar app api can provide validation of)
    - they can dis/associate other info with their id as needed (voting, address, purchase/subscription/transaction/configuration history)
    - using contribution to economy/markets/financial instruments/purchases/legal frameworks (like whether they can influence/create purchases or markets or product regulations) as an input to credit (indicating their value-creation potential)
