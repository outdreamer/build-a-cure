## Standard Neural Network Design for initial complex problem factor identification reduction
  
  - given that neural networks apply "apply, aggregate, & filter" functions to sort causative information into a standard shape like a tensor or vector set 
    (representing function variables generating an output variable)

    to identify sources of causation (like feature position or feature shape),
    
    how can neural network structure & algorithms be designed to generate a network & algorithm that is likeliest to be able to identify causative factors in the largest range of problem types?

  - there is an optimal network structure & algorithm that can handle the derivation of most causation shapes, since features aggregate in sets that have patterns between input features & output sets

  - the goal of optimizing neural network use is to identify the prediction function from as little data as possible

  - once you can identify an accurate prediction function using one data point (so its robust to changes in causation), the field of machine learning would be invalid

  - in order to do this, you need to identify:
      - candidate variables (cant verify which are actual variables without more data points)
      - variance patterns in the data point (one candidate variable leading to other candidate variables with net impact on overall variance)
      - causation shapes related to those variance patterns (causal loop, causal vector, causal network, etc)
      - priorities (structural priorities like aggregate, distribute, balance - functional priorities like align incentives, produce variance, optimize - conceptual priorities like change)
      - patterns, structures, generative functions, etc - all derivable objects on all interface layers
    - or any subset of these which can explain the complexity of the data point

  - given the profile of these derived interface objects, you can design a neural network that can identify:
    - the minimum information of future data points necessary to accurately categorize a new data point as belonging to the class of the training data point
    - the change patterns objects of this class are likely to display

  - so a neural network that can identify any prediction function takes these interface object derivation functions as input, and if they are above a threshold, 
    integrates them into a final decision of class & other metrics like 
      - change patterns
      - minimum information
      - optimal network design for this complexity level (which will probably involve fewer calculations than the 
        original classification calculation because not all information from derived interface objects 
        provided enough variance compression to be included in the final classification)

  - given that existing networks identify feature contribution, using metrics like feature position, 
    more accuracy in generating prediction functions can be added without extra computation using other interface object metrics like:
      - feature type
      - feature variance
      - feature priority
      - feature distortion
      - feature uniqueness
      - feature causation shapes
      - feature change patterns

  - this means a set of networks evaluating the contributions to final classification for a given complexity level or other system metric made by:
    - causal shape
    - change patterns
    - type stack
    - conceptual query

  - can produce answers to questions like:
    - which interface object combinations can be used to generate an accurate prediction function?
    - which interface object combinations map to which prediction functions?
    - which interface object prediction-function generating networks should be used first on a problem, 
      given that interface layer's higher independence/causation/variance-generation?
    - which problem types (conflict, alignment, asymmetry, lack) map to which interface objects?

  - so instead of doing problem-solving operations like:
    - get data
    - apply standard DNN or neural network structure designed by auto ML
    - use prediction function until no longer valid

  - you can run problem-solving automation operations like:
    - get data point
    - apply interface object derivation function
    - check if problem is solved
    - if not, apply interface-based neural network design function to generate optimal neural network for this problem until problem is solved, 
      at which point, store this interface object combination in index of solved problems
      and to make each new prediction, first apply interface object derivation function to each data point to format it 
      in ways that the neural network trained to identify contribution of interface objects to final classification can interpret
    - if problem changes:
      - generate new prediction function, according to previously identified change patterns of derived interface objects if they exist
      - re-apply whole process to generate the new prediction function or a neural network architecture to generate the new prediction function


  - if weight path patterns are a wave or other function - extra nodes between them add to the curvature, which is why adding extra nodes can add complexity

  - neural network nodes as facets of additional complexity/dimensions - calculating the complexity of a prediction function-determining problem (based on which distortions are likely from prediction function patterns) would allow selection of the necessary nodes
    - higher complexity requires that more combinations of weight path patterns be experimented on, and more nodes allow room for more experimentation
    - auto-configuring the network with common or data pattern-specific weight path patterns rather than random or equal could speed up training
    - reverse logic can be beneficial here - given the complexity of a problem, which features with which differences would have to occur for the training to be useful (or for the problem to be solvable)? check the data for those variable types/differences
    - use prior knowledge of patterns (insights like 'differentiating variables tend to cluster') as a way to organize analysis of the corresponding feature data pointed to by the insight (adjacent features are passed in to higher weighted node sets or node sets equipped to handle subtler differences)
    - different network or node sets can represent different problem-solving automation insights (one node can represent a 'differentiating variables' filter, another node can represent a 'cluster' verb/function filter)
      - if none of these node sets finds a pattern, the node sets can be recombined into new options (like another outer layer of a core function diagram) and re-trained
    - adjacent networks are created for stacked variables (like symmetry stacks, where features differ on a symmetry and symmetries are layered (like the hand-limb-spine symmetry stack)
    - phase shift points are identified first & the data is standardized around them - so when one type has extreme/compounding attribute values emerging as another type, that threshold is built in to the data (data near to that threshold is transformed to be higher to differentiate the types, or you add a third output category like 'transforming' or 'interim type')
    - possible causal shapes are identified first & the network is organized to fit them
      - for example, weight paths trained to highlight one attribute set are applied to other alternative equivalent attribute sets (an alternate causal route to the output)

    - what is the ratio of coverage of all possible feature interactions that is fulfilled by a standard neural network? what does the standard architecture reward in terms of clustering attribute sets for experimentation?
      - it rewards attribute sets that appear correlated in the data, with generalizations applied

    - should you use position as a determinant of feature importance? should position be removed from the data & another network trained on position-removed data?

    - would it be better to frame features in terms of system analysis (attributes, functions & routes)
      - an ear definition route can be framed as:
        - take other dimensions of change (than vision or taste) & assume methods to detect them (sound), then design a system (ear) based on efficiency as a priority to detect that change
        - stack a symmetry on top of the spine to make calculations & choose priorities, then stack another symmetry (face) on that symmetry (head) to host multiple change-detecting methods (facial features) to guide calculations
      - once you frame features in this way, training to find prediction functions should be trivial

    - can you partially reset the neural network mid-training to help improve generalization in addition to existing methods, so it doesnt tend too far in the data-dependence direction?
      - identify features that are likely to be data-specific, given whether the categories share that feature with different attribute values

    - training prediction functions on system data rather than data for objects within the system would add other gains
    ` - by knowing the structure of a system, you can infer insights like:
        - which object shapes are most compatible with the system
        - which forces/interactions are likely to evolve in the system
        - system metadata (stability, priorities, potential)
        - system info objects (assumptions, inputs, efficiencies, incentives, phase shifts, ambiguities, core functions, boundaries)
      - for the dog vs. cat classification, training on causal system data (the evolution system, the bio system, or the DNA system) might be a better target for the prediction function than training on images of the outputs of those systems
      - this analysis would help predict ambiguities (dogs & cats will have very similar features sometimes given how DNA & evolution works) and how to differentiate them (check for specific attribute sets in data, otherwise indicate that data is insufficient but here's the data you should gather for this problem type)
      - you might also be able to identify a sub-system that has the most valuable data for this prediction (mutation sub-system as a sub-system with a distortion function applied to the DNA system)


  - prediction model trained on conversations as encryption key/alg parameters, updated with new messages

  - how to check if a data set is similar to one that has already been trained, to avoid re-training to save CPU

    - store metadata about the data set like shape (groups/clusters, linear, random) and the metadata for those shapes (radius & overlap for clusters, distortion patterns & outliers for linear, starting point for random)

    - derive info metadata like type, cause, change patterns & check if determining/generative structures (core functions, symmetries, false similarities) match across the two data sets

    - identify patterns of variation once a similarity has been found, to avoid checking the whole data set
      - example: once you identify that both data sets have two output categories, what are the patterns of difference in the internal points of those categories (patterns in overlaps, misidentifications, corrupt/incomplete data, differentiating variables) - usually youre applying a categorization model to two categories that are very different (so its important to identify them correctly) but have some illusory similarities or features in common, making the categorization task non-trivial - so you'd look for patterns of differentiation within categories, to check if the data sets are approximately equivalent so you can use the same model without training - either specifically, storing patterns of differentiation for specific categories, in the model metadata, or generally, for general category differentiation patterns

    - store adjacent functions or specify a parameter range generated from the original function to identify functions that can be generated with accessible transforms or functions that are usually generated for similar variable sets (using common function patterns), to identify similarity in parameter values (using various types of parameters, at various layers on the causal stack, such as preceding functions like the function producing this function as its derivative, alternate functions like the series sum, or descriptive parameters like moment-generating functions)

    - identify function/data vertices, which are determining points like maxima/minima/inflection points as well as the minimum number of points necessary to identify the momentum of the curve, or points that indicate phase shifts in general

    - store semi-trained models and use them as vectors to create a complete trained model, without training

