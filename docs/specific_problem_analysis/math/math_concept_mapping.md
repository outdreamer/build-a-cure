    - formatting primes as the 'gaps in the various configurations of a four-sided shape; (produced by multiplying two integers) is a useful way to see patterns in the gaps, which are also 'intersections of gaps in various configurations of other factor sets within a range' which form structures similar to 'concentric circles'
      - finding the circular (repeated) structure in the riemann zeta function is probably relevant to the zeros & the primes, which may also correlate with these 'concentric circles' formed by configurations of four-sided shapes in factor range sets
        - this is also relevant bc the riemann zeta function looks like a connecting function providing the conversion between the structures of infinite connected change/curvature/continuity & finite unit change/constants/discreteness
        - this unites a lot of opposing conceptual structures which is why one reason its an important structure
        - another reason its important is that it involves a core structure (combination, as in 'sum') of core structures (units, as in 'integers' and 'constants') having a core operation ('inverse', to connect them with the imaginary unit, and 'exponential change', as in 'continuous infinitesimally small changing (curved) change') applied, and core structures/operations are usually important by default as input/component structures
        - you could predict that this function would connect change types 'infinite connected change/curvature/continuity' & 'finite unit change/constants/discreteness' by identifying that unit structures of these change types occur in the function
        - related questions
          - what relationship does this function have with adjacent variants of it (non-inverse, fractional powers or constants, different number types, different starting position, etc)
          - what emergent structures exist from the sum of these numbers (the maximum value that can be created with the 'addition' operation from the sequence values in this pattern)
          - how to frame this as a different operation type like multiplication rather than addition (area calculation rather than a sum of values indicated by a line), so that a multiplication problem can be formatted as sums of sequences like in some integration methods
            - variant: how to format the prime identification problem as a sum of sequences
      - the 'various configurations of a four-sided shape produced by two integer factors' is a useful way of producing curvature in their 'integrated tangents'

    - this is just applying any of the useful interface structures: 'change types' or 'generative structures' or 'symmetries', using 'change types that dont break a symmetry' as a 'filter' structure of relevance
      - https://www.quantamagazine.org/how-galois-groups-used-polynomial-symmetries-to-reshape-math-20210803/

    - apply 'physics' (energy) interface, 'function' interface (composability), 'logic' interface (requirement), 'system' interface (scalability, interactivity), and 'concept' interface (certainty) to 'math' interface

      - information is a form of certainty that has energy from various sources

        - energy sources include:

          - interactivity
            - if a structure is more interactive with other structures, its likelier to be required and can get energy from those other structures, although its also likely to produce energy if its highly interactive and may be self-sustaining
          - similarity
            - similar change types are likelier to be found near similar change types 
              - one of the reasons for continuity in a function with curvature
          - efficiency
            - if a structures has more useful attributes (like -1, 0, 1, 2, and 10), meaning it 'stores more information' than other structures with the same type of structure (differing just on 'position'), it is likelier to appear in more interaction rules (have higher interactivity)
            - reusability
            - scalability
              - if a generative function can efficiently create an infinite sequence or convert a non-infinite sequence into an infinite sequence or conduct infinity operations, it is optimally efficient bc thats the largest scale
          - requirement
            - if a structure exists by requirement, it gets its energy by default from the structures requiring it, so any energy it produces is a net gain
          - composability (unit that interacts with other units)
            - units interact with every other structure in an interaction space & with other units in the unit (type) space
          - standards
            - interaction with y = 0 (zeros) provides info about the behavior of a function in its default/standard form, which can be used to describe it efficiently

        - other structures are structures of energy distribution/storage
          - equivalent or similar alternates can share the energy distributed from another energy source and distribute it using an efficient method like a rotation function, or store it in its components (roots of unity)
          - given that infinity is a 'sequence that doesnt end', the opposite of infinity is a 'sequence that ends'
            - the structures that are semi or almost infinite indicate the boundary between non/infinite sequences
            - a similar structure is a closed vs. open shape, or a wave (or another function defined for all values of x) vs. a line with endpoints if infinities can be mapped to a regular repeating pattern by some parameter
          - what structure store energy the most (consumes energy in the form of inputs/information but never pays off, or just stores it), like a black hole, such as a set of numbers like the real numbers
            - self-sustaining structures like recursion structures
            - the opposite structures 'self-invalidating' or 'neutralizing' structures are useful in determining less efficient structures
            - the related 'boundary structures' (halting conditions, boundaries between in/finite sequences) are useful as filtering structures, so may be more efficient depending on the energy intent (energy storage, categorization, vs. energy conservation or 'cost minimization')
          - what is the 'qft' structure or 'meaning' interface of other structures than infinite sequences
            - what is the summary or integration structure that describes or forms a base or average metric of other structures
              - given that all interfaces have rules, and physics is the generative rule system, is physics a more effective 'meaning' interface than the meaning ('meta' or 'interface') interface, and for which intents
          - what structures correspond to pi (which represents the 'cost of creating a unit shape from a unit line, converted into an area (cost of applying the line to itself), by applying the default symmetry operation of rotation, as in "applying all possible changes within the symmetry"'), which is a particularly useful number (with high energy output)

        - example of combination structures that form other useful structures
          - an interactivity combined with orthogonal (applying 'maximal differences' as a source of independence) symmetries form the basis of default useful structures like 'rotation' functions (by connecting endpoints of the symmetries)

        - some structures make these energy sources useful for other intents requiring numerical structures, like:
          - ambiguities providing a source of obscurity/protection
          - uniqueness like prime numbers as a source of reference points

        - semi-information is:
          - 'allowed by the definition of a space'
          - 'has interaction rules in that definition, with its own type and with other numerical types'

          - imaginary units are useful in that they form an opposite structure of standard units, which can be useful for forming a spectrum or a limit filter structure

          - quantum superpositions may take the form of:
            - possibility interaction space: 
              - topologies (attribute value combination spaces)
            - mixed certainty/uncertainty: 
              - attribute set cross-sections (combinations of interfaces/types/variable structures & attribute value structures)
            - uncertainty addition: 
              - variable injections (allowing variance of a constant)

        - these energy structures follow other energy patterns, like energy dissipation/distribution & energy storage
          - if a number has more energy than its structure can contain, it may distribute it into a system of related numbers, like components or variants
          - this implies there are input/output sequences in terms of energy flow across math structures, which may reveal intent structures of matter, just like how some math structures have useful outputs for human intents like 'security' by 'obscuring inputs'

        - math structures are a form of energy that is useful/interactive/similar/efficient/required/composable/standard in some way, so it acquires & maintains a stable structure
    
    - similarity of structures like data type in connections (like how 'absolute references' are a possible connecting structure between absolute structures like 'infinities' and referential structures like 'ratios' or 'constants')
    - imaginary unit as a unit of non-definition, or non-structural definition (requires a different axis to portray bc its not defined in the original axes), or a unit of isolation/independence from a dimension set
    - numbers as symmetries given the adjacent change types available to them, and math as the interaction space of these symmetries, where values that dont have structure can exist between the interactions of these symmetries but only while they can maintain a lack of structure & interaction
      - math helps with calculatable problems
      - there are limits to what math can calculate, bc there are limits to the interaction space of number types
        - like how 'integers' and 'infinities' can interact bc you can have 'multiple infinities' and 'infinite integers' and so on, but not every number or number type/attribute can interact like this, in such a clearly defined (structural) way
        - for example, the 'root of negative infinity' is less structural than the 'root of infinity', and the 'root of infinity' is less structural than the 'unit of infinity', bc the less structural interactions require special definitions/limits creating spaces in which they can exist, rather than having structure in a high ratio of spaces
      - relevant questions
        - can you extend the direction of reductions in structure in the interaction space to determine the limits of structure
          - does it reach zero structure at its limit
          - does it extend indefinitely by definition, bc of the lack of structure and a corresponding lack of limits enforcing structure to exist/develop
          - at what point do the requirements of the 'special definition' prevent any structure from being defined?
          - is the interaction space continuous (does it form a topology)
      - some questions (lack of structure) cannot be adjacently resolved by any combination of known structures (such as ambiguities that are more efficient/stable than any structure that can deconstruct them or any input/output structure)
        - is this an absolute limit or does it result from logical flaws, lack of info, or other errors
        - example: calculate interactions of infinite sequences (like in quantum field theories) with perfect accuracy in less than x time type
          - in order to calculate these interactions, the following would be necessary:
            - rules about sequence interactions (why one sequence is adjacent to another, if there is such a rule, and how they can be combined)
            - info about the probability distribution or function that could generate the sequences
            - rules about combining infinities, where each infinite sequence could be defined as an object in the space of infinities
            - rules about interactions in a space that compresses to other relevant info about the sequences
              - meaning alternative compressions than the value/sequence attributes of generative functions, progressions or probability distributions
              - rules about other interface structures than the values or the values' attributes themselves, such as structures like:
                - requirements/opposites & other standard structures
                - alternative equivalents
                - approximations/probabilities
                - difference topologies (rather than infinite sequence value topologies)
                - rules about the system where these sequences could exist rather than the values that exist in the system
                - the structures (of differences & patterns & other useful structures) in the sequences/values that would be impossible, possible, adjacent to calculate, and adjacent functions to determine structures of calculation impossibilities/possibilities/adjacencies in the original topology
                  - finding the structures of sequence sums that would be adjacently calculatable creates a test that can filter out structures that are not adjacently calculatable, like finding local minima using gradient descent
                    - this is an example of why other system structures than input/output sequences/networks are useful, such as the 'structural similarity' of 'gradient descent' and 'filters of structures of adjacent calculation potentials'
          - if there is an ambiguity that defies calculation (without checking every value), it means there is a certainty in its structure of uncertainty (like an ambiguity between a 'random generative function' and an 'input structure that generates output that seems random') that can be relied on to calculate its attributes (like requirements/limits, such as 'equal distribution of outcomes as trials n increases'), if not its actual output values at a given input
        - in terms of graphing these structures, a space where every variable can be reduced to a spectrum with opposites indicating a difference type would be able to visualize these structures
          - a variable indicating additional operations added to a function, where each operation has an opposite, and each operation adds a change type, still doesnt have an inherent ordinal value indicating how far from the origin it should be, unless there's a clear association in increases in complexity/potential between change types added by each operation
          - the definitions of 'ambiguity', 'inevitability', 'intent', 'output', and other structures may allow visualization in a mathematical space without using vectors or networks, if their definitions can be mapped with opposites & incremental increases in an attribute with an inherent ordinal ranking and a zero value having no structure
            - ambiguity: 'lack of differences in alternatives (different options)'
            - inevitability: 'lack of alternatives (different options)'
            - requirement: 'exclusive trigger'
            - output: 'subsequent causal node'
          - if 'lack' can be mapped to the negative direction, the other structures can be mapped to structures of certainty (largely in the form of logical sequences & variables as useful axes)
            - 'output' creates a certainty in the form of a sequence (as in a 'guaranteed product of the cause')
            - 'requirement' is a 'certain input' if another structure occurs (a function is triggered), which is also a sequential structure
            - 'ambiguity' is a lack of 'structure indicating difference between different objects', meaning the differences cant be mapped in the current space, indicating the structure of a sequence of a 'conversion' (like 'adding a variable') before the difference can be mapped, which makes sense bc it offset the 'lack of structure indicating difference' (a variable), and if change types (variables) are mapped in this space, this can be structured as a function converting the current or previous change type value to the required change type value

    - example specific math-concept function mapping:
      - https://www.popularmechanics.com/science/math/g29251596/impossible-math-problems/

      - 'is gamma rational' problem
        - this is a problem of determining how operations on numbers with attributes produce numbers with attributes
          - a 'limit' operation applied to (harmonic series - natural log) to find its 'converging value', which may or may not have 'rational number' attributes (can be a relation between integers)
        - if one attribute of ir/rational numbers is contradicted, that would be a sufficient proof
        - the 'patterns of differences between ir/rational numbers' would be a useful structure to prove if gamma is rational
        - related question: are pi and e a unit case of a number type, like a gap in a set of number sequences such as 'core integer relations' (rational numbers) - if so what are the operations used to combine those numbers in a way that invalidates or preserves their attributes?
          - pi is the number that can be used as a coefficient to convert a square's area (r squared) into a circle's area (pi * r squared)
            - a circle's area is a transcendental number * an integer power of a number
            - pi is how to relate a number to the area of a shape created by:
              - rotating that number
              - connecting the midpoints of its original area (r squared) in a continuous convex curved line
                - related question: what is the relationship between r and the area of the associated concave shape
          - the relation between the radius r and its circle's area is specifically 'not an algebraic number'
            - why would the number creating this relation (pi) not be algebraic (multipliable by itself an integer number of times to be an integer)
          - relations between a number (that is algebraic) and the generated areas producible with it are probably lacking an attribute of circles, like curvature
          - why would a transcendental number produce curvature when applied to a square?
          - what other numbers produce curvature when applied to a square & are they of the same or related types or have attributes in common with transcendental numbers?
          - exponents are a factor in curvature in polynomials bc of interval patterns in sums of sequences ('curvature' defined as 'differing adjacent differences in change rates')
          - why would pi produce 'differing adjacent differences in change rates' when applied to an area? it doesnt have to be represented as the area of a circle 
            - can the area of a circle be represented as an area of a rectangle or other shape producible with just integer factors, or can it specifically not be and is an 'interim structure' just like primes are an 'interim structure' that cant be represented as an area of integer factors or the sum of sequences?
              - related question: is there a sequence that sums to or converges to pi, and do you need to use specific number types like transcendental numbers to generate it

      - 'is (pi + e), (pi * e) or (pi / e) transcendental' problem
        - algebraic definition: numbers that can be multiplied by themselves (an integer number of times) and multiplied by integers to equal integers (vs transcendental numbers, which cannot)
          - this definition can be reduced to: numbers that can be multiplied by themselves an integer number of times to equal a rational number (integer constant divided by integer coefficient) in the unit case of a polynomial with one term
          - rational numbers (relations between integers) and roots of rational numbers (rational number powers of rational numbers) are algebraic
          - pi and e are transcendental, but operations of them are not definitely transcendental
            - 'pi + e' cannot definitely be multiplied by itself/integers to equal/not equal integers
              - alternate version: an integer multiple of (pi + e) to an integer power doesnt definitely equal an integer
        - this is a question of finding 'invalidating conditions' that 'prevent number types from being operated on to produce different number types'
        - this is related to the definition of 'rational numbers' as 'relations between integers' and the rule of 'multiplying an integer by an integer equals an integer'
          - a rectangle with an integer side and an integer side produces an area that is an integer
          - a rectangle with an integer side and a pi side produces an area that is not an integer
          - if it cant be represented as a fraction of integers, it cant be used to form an integer area using just multiplication with an integer
        - a related question is 'can shapes with equivalent non-integer sides (areas, cubes) be used to produce an integer given simple operations like multiplication by an integer'
        - a 'connection between rational/transcendental numbers' is a useful structure to solve this and connect a possibly transcendental number with 'integer relations' (rational numbers)

      - large cardinal limit problem
        - the size of an infinite number type set varies across sets bc some number types have more members
        - this can be formatted as 'what types of numbers can form infinite sets and what types cannot'
          - the implication is that if there are non-zero types (at least one type) of numbers that cannot form infinite sets, there is a limit on the number of large cardinal number types/sets (it is not all number types)
        - by definition a number type refers to a subset of numbers (or it wouldnt be a type, it would be an inherent attribute of all numbers)
          - the resulting question from this definition is 'are there infinitely many subsets of numbers that have infinite sets'
          - a 'type' is a compressing attribute describing a 'subset', but a number can have multiple 'types'
          - how many possible number types are there having infinite members in the set of numbers in that type
            - related question: how many possible combinations of attributes can be combined into a type (producing a 'number type')
          - a 'type' varies around the symmetry of a 'definition of an object'
            - how many ways can a type vary around the 'number definition' symmetry?

      - unknotting problem
        - this can be standardized to a problem of identifying structures that prevent change types (or 'moves')
          - as in, once a structure is in a particular knot type (having various core structures like overlaps, intersections, twists, & loops), which moves arent possible, and what formats can be produced by changes given the available operations once those operations are limited
        - it can also be formatted as a question of 'which change types or structures like overlaps prevent neutralizing structures from being applied'

      - kissing problem
        - this is a problem of matching the rate of change in the definition of a sphere (an 'object that can be adjacent to another object in a containing object') with the rate of change in the definition of a dimension (a 'possible change type', such as 'in a straight line' in 2d bc theres no possibility of a non-straight line, its excluded by the definition of 2d & the resulting change type possibilities & change type interaction possibilities)

      - swinnerton-dyer theorem
        - elliptic curves are a unit case of 'higher-dimensional inputs (power of 3) generating lower-dimensional outputs (power of 2), having more than one opposite value (roots of y squared)'
        - elliptic curves add an attribute of obscurity in their outputs by having more than one possible output (two opposite factors of y-squared)
        - another useful structure related to encoding info in low dimensions is a sequence that converges to a particular number, or a wave/circle with a magnitude/radius but obscurity in position (which particular peak in the wave a y-value occurs on, or which particular point on the circle given its equivalent distance from the center)
          - this structure enables high-dimensional inputs like sequences to be highly varied but produce the same output bc they converge to the same number (have a symmetry around the number)

      - riemann sum
        - related questions
          - why would the sum of inverses of squares (like an 'area') equal a factor of (pi squared)/6?
            - inverses are related to the natural log base e having its area summed across consecutive values, and e is related to pi
          - how is the riemann zeta function for complex numbers connected to other structures:
            - how is it connected to the unit case sequence with power of 2? is it connected by the symmetry of the root power (1/2)?
            - is the unit complex structure of 'roots of -1' related to the 'roots of unity' structure, which occur around a circle?
            - what is the connection to primes having difference patterns centering around 6?
          - why is 6 a relevant number? is it bc its:
            - a product of a unit even number and a non-1 odd number, or bc its the first multiple of the first non-1 odd number
            - just big enough to allow for more than one different difference types to generate primes (1, 5) having a unit distance (2)
            - inherently related to other relevant connections between pi and a circle, the rules of which are an input to this theorem, so those connections impact these connections
          - how do you prove the behavior can be represented as a circle/wave, indicating its a structure of infinity?

      - twin primes
        - standardized version: the 'prime differences equal to the unit even number' is an infinite sequence
        - related rules:
          - standardized definition of a prime: an integer (number divisible by 1) with zero other factors (a unit integer having zero factors)
            - this means a prime can be described as just an integer, excluding other factors bc it has none, and the 'integer' definition replaces the 'factors': [itself, 1] attribute, so you could call it a unit factor integer
              - prime: 
                - 'integer': true (or 'factors': [itself, 1])
                - 'other factors than itself and 1': []
          - standardized definition of a related number type unit (2): 2 is by definition a prime (or unit factor integer, having itself & 1 as a factor) and an even number (bc its divisible by 2 and it happens to be equivalent to that divisor, so itself is a factor of itself)
          - structures of infinite sequences that have regular value attributes (like a regularly occuring pattern in 'prime differences') like waves or circles are a useful structure for depicting patterns with no contradictions or end conditions
        - example of determining a rule excluding prime candidates using operations applied to another rule excluding prime candidates
          - what is definitely not a prime (definitely not an integer with only itself & 1 as a factor)? even numbers
            - what is the connection between even/odd numbers? a difference of 1
            - what is the connection between even numbers & a partial sequence of even numbers (6x)? differences of 0, 2, or 4
            - what is the connection between odd numbers & this partial sequence? differences of 1, 3, or 5
              - what attributes do each of these differences from the partial sequence produce?
                - difference of 1 from a multiple of 6 = odd
                - difference of 3 from a multiple of 6 = odd, with a factor of 3 (which is a factor of 6)
                - difference of 5 from a multiple of 6 = odd
              - one of these differences disqualifies a number from being prime (having only itself & 1 as a factor)
        - by applying change operations (difference, partial, sequence, factors) to connect these objects, starting from a limit condition, we've reached another object of the same type (a limit condition)

      - goldbach's theorem
        - standardized version: every even number (greater than an even number that is only the unit prime away from the unit prime) is a prime away from another prime
        - alternate version:
          - 'every number with a factor of two can be generated by summing a pair of numbers that cant be generated by non-self and non-1 factors'
        - related rule: 
          - the distance from an even number and a prime is odd, so when added to another prime (primes always being odd), it creates an even number
        - possible related rules, given implications from the definitions:
          - there may be a rule connecting factor types of combined numbers having the same type
          - there may be a rule about combining numbers that also applies to combining their factors
        - related questions:
          - why would every even number have this prime distance from a prime?
            - when an even number n is low, the even numbers are more similar to the primes (meaning even small primes are useful in summing to them) and primes are proportionally common, related to the number of available numbers less than n
            - when an even number n is high, the number & variety of available primes that can be summed to them is higher, allowing for greater probability that each even number can be summed with primes
        - solution metric:
          - these rules allow for the possibility of an even number resulting from a sum of primes, but doesnt require it for every even number by definition, bc the definitions are incomplete 
            - an even number should be definable in terms of the sum of primes given that the theorem is true and an even number is equal to the sum of two primes
          - by definition, summing two odd numbers will produce an even number, which applies one attribute of primes (theyre always an 'odd' number except the unit exception case given low availability of factors) & and the definition of the 'sum' operation, but not every attribute of primes
          - it should be provable using every attribute of the definition of primes, bc every attribute will contain info related to the solution success cause (the reason 'why it works' or 'why its true')

      - collatz conjecture
        - the key variable is not that it 'always arrives at 1' but that it 'always arrives at an input to 1, like an even number that when halved will always produce 1' 
          - an odd number multiplied by an odd number + 1 will produce an even number, which makes it less unlikely that the even number triggering the 'even number sequence leading to 1' will be produced
          - sub-problem: finding triggering numbers (like 8 or 16)
          - sub-problem: finding odd numbers that when multiplied by an odd number + 1, produce the triggering numbers (like 8 or 16)
          - sub-problem: finding out if these odd numbers can always be produced by the sequence, which is the key question to answer (or its opposite, finding out if theres a starting term that prevents these odd numbers from occurring in the sequence)

      - proof using radicals
        - related questions
          - why are rational coefficients relevant for the 'relevance of permutations of roots where any algebraic equation involving roots is consistent after permutation'
            - number unit (integer) relationships (like rational numbers) are relevant to the consistency of unit relationships having number unit (integer) coefficients
            - standardized version of permutation requirement: the 'unit relations' of roots must be consistent when the root positions are changed
            - the number unit relations hold despite position changes bc their relations (differences connecting them) are similar, given their common symmetry
          - why is the symmetry of an average between the roots relevant for this consistency?
            - bc the symmetry in roots produces a cancellation of non-integer terms and the multiplication of square roots produces an integer, which when combined with the integer representing the average is also an integer, so the operations dont require a change in number type, meaning the relationship of A multiplied by B is likely to contain rational coefficients
          - 'change within the range of a symmetry without breaking the symmetry' is a common structure used in other equations/definitions
          - why is 'associativity' a relevant attribute, indicating the relevance of 'groups' to this proof? bc changes are being made and the changes need to fulfill the metric of 'not changing the output'
            - so you could select 'associativity' as an important attribute of a solution structure, given that youre making changes that need to not change a related connection

      - prime number theorem
        - related questions
          - why would ten be a relevant standard to frame other numbers in terms of?
          - the theorem frames the probability of a prime less than n digits in terms of the inverse of its value in terms of powers of 10 (log 10 ^ n), where 10 is a standard that is required for the definition of a digit
          - why would e be a relevant standard to frame the area of the unit inverse function (1/x)
          - why is e a relevant structure to the prime number theorem? bc it involves an inverse function, n / ln(n)
          - why would comparing a number standardized to e and a number standardized to 10 (to the power of the digit count) be relevant? bc it 'connects' the concept of an inverse and a digit count

          - why would it be true that as x increases, it is less likely to be prime? restate it in different formats:
            - related rule: as x increases, the number & variety of factors that can be multiplied to generate it will increase in most cases just by the attribute change of its size being larger (for example, 6 can be used to generate 12 and both 6 & 12 can be used to generate 24, which is larger than 12)
              - given the variety of factors increasing, the number of different factor combinations (producing possible differences in outputs) increases the possible areas created, covering more integers, just like an increase in size increases the possible areas created
              - problem format: this problem can be framed as 'find the integers that cannot be formatted as a rectangle made of unit (integer) components'
            - related rule: the probability of a number overlapping with a number sequence like 2x or 3x or 4x is likelier the larger it is (3 can only overlap with the 3x sequence but a larger number like 12 overlaps with all three sequences)
              - problem format: this problem can be framed as 'find the gaps in overlapping number sequences of 1 ... x where x is the coefficient and find the patterns of these gaps'
            - related rule: the probability of a gap in increasingly large integer areas x of a rectangle (an integer not representable as an integer-sided shape) is less likely the larger it is
              - problem format: this problem can be framed as 'find rules allowing existence of a prime number x given available multipliers smaller than x'

      - godel's incompleteness theorem: 'this statement cannot be proven true'
         - examine alternate interpretations of incompleteness theorem statements & implications:
          - 'has to use terms outside of the definition to define the object'
          - 'the definition has to exist in a system where contradictions to it can exist'
          - 'are there non-mathematical structures (cannot be standardized to math interface) that are necessary for describing math structures'
          - 'structure only has meaning in relation/reference to other structures'
          - what about recursive definitions with no halting condition defined or triggered
          - apply the definition of absolute/contextual/alternate/potential meaning to this problem
          - finding a system to define/prove the rule set is required if the rule set has a false paradox/contradiction in its definition, which is resolved with conditional logic
        - structural version: this is like a structure (such as a curved line) that forms a lack of structure (like a gap inside a circle when the line forms a circle)
        - standardized versions:
          - 'this statement cannot be defined with a structure of truth'
          - 'this statement is not subject to truth derivation methods'
          - 'this statement cannot be structured'
          - 'this structure cannot be structured'
          - there is an inherent contradiction given the definitions of these terms
          - if true (it cant be structured), it cant be a structure
          - if false (it can be structured), it can be a structure
          - whether it can or cant be a structure is taken as a variable in this system
          - in what system would this be a variable of structure? where this structure is 'not guaranteed' but also 'can occur', and both states can occur simultaneously in different system positions or sub-contexts, sub-contexts that may invalidate the host system context
            - it undoes a meta self-reference by replacing itself with its definition or lack thereof as required by the system, using abstraction or structure as needed
              - so it places the responsibility on the 'system context' as being the 'structure responsible for or capable of determining truth', rather than the statement being the 'structure of truth'
              - this interacts with the requirement that any statement necessarily has a system context where it can exist (have structure/truth) in, rather than being independent of a system context
              - if it doesnt have structures of truth (like stability across varied system contexts, such as where its been proven true/false or is capable of being proven true/false), it is less likely to be absolutely true (true in any context where it could possibly exist)
        - alternate version: 
          - when a proof (or a definition in general) has to use itself or its definition as a reference to explain itself, it cant explain/define itself
          - this is like a structure that says 'I dont have structure' a statement that contradicts the concept of 'making a statement about its structure' (a structure which involves having a 'connection' between objects, which is a structure, and 'missing' objects, which is also a structure)
            - saying 'I dont have limits' is a limit structure that prohibits 'any structure with limits', so 'I do have limits' in that I have to follow the limit that 'I cant have any limits'
          - 'self-description' involves the function of 'checking if the description is true' and in the process of 'checking a self-descriptive statement', the object has to recurse
          - 'this statement cant be limited in a way that will make it definitely true'
        - variants:
          - true
            - if true, (meaning 'it cant be proven true') 'this statement cannot be proven true' is:
              - true in the sense of its definition as 'true'
              - false in the sense that its definition contradicts its application/usage in a particular system context structure ('once its proven that it cannot be proven true')
              - once 'proven true', the statement has a new state in a new context where it was proven true, meaning some component of the statement like 'cannot' was incompletely defined and applies only in a particular subset of contexts
          - false:
            - if false, (meaning 'its proven true') 'this statement cannot be proven true' is:
              - false, in the sense that it 'can be proven true' (it 'contradicts the original statement', so its by definition 'false')
              - true, in the sense that 'its proven true' by a prior operation of 'proving it'
                - so "'this statement cannot be proven true' is a true statement that is proven true once its proved"
                  - this embeds the reference to the original statement in a new context where it "is a true statement that is proven true once its proved"
              - the statement has a new state which is that 'its proven true', so its the new state that is false in the new embedded context ('cant be proven true' is false once 'its proven true' has occurred)
        - the structure of this problem is incomplete - its not just a rule to prove (with a static related set of axiom rules used to prove it), but a system network structure that the rule exists in (as well as the axiom rules)

      - continuum hypothesis
        - when something is both true and false in a system using different rule subsets, there is usually a structure of incompleteness in info, such as:
          - one version that is more relevant/useful or has a higher number of other structures of truth, like interactivity, stability, reusability (occurrence in other systems) or fulfills inputs of structures of truth, like similarity/commonness
          - a hidden input like an assumption that is not identified in one rule subset vs. the other rule subset
          - a different implication of the output that is misinterpreted to have more structures of truth than it actually does
          - a missing rule/variable/structure like context in the system that would differentiate the two or contradict at least one
          - the two versions are sub-components of the same system context:
            - 1x + 0x = 1x and 0x + 1x = 1x are equivalent (in a system where 'sequence is irrelevant')
            - 'evil is good' and 'good is good' are both true (in a system where 'the definitions of objects arent clearly defined or when contextual evil is applied in the wrong context, negating it')
              - example: its evil to steal in the context 'when you dont need it' but in a different irrelevant context like 'when you need it in order to do something good', it would be the right thing, a context that invalidates the structure of evil in the first context ('stealing') bc the definition of 'stealing' is 'taking something undeserved' but in the second context, that definition is negated bc 'its deserved' so its not stealing in the second context, and doesnt match the first context's structure of evil ('stealing') which is only evil in some contexts, so its not the definition of evil, just a structure that evil takes in some contexts, so it shouldnt be applied as the definition of evil in other contexts where that definition is irrelevant bc the structure has a different meaning

      - four color theorem
        - the key solution metric here can be:
          - whether an 'equivalent component' interaction type (two adjacent nodes having the same colors) is required to color a graph having the input graph restrictions
          - whether the most reduced graph (removing guaranteed irrelevant position values, like the "outer border nodes having one connection") requires the 'equivalent component' interaction type
          - whether any interaction structures created from allowed interaction types match the graph structure
        - input (graph structure) restrictions:
            - number of connecting nodes allowed
            - interaction structure type allowed (such as "no surrounding/containing/overlap/stack/merge structures allowed, only isolated bordering structures")
            - interaction types allowed (every different combination of colors, where the combination has size 2)
              - interaction layers emerging from restrictions & variables, like concentric circuits connected to at most to adjacent nodes on the same circuit & two other circuits

      - fermats last theorem:
        - why would the "sum of a pair of interaction spaces (areas) created by equivalent integer multipliers (integer x multiplied by itself once) equal the interaction space of another equivalent integer multiplier" have many solutions, whereas the same formula with a different exponent (3 as opposed to 2) doesnt have any solutions:
          - possible structural answers involve:
            - probabilities based on structural similarities using definitions:
              - unit cases are likelier to be representable with units (integers)
              - insight 'adding more dimensions to a problem creates more complexity that cant be captured with integer coefficients' (just like adding self-multipliers in the form of exponents creates curvature)
              - derivate of first is a constant whereas derivative of the second is another exponent term which is less likely to have integer solution
        - why would the solution involve elliptic curves?
          - bc of structural similarities like 'elliptic curve parameter patterns are related to wave functions (polynomials) which are created with exponents'
