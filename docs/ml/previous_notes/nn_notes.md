- examples of other types of operations a neural network can support including 'interface operations using interface structures', which are particularly useful for a neural network to implement as they fulfill useful intents such as 'resolve errors', 'add functionality', or 'fulfill a solution metric'

  - Ideally all of the following example solution metrics, conditions, & other interface structures would be supported by a neural network, with various structures like 'injecting interface structures' & 'allowing communication with other networks or generation of networks'
  - Functionality to select between alternative priorities by the functionality gained from that priority
    - example: maximizing the number of functions supported by a network (varying constants like weight sign to allow different operations) vs. maximizing the number of emergent/conditional/compression/other function types supported by the network vs. maximizing the number of error types avoided by a network in a variety of data cases vs. covering the functions necessary to cover the functions required to quickly converge to most prediction functions is a useful set of limits to apply when filtering possible networks
  - Functionality to derive insights, even if the insights are certain and can be applied as preprocessing functions rather than in the neural network
    - neural networks are for resolving uncertainties to find rules in the problem system, but insights enable this process to be optimized, and the uncertainty of 'finding insights to optimize neural networks' or the uncertainty of 'selecting which insights to find/apply' are likelier to be more valuable uncertainties to resolve than the original problem
    - example insight: different label ratios create a higher likelihood of predicting the more common label bc networks dont have a structure to handle this, like an input-representation-ratio metric included as inputs by a preprocessing script or derived by the network itself, such as through a function that calculates what percent of the dataset contains that label or a structure that emergently calculates the same (like a function that amounts to evaluating if the ratio of a predicted label is too similar to the ratio of that label in the training data set, beyond what the test set implies), (preprocessing functions like a commonness type evaluation function to evaluate what the source of commonness is and whether that source is legitimate to influence the weight changes toward a particular output or a standardizing function that removes various illegitimate sources of commonness), and then adds it as a feature after a layer containing these functions, which would likely discover such associations as false and being attributable to data ratios rather than meaningful connections that should be included in the output prediction function
    - this type of insight can be injected into networks by force (designing the network to apply the insight), but it can also be discovered by particular neural network structures (emergent functions), and given that new prediction function-correcting insights will always be in-demand and should be considered part of the responsibility of a neural network, given their potential to discover them if used & built correctly
  - Functionality to discover the right variable interface level at which most of the variation occurs (variables like position/angles for facial recognition) & retain that variation
  - Functionality including interface operations like:
    - merging the high-variation variable interface with the interface containing the specific functions creating that variation or the standard functions of the network (aggregation, pooling)
    - removing interface structures like the 'requirement' structure to identify concepts like 'play' (unrequired activity without a required point/intent like 'survival'), this concept being useful for optimizing resources to exercise/learn when not used for other intents, which is a useful system design insight that networks should integrate
    - identifying useful concepts like the following, and identify the set of concepts that are useful in optimizing the network system:
      - 'sharing' which allow it to coordinate with other networks to optimize various metrics (this concept having requirements in the form of other input concepts like 'other networks' which requires the concept of a 'network' for the network to be able to identify this concept), and apply these concepts to its own structure ('learn a more optimal network structure' such as by including them in the input or by changing its structure/params to consistently create these concepts) to enable learning other concepts
      - 'helping' which allows it to identify extremes such as 'fighting other networks' as sub-optimal and identify when another network is not helping it but rather exploiting it so it can defend itself against exploits/hijacking
  - Functionality to find operations like the 'attribute removal' and 'attribute generalization' to identify concepts like 'type'
  - Functionality to find useful structures like similar structures across interfaces for intents like:
    - a 'priority' -> 'hierarchy' -> 'tree' -> 'overlapping sequences with fixed end point' -> 'rotation with fixed end point' -> 'circle' -> 'symmetry about the center' -> 'direction' -> 'priority' connection structure for intents like 'find a structure to model a priority or hierarchy'
    - a 'combination into one output' -> 'tree' + 'overlap' -> 'network' + 'select/summarize/filter' -> 'neural network' connection structure for intents like 'find structure to integrate multiple outputs of trees'
  - Functionality to find common distortion functions of features like 'corruption around a symmetry'
  - Functionality to identify useful structures as particularly powerful structures applicable across neural networks/intents/problems, and finding alternative optimal paths to generate these useful structures like the following paths (which are solution automation workflows), if these concepts/structures like 'useful structures' and 'insights' are injected as inputs or built in to the network structure emergently by creating a network that priorities creating/finding/applying useful structures or by other function sets amounting to the same
    - apply useful structures like input/output sequences to problem-solving structures like problem-solving intent functions
      - find structures like 'similar' that implement/enable or are inputs to core problem-solving intent functions like 'connect', such as finding structures with similarities that may be relevant/useful in 'connecting the problem/solution'
    - find alternate structures of 'usefulness', like structures of 'obviousness', such as structures which make clusters linearly separable or highlight differences by maximizing them, & developing functions to find these structures
    - start by solving a unit case & generalize
      - start by solving for a function to find functions to connect input/output pairs that are connectible with adjacent/simple transforms, and find a function to generalize unit cases (generalize by 'removing specific problem attribute values such as inputs or requirements, like the number of inputs') and apply this function to the first function
    - specify inputs & outputs
      - specify solution outputs to restrict possible outputs: specify a range/area of functions for a network to find a prediction function within, which has a particular error rate across data subsets, without varying on any function subsets that are more certain/calculatable
        - if the outputs are more restricted in this way, the network can identify optimizations for those specific outputs like 'calculate the impact of a de/activation decision and if it contributes significantly to violating the specific solution function error range with other decisions being made in this iteration or likely to be made in future iterations at that point, prevent it'
    - identify alternate function sets
      - identify alternate functions (like a set of useful testing functions, a change function, and a selection function as an alternative function set to the functions of a neural net) to fulfill a problem-solving function like 'connect the problem inputs & the solution output'
    - apply insights from other systems 
      - identify alternate systems (like physics) with the complexity to delegate functions like 'generating new change types' to that system, or alternatively identify a system that is the source of problems solved by neural networks, or alternatively generate a system that could be the source of problems solved by neural networks, in order to use that system info to optimize neural networks & derive intent/meaning/usage of neural networks, derive other networks & coordinate with other networks, and develop self-awareness in that system
    - identify useful structures for core standard intents like 'identification' (such as 'identifying whether something has changed') or core specific neural network required intents like 'identify change' or 'identify change contributed by a unit (node)'
      - identify the concept of a 'derivative' by identifying the following, and identifying variables to compare it to (previous success, time, other input variables)
        - the useful structure of the combination of a 'change' and a 'comparison' to derive a 'change rate' concept by identifying the relative low value of change information when not compared to another type of change ('the meaning of a change, compared to what')
        - the requirement to identify change to test if a weight update improved the solution ('meaning of a change, compared to the previous solution success')
    - apply general solution metrics as filters of possible solution components & further inputs to derive problem structures
      - apply general solution metrics like accuracy (with possible input solution components like 'specific equivalence' with possible inputs like 'equivalent structures')
    - identify rules & inject those rules as prior knowledge: 
      - identify insights & applying insight operations like 'variables usually vary more than a particular subset of the data set' + 'real systems typically have many variables leading to noise' = 'variables should be corrupted to generate a more realistic data set'
    - change problem-solving intent (like 'find structures to prevent errors' rather than 'find solutions')
      - rather than finding/generating solutions & checking if a particular solution has errors, identify possible errors (differences from solutions) & reasons why (causes) an error might occur ('over-prioritization of a priority, like simplicity') and check for & prevent these causal structures of errors by generating counter-structures to correct it without causing other errors 
    - trial & error: 
      - alternatively, apply every possible change to every possible variable to generate every possible variable structure and then select for those which perform better & repeat this process for every task
    - self-awareness/modification or awareness of neural network structures like usage structures (like 'training structures')
      - make one training iteration aware of another by allowing a network to keep track of other training data sets & contexts & outputs it's trained with, to identify the reason training is more successful (difference in data sets making one quicker to converge than another) in order to identify differences to apply (change a data set by adding noise to account for these differences in data sets) and identify possible operations to try that could identify useful structures (like combine the data sets, select subsets, combine training input/output in a sequence of training iterations, etc)
  - Functionality to identify useful high-level & meaning-adjacent intents like 'standardize' and 'organize' as particularly useful functions to create and apply across intents/problems
    - identifying that its 'operations are more effective once a standard is applied to inputs' or 'operations like comparison is more effective when inputs are more similar in some ways and more different in others' can be an input to identifying 'standardize' as a useful function
      - alternatively, a function that can identify when structures have the same input/output like 'operations are more effective once a standard is applied to inputs' or 'operations like comparison is more effective when inputs are more similar in some ways and more different in others'
    - identifying the insight that 'some structures are more useful in specific positions' or 'structure adds value when variation is known and randomness adds value in discovering new change structures' can be an input to identifying useful connecting structures like 'networks' and identifying useful implementing functions like 'organize' of those connecting structures, or in identifying useful structures for improving prediction functions rapidly
      - alternatively, identifying that functions which support multiple cross-interface intents like these are inherently more important/useful and should be prioritized & developed by the network
  - Functionality including other variable operations than aggregation (of small features into big features) such as 'selecting' (between alternates) or 'changing' (creating alternates), or 'breaking the original output into components' (reverse direction of aggregation) or 'generating all feature structures like combinations and filtering them' or 'switching & mixing abstraction & interaction levels'
  - Functionality to find contexts where applying structures like 'opposite' (such as by negating a sign of a network structure or executing a filter instead of a combination operation) is useful for quick or accurate convergence, for finding maximally different functions, for finding alternate conditional functions, for handling errors of 'falsehood' where the trend in a particular direction is an error to correct by negating it, or other intents relevant to 'finding a prediction function' that could be fulfilled by neural networks if informed by interface structures
  - In addition to finding interface structures like interaction levels of related objects in a network, functionality to find other useful structures like opposite structures (input variables & output requirements, problem/solution, difference/similarity, component/whole, generate/filter) which provide a network of useful boundaries to base solutions within, as few extremes/absolutes apply in real systems (except in for example cases like booleans) and therefore these opposites act like bounds
  - Functionality to find/build/derive a solution to known error types, like 'missing variables' (solution like 'adding random noise') or 'nested variables' (solution like 'expanding variable into sub-network of variables')
  - Given that the standard neural net structure supports variable interactions like 'combine' and 'filter' to fulfill problem-solving intents for problems in the 'find a prediction function' format, like 'solve for relevant structures to solve a problem (such as on an adjacent interaction level as the problem/solution structures)', 'combine variables in many possible combinations' and 'filter possible combinations', functionality including other core problem-solving workflow function sets other than combine/filter variable combinations (similar to build/test, generate/reduce), like 'change existing solution', 'reduce problem', etc
    - functionality to identify/derive/find which structures align with these problem-solving function sets (finding 'variable interactions/combinations' as a solution structure for the 'find a prediction function' problem)
  - Functionality to find tasks that would capture the functions of or generalize many tasks, like abstract tasks or other interface tasks, or standard problem format tasks like 'sorting', 'filtering', 'building', 'fitting/matching', 'connecting', 'combining'
    - meaning 'would a network trained specifically to perform a particular interface operation be better at tasks in general than a standard neural network'
    - is there a task or set of tasks that generalizes most tasks better than other tasks, and which is it (is there a set of interface operations which, when supported by a network, can solve most 'find a prediction function' problems)
    - is this the reason networks that learn functions like compress/expand (encode/decode) or translate perform better than standard neural networks, because these functions are similar to interface functions (like 'standardize to a (network)/interface') or core functions like 'change a (language) network into another network'
  - Functionality to apply other solution automation workflows like 'reverse engineering a solution' such as by first 'finding out what structures could influence the target structure, then checking if any of the inputs are those influential structures' (a 'function output' or 'function intent'-based interface query which first generates candidates for solutions using solution requirements before checking if each input is one of these candidates), rather than a standard workflow such as 'check if each input influences the target structure' (which iterates through all possible inputs and checks each one for equivalence to a solution)
  - Functionality to identify structures of optimization such as structure to optimize for the number of data points predicted
    - example: instead of predicting one particular data point in a set of adjacent or otherwise related data points (adjacently converted into each other using minimal probable available operations in the input problem space), try to predict that data point earlier in the network and then apply distortions to it to optimize predicting data points generated by distortions of that data point, to optimize predicting more data points accurately than to predict each data point accurately
  - Functionality to derive the input problem space, such as the network of variables, the system in which this network occurs, the functions that take some subset of the variables as inputs or creates subsets of variables, etc
  - Functionality to identify opportunities for optimization like:
    - developing a 'function to identify adjacency/groups and predict one point from an adjacent point or a point in a similar group' rather than 'finding prediction function coefficients of input features', which may be useful for local optimizations as opposed to the standard function developed by a neural net
    - identifying when a subset function is better than a combination function to identify features, such as when a 'surrounding structure like a container' is relevant to identifying a medical problem like 'structural damage', to identify that the 'subset of the damage' that has a similarity to the surrounding structure is the important place to use a subset when looking for interface structures like similarity that can indicate relevance, to identify other relevant features like where the damage can not be and where the damage may hit next
    - identifying 'attachable sensory/function simulation networks' as a more effective/efficient way to gain feedback than 'labeled data with supervised learning' and creating & attaching these networks to avoid over-focusing on a priority/metric/structure/task and identifying the tasks these sensory/function simulation networks should perform in order to gain the most useful feedback (for example identifying that a 'robotic arm used to put blocks in a pattern' is a useful system & task to create a 'sensory vision network' and a 'functional arm network' for in order to optimize a network used to 'rank features in a particular sequence' (like a sequence of blocks))
  - Functionality to identify sub-optimal structures, like whether a neural net that aggregates features is only useful for image recognition bc adjacent features in an image tend to combine to create larger features in reality, so by accident, the aggregation function aligns with this real function applied to features in reality
  - Functionality to identify structures to counter these sub-optimal structures (correct sub-optimal structures rather than purely optimize structures) such as phase shifts/thresholds between features that should not be combined with adjacent features (detecting the limit/boundary of feature groups that dont always appear adjacently in real life)
    - example: identifying these boundaries would be a clear counter-structure to the structure of combining adjacent features which would be sub-optimal in situations where the adjacent features dont always appear together, which is a possibility the network should be able to generate & create a counter-structure for
  - Functionality to identify insights about its own structure like 'a network is insufficient to describe its own interactions with other networks'
    - 'inputs' like injecting interface structures like concepts like 'networks' into a neural net along with the data set input features might produce this functionality
    - 'network structures' like 'giving every node the ability to connect with every other node', 'conducting regular global communications', 'abstracting features', 'allowing the network to generate other networks' could also amount to the same functionality
  - Functionality to identify problems like 'over-weighting common data as if its more important bc of that commonness, given statistics of the data set and given that default neural networks treat commonness as equivalent to importance' and correct them with solution structures like 'over-weighting less common but equally valid data that hurts the accuracy of the network in cases where accuracy is required (the model cant be generalized so much that it ignores these outliers if the solution metrics are to be achieved)' and convert those target solution structures into neural network structures like 'guaranteed protected or isolated weight paths that allow the outliers to be correctly labeled, once a weight path/tree is identified as being able to correctly identify an outlier or other example type in a way that doesnt contradict the rest of the model or can coexist with the rest of the model as it uses the same variables in a significantly different combination that would be generalized out if the network didnt have protection structures in place, to avoid updating certain paths in the network where those paths are useful for some intent that would be invalidated by allowing them to be updated' or an 'enforced/required layer of all possible outcome variants (distorted members of a class) before the final pooling/selection layers so that all possible outcomes in the data set are always given some probability at which point this probability can be changed to account for prioritization (prioritizing structures like patterns of extreme low probabilities that still indicate valid members of a class), after calculating all possible outcomes including the outliers, this layer acting like a solution metric requirement embedded in the neural network, where all required outcomes to predict can be predicted by the network, even if theyre over/under-weighted by their data set statistics
    - this applies a process used in solution automation workflows that derive structures that are derivable from solution metrics to specific more structures than those directly derivable from the problem, using those solution metrics as requirements of the solution to specify more of the solution's structure
    - rather than being a random or standard network applied to inputs, the solution metrics are then embedded in the final layers of the network to require the output to fulfill solution requirements
    - this injects the certainty of the solution metric requirements into the network in different positions - the protected weight structures, or the conditional weight structures that allow the normal data and the outlier data to be accurately predicted, or the enforced output variant layer requiring the earlier layers to produce some probability for each variant at some point, or the network has to reverse its weight state trajectories and try other combinations of weights once its determined that some output variant is being generalized out
  - Functionality to find/derive/apply useful error-triggering structure, like the most different/contradictory of examples that would still be valid in the same system (supporting both the most distorted/standard members of a class), using the least informative data (images of other members of a class rather than either of the two most distorted/standard), meaning can the network determine useful structures like 'differences', 'averages/standards' and 'extremes/outliers' without being explicitly given that ability and apply those useful structures to increase its accuracy on thsoe examples (can the network come up with ways to solve the problems of identifying these structures and these contradictory examples, like conditional weights, protected weight structures, etc), given that 'differences like weights/combinations applied to variables' are a default network structure that can solve these problems if changed slightly
    - functionality to identify these slight changes to its functions/structure/params, such as applying variables to the 'weight' structure to create the concept of a 'conditional weight', and applying the concepts of 'difference' and 'extreme/maximum' to create the concept of the 'most extreme difference' as a useful test of its emergent prediction function's accuracy
    - how to embed these concepts in the network's input features as variables that the network can change (input parameters of the network and concepts like 'maximum' and 'difference' as inputs to the network so the network can change these variables and combine them in order to change its functionality, or alternatively embedding these variables in functions applied in the network, such as by applying conditional weights by default using code, and allowing those conditional weights to be updated like normal weights are updated and allowing input variables like 'difference types' like 'exponential' or 'subtraction' or 'net' or 'count' or 'position' difference to be applied to these embedded functions in a separate 'metadata weighting function' of the network to weight that inputs to these embedded functions using alternate input data sets containing these useful structures as variables)
      - this enables the network to have a concept of itself, by embedding neural networks terms into the network inputs, so it can conceive of functions like 'creating an alternate network to train each extremely different data subset, to avoid errors of de-prioritizing less common example data by forcing all of the data to be an input to the same network'
      - its possible this is as simple as having an initial or wrapper neural network (an abstraction level above the problem of finding the prediction function) trained on different network configurations (like multiple networks for each different data subset, or a network having conditional weights) to produce varying output success on solving the data set prediction function problem, with possible alternate implementations like:
        - network to find neural network configuration/transformations (using concepts like 'network' and 'weights' as input variables), followed by network to apply changes to data recommended by initial network, followed by network to find prediction function for original data set
        - network to solve multiple problems like 'find useful neural network configurations/transformations' or 'find useful neural network configurations/transformations for a data set', then 'apply recommended changes to network before/during/after training to find prediction function' and 'find prediction function', using concepts like 'network' as input as well as original data set variables as input, and adding 'recommended changes' to inputs once found
      - this would involve converting concepts like 'network' into a numerical format (such as how a variable might change if it represents a particular node on the network of related values, like different tenth values in the set of 0, 0.1, 0.2, up to 1.0, where values are clearly members of a type, and where subsequent values are likelier to follow similar values as opposed to very different adjacent value changes like from 0 to 1, similar to how an actual network works given that connected/adjacent nodes are related for a reason, hence the structure connecting/positioning them in that way), and applying those value changes as a variable determining some network configuration (like the percentage of the network devoted to differences in weight path protections), or another format that represents the useful intents fulfilled by the network, formatting the 'network' concept as a prediction function-generator (so the 'network' concept variable would be able to influence as in 'correct errors in' a variable representing the 'prediction function', where the network would have both these variables as input, and where the 'prediction function' variable would be a 'set of variables representing coefficients' or a 'scalar representing the vector applied to other variables which are inputs', meaning the original data set variables or some variant of them like 'general common variable interaction patterns', and including other useful structures like 'errors' as 'sub-optimal differences' such as 'difference types' applied to a value like exponential/subtraction/negation or applying the errors to the data to generate 'error data sets' as inputs)
    - functionality to identify whether simpler structures like embedding 'error weight structure patterns' (patterns of weight structures indicating an error like data corruption) into the network by checking for these error patterns during training and de-prioritizing them if there is no overlap/ambiguity between the error pattern and a useful pattern like an outlier pattern
    - functionality to identify other useful patterns than just the data set variable interactions, such as the aforementioned training/network error patterns, outlier patterns, as well as the patterns in the data that reflect errors such as bias and whether the network can connect these patterns to useful structures like perspectives (what did the data set over-prioritize that resulted in alternate data set being lower accuracy with this model, and can those priorities be offset to generate alternate data sets reflecting different priorities)
      - if there isnt noise in a particular data set or variable interaction, its probably not realistic data, and as sometimes this noise isnt noise in all contexts but is useful in certain contexts, some of this noise should be preserved and used as variables rather than removed from the data set
      - removing this type of data error reflects a perspective that prioritizes 'just learning the patterns of the variable interactions in the data set' which is limited in its usefulness
      - to offset this pattern, techniques like generalization & data augmentation/generation can be applied, which contradict the structure of the error of 'specificity' that over-prioritizes the original data set with noise removed
      - the structure of 'generalization' directly contradicts the structure of 'specificity', and the structure of 'alternate' (applied as alternate data sets) contradicts the 'static' attribute of only/specifically the original data set
      - functionality to identify other error structures of over-prioritization and correct them is another solution metric of neural networks that can be resolved with interface structures (deriving the opposite of a structure like 'specificity' is trivial with interface structures, and deriving a method to implement the 'generalization' of a neural network is similarly trivial, which would identify the usefulness of 'random filters' to fulfill the intent of 'generalizing the model')
  - Functionality to identify useful structures to reduce errors/improve solution metrics, like identify the network configurations and original data sets that would minimize/maximize errors, and finding overlaps in the configurations & data transformations that would cover the most of these error structures, and identifying patterns in these configuration overlaps to identify more optimal configurations/transformations more often in other examples, given the usefulness of patterns as a generalization structure
    - for example, identify configurations/transformations that minimize/maximize errors with a particular data set, then repeating this process for alternate data sets (or data subsets of the original data set), and identifying the configurations/transformations that are useful in the maximum number of different data sets (the configurations/transformations that overlap as useful among these different data sets), then finding a network configuration/transformation structure that identifies the useful configurations/transformations given an original data set
    - this applies one neural network to solve the problem of 'finding useful configurations/transformations to avoid the most errors in the most different data sets, using the original data set as input', then applying the outputs of that to another neural network to solve the problem of 'predicting outputs from the original data set input, using the original data set as input and using the output of the first neural network as configuration/transformations'
    - this applies the workflow of 'applying solution-finding methods to the problem of applying solution-finding methods in the specific problem of finding a prediction function using the specific solution format of neural networks'
  - Functionality to identify useful transformations that its weights should support, these transformations being useful across data sets and across problems, such as 'maximal difference-producing transformations' (producing the alternate variants of a prediction function that are equally valid but maximally different, to average or merge into one prediction function, or use as conditional alternate prediction functions)
  - Functionality to identify the data as benefitting from alternate configurations/networks than a standard network solution, such as splitting the data into separate data subsets that would benefit from having their own network to avoid errors like de-prioritizing a less common outlier example
  - Functionality to identify errors produced by structures like 'causal loops' that are variable interaction structures which are not accurately modeled by neural networks, to generate alternate solutions like training multiple networks to predict each variable in the causal loop from the other variables, and integrating the output prediction functions of these networks as input variables to another network, or allowing 'reverse weight combinations' where a feature contributes to a preceding weight to create a causal loop in the network (or storing the output variable as a factor to add to the input variable in the next propagation), or including the output as an input variable, or identifying alternate variables to predict that encapsulate the intent of the prediction function better than the original target variable involved in the causal loop, or removing the difference added by an output variable in causing itself to isolate the input variables, and identifying structural changes that fulfill these intents
  - Functionality to identify & correct conceptual errors with conceptual corrections
    - the error of assuming a sequence will always have a 'high probability of ending or proceeding in a particular way', even when data suggests that the pattern of this sequence is changing, results from the assumption of 'commonness' of a 'current state' indicating 'commonness' of a 'future state'
    - if the occurrence of different states than the common state is increasing/differentiating (both being indicators of further changes), statistically that would not indicate the common state will continue to be common
    - current ml models convert the 'assumption of the correctness and absoluteness of the priority of commonness' into other assumptions that lead to incorrect differences (errors)
    - ml can be built to consider structures that fulfill alternate priorities if there are reasons to consider other priorities (reasons such as 'previous patterns indicate a change in a variable's average is probable') until those reasons are invalid, or built to integrate priorities into one structure, or build to apply conditional priorities as needed (storing conditional weights)
    - these structures can correct a 'scope' error structure (assuming the priority of commonness is always correct) and the 'degree' error structure (assuming the priority of commonness is not an error or suboptimal state but a solution)
    - there are other structures of importance than 'commonness' which cant be directly integrated into 'commonness' bc they contradict it ('initial signals of a change cascade' contradict 'common signals'), which could be integrated as 'initial states' of a 'commonness structure', which would require the ml model to have a concept of 'state' applied to its processes, to keep track of its weight state changes to derive structures of change like 'initial signals of change' that it detected during learning processes, like when moving in a different direction, or diversifying its weights to integrate handling a new difference, to remember that many or every major change it made started as seemingly insignificant initial signals of change, which would prioritize 'future importance' or 'possible importance' rather than 'current importance' or 'known importance'
  - Functionality to identify optimizations like:
    - identify alternate output formats like 'vectors that change a base function' to create the prediction function and inputs that condense those vectors
      - example: given 'subset averages' indicating a vertical change to a function subset, or eigenvectors indicating primary vectors of change in a data set, what vector sets are likely to connect to create the vectors that change the base function into the prediction function, and what filters identify the more optimal vector sets, and how are these vector sets connectible to input data set points (like the 'subset averages' and 'base function' created from input data set points), to predict change vectors applied to a base function, as an alternate to predicting the coefficients starting from the data set
        - this reflects an insight of 'finding a suboptimal solution to base changes on' by first starting from a base function summarizing the data set, then applying changes to refine it
        - a variant of this would be 'alternate the preprocessing and network changes' to find the changes which are constants (preprocessing changes that should definitely be applied, bc theyre true) and the changes which involve unknowns (changes which should be explored in the network, bc theyre uncertain)
        - a variant of this would be 'find alternate condensed variations of preprocessing changes which reflect truths' to reduce the steps required to preprocess the data in a useful way
        - a variant of this would be 'find change vectors that would be interchangeable alternates to summarize a data set and test them on other data sets/subsets to find the vectors that summarize the most data sets'
        - another format would be 'maximum point-intersecting lines', 'boundary lines' of a data set to summarize the limits of its changes, 'tangent bundles' (sets of adjacent change rates of a curve) to summarize that adjacent change types of a function (included by probability), 'vector sequences' to create variation in a data set from base points or base functions of data subsets/sets, 'bounding functions' to indicate probable ranges where the solution function should be in most alternate data sets, 'local linear functions' to summarize data set subsets in simpler ways given that local subsets are likelier to be connected with fewer variables, than the possibility that all subsets given common structures like phase shifts from threshold values, etc
        - a variant would identifying the useful intents supported by each alternate format, identifying the unique set of useful intents and how these intents are connected, and integrating these intents & the associated formats in a network structure that uses all of the advantages of each alternate format
        - a variant would be to dynamically identify useful alternate function formats (sequences of terms) and mapping those formats to the neural network structures (variable components mapping to nodes/layers as weight changes & deactivations), given insights like how variables that interact to contribute to the output variable are likely to have similarities, like a common base/denominator, or insights like how variables can form 'neutralization structures' (like 'added opposites') that temporarily hide a variable or variable set by negating another variable or variable set, in which case the alternate format also has to have structures supporting that interaction type
    - identify alternate variable sets that can be used in place of alternate variable sets (like if a variable value is missing or outside the original training set in a way that the category cant be identified using that value, what other alternate variable sets can be used to identify a category)
    - change order of feature aggregation or change the function 'aggregation' to another function like 'isolation' or 'change'
      - instead of aggregating small to big features, store types of images or store big features like average/base examples of a type, or common base components of a type (eye/ear shapes, fur) and apply changes to these base features
    - aggregate features by order of variables
      - once a 'skeleton' structure is constructed from features, other structures can be built on top of it, like fur or fur color
      - this is relevant in cases like missing features, which might be incorrectly predicted by sequential/adjacent pixel data aggregated from small to big features, but might be accurately predicted by ordered feature data, where a feature built on another feature (meaning a 'dependency') cant exist if the underlying feature doesnt exist
    - solve the 'find a prediction function' problem not by 'condensing' features into representative features like 'averages' to reduce steps, but by 'expanding' variables into many possible variable combinations & variable components to determine varying contribution size of variables
      - specify variable values as features of a network rather than variables themselves to further expand it
    - identify features like lines/curves/colors which can be used to feed a network of 'differences' between those values to determine a particular shape (dog/cat) to encode relationships between useful structures like determining features which tend to be medium-sized in between smallest possible features and output label categories
    - feed sequential data of image pixel sequences to predict next value in sequence, given set of random points on an image, and generate probable dog/cat images based on these sequence probabilities, and use these probable images to determine similarity to a new image
    - identify structures with a true insight reflecting the actual variable interactions (like 'adjacent features are likely to predict each other in many cases'), then apply ml to identify the patterns of the interactions of those structures (where the network creates adjacent feature combinations and finds patterns in the combinations that are successful in predicting outputs)
      - a variant of this applying the 'opposite' structure is to identify pattern components that do/dont exist in the data set and use those or the remaining components to form possible patterns of variable interactions (like find a prediction function for data set subsets where 'difference types' are estimated by boundary lines or average/base lines to be likeliest to be different, given known difference types like constant/exponential or negative/positive change or missing/present data)
  - Functionality to find/derive/build functions to translate net/emergent operations of a network like 'aggregating small into big features' into variants of those operations like 'opposite of aggregating small into big features (decompose big into small features)' 
    - meaning, how to translate 'reverse' or 'opposite' of a network's emergent/net/explicit function ('aggregate') into a network configuration, in other words, how to implement 'semantic relevant automatic generation of neural networks'
      - such as by keeping the first 'combine input features' layers to create as many of the big features as possible, but then splitting & filtering component features after that, to align the input/output data types by adding an opposite operation of 'aggregate' (decompose) once the input (big features) is created
      - for intents like 'implementing a neural net for each basic core structural operation like combine/aggregate, find/filter, decompose, connect, reduce' by auto-generating each neural net config for these operations with interface queries, or intents like 'changing the position of features or filters emerging from a network to maximize filtering or optimize another function like aggregation, such as by changing feature position to maximize explainability coverage of earlier features similar to decision trees'
    - interface query to implement this 'find opposite function' operation
      - find opposite of function 'aggregate small features into big features'
        - 'decompose big features into small features'
      - find requirements of opposite function
        - 'big features' are input requirements
          - create input of target function 'opposite of aggregate small features into big features' ('decompose big features into small features')
            - check for existing structures fulfilling requirement (first aggregation layers)
              - keep first aggregation layers creating big features
        - 'small features' are output requirements
          - convert big feature inputs to small feature outputs
            - add decompose operation
              - add feature split/filter operations to create small features

- examples of interface structures applied to neural networks, such as 'error/sub-optimality structures' of neural networks

  - Basic backpropagation cant identify error structures such as 'previously barely deactivated nodes' that would have contributed with slightly different inputs (ability to recall prior deactivation values & decide whether to re-activate a node, possibly reverting to a previous training state with less information but excluding fewer useful nodes)
    - if a change to inputs is required to avoid deactivation or optimize weights according to some optimization structure (like creating weights that 'maximize differences in outputs') doesnt contradict the output of other weight paths, deactivating a particular node can be avoided or weights can be optimized if its barely under the threshold (which moves the error to a new threshold, the threshold value to determine whether to apply the original threshold value)
    - examine effects of 'weight-swapping' across structures of relevance like 'adjacent nodes' if node position indicates initial or emergent similarity in weight path or 'adjacent weight values in a node layer' to test if similar but not equal weight updates apply to the possibly similar weighted feature sets that created those similar weights or are otherwise useful in generating errors (such as how values relevant by a similarity such as adjacence should be or remain similar)
  - Neural networks cant identify & correct their own possible error structures in pattern-finding tasks, such as assumptions/biases or the cause for its errors like 'missing information', or change its predictions given its error structures to correct them or at least account for them
    - they also cant identify why its not being used (has error structures for a particular problem), which is bc its a function network, rather than a data store of 'user intents' and 'user queries', and 'functionality to infer this related data to improve itself' is not built-in to neural networks by default
  - By default, neural networks optimize for 'finding prediction (variable interaction) functions of the original data set', not 'creating an optimal solution-finding method for finding variable interactions in a data set' or 'inferring related data to improving itself' or related intents, integrating 'local specific optimization structures for a particular solution metric' (to find prediction function for original data set) rather than 'generally useful optimization structures' or 'optimization structures specific to problem attributes like problem type'
  - A target 'explanation' structure for neural networks to generate with their prediction output, which they don't currently implement, is: 
    - 'given my understanding of the concept of "differences" applied to identify different variable values such as a "category" for a particular input in the data set, and given my ability to identify differences & my ability to derive output features from input feature change combinations, I think these inputs map to these outputs with x% accuracy, which should be adjusted for my inability to correct "ambiguity resolution" errors in contexts such as "unexpected new inputs" which differ from the ambiguity structures I can resolve, because the differences I cant resolve are less obvious'
    - this explanation connects the network's abilities (functions) & decisions (solution filters/selections), the error structures the network can infer as possible given its functionality, the cause of those error structures, the interface structures like 'concepts' and 'assumptions' involved in its functions & decisions, & the cause of its input-output mapping decisions, and how the network (& its probable usage intents, given its abilities) relate to problems including problem attributes like 'obviousness of a solution'
    - if the output isnt exclusively a function of structures (like combinations/subsets) applied to inputs, it wont identify those structures that its missing
      - if the neural network 'differentiates' too early (by commiting to a particular structure as a 'certain' useful structure for generating the output, like stem/blast cells differentiating too early or certain pre-processing rules applied to data that shouldnt be assumed constants), that differentiation cant necessarily be reversed later by emergent effects, so differentiation should happen on subsequent layers rather than immediately after inputs
      - this would occur if there are multiple input-output sequences of different structures leading to outputs that coordinate (rather than providing alternatives)
  - Over-prioritization of correcting 'known errors', such as 'filling in missing information', which occur frequently in language data sets but not frequently in highly structured language data sets like math word problems
    - example: assuming that two different examples of a type should have every attribute/function the same, and assuming that the problem should have similar structures as the solution, because over-prioritization of a priority like 'equivalence' fulfilled by 'inferring missing information' can create errors like 'forcing equivalence of different variables that dont need to be equal'
  - The error structure of a 'gap in the 'input-output sequence' of a possible function of inputs predicting the output can prevent almost useful sequences from contributing to output, if a node is deactivated to create the gap
  - Given that a network learns one representation of a prediction function, it cant learn multiple representations unless it retains 'alternate conditional' neural network nodes/layers/paths that allow other structures to be considered in case a hidden pattern emerges in another data set (like what appears to be a parabola can be produced by multiple polynomial structures) - restricting ml networks to the 'most efficient compression' of a network to represent the found prediction function would remove its learning potential for these possible alternate structures
    - these 'functional similarities' can be encoded in the network if it evaluates which decisions are the result of possible emergent functions in the network that could have 'alternate conditional functions' also explaining that decision, and retains multiple alternate weight sets


- example of deriving the neural network structure
	- deriving the neural network structure by applying useful insights relevant for problem-solving intents like 'generate the solution' (as opposed to finding it) - insights such as that 'a structure (like a function) can usually be generated from structures similar to itself (a function) or structures of the same type (a function) or structures on its interaction layer (other functions, variables)' an insight which is derivable from math structures such as 'requirements involving the output data type of a particular operation like addition' - to derive the solution structure of a 'directed function network' as a useful structure to use as input to fulfill the intent of "creating a function to solve the 'find a prediction function' problem", given that functions can be formatted as 'sequences and combinations of other functions' and a 'directed/tree function combination network' could 'apply multiple combinations of functions' or 'apply functions in multiple sequences', which can 'build a function' so are useful for 'building a prediction function'
	- find a prediction function
		- build a prediction function
			- build a 'directed function network' to build 'function combinations' and 'function sequences' that could 'build the prediction function'
				- identify change structures (such as weight update or routing functions) of function combinations/sequences that would allow maximal or otherwise useful differentiation/reduction of function combinations/sequences
			- identify core change structure as a 'function performing a sum of weighted input coefficient changes' to create the useful change structure 'different prediction function coefficient sets' that would solve the problem of 'sorting/filtering possible solutions in the form of prediction function coefficient sets', where this change structure ('function parameter changes') happens to be the only change structure allowed in the problem space, so by definition the solution format for the 'find a prediction function' is a 'set of constant values for prediction function parameters applied to inputs', and the way to generate those coefficients involves applying changes to an initial set of coefficients, and the changes involve structures like combinations of core changes like 'summing weighted inputs' where inputs would be 'previously summed weighted inputs' or the 'original inputs', to generate 'different sets of coefficients' to input to a 'solution metric testing function'
				- then identify structures that could produce these change structures

- example of deriving a 'mental model or state of interacting structures like functions/errors' (such as 'learning' or 'misunderstanding' or 'handling a contradiction' or 'disorganized' or 'over-prioritized error correction')
  - these 'mental models' of networks involve various functions, errors, alternatives, priorities, concepts & other interface structures, including functions as 'components of the concept of intelligence'
  - these 'mental models' of networks have some alternative structures, where the reason for an error/success could involve multiple different interface structures
  - they also have some 'neutralization' structures where a particular function would 'invalidate' an error structure
  - these are not direct or exact mappings from the neural network parameters to interface structures, but rather these interface structures offer an understanding of the emergent effects of the model when applied to a particular input, that may be a functional understanding that can be changed with later output indicating other interface structures
  - on the 'agent' interaction level, the corresponding object is a 'personality', such as a network that is particular averse to learning or new information, over-simplifies everything, more rational/logical than other networks, more stubborn in its resistance to change, more interested in the truth than other networks, lacking in self-awareness in not correcting its own errors, more intelligent in having more abilities (like an imagination/simulation function) or having more experience or better at avoiding errors than other networks, etc 
  
  - a 'mental model' of the neural network from example 1.1 can be inferred as:
    - having the ability to identify the correct 'missing information' error to fix ("capacity of John's multiple classes" and "total capacity of John's multiple classes"), given its ability to identify when the correct variables are different (number of classes, which determines whether a connection function relating their class capacity needs to be adjusted (for multiple classes), or is equivalent), which differences need to be resolved in which sequences (calculate John's individual (unit) class capacity before calculating total capacity of John's multiple classes), and which variable differences are relevant (they dont need to have the same number of classes or class capacity, but John's class capacity needs to be calculated just like Ali's class capacity was given before total capacity can be calculated, and their total capacities need to be calculated the same way before the values can be added to determine the overall total)
    - having the ability to identify when an object is relevant to adjacent sentence's objects in the sentence sequence
    - having the ability to identify related or equivalent objects ("Ali's total class capacity is given, so John's must be calculated, as John's total class capacity is an input to the solution format of 'overall total capacity'")
    - having the ability to sort information in order of factuality, prioritizing factual information first to start applying possible connection/change functions to facts first, identifying that assumptions need to be based on facts
    - having the ability to identify membership 'class of John', 'class of school' to infer object connections
    - having the ability to identify the solution format of 'combined capacity of all classes in all schools', thereby connecting the given & adjacently inferrable information 'class capacity' and 'class count' with the requested solution format 'combined capacity of schools', inferring the connection between 'class' & 'school' in the process
    - understanding of how to build features from sequential operations applied to input features, like how 'class capacity' and 'class count' are inputs to a 'school count', and how 'school counts' are inputs to 'combined count'
    - possibly a concept of problem-solving workflows such as 'build possibilities from facts', 'build outputs from sequences of functions applied to inputs', 'connect original inputs with target solution output', 'identify differences/errors to resolve/connect/equalize and only connect those differences/errors', 'identify requirements & fulfill requirements using inputs', if the neural network can store the abstraction of the 'workflow' rather than generating the workflow implicitly in solving a problem

  - a 'mental model' of the neural network from example 1.2 can be inferred as:
    - an inability to identify when a value has already been calculated, in assuming an inherent required difference between 'total capacity of a school' and 'class capacity', in the case where 'class count' is one
    - an inability to infer alternate contexts, such as the case where 'class count' is one, making the 'total school capacity' and 'class capacity' variables potentially equal
    - an inability to identify that there is more than one school object, despite the differences in school descriptions
    - an inability to infer an error of a 'false difference' or avoid this error, in identifying 'total capacity of a school' and 'combined capacity' as necessarily different when the 'combined capacity' was already calculated because of the assumption that there is only one school so all schools should be grouped in the 'combined capacity' calculation, and if this error had been avoided, the other error wouldn't have been a problem, as 'differentiation of schools' isnt a necessary input to 'add the individual class capacities'
  
  - a 'mental model' of the neural network from example 1.3 can be inferred as:
    - having the ability to correctly identify 'total capacity of John's classes' as a relevant interim variable value to calculate before calculating 'combined capacity of all classes', but has an error in identifying the correct calculation to do so, instead performing the calculation to determine the individual capacity of John's classes and conflating that output with the output of the next required calculation in the sequence, 'total capacity of John's class', instead of finding the 'total capacity of John's classes', which is the similar comparable variable value to add to the 'total capacity of Ali's classes'
    - having an inability to identify whether an operation has been done, is required, or in what sequence the operations should be executed, producing errors in 'missing operations' and 'incorrect operation-output connections'
    - having an inability to identify the inequality in the class count used to calculate John's total class capacity compared to his actual class count as relevant or as an error to fix
    - having an inability to identify the difference in the variable 'effective coverage of class count applied', rather than inferring the concept of 'all' from the 'total capacity' given for all of Ali's classes, indicating an inability to infer the concept of 'all' or inability to infer the a class count of 'one' can be equivalent to the class count of 'all classes', or an inability to infer that not every value should be equal, and John's class count can differ from Ali's class count, rather than calculating the corresponding value of one of John's classes for comparison to one of Ali's classes in the addition operation to find the 'combined capacity'
    - having an inability to identify the right format to input into 'combined capacity' addition operation as 'all class counts of each teacher' or 'all class counts of all classes' rather than 'class count for one class for each teacher', which is comparable as a unit capacity of each class (as if John and Ali are types & the intent is to get a unit class capacity count for each type), but not comparable as relevant for adding all class capacity values, which is the point of the problem, so inferring the concept of 'all' classes in the inputs and the target solution output would have avoided this error

  - a 'mental model' of the neural network from example 1.4 can be inferred as:
    - having a 'priority' of simplicity leading to an overly simple 'concept' of errors as 'differences', limited to a particular 'example' error structure that it knows how to handle which is 'missing information, where "missing" is determined by inequality'
    - a 'priority' of preserving 'structures' like similarities, without evaluating usefulness
    - a 'priority' of 'equalizing' variables to create similarities, without evaluating whether a difference is useful, such as for a 'comparison' intent
    - having minimal 'understanding' of usefulness, and an 'inability' to imagine other contexts like different problems to solve such as 'compare'
    - an 'inability' to correct its errors, identify the cause of errors, identify other errors that are more high-priority to avoid such as 'removing information about a difference', an error which the neural network creates by trying to fix the 'missing information of the inequality present in "one object's variable not being populated when the other object's variable is populated"' and in trying to fix this definition of 'missing information', it creates a 'missing information' error by removing the information that differentiated the two objects, which is the actual 'missing information' structure the model should have avoided
    - never having encountered the 'experience' of negative feedback for errors in its error-correction method
    - given these priorities, examples, experiences, concepts & other components, this neural network can produce errors when applied to language data that is highly structured for a particular purpose, simply applying any equalizing method it can, without evaluating whether all variables of the problem/solution should be equalized to connect the problem/solution state or if a subset of variables are useful for doing so
