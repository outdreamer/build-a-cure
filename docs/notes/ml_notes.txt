"For the CNN-based classifier they observe that units associated with objects and parts emerge in later layers, while earlier layers are largely associated with colours. For the generator network, on the other hand, object/part neurons can be found more frequently in earlier layers, while the later layers focus on colors."
	- https://towardsdatascience.com/four-deep-learning-papers-to-read-in-august-2021-7d98385a378d

- for a cnn, the feature causation moves from adjacently identifiable features (colors being an attribute found in every pixel/feature) to absolutely identifiable features (larger features like objects being identifiable with features representing larger sections)

- for a gan, the feature causation moves from foundation/type/template structures (objects) to apply details to, and specific details (colors) to tune the output with.

- these methods have biases toward priorities that may help or hinder their intents
	- cnn: prioritization of 'adjacent feature' structures (as inputs to 'larger features')
	- gan: prioritization of 'template/type' structures (as inputs to 'detailed type examples' output)
	- gpsa: de-prioritization of 'locality' priority

	- these priorities are conceptual, and the implementation of structuring these priorities may or may not be correct for these intents
		- the structure applied to the concept of 'locality' may or may not be applied in the right form when assigned to the position of 'features' in the structural problem space (compared to other structures like variable/interaction structures, functions in the function network, parameter output difference patterns, etc)
		- these other structures may be more relevant to apply this conceptual priority (or de-prioritization) to, in order to correct associated error types with that priority or contradicting priorities
		- 'parameter output difference patterns' is a particularly useful structure in this problem space that is not being applied optimally

- identifying the relevant interaction layer or base to act as the symmetry (foundation/type/template to apply variations to) and the variables/attributes that determine the variations from those bases is a workaround that integrates these feature causation structures.

	- the algorithm would list the identifiable structures (components/attributes/objects/interaction functions/errors) in the data set
	- then it would try to identify default relevant interface structures like types that form the basis of different clusters/subsets in the data set, applied to the structures (error types, component types, variable types), which are relevant for categorization problems (predicting category, generating category example)
	- then it would try to identify variables that determine variations from those types
	
	- this is similar to 'starting in the middle interaction layer and radiating outwards', as opposed to starting from adjacent details or starting from core objects as foundations for change
		- it integrates error types as an 'adversarial guide'

		- this uses a cross-section of interaction layers rather than the raw objects/attributes clearly identifiable in the data set, so there is some derivation work to do before it can be applied

		- another version of 'starting from the middle' would be a cross-section of interaction layer attributes, like:
			- a component of the image + common attribute values for that component + a partial adjacent component
			- pairs of components commonly found together across the image, regardless of adjacence
			- variable & error structures commonly found with attribute values or value patterns

		- this applies a different cross-section as a different interaction layer than the default interaction layers that could act as symmetries, such as a template/foundation/type, or the raw data set attributes, or the default object/attribute/function structures, or an interface layer, where these cross-sections are mixing interface components

		- another variant would be starting from the cross-section definition as the symmetry, & identifying various cross-sections that can act as symmetries & applying them as input data to identify the cross-sections that are most predictive of predictive feature structures or algorithm success

	- applying interface components (like intent/structure/bases) is better than ML (which builds a function from an algorithm & function network that is tuned & designed & applied seemingly by accident) bc it starts from understanding of what is useful for solving the problem, rather than guessing based on a limited list of mental functions & structures (like neurons, activation status, weighted connections, & attention) that drew ML engineers' attention for being simple & known.

	- this is also better bc it starts from the correct interaction layer (problem/solution on the meaning interface) where alternate solutions can be generated/applied and coordinated with other solutions & solution-generating queries for other problems.

	- this is different from a math 'solver' program that just applies known math rules to solve a function with known associated solution rules, which is unaware of any concept of 'meaning' except the definition of 'equivalence' and does not integrate any concept of 'interfaces' like potential, cause, intent, concepts, logic, or information.
