# to do

  - give example of the network of formats

  - make efficiency map
  
  - abstract risk insurance: guarantee a relative position (without specific currencies or amounts), such as 'resources giving a top 10% economic position'

  - finish applying structure to info components (memory components like personality, forgetting, compression, uniqueness, generation, learning, bias, and organization components like relevance, differences, type, abstraction, standards, randomness) to generate full set of neural net types
    - filter by usage intent

  - check reduced language components for any other useful functions (what terms cant be adjacently, clearly & accurately framed in terms youve defined) for completeness

  - gauge theory definition: field where the difference in kinetic & potential energy doesnt change locally from a symmetry in the form of certain continuous (differentiable) sets with multiplication/division operations
    - find interface boundaries by how its definition & structures break down
    - find gaps in interfaces by points of variation not covered by other interfaces

  - why not call interfaces a system? 
    - everything can be formatted as a system, not everything is an interface - an interface is like a location where different systems can meet to communicate

  - science: 
    - alternatives
      - a limit on potential energy in the universe, concentrated in space-time moves or symmetry violations, where all other changes align with the standard model
      
    - examine muons as a reflective surface or temporary boundary for electrons to use to avoid violating symmetry, where artificial experiment conditions or other muons can interfere with planned reflection, leading to an imbalance in particle ratios that would occur with distributed/isolated particle pairs

  - chart type: overlaying multiple 2-dimension variable comparisons to identify common shapes of variable connections (density of points added with a visible attribute like more opacity)

  - assess fair use of copied code by:
    - how much effort it would have been to not copy (if its low-effort to not copy, there's no reason to copy)
    - ratio of value contributed by those lines (such as by the cost of bugs caused by distorting the line)
    - difficulty (cognitive distance) of inventing that product given what had been invented prior to that
    - ratio of total value that the code can generate (what other software can it generate, what can it automate)

  - anti-stupidity addiction counseling & meditation app, fixing addictions with incrementally slightly less evil replacements:
    - racism by convincing them there are non-racial groups that deserve hatred more ("hey Sharon, you're so right about the Jews, they absolutely cared about covering up their space weapons program enough to serve you that ad about fun outdoor non-genocide activities in your area, but you know who I hate more - wiccans with vegan pets" could be all it takes to wean Sharon off of her ethnic hatred so she can write manifestos about the behaviors she hates instead)
    - jealousy, by convincing them there are other people more deserving of jealousy, such as people who don't feel it bc they're the best ("my dearest Beatrice, rather than trying to criminalize your male coworkers complimenting someone else, dare I suggest developing intelligence so you can create any asset your heart desires" can fix Beatrice so she fulfills her destiny of being the recipient of increasingly & unnecessarily dramatic letters)
    - false hope that their new accessory, new dance move, brow grooming technique, or another just barely acceptable trait is giving everyone the jels ("have mercy Kevin, your false eyelashes are murdering our will to live, an asset that is literally necessary for life, which is technically murder" could inspire Kevin to dim his own light to let others shine for once, since absolutely everything is able to kill someone's will to live, if you just wish on a shooting star & believe & if theyre a total dweeb hurt by everything)
    - victim complex, convincing them there are actual problems, and that they have actual power to fix the illusory problems they think they're a victim of ("oh my god, are you ok? why is the red cross trying to help sex trafficking & genocide victims, when that cake just forced you to eat it?" could alert Pamela to the fact that she does in fact have superpowers instead of victimhood, powers like fixing her impulse control (the stronger she'll be to strangle us), or alternatively, her priorities (the better to crucify us with)
    - god complex, convincing them that they are not in fact allowed to murder other people who happen to exist, which they take as an intentional malicious reminder about their own mistakes ("no Lisa, someone else having something out of your intellectual price range is not justification for altering international human rights terminology just this once to justify what you did to them" could be the wake-up call Lisa needed to acknowledge her own limitations)
    - judging addiction, where they act like anyone trusts their judgment and thinks they're incapable of hypocrisy ("sure Chrissy, we'll punish all your victims youre jealous of who did nothing to you, we totally trust that you're not jealous of them, since you only told us to punish them bc you want the best for us, in your infinite wisdom, not bc you think that if we can't interact with them, we'll someday start to think you're great")
    - lying addiction, where they say stuff that is clearly false bc they think its "play pretend" time all the time and pointing out lies is "violating the social contract" in some way ("sure Chrissy, youre saying we should all have kids bc you think its the right thing to do, not bc you want every woman's body to be ruined" might trigger a thought in Chrissy's mind, like that she might not be great at hiding her intentions, which are a shade less complicated & interesting than she claims)
    - self-nominating sainthood of their own religion, where they act holy & concerned about their homicide victims so they make sure to check their email every day in case today is the day they need to act sad about their victims' deaths ("sure Martha, that bake sale almost ended all oppression & inequality - it's like you invented something that changed the world and made all problems trivial to solve, but slightly different in that your strategy didn't work bc people persecuted you for being better than them (at pretending decorating cookies is the only thing that has ever mattered)" might alert Martha to the possibility of other strategies to seem good, like actually being good)

  - finish poc & give other examples applying different workflows

  - self-explaining AI test: able to identify metadata that align with its decision path, like:
    - thresholds
    - alternatives (selected & unselected based on thresholds)
    - testing points (gather info about relative value to threshold)
    - types/clusters
    - examples
    - statistics like average examples within a type

  - finance: assess value of prior work by work that is still relatively valuable, incentivizing new work

  - alternative intent coordination & compatability of metrics

    - calculating interactivity by coordinating/adjacent/convertible structures

  - rather than learning (applying new info to update standard equalized or randomized structure), apply structural insight paths that frequently produce accurate task completion (in general like producing problem/solution format connection sequence, specifically like producing prediction function)

  - apply definition of errors as structures of difference (what is not correct, meaning different from correct) to generate error types (structures of difference, like stacking variable permutations/distortions or generating new variables) and error patterns
    - create error types of ai using core combination generative function
      - includes generating error type structures (combination of error types)
    - identify error type patterns (when differences accrue in this pattern, an error of some type is likely to occur)
    - create ai algorithm that is different in some variable from error type algorithms to guarantee an algorithm without those known error types
    - identify interface queries (or ai algorithms) that generate error types to use as filters to differentiate & guide design of new queries algorithms
    
    - example of error type in structure: 
      - any distortion can be used as an asset, & every position has an error inherent to its structure
        - for example:
          - 'occupying the center position' has:
            - errors: having to do extra work to get to a position where it can handle less adjacent (outlier) problem types
            - advantages: its work is distributed among many positions in every direction (many positions are adjacent) so if the problem is solvable with an adjacent position, and encountered problem types vary a lot, the center has an advantage
            - 'a position in between most common error types' is another similar position that would have an advantage inherent to its structure, with the cost of having to do more work to get to a position where less adjacent error types are solvable, the less adjacent error types being more common than adjacent error types, but still less far than the average cost from other positionss
          - 'having the most power' has:
            - errors: intent of 'requiring dependency', inability to delegate, over-responsibility (imbalance in blame allocation), boredom
            - advantages: freedom in movement/change, ability to handle stressors, ability to make decisions that favor itself or its goals
      
      - how to derive the error type from this distortion structure 
        - distortion structure: 
          - 'too far in the direction of power centralization'
            - associated objects (inputs/outputs) to components (power)
              - with power centralization (power being at least an input to everything), other things are also centralized, like inputs/outputs/sub-processess of power (responsibility, decisions, dependency)
          - 'too central to reach outer positions quickly'
            - variables (cost, function, priority) in structures (paths) to similar objects (positions)
              - average cost to reach other positions may be lower than other positions, depending on density distribution or commonness of adjacent positions' associated error types, but cost to reach outer layers would be higher in the absence of efficient connecting functions
                - this error structure can generate other error structures:
                  - bc it cant reach outer positions quickly:
                    - it cant identify/handle external stressors quickly without building functionality to offset that error, like an alarm system to get info to the center faster
                    - it cant quickly generate new outer positions like it can generate new adjacent positionss

  - finish applying structures of concepts into algorithms
    - apply structure of time (state) into algorithms (network state algorithm)
    - apply structure of hypnosis (multi-interface alignment) to algorithm (hypnotized algorithm is static & cant learn, which is an error type)
    - apply meta structure to algorithms
      - an algorithm that cant see its own error types is one that cant:
        - change its perspective/position
        - change the variable creating the error type
        - receive negative feedback for errors
        - apply negative feedback to correct structure (like direction)
        - identify costs (indicating why its an error, as in what resource is lost)
        - structures that depend on the outputs of their distortion, becoming dependent on their distortion
        - structures that cant develop a function to correct the error (a power source that cant develop a power distribution/delegation function)
    - organize list of structures required for system optimization & make diagram & generative insight path & query
      - concepts
        - anti-chaos structures (organization)
        - lack of requirements (dependencies): an optimized system operates in a self-sustaining, self-improving way with as minimal requirements as possible with existing resources like functionality, and with decreasing requirements over time
        - multiple alternatives
          - example: having multiple definitions of cost avoid errors like 'lack of flexibility due to over-prioritization of avoiding costs like pain' and instead be able to sustain one cost type to reduce another cost type, for a duration like 'as needed' or 'while advantageous'
        - anti-complacence structures (checking for new error types that cant be measured with existing tools yet by always building new measurement tools)
        - other structures for optimizing systems
          - anti-complexity
            - apply filters to remove information that is repeated without value added
          - anti-trust
            - apply tests regularly to system components & structures of them, checking it for new variance sources & error types as well as known sources/types
          - anti-dependency
            - apply solutions to optimize system that increase similarity of components in the direction of independence, distributing functionality across components (like cross-training)
          - anti-static
            - add solutions that dont remove possibility of generating other solutions/error types (thereby reducing the variation the system can handle)
      - functions
        - apply error types to check a system for known optimizations (error types like 'structures that seem similar but are not')

  - use exclusively ai with known biases & error types so output can be corrected with the associated solution type
    - algorithms that dont have a mechanism to offset/correct biases from data can be used with a correcting function to improve output likelier to be an error type
    - this is an interim solution (algorithm/model + correcting logic of error types) while other algorithms are tested
    - every algorithm has limitations - those with known limitations can be an asset in some problem types (like to discover biases in data), while other algorithms with unknown limitations can be an asset in other problem types (like to add uncertainty or delegate responsibility for unfair decisions)

  - integrate related AI models within the same network of variables to derive functionality 
    - if you have an AI model to predict relationships between causally sequential variable sets A/B/C, D/E/F, and G/H/I, apply the connecting variable set models (A/B/C and G/H/I) to create a logical function to connect inputs/outputs of the D/E/F variable AI model (or a subset of variables), as a filter to streamline output of the model in response to changes to relevant to data & variables
      - this is an alternative to training a model on D/E/F in isolation, & updating it by training it on new data received
      - not only should it be able to identify the dependent variable value with accuracy, it should be able to fit into the network of relevant variables, connecting other related variable sets (A/B/C and G/H/I)
      - this may offer the possibility of skipping modeling D/E/F at all, if A/B/C is predictive of G/H/I on its own in the target range of accuracy, but at least will offer extra validation potential of D/E/F model inputs/outputs, and may provide core functions/structures (generalizers, thresholds, filters) to use in building the reduced stabilized logical form of the D/E/F model on-demand
      - answers the questions:
        - 'given A/B/C and G/H/I models, does D/E/F make sense'
        - 'can a reduced stable logical form of DEF be derived from ABC & GHI, and does this logical form match DEF, and to what degree'
        - 'why a variable is useful to predict another', not just 'if a variable is useful to predict another', since knowing 'why' will help the model adapt when that reason changes

  - apply insight path to solve problem of 'finding factors to produce number without using multiplication of every combination'
    - insight path: use filters to reduce solution space instead of generating solutions (such as by identifying metadata of solutions & applying combinations of those attributes)
    - problem: find factors of 28 without using multiplication of every combination (trial & error)
      - factors of 28: 1, 2, 4, 7, 14, 28
      - remove: 1, 2, 14
        - divide by integer unit 1, divide by 2 bc even, divide by co-factor of 2 which is half (select midpoint without multiplication))
      - the remaining candidates are: 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13
      - apply filters to solution space
        - apply similarity of value structures as a filter
          - adjacent items can be ruled out by proximity (for example, 13 couldnt be a candidate bc its too close to 14 to be a factor of such a small number)
            - the remaining candidates are: 3, 4, 5, 6, 7, 8, 9, 10, 11, 12
          - apply similarity (of adding factors to sequence) as a filter
            - test sequences for adjacent computations
          - apply similarity of components (factors) in definitions (numbers definable in terms of their factors) to find relevant structures
            - test primes which are relevant bc of their definition being definable in terms of the factor standard
        - apply output patterns as a filter:
          - multiples of 10 and 5 can be ruled out bc it doesnt end in zero or 5
            - the remaining candidates are: 3, 4, 6, 7, 8, 9, 11, 12
        - apply combination structure to produce solution format (multiplied pairs of factors)
          - pairs are a combination structure
          - the remaining factors can form pairs, which can also have filters applied
          - apply filters to pairs 
            - apply output requirements
              - metadata of the output, 28, includes that its an even number, so multiplied pairs must produce an even number
                - odd number x even number can produce an even number
                  - 3 x 4, 3 x 6, 3 x 8, etc
                - even number x even number can produce even number
                  - 4 x 4, 4 x 6, 4 x 8, etc
              - apply reduction tests (what could not be the solution)
                - apply tests to inputs
                  - inputs must be spaced according to the output number
                    - adjacent numbers are unlikely to produce the output number (as a multiplied pair) for an increasing output number
                  - structures of inequality (not equal to solution)
                    - too large
                    - too small
                    - not even
                  - identify threshold structures (values) of input structures (values, value pairs) that would produce one of these inequalities
                    - filter out inputs if they would produce an output that was too large to be 28
                      - 28 is quite a small number so pairs of numbers above a threshold value (3 x anything above 9, etc)
                      - some pairs are clearly too big to produce 28, without checking the product
                        - 11 x 12 is clearly too big, so can be removed from list of possible pairs

  - concept of attention in structures
    - mixed interim high-variation & high-similarity structures tend to maximize attention

  - examine conflating intent & requirement

  - insight path example

    - when generating solutions, identify:
      - context/case/condition that can filter it out
      - variables that can generate the most solutions
      - filters that can filter the most solutions
        - apply filters to solution space by solutions that are ruled out in fewest cases, best cases where solutions are less required or least probable cases
    
    - example: how to put shirt on underneath jacket without taking off jacket completely
      
      - alternative queries

        - identify sub-problem: 

          - find a format where sequence (shirt on top of jacket) can be changed into solution format (jacket on top of shirt)
            - identify adjacent format 'bunching into circle around neck' that allows changing sequence (which is on top) and transformation function into that format from origin format 'taking off sleeves'

        - apply adjacent formats to problem & solution formats
          - identify formats that have a sequence (stack, row) which is a structure implied in the solution format ('underneath')
            - apply functions to test if shirt can be transformed into one of those formats

        - generate adjacent functions (bunching) from core functions (move sleeve, lift, rotate) & try them to see if any useful structures emerge moving objects closer to solution formats/positions
      
        - generate default connecting function and apply structures of optimization (reusing functions, avoiding extra steps) to improve the default connecting function incrementally

        - identify tests that can filter out solutions

          - identify tests interacting with structures of variables (change types, potential, uncertainty) & constants (requirements, limits, definitions)
            - possibility test: 
              - interaction test:
                - in what ways can the shirt/jacket interact
                  - can the shirt occupy position (fit) under the jacket
            - requirement test: 
              - does the shirt/jacket have to stay in its current position/format
              - does every step of functions ('removal' function) have to be executed (can you just remove pieces, like the sleeves, without removing the whole thing)
            - change test: 
              - in what ways can the shirt/jacket be changed while remaining a shirt/jacket (bunching, removing sleeves) 
              - are these ways reversible (can it be put on after being taken off)

          - apply tests to reduce solution space
            - solution can involve variables:
              - position 
              - format
              - change functions (bunch, lift, remove)
              - components (sleeve)
              - interaction functions (stack in sequence)
            - solution must fulfill requirements
              - jacket must be in 'worn' position at all states
              - change functions cant change object identities (change jacket into shirt or into a not-jacket)
              - solution must reverse sequence of objects in stack structure)
            - any solution involving removing the jacket completely in a state, change functions that change object identities, and where solution format is not fulfilled are ruled out
            - other tests include:
              - minimize steps (did solution do any unnecessary steps)

  - alternate insight path direction types
    - generate solutions from problem statement using interface objects
      - core functions 
      - mixes/changes of previous or abstract solutions
      - insight paths (break problem down, trial & error, etc)
      - system structures
      - core structures (opposite, equal, adjacent)
      - function input/output chains
      - vertex variables
      - conceptual structures
    - apply solution format and reverse engineer solution
      - apply solution filters that are adjacently derivable from problem/solution metadata (most-reducing filters that rule out the most solutions)
    - apply both the generate solutions method & solution format method and connect them in the middle

  - example of deriving solutions (from https://www.quantamagazine.org/mathematicians-inch-closer-to-matrix-multiplication-goal-20210323/)

    - original solution (apply method to smaller matrices) applies:

      - core structures: 
        - meta (matrix of matrices)
        - subset (sub-matrices)
        - substitute (addition for multiplication)
      - core functions:
        - apply substitution method to subset once matrix is formatted as a matrix of matrices
          = apply(substitution_method(format(original_matrix, 'subset')))

    - how to generate other solutions

      - multiple queries to arrive at the same solution of 'finding adjacent interim values & re-using multiplication operation, in case where adjacent interim values exist in a matrix'
        - you can start with the target solution formats as your interface query filter (equating "problem format + operations = solution format")
          - a more efficient operation than multiply
          - a more efficient combination of operationss than 'multiply then add'
        - or you can start with applying interfaces, and iteratively focusing on & applying useful structures found for the solution (problem-reduction or problem-compartmentalization)
          - apply structures known to generate solutions to fulfill solution metrics (move toward solution position or reduce solution space or reduce problem)
            - apply core/adjacent/efficient/similar structures

      - apply structural interface

        - apply core structures of structural interface
          - apply structural similarity to structures of problem (including value)
            - similar values enable addition instead of multiplication (multiply 5 * 8 & subtract/add 8 instead of multiply 4 * 8 and 6 * 8)
            - if there are similar values in a matrix, and storage is allowed, this can reduce multiplication count (ignoring storage search)
          - apply adjacence structures
            - find values adjacent to matrix values to find similarities in computation requirements
          - apply similarity structures
            - find values in matrix having a common factor (base) and standardize operations involving those values
          - apply sequence structures
            - find sequences in multiplication operations & apply sequence operations rather than individual calculations
              - find numbers in even number sequence (common factor of 2) and reduce to addition of coefficients of powers of two
                - 3 * 5 + 2 * 6 + 2 * 4 =  3 * 5 + 2 * 2 * 3 + 2 * 2 * 2 = 3 * 5 + 3 (2^2) + 2 (2^2) = 3 * 5 + 5 (2^2)

      - apply function interface

        - find functions that convert multiplication to addition or other lower-cost problem
          - replace/substitute
            - identify when multiplication can be replaced by addition
              - addition can replace a multiplication, if an adjacent multiplication has already been done
            - convert numbers to efficient multipliers like powers of 10 that involve moving digits rather than multiplication

      - apply core interface

        - apply core functions (replace) & core structures (unit) to problem components (problem functions of multiply & add)
          - apply interface interface (standardize problem to interfaces of problem space)

          - apply system interface
            - apply system structures
              - apply efficiency structures
                - identify efficiency structures in problem 
                  - inefficient operation (multiply)
                  - efficient operation (add)

                - apply change interface
                  - connect an inefficient function (multiply) to an efficient function (add) to change inefficient function to efficient function
                    - define one problem function as a transformation of the other problem function
                      - define multiply in terms of add using core functions/structures or problem functions/structures
                        - apply replace to one unit of original multiplied values with an add operation until multiply is defined in terms of add (standardize to add interface)

                - apply efficiency structures
                  - apply efficiency structure 'apply one operation instead of multiple operations'
                    - identify when multiple multiply operations can be replaced with this type of adjacent multiply/add operation 
                      - identify when a multiplication operation can produce an interim value in between other values so the multiplication can be re-used for another value

          - apply structure interface
            - apply structural interface structures
              - apply filter structure
                - identify matrix cases where these operations are inefficient or unusable
                  - identify operations/information needed to determine inefficiency/unusability of this solution
                    - apply function to determine threshold value for matrix dimensions or metadata like value variability (if values are in a known range or have a known type): 
                      - 'if there are more than x adjacent values with an interim value in a matrix of size n x n, this method can save computation steps even with the determining operation'
                    - add average cost of determining operation to cost metric (computational complexity)

      - apply system interface

        - apply system structures
          - apply efficiency structures
            - apply efficiency structure of 'reusing existing resources'
              - identify what resources exist or are created in original solution (values output by multiplication & addition operations)
                - identify condition where these can be reused for other operations
                  - when other operations are adjacent
          - apply symmetry structures
            - apply symmetry structure of 'interim value one change unit away from multiple values - one being addable in the position of a coefficient'

  - add intent metadata to interface query examples 
    - 'find combine structures after applying system interface - to find connecting structures in problem/solution system'
    - the intent of a sub-query should be defined in terms defined on that interaction level, to avoid gaps in connecting structures across sub-queries, so that further sub-queries of the sub-query can connect to the original triggering interaction level intent
    - example: 
      - when solving a problem with an insight path like 'break problem into sub-problems', the sub-queries to solve each sub-problem should be defined in terms used by the insight path & problem statement
      - a sub-query to solve a sub-problem like 'reduce & isolate dimensions of problem' should be defined using the problem statement components & the insight path ('break' as the original function mapped to sub-functions 'reduce' and 'isolate'), so when it comes time to integrate sub-solutions into a solution, the corresponding opposite function to 'break(problem)' can be applied to 'integrate(solution)', using a version of 'integrate' such as a specific version of 'merge' that connects to the version of sub-functions of 'break' used

  - applying non-standard methods across systems

    - example:
      - applying concept of 'bias' used to fulfill intent of 'creating a truth filter'
        - bias is usually used to evaluate intentions of agents when interacting with other agents with some level of variance in agent identities
        - after abstracting intentions as decision/function triggers:
          - apply bias as a truth filter to determine non-agent change/function triggers
          - this can work bc even components without agency respond to incentives bc of their common tie to physics
          - bias also interacts with the concept of randomness & randomness can explain false info signals, which connects to problem-solving intent of identifying truth

    - queries to generate insight path to find useful structures to apply across systems, for an intent like 'truth filtering'

      - apply insight paths to generate insight paths

        - find structures with 'truth filtering' intent in solution (source) system
          - map system components across systems (map 'truth' in agent system to 'correct' in non-agent system, match 'intent' to 'incentive' bc non-agent systems always respond to incentives)
            - map connecting structures in source system to connecting structures in target system (what connects bias function in source system vs. corresponding connection in target system)

        - apply components of structures with 'truth filtering' intent across systems, to equalize problem (target) & solution (source) systems
          - apply metadata of 'truth-filtering' structures (bias) from agent source system to non-agent target system
            - apply bias/interface metadata (intent) to target system components
              - find intent ('reasons') for 'randomness' (find the change interactions producing false or temporary randomness in non-agent systems)

            - apply bias interface objects (intents/reasons to use biased rules) to target system components, due to commonness in intents across systems
              - bias intents/reasons: over-simplicity, lack of storage, lack of change type functions (update functionality)
              - 'if an info signal has bias intent signals (if its clearly caused by lack of storage), classify it as a potential false info signal (request from pathogen rather than from host cell, false electrical signal, illusion of an electron count)'

      - standard interface query 

        - apply structural interface
          - identify connections between structures in problem
            - problem: 'find true info in agent-based system interactions despite agent incentives to send false info & intentions/decisions to do so'
            - problem structures:
              - concepts: 'truth' (intention matches decision output = 'successful decision'), 'agency', 'incentive', 'intent', 'decision'
              - functions: 'interaction functions', 'decision functions'
              - other structures: 'decision function triggers', 'false info', 'true info'

        - apply combine function to conceptual interface
          - create combinations of abstracted versions of structures
            - problem: 'find true info in system interactions despite incentives to send false info & other sources of false info & change functions enabling that'
            - problem structures:
              - concepts: 'correct' (info implication matches its impact), 'incentive', 'change', 'randomness'
              - functions: 'interaction functions', 'change functions'
              - other structures: 'change function triggers', 'false info', 'true info'

        - apply connect function to abstract structures
          - find structures that connect abstract structures (randomness, false info, change/function triggers) without the specific attributes tying them to one system (agency)
            - test whether the connecting structures fit with the new system after removing attributes:
              - can bias be used to filter out false info or find true info in chemical interactions, despite elements not having agency, as an abstracted way to decompose randomness/noise or complex systems
                - for example, can an abstracted version of bias structures correctly model the integration of quantum physics with chemistry rules to explain some chemical phenomenon

  - finish core function structure example diagrams

  - vpn's & proxy servers to enable protection functions (viewing science research or medical info) by 
    - automatically finding countries with laws allowing those protected functions & routing requests from servers in those locations
    - finding a version of an app that has target features so user is directed to download for that versions

  - successful AI would identify multiple solutions as probably successful once variables of inequality were identified

    - query: identify 'value' as the vertex variable

    - query: identify input variables determining value: 
      - location
        - what is a low-method to change location: public transportation
        - what is a barrier to change location: visa, lack of info
      - proximity to supply chains
        - make an alternative supply chain between high-traffic suppliers/demands in other direction (across continent rather than across an ocean)
      - relevant cost ratios (cost of going somewhere, finding job, selling something, finding info)

    - query: find methods to transfer resources
      - temporary markets (tasks that will probably be automated within n years, markets for goods people probably wont want/need in n years, or only need once, or only while a law is applied that will be changed soon, or products that need a connecting product until theyre all invalidated by another product being built)
      - supply chains
      - transportation
      - delivery services

    - query: find relevant interfaces
      - laws
      - code
      - resource distribution
      - location

    - query: find solution methods
      - connect existing resources
      - apply multiple high-difference solutions, vary them to find subsets & versions that work

    - query: find lowest-cost combination of solutions
      - finding highest-value public transportation infrastructure to build (what routes would allow low-cost resource transfer for the most agents)
      - finding temp markets (delivery/resource-sharing/education services)
      - finding adjacent/existing law combinations to benefit the most low-income agents
      - finding adjacent/existing bugs or code loopholes to benefit the most low-income agents

    - query: organize info into a combination solution
      - example of a combination solution, integrating multiple relevant interfaces, solutions, covering a high ratio of input variables to vertex variable
        - 'investing in delivery businesses near planned supply chain routes offering a high-traffic alternative route, and relocation or transportation infrastructure to enable lower-cost market participation with subsidized education for delivery workers to help them get better jobs and leave their jobs open for immigrants'

  - consciousness as choice to move between neural nodes (rather than being directed) required:
    - the development of alternative node paths performing equal/similar functions, requiring:
      - the development of excess resources, delaying required decision time (making immediate decision unnecessary, avoiding a forced decision), requiring:
        - the existence & application of previous efficiencies & functions for alternative evaluation, energy storage, storage-checking, & energy requirement-identifying
    - the cause could be framed as structures such as an 'efficiency stack' or 'energy maintenance functions' or 'alternative options' or 'navigation/motion control' or 'lack of requirement/need'

  - example of applying interfaces to derive metadata about a component
    - apply causal interface to identify connecting function 'power is responsibility' (also an insight)
      - power can be defined in causal interface components as 'causative potential' (its the input reason for change in a system, including changes preventing changes)
        - given that it has structure 'change input', its also a source of other change types than intentionally triggering the correct function (errors, side effects, changes to errors)
        - changes to fix errors are related to the concept of 'responsibility' (definable as 'work that isnt incentivized but is necessary')
    - apply structural interface to identify connecting function 'power is responsibility'
        - 'aligning error & fix sources' also corrects the 'power source distribution imbalance' error, which is another way to derive this insight, using the structural interface (correct distribution imbalance with alignment)
        - identifying the 'similarity' (a core component of structural interface, applied during a standard application of interface) in the 'direction' structure, between power & side effects (including errors) as similar to the direction between power & fixes
        - identifying connecting functions positioning power as an input/required structure to fixing errors:
          - identifying that 'fixing functions' have an input trigger requirement like any other function, and function triggers therefore have power to fix errors
          - identifying that if something can generate a 'fixing function', it necessarily has power
          - identifying that if power is necessary to change a structure, by process of elimination, nothing else could fix an error

  - connecting function of math/logic 
    - a problem like the following is a logic problem ('find the logic connecting this input/output') that can respond to the general solution workflow (given a problem input format of a 'function' to check possible solutions with) of:
      - 'identify the unique correct solution in a solution set to a problem of equalizing the sides of this function' 
      - 'identify which solutions are not correct, reducing the set to a size of 1'
      - this can be converted to a math problem of:
        - iterating through solutions
        - checking each solution to see if it solves the problem ('equalizing both sides of a function')
        - removing it from the solution set if not
        - otherwise checking if the set of possible remaining solutions has a size of 1 yet to give a success signal
        - continuing iteration if not
      - the connection between these interfaces is in the structure of logic (math being structural information in core terms like numbers):
        - the set iteration has a 'sequence' (set, progression) structure
        - the remaining solution set size has a 'integer' (set, progression) structure
        - the success signal & the continuation condition has a '0/1' (core alternative) structure
        - the solution test has a 'function' and 'equal' structure (are both sides equal yet)
        - the remove operation has a 'subtraction' structure
        - the continue operation has a 'sequence' structure
        - the condition component has a 'direction' structure (change direction in logic network/tree) and 'multiple option' structure (a decision between differing & mutually exclusive options must be made)
        - the check/test operation has an 'equal' & 'inject' structure (inject variable values to see if both sides are equal)
        - the logic function has a 'directed network' or 'tree' structure (follow directed relationships between function components)
      - apply structural interface to connect logic & math structures:
        - 1. some of those structures have structural relationships which should be identified by applying interfaces, like structure (including components like the similarity concept)
          - similarity:
            - the similarity in structure between the solution set size & set iteration (a progression or sequence) is relevant, bc the iteration & the set size should:
              - move in opposite directions
              - equal the original set size when added
          - by applying the structural interface (with components like the concept of 'similarity'), the query can identify this relevance by checking if an adjacent connecting function between the similar structures exists & is relevant to the problem/solution
            - generate core functions & generate combinations of them, applying them to problem variables being examined for a connecting function (solution set size & set iteration)
            - filter by those applied core function combinations that move/change the problem (converted into a solution space, once identified) to be more similar or closer to the solution structure (solution set of size 1)
          - direction:
            - given the sequence & other direction-related components/attributes/structures of the problem, the input problem components & output solution structures can have a position structure applied
        - 2. given that the solution format is a 'set of size 1', and the input problem format is a 'set of size greater than 1', it can be derived that:
          - when executing problem-solving method, the method should include a step where:
            - an item(s) is removed from the set 
          - this connecting function between problem & solution format derives the solution requirement of the 'remove' operation (without being explicitly told to include that operation in the problem definition)
          - given the other structures involved (integers, iteration sequence), it can also be derived that the remove operation should apply a subtraction operation rather than another structure like division, which would introduce other less relevant & adjacent formats like non-integers
            - this applies problem-solving insight paths like 'adjacent solutions should be tested first in an absence of reasons to do otherwise', where reasons to do otherwise could be metrics like system complexity, info about adjacent solutions failing in that system, info about non-adjacent solutions succeeding in that system (info about non-adjacent solutions being optimal for a system metric)
          - interface query design should involve queries to check for inputs to a step given required sub-query tests for alternatives
            - before applying a step, apply its required sub-queries to test for its alternatives, like for an adjacent solution step, checking that alternative non-adjacent solution sub-queries have returned no contradictory info indicating an adjacent solution should not be applied

  - examine similarity (alignment/overlap) structures between 
    - different components (when an error type is an incentive, or a function used for other intents)
      - contradictory/opposite components

  - decision between selecting insight path/query for a problem & generating a new one is dependent on:
    - problem metadata (complexity, adjacent formats)
    - available info (whether metrics are capable of capturing relevant info)
    - input data set metadata (whether variables are output metrics, variance-covering metrics, proxy variables, etc)
      - different input/output relationships will imply different interface queries that will be useful
      - beyond that, other (interface analysis-identified) methods to design an interface query for a problem type
      
      - apply interface analysis to interface query design (system including interface components, query components, metrics) - apply interfaces to the problem of designing an interface query
        - examine what are the core functions, efficiencies, incentives, error types, etc of the interface query system, and check that they match what Ive identified
        - check if you can skip some interfaces, like when you start with an input containing mixed-interface (concepts, functions, intents) or cross-interface structures (structures that apply/generalize to or connect interfaces), such as when you can identify common terms in input component definitions that can be used to frame all relevant objects
          - once you standardize terms of component definitions, is there an interim sub-interface youve standardized components to, which can be used in place of a full interface query
        - example:
          - adjacent formats: 
            - problem is route optimization, problem format is network, solution format is network path, interface query should include function interface, bc function format is adjacent to finding a path on a network
          - intent alignment:
            - problem is over-complicated system, problem format is network, solution format is reduced-complexity system network, interface should include math & structure interfaces, to find & apply dimension-reducing functions (interfaces already contain functions that align with 'reduction' intent)
          - required inputs:
            - problem is 'find a relationship between functions for calculation optimization intent', solution format is 'connecting function', interface query should involve 'connecting' functions, which are a required input to solution format of a 'function to connect functions that optimizes calculation efficiency'
        - this can optimize for problem/solution metadata, as well as general problem-solving methods
          - optimize for problem type: interface query for 'missing information' problem type should include the 'similarity/difference' sub-interface on the 'structure' to identify 'opposite' structures like 'what is not there'
          - optimize for solution format: interface query for a problem with solution format 'prediction function' should include either causal, potential, change, or function or structure.network interface, all of which can generate a structure connecting the in/dependent variables
            - causal: organize variables with causal diagram having direction & check for predictive ability (identifying correlation, applying causal structures like moving/deactivating variables, using variable proxies or aggregate variables) to filter diagram for probable causation
            - potential: identify potential alternatives (variable sets not in data set, randomness explanation) and filter if possible, possibly leaving original data set as last remaining solution
            - change: identify variable change functions, and evaluate distorted data sets using those functions for alternate prediction functions, filtering by functions that are robustly predictive with more change conditions applied
            - function: index variables as functions (functions using variable combinations/subsets) to check for input/output connectivity potential between in/dependent variables
            - structure: organize the variables as a network to find relationships & if there is a relationship between in/dependent variables
          - optimize for general problem-solving methods: 
            - example: 
              - 'generate set of possible solutions & apply filters to reduce solution space'
                - the interface query should have a format that is filterable once it reaches the filter step of the general solution method
              - 'break problem into sub-problems & combine & merge sub-solutions'
                - the interface query should have a format that is combinable/mergeable once it reaches the combine/merge step of the general solution method
  
  - organize list of structures relevant for intents
    - for 'identify' intent, relevant structures include structures of difference (filters) and uniqueness (unique identifiers)
    - for 'connection' intents (identify/generate connection), a structure where components are only defined in terms of other components (by their relationships to other components), like a network or vector space
    - for 'differentiation' intents, a structure where the definition of difference is clear & applicable (can differentiate all different components)

  - grassroots citizen info tech & citizen journalism as an alternative to top-down govt law enforcement, where centralized/organized govt law enforcement is allocated when a metric threshold for citizen reports is reached
    - the correct position of govt is an automated tool usable by citizens to solve problems (prevent crime, enforce laws, exact justice)

  - example of multiple structural filters to reduce solution space
    - example of where a structural similarity could be used as an initial filter (in a dog vs. cat categorization algorithm)
      - find similarity to type 'dog' and type 'cat'
        - in cases where similarities point to equivalent probabilities for each category, apply additional filtering structures than similarities
          - apply base structures (random, core, common, etc)
            - apply path structures (how many steps from a base to produce a clear answer)
          - apply opposite structures (what is not a cat, what is not a dog)
          - apply filtering structures (both/neither) - (what are cats/dogs both or neither of)
          - apply structures of difference (what comes from a different origin/cause, like causes of evolving dog functions)
          - apply state/time structures (could this become a dog or could it have been a dog previously according to definitive attributes/functions)
          - apply variance structures (does this have variance from the cat base or following cat variance patterns)
          - apply agency/group structures (what groups do cats belong to or which groups are they found with)
          - apply system structures (what contexts normally go with 'cat')
          - apply change/distortion structures (what distortions are often applied to cats or dogs)
              - apply alternative path structures & network structure
                - how many different paths could this data produce a dog category? (how to get to 'dog' answer using that particular data)
                  - apply boundary structures in network (cat type path set or path region, dog type path set or path region)
                    - re-apply similarity structures to boundaries (is this within the cat path region)
                    - apply pattern structures (does this match cat path patterns)

  - usb that stores os/state/processes/files so when you take it out, all thats left is hardware, so secure portable destructible readonly sessions (or sessions allowing only one write at a time, from a user-facing process like a document editor, with regular approval requests to re-authenticate writes or session) can take place
  
  - organize examples of logic for functions (interface query design logic)

  - add functionality (or associated attributes) with components with base/core functions included, components which can be connected with user-defined functions
    - this can add functionality to products to reduce need for producing new versions
    - physical sensors can use communications tech with varying required internet infrastructure (beacons/bluetooth/radio) to integrate with data, computers, physical resources, building blocks of robots
    - physical components examples:
      - use a sensor added to non-electric or non-AI-driven vehicles, pedestrians, & other moving objects on roads (animals, robots) to detect other objects or sensors & help avoid crashes by attaching sensor output as input to steering mechanism with a steering component (interim tech while waiting on market capture of EV & AI vehicles)
        - can also be used to turn a cart or anything with wheels into a delivery robot, to reduce human traffic
        - this can turn the delivery market into a sensor coding market to add functionality/integrations to sensors & the robots or resources controlled by them
      - use a sensor (indicating position to lift away from) as input to another sensor (lifting sensor) with connecting function (fetch position to move away from, direct lift away from position, initiate lift)
        - add sensors with user-defined connecting functions & prioritized sensor functions
          - if a sensor on top of trash can has function "lift" and can take input like "heat motion in range", add user-defined connecting function to another sensor not on lid that the sensor on top can use as a reference point to find direction to move in (away from other sensor) 
    - code components/functions
      - user-defined connecting function like "query regularly for a function that can do this (publish, copy, export, search, build), and when found, add to querying component"
      - find connecting function like 'abstraction' to add functionality like 'handling other inputs' or attributes like 'flexibility' and distribute flexibility to other accessible components
      - hook a search function component up to input component (filters) using user-defined connecting functions (input filters to search on)
      - user-defined connecting function to connect components like core functions/scripts/metrics (when this event occurs in the sensory input function, send signal to trigger other function)
        - this is a way to abstract code (any function that can receive input data of that type) & code connections, delegating execution to code located with queries (find a function of this type or with this input/output) and modularize code as well as making it more connectible
    - task: identify the core functions/components that can generate required functionality for most user intents without introducing security flaws (making hacking devices less adjacently buildable than common legitimate use cases)

  - function-usage-intent::output or demand::supply combination/merging/building/matching functions (alternatively formatted as a solution-finding query for a problem or lack-resource matching function) as an alternative solution to ads

  - finish lists:
    - interface implementation problem type structures (suboptimal interface queries, incomplete definition routes, sub-optimal or mismatched formats) 
    - implementation variables as config options (different generation starting point/source of truth, equivalent/different voting influence in determining interface queries or system optimizations, different constants/derived info/functions, different default interfaces/definitions, etc)
    - core problem type structures (reduction, expansion, organization, matching, standardization, regulation, prediction/derivation (missing info), limit/change conflict resolution, error-to-resource conversion, optimization) & optimal formats & format structures for each
      - optimal optimization formats include network path-finding
      - optimal reduction/expansion formats include change type isolation as shape dimensions after structural assignment of problem attributes
      - optimal organization formats include layered networks & vertex variables

  - add to definitions
    - valid: having reason/logic/info supporting why it would be true, without higher-validity contradiction (info, more valid logic with higher support:contradiction ratio or higher applicability)
    - games (metric optimization, input/output link finding) 
      - games applying system context (metric selection) & function (function building) as a source of interfaces
    - important decisions as changes that are limited, clear & necessary (two options to change direction rather than 360 degrees of direction change options)
      - calculating decision metadata (optimal decision given intent, optimal decision across intents, least risky/causal decisions, alternative/equivalent decisions) can reduce the solution space of likely decisions
      - rather than predicting just using user decision history/incentives, predict using system incentives present in the decision-generating limits & indicated in decision metadata
    - integration/organization structures
      - give example of structures (like alignments, positions, directions) necessary to integrate structures of organization
        - organization structures are methods of organizing information (like neural architecture, information networks, OS)
        - as organization systems become integrated (like "applying an OS to machine learning networks to intercept/replace/validate bio system functionality"), their differences in structures like position and their organization & optimization structures will cause problems that are less predictable than other problems
          - example: applying a 'separation of functionality' structure to folders like occurs on an OS to a machine learning network structure may produce errors like 'separation of function & intent', which can be sub-optimal for tasks like 'identifying optimization metrics'
            - if this is further complicated by integration into a system as complex as the bio-system (for example by using that OS/network organization structure integration to filter & allocate sensory input information), it could cause less predictable errors, like misidentifying a bio system interface

  - add structural queries to insight paths
    - alignments present in security innovations (like alignment in inputs like keys)
    - source of rule development as structures of conflict between forced interactions like change causes & constant structures like limits
      - incomplete inevitability of interaction as a decision structure
    - other examples  
      - group device history authentication: authenticate credit card by proximity to cell phone & continuity applied to user usage history pattern

  - summary of advice

    - invest based on:

      - prioritizing real value signals: 
          - products that fulfill a need
          - companies that self-invest (prioritizing growth by re-investing in growth)
          - leaders that guide by example
          - independence: invest in independent value sources & independence-generating assets, become an independent self-supplier of your required inputs
          - understanding: invest in assets you understand
          - established/proven (long-term) value
          - efficiency: take responsibility for your required inputs

      - avoiding false value signals: 
        - incentives: high-reward/low-cost reasons to invest that may not align with real value or be sub-optimal dynamics that destroy value in a different position of the system 
          - speculation
          - investment banker advice
          - ceo status
          - short-term value changes

  - future value signals

    - problem metrics: current problem-solution ratio, problem to problems-solved ratio
      - solution metrics: 
        - efficiency: sustainability, reusability, cost-benefit ratio
        - independence: self-generatability, self-awareness/regulation/correction
    - efficiency-generating metrics: 
      - integration/organization/optimization/regulation/generalization
    - info distribution (across teams, departments, ranks, customers, other businesses)
    - info proxy derivation/acquisition/building
      - education
      - group membership (do they outsource some processing to groups, and which ones, and how do they evaluate groups like partners/clients/competition)
      - understanding
        - group dynamics (do they help toxic groups improve, do they have a self-destruct mechanism if they become a toxic group, etc)
        - markets (do they organize & optimize markets to achieve their goals quicker)
      - flexibility or learning potential (intelligence derivation/generation/acquisition/building)

  - give example of mathematized insight path 
    - standardize variables to math interface structures & values
      - apply type interface
        - identify types
          - standardize variables with types to differentiated clusters
          - apply difference definitions (like variable subsets) until type separations are clear
          - apply difference types until type separations are clear
      - apply structural interface
        - identify relative difference (difference from reference point, like origin node)
          - apply adjacent structures (vector or spectrum or loop) to variables having the concept of 'opposite'
      - apply causal interface
        - identify causal structures like direction
          - apply structures with direction to variables having causation in their connections
      - apply function interface
        - identify variables with input/output relationships to form path between structures on meaning interface
      - apply concept interface
        - remove randomness
          - compress variables with randomness injections to lower dimensional representations
      - apply meaning interface (using a structural relevance definition)
        - integrate variables in one structure to relate them
          - identify any vertex variables as the preferred variables to standardize other variables to
          - connect variables once formatted using adjacent/interim dimensions like topologies with variable subsets that can act as interfaces between connected formatted variables 
            (can capture info from input & output variables in the connection)

  - functionalize insight paths & integrate functions in optimized program with parameters to select function subset & structure for input problem
    - give parallel/perpendicular insight path examples, for insight paths that add info that the other is less/more likely to retrieve

  - diagram with error types
    - examples: 
      - over-structurization (specification) of an uncertainty/variable (assumption as fact, variable as constant)
      - over-correction of an error
      - over-prioritization
      - over-reduction (over-simplification)
      - over-variability (over-complication)
      - misidentification of minimum info to solve

  - new insight-fitting algorithm for error type avoidance
    - when a new discovery is made, apply insight paths formatted as questions to spot error types before they occur
      - could this violate any assumptions/requirements/dependencies we rely on for other tasks like calculations or applying systems of understanding
      - could this cause cascading (self-sustaining) errors
      - could this cause emergent errors, given other knowledge like probably interactive trends or rules
      - what are triggers of this? what can it trigger with certain interactions, how likely are those interactions

  - diagram with joke types
    - 'annoying when they bring up human rights in a conversation'
      - conversation system context
        - functions
          - change topic 
            - change topic structure (sequence)
              - introduce a topic (first time topic is included in conversation)
          - expected interaction functions
            - criticism of a behavior
              - 'conversation with dictator' system context
                - criticism of power abuse (law violation, specifically human rights violation, which are a related object to dictators)
                  - interpreted as right in the 'conversation with dictator' system context
                    - expected interaction in this context
                      - 'should bring up human rights to a criminal'
            - norms:
              - for low-stakes interactions & interaction errors (manners, annoyance, disrespect)
            - laws: 
              - for high-stake interactions & interaction errors (rights violations)
        - placing a norm (or related objects) in the place where a law (or related objects) would normally go:
          - 'its annoying when someone doesnt let you end the conversation'
            - 'its annoying when someone keeps going on & on about your previous conversations where you ordered deaths of a dissident'
              - 'its annoying when someone keeps going on & on about your previous conversations where you ordered deaths of a dissident for being annoying & then abruptly stops without explanation'
            - 'its rude when someone doesnt let you end a conversation with a laywer interrogating you for war crimes' 



  - example of applying structure to components like technologies to find emergent trends

    - tech, standardized to common terms
      - movie: sensory info emotion triggers & info/abstract paths (stories)
      - video game: decision visualization
      - music: audio emotion triggers & info/pattern paths
      - ai: prediction/generation
      - ar: integrate visualizations with real sensory info
      - screen: visualization interface
      - video conferencing: visualization sharing
      - text voting: decision aggregation
      - drug: direct sensory info semotion trigger
      - brain-scanning tech: visualize memories & thought processes

    - multi-player video game voting: applying voting tech of viewers to influence video game tactics/resources/problems/outcomes/decisions
      - generative query: switch input of decisions to another decision-producing tool (audience voting vs. player/algorithm decisions), for randomness/customization/reality integration intents
    - user character customization: applying AI to generate characters of real people or characters from other games to play as other players in video game
      - generative query: switch input of character personality/story with another source of that info, for customization/reality integration intents
    - memory-generated vidoe game: apply ai & brain-scanning to generate a game based on memories
      - generative query: change experience level or skills required (use memory as a tool or test memory functionality), for testing/customization/reality integration intents
    - emotional/sensory alignment games: query for desired emotional path & map a game/video/audio/drug to produce or match that path
      - generative query: change content-creation direction & other variables, from story => emotions to emotions => structure applied to emotion-triggering tools
    - brain-development games: apply AI & brain-scanning to identify missing functionality in brains & generate game to develop that function
      - generative query: use output of game (learning) as input assumption for learning intents using games as intent-fulfillment resource

  - diagram for structures of emergence
    - example: 1-1 input/output relationship up an interaction layer, where extra resources that dont dissolve immediately on the higher interaction layer aggregate & form core structures like combinations, where interactions between combinations & sequences have different dynamics than the individual output interacting with other individual outputs
    - emergent functionality/attributes come from interaction structures (sequences & layers)

  - calculate deaths caused by products/companies by proportional contribution to deaths from slavery & pollution/plastic/additive/medicine & other chemicals

  - generate other interfaces with interface components (connection, requirement, structure, abstraction, set, independence)
    - intent: future direction with benefit to agency
    - cause: preceding inevitability requirement in sequential structure
    - function: structure of task structures (conditions, assignments, iterations) consistently connecting input & output
    - logic: function to connect information using info structures (definitions, inevitability, pattern-matching, exclusive/inclusive conditions, requirements, assumptions)
    - potential: structures like combinations not certainly excluded by requirements
    - change: difference in an attribute value, according to a base (time, relative change, change type)
    - abstraction: general pattern of a specific structure set
    - pattern: a set of connecting functions, often in a sequence structure
    - structure: connections & change of measurable change & difference types
    - information: specific description of a structure
    - math: description-connecting functions
    - system: structure of independence, often having boundary, function & other component structures, at a particular interaction level

  - platform to apply a portfolio of AI models to price a stock given private company data like available resources, internal analysis, & implementation plans & publish the ai-generated prices, with comparative historical pricing of other companies using similar data pre-ipo or valuation, as an offset to price pumping & other forms of misrepresentation

  - identify accidental & intentional govts/laws/markets, based on function metadata concepts
    - responsibility (restricting functionality to the functions that can & should handle, based on whether they caused the problem resolved by that functionality)
    - relevance (restricting info only to functions that need it)
    - structure (functionality gaps)
    - potential (analyzing future functionality and paths to those states)
    - integration (analyzing impact of intent/responsibility/optimizations of a function)
    - optimization (storing functionality needed, generating functionality where possible & where usage allows)
    - organization (indexing functionality in a way with specific side effects like limiting possibilities, and organization through queries & changes of functionality)

  - solution investing app
    - Is the cost (implementation/opportunity/mgmt/bug-fixing costs & lost previous work/equipment value) higher than the benefit?
      It's a technology if its problems solved/created ratio & relative feature value is high enough; if not, it's just a tax/debt
      We don't need to create problems to create jobs, we need guaranteed scientist jobs to handle existing science problems
      Companies/agencies should exist to manage/build solutions to existing science problems (pay this company $x to get y% of pollution removed from outdoor air)
      Taxes are a relatively inefficient & obscure way to allocate funds to these public good solutions, compared to product purchase payment plans
      People should be able to see what their taxes are funding & opt-out to invest in other products/companies
      - example: "avoid a local road that needs local govt budget to repair, to decide where to route funds to more important projects"
      There should be an app to opt-out of taxes if they agree not to use local resources those taxes pay for
      Companies can have efficiency & problem-solving scores (problem-solution, solution metrics, cost/benefit, hidden costs, time to solution, problem solved/created metrics) in a solution investing app to win investments from citizen investors to solve problems relevant to them
      - identify which companies/traders have the right market signals or info by retroactively analyzing historical data about which agents' investments turned out to be correct in the intended investing timeframe

  - apply intents & other interfaces to other decision (transaction) types (code transactions, financial transactions, legal transactions)
    - code transactions (user action like 'clicking a button' or 'running a script' indicates what intents, according to relevant system contexts, like applicable laws/protocols)
    - resource transactions (financial resource trades), to manage intents of a transaction - money is deposited on resource delivery, otherwise in pending state for x days agreed on by agents
    - legal transactions (allow laws to be passed having any of a limited list of approved intents)

  - finding necessary forms for an intent subject to indexed rules like laws, filling them out, and optionally filtering info by regulations cited in forms, including relevant regulations applied
    - involves automated calls/faxes to request/send forms, where processes/forms arent online, like how calls to find appointments are automated
      - involves functions to:
        - derive steps to complete the task in the right sequence/decision tree/flow chart structure (fill out form, fax form, consult legal consultant, review auto-filled input)
        - derive steps in the digitized process (log in, submit form, schedule appointment)
        - find & apply relevant regulations
        - find related forms
        - auto-fill forms
        - derive & execute steps to complete sub-tasks (like 'send a form' or 'schedule an appointment')
        - identify & highlight input that needs manual review
        - find people with expertise to guide manual review (legal consultant, govt employee)
        - digitize process (auto-import to workflow management tool or multi-step form component)

    - alternatively an automated process to digitize a process/form with necessary security, search functionality, and integration with other services/processes as digitization tool variabless
    - the tool should be able to submit user-permitted/submitted input to a preliminary process (like 'apply for a license' or 'submit voter registration') form (like a wsdl, other api spec, url with html form, or just a form pdf template with unfilled fields) and guess the values based on accessible inputs (user address info), then lookup any relevant regulations or related forms & fill out those forms or apply the regulations, and then return suggested output, with highlighting for missing fields or predicted fields with certainty below threshold that user or a legal consultant can manually review, and a list of remaining action items, which can be triggered if the user is ok with the output or updates the output, such as faxing/sending/printing/mailing the form on remote servers or using task-running apps to find a person willing to run the errand, or scheduling a call/appointment (like a dmv appointment).
    - this should also be applicable to software updates (submit a current request to a current wsdl, and find/apply relevant or recent govt regulation updates as well as web protocol updates to generate updated wsdl/request/response as well as request/response wrapper/handling functions, like updating new field names or request structures in codebase)


  - search of local product supplies across exchanges

  - diagram of alternate interfaces (information = combination of structure, potential, change or structure, cause or structure, system)

    - example of applying alternate interfaces with examples of advantages of each

      - the structure (position) of the component can be used to determine/differentiate its meaning
        - 'logy' and 'logi' as prefix/suffix
          - '-logy' as a study of the prefix
          - 'logi-' as a permutation of 'logic'

      - the usage context (sentences where they're used) can be used to determine intent
        - '-logy' used when 
          - discussing science & interactions between fields/topics or changes in a field/topic
        - 'logi-' used when 
          - discussing reasoning/rationality

      - intent can be used to determine meaning 
        - use '-logy' to describe a studying activity & topic
        - use 'logi-' to reference logic, its interactions & permutations

      - structural interface (differences in position) can be replaced with: 
        - intent (reason to use within a system usage context)
        - system interface (usage context to derive reason for usage), and fit to system (meaning)

      - applying different interface queries
        - apply system context to derive intent
        - apply structure (position) as an alternative to system context & intent
        - apply intent to derive usage & system context

  - examine temporary stabilized filter structures in ozone to push co2 out of atmospheric layers away from earth & forces to do that

  - reverse engineering structures like bet types & their ratios (ratio of types like random guessing, price-dependent algorithm bets, temporary bets in non-viable companies for profit beyond actual value, actual investments in innovation/businesses) to identify & filter out trading cycles to isolate unidentified bet types

  - examine calculation errors from one partitioning method vs. other methods, & a function to balance their contribution to error to select an optimal partitioning method for an accuracy level
    - a way around the discrete vs. continuous dichotomy is combinations: 
      - discrete counts of continuous compositions (overlaps, layers, components)

  - find meta-math structure: 
    - which would allow/incentivize/generate the changes in info functions/variables (change types: interaction, aggregation, structure-filling, gaps, convergence, similarities) of known math operations
    - is it a metric like efficient stability that allows info to develop into a measurable structure in the first place (possibly changeable interaction), or is it enforced by a system of a set of limits forcing info to interact those ways (definitively inevitable interaction)
    - 'the information amount/type/variance stored in this definition/structure can only take form in or interact with these other structures/to these degrees/in these spaces/on these interaction levels'
      - information = certainty = definition = structure
      - 'this certainty/structure can only interact with or be formatted in these certainties/structures'
      - can you calculate the set of math relationships more quickly by examining opposing structures of uncertainty/randomness, by applying operations to existing certainties, or by finding a common differentiating standard in between, like abstraction'

  - algorithm to generate variables in a system

    - development of a 'concept' in a system: an object begins aggregating changes (like functions/attributes) in such a way that it develops unique interactions that differ from those calculated by a simplistic summing of the interactions of its components
      - example: a system may develop a concept like a 'layer'
        - structural definition of a layer: a set of components that separates other components & their interactions, inside a containing boundary
          - this definition differentiates it from a boundary, limit, line, or container structure
        - the definition also has dimensions beyond a simple line
        - the layer may aggregate functionality, such as:
          - being stacked or combined to create larger layers or structures on top of a layer
          - forming a base for interactions to develop on, if its a vertically stacked layer
          - acting as a filter, if there are openings in the layer
        - so the layer is not only measurably different from similar structures, it may also have significantly different functionality, earning it a unique term (meaning it has developed into a 'concept' in the local system)

      - the variable of 'structure' can describe the layer & generate it, but it doesnt capture the full definition of the 'layer' concept
      - other variables are necessary to fully describe the layer, such as:
        - adjacent structures (line, container, limit, boundary)
        - core function (stack, combine, bridge, support)
        - adjacent functionality (filter, separating interaction layers)
        - default structure (vertical layer related to stacking function)
      - because it stabilizes into a useful unique component, the layer concept begins to act like a vertex variable and/or an interface, since it starts becoming causative of changes due to its stability (rather than just being the output of changes to similar structures or iterated core functions or aggregated variance)
      - concepts in a system can be local interfaces that are useful to use as standards for comparison
        - standardize to the 'layer' structural interface
        - standardize to the 'local system structural concept' interface

    - so you can generate the sequence of a set of variables for a system by which change type structures are stable enough to act like concepts/interfaces for a given stage subset in the sequence of system development

      - system metadata: invalidating/triggering/development conditions

    - you can also apply core structures to get change types (multiply a number by the structural concept of 'opposite' to get the 'sign/direction' variable)

    - variable definition: isolatable, measurable change type 

    - component generation: identify components of a system & generate possible change types that enable/optimize interactions between those components
      - core generation: identify core change types that can be combined to create other possible change types & generate other possible change types & filter
      - subset generation: identify subsets of a system's components that are sufficiently stable in functionality/attributes to interact with other subsets without invalidating the system
    - limit generation: identify limits of a system & generate possible change types that can develop within those limits & filter
      - reverse generation: generate required functionality in a system & derive possible variables that could produce it & filter
    - filter generation: identify & apply filters that determine variable development functions (like change combination, change metadata pattern, change coordination functions)
      - apply 'variable' definition filters: generate possible isolatable/measurable change types & filter
      - apply 'efficiency' definition filters: generate structures that would be efficient & check for components that could generate those structures
      - other example filters: 
        - are there resources to sustain this change type
        - does this change type contradict a system rule
        - is there a reason/intent/usage for this change type that is not fulfilled elsewhere (by metrics like adjacence to justify creating the functionality)
          - is there a system-invalidating force requiring a new change type
          - is there another position that could use similar functionality to existing functionality that is inaccessible in that position
        - is this change type adjacently buildable with system resources
        - is this change type probable
        - would this change type trigger changes that invalidate the system or reach stability
        - how would this change type interact with other change types
        - does the environment system change enough to justify developing another or extra change types
        

  - authorized pick-ups/drop-offs by people in your social circle, extra keys for drop-off in lock boxes or cars, picking up packages from warehouses
    - https://www.vice.com/en/article/v7mnga/amazons-megacycle-shift-will-push-some-delivery-drivers-out-of-work

  - 'shared responsibility pools' as a form of insurance
    - anyone who uses a particular proxy/VPN/cryptocurrency accepts some responsibility for requests/transactions executed on that service in cases where the actual criminal cant be determined
    - feature where they can pay to prevent non-verified users from using the service or pay to use an 'invite-only' service

  - use isolatability/inevitability/uniqueness as a structural foundation for interface conversion/generation logic

    - identify 'inevitable' definition routes that are unique which can be used as a default generation intent for the core data included for app functionality
      - example: a definition route that cant be used as a definition of both balance & power, just one
      - unique intents are also a useful foundation structure for the intent interface

    - apply structures to overlaps in definition routes
      - find the adjacent structure without contradictions, that doesnt resolve to either specific option, within the limits of both definition routes
        - lack/limit :: resource 
        - function :: resource 
          - resource-generating function :: resource
            - resource :: function

  - give example of mapping to structures & identifying contradictions its safe to ignore for applying a structure

  - identify structures (like contradictions & distortions from expected normal) as input to info type generation algorithm

  - examine the distortion vector paths that adjacently decompose a data set into a prediction function from a base point/function set

  - add to decision points
    - when a method & data set can be determined to be capable of deriving the answer to a prediction function problem

  - questions that a computer may not be able to answer even with unlimited memory/computation capacity, without trial & error or other memory-based approach (simply storing methods that worked & incrementally building on that info) to determine system analysis methods
    - what calculations will prove to be optimal (faster/more accurate), before or during processing

  - examine subatomic superpositions as such a fast aggregation of time that each possibility is occurring simultaneously
    - if superpositions are a core physical structure of uncertainty, examine whether they can be used as a base for the optimal neural network structure, where core problem types are handled by subatomic particle type structures & other structures relevant to superpositions
    - applications
      - anti-structures: enforced lack of structure to preserve lack of structure development to ensure scale of operations
        - performing calculations in places with less gravity to speed them up and send them back to places with more gravity to get answers relatively quickly
    - questions
      - what combinations of velocity/time/scale produce equal positions/perspectives, and are there stable paths between them
        - what differences in potential emerge in different perspectives (differences in potential like reversibility)
        - how many different perspective types are there, and do they stabilize to a particular perspective in a vacuum
      - which change measurement syncs the best with time progression
      - which metadata (scale) are the best sources of randomness structures found in
      - which structures can store one-directional time (aka information)
        - where info is measurable, leaves signals, and processes are irreversible
        - is there a structure that can permanently store information (unchangeable information)
        - what structures of cause (inevitability, certainty, stability, equivalence) exist at subatomic scales
      - time speed factors: 
        - more interactions have to happen at larger scales
        - fewer things change at large scales
        - there are more randomness injection points at larger scales
        - change-resistance (stability) occurs more at larger scales
        - change measurability varies across scales

  - primary variables of brain functionality:
    - connectivity/alignment
    - position/adjacence
    - structural integrity
    - available/adjacent/possible structures
    - circuits (closed/open)
    - sub-systems (optimized for a function)

    - for some problems, some aspects of the optimized network should be deactivated/inaccessible - give example of how to calculate the structures necessary to solve a problem structure

  - in a market where uncertainty & unexpectedly correct predictions (unlikely predictions) have value, high-value contradictions of assumptions (high price of low-valued stock) are an error type structure

  - example of merging structures and filtering by intents that are useful to some agent
    - stock market (predicting uncertain value) x gaming (low-stakes task completion in a system)
      - stock market tasks in a (legal, business) system
        - deriving value of legislation
        - predicting legislation
        - legislation (more static rules) competing with more dynamic rules
        - forming business structures to aggregate/delegate/distribute risk
      - predicting uncertain value in tasks
        - predicting which tasks will win a game
        - insuring against risk of players completing or not completing a task
      - feature request & prediction market
      - game plot/cheat code/successful strategy prediction market
      - prediction games
        - false signals, gathering/deriving info, identifying important variables, applying successful analysis rules
      - insurance & other risk & financial products in games
      - stock market games allowed by legislation to allow a degree of collusion/organization in prediction markets
      - organization & risk structures allowed in a particular game, for a level of difficulty/complexity
      - games accessed with performance in previous prediction games to find best predictors and assign them more complex problems, like predicting emergent trends in interactions of complex systems
      - business & stock markets as an info-trading game to get products/features/prices and other company byproducts (clean energy practices, mergers, etc)

  - function to convert article/listing/social posts into variables to enable queries (product with feature x in budget y that integrates with app z and has attribute independent)

  - document locked objects that are inputs to core objects (like functions & concepts)

    - core functions like 'change', with locked objects which should be generated as inputs to other functions and should not be removed bc they enable other rules & core objects
      - a 'check for errors' function
      - a concept of 'self-correction/optimization'

    - these locked objects can be used to generate rule-generating/deriving/finding structures, by forming an initial structure of locked objects and filling that structure with conditional & changeable structures
      - these rule-generating/deriving/finding structures can be used as solution automation workflows

  - document interacting AI error types (as in financial price & crime prediction models)

  - examine function topologies (structures & structure change metadata that can maintain a particular function)
    - document intent structures (like intent sets) associated with function topologies
    - even if a structure maintains a particular function, its other metadata like adjacent interaction/change types & intents may change with the structure change
    - intent topologies dont necessarily match metadata of function topologies
    - interaction of interface object topologies as a source of variance reduction

  - design an optimal sorting structure for general interface queries to apply to problems manually

  - example of how to predict most interactive/causal concepts in a system

  - list interface selection (based on inputs like available APIs/data sets/definitions)

  - problem interface structures: solution constraints/metrics, problem space variables, available functions, useful formats/structures

  - identify economic cycles not integrated enough with other economic structures so as to be considered essential
    - debts to entities who dont provide essential inputs or inputs further up the chain with x degree of distance from essential resource suppliers

  - examine structures of trend convergence 

    - trends 
      
      - micro internet markets
      - micro/specific app favor markets
      - violent power transitions
      - competitor/competition bans/taxing
      - currency/wi-fi competition & dictators as a source of stability
      - anti-democratic activity as a specific case of anti-trust activity
      - investment in job creation/antiquated tech subsidies
      - customer product lock-in
      - dependent product price-raising
      - drug discovery automation
      - all-service companies
      - info derivation tools
      - temporary/sequential info markets as a social mobility/equalizing tool
      - delegation of high-cost/low-interest problems to AI
      - ending resource inequalities (tech, energy, internet)
      - hacking targets (democracies, big consumer markets like traders/gamers)
      - labor trends of balance between priorities (organization/innovation/optimization/integration/cooperation/research)

    - structures

      - cascading errors
        - AI is applied iteratively to tasks that people dont want to pay attention to bc they assume lack of relevant or changing variation, which may include monitoring AI errors or designing AI tests

      - interacting trend trajectories
        - price manipulation for investments in systemic price reduction (ending resource inequalities necessitating competition for moats)
        - markets for info, decisions, risks, intelligence, potential, justice, laws, independence, problems/solutions, customization, organization
        - competing prediction/computation tools: stats, system analysis, quantum tech, AI-optimized processing units
        - AI as an error-correction tool for quantum tech
        - checks & balances through competing evaluation tools: 
          - science experiment automation, automated testing tools, AI, quantum computing, system analysis, stats
        - evaluation/info-derivation/prediction/computation tools as components of a system building understanding
        - competing task runners: AI, robots, & gig workers
        - contact-reduction & independence tools like 3d printing
        - organization tools, encryption & dictator overthrow-planning/subversion, consensus-building, or dictator-manipulation
        - organization of competition in a problem market, for important optimizations only
        - market selection/optimization/automation

  - organize examples
    - label examples so they can be queried more structurally
    - query for logic in examples when implementing functions
    - give structural query example diagram for GANs + image compression problem

  - update default function list

  - add mapping for data sci use cases => tools

  - function to translate interface query logic into interface language (combination of core functions (find/build) & other core components)

  - de-duplicate logic
    - organize interface analysis logic definitions
      - organize functions in problem/interface definitions, before organizing functions in implementations/*
    - integrate problem_solving_matching.md
    - integrate find/apply/build/derive logic from system_analysis/ & maps/defs*.json
    - separate interface analysis logic into implementation/functions (functions dont need unique info)
    - add functions from workflows & analysis (to do list, questions answered, problems solved, interface definition & functions) as files in functions/ folder
      - organize into primary core functions & list sample parameters (like objects to identify for the identify function)

    - integrate rules from diagrams in patent applications to relevant documents
          
  - using set theory in query operations:
    - edges as core organizing/formatting operations (find/apply) & interfaces (connecting/explanatory concepts/functions)
    https://en.wikipedia.org/wiki/Hypergraph


## examples

  - example: to identify false information across user requests
    - apply intent interface: 
      - check with intent store (site) if a request for an intent (request password) was just made by the user, to validate messages
      - apply pattern interface: 
        - check if user access patterns (like 'navigate to site, then check email for site password reset') match that intent

  - example of permuting assumption: "reports of power consumption have to be exact measurements" (platypus)
    - a temperature monitor sensitive to a hundredth of a degree might provide similar but non-specific power reporting for important/extreme usage patterns without revealing such specific information as that which could infer exact operations being done, bc the interval of temperature measurements allows for greater variation in calculations that could explain it

  - finish dilemma problem type example formats
  
  - query examples for use cases like:
    - lack of information stored (match problem of type 'information lack' with interface query 'check pattern interface for similar patterns')
    - query problem breakdown & integration diagram
    - calculating various different problem breakdown strategies first before executing normal query-building logic for each
  
  - add examples of system/object/rule/type change patterns
  
  - include example workflows with example problems
    - include example of how to generate other workflows (different starting/ending points & trajectories)


## diagram
  
    - add diagram for intent-matching
    - add structures to diagram: interface overflow (to sub-interfaces), interface foundation
    - diagram for workflow 1: 
      - function to determine relevance filter ('functions', 'required') from a problem_step ('find incentives') for a problem definition, to modify problem_steps with extra functions/attributes ('change_position') to be more specific to the problem definition ('find_incentives_to_change_position') for problem_steps involving 'incentives', so you know to use the function_name to modify the problem step if it's between the type 'functions' and the object searched for 'incentives'
    - add conceptual math interface query diagram
      - use lattice multiplication as standard example, other than core operations (add/multiply mapped to language, concepts like irreversibility/asymmetry mapped to math)
    - interface conversion, matching, starting point selection (applying structure, checking if relevant information is found)
    - diagram to document sub-functions of core functions with distortions
    - make diagram for dimension links higher than 3d that are depictable in the same network space
      - should show variables that impact other variables, the change rates of these relationships
      - overall impact should be calculatable from these relationships
      - should show similar movements for correlated variables
      - should show skippable/derivable variables (variables that can be resolved later than they normally are)
      - should show meta forces for overall trends in change rules (direction of combined variable forces)
      - should show limits of measurability & threshold metrics

    - diagrams for specific concepts, core functions, concept operations (combine, collide, connect, merge, apply), ethical shapes
        - variable accretion patterns (how an object becomes influenced by a new variable, complex system interaction patterns, etc)
        - make diagram of potential matrix to display the concept
          - map parameter sets to potential matrix shapes 
        - finish diagrams for cause (shapes & ambiguity), concept (evolution of concepts, networks, distortion functions)
        - diagram for argument
      - make a system layer diagram for each interface to allow specification of core interfaces & other interface layers (interface interface)
        - make a system layer diagram for structures to include layers of structures 
          (beyond core structures like curves, to include n-degree structures like a wave, as well as semantic output structures like a key, crossing the layer that generates info structures like an insight, a probability, etc)

    - map variable structures to prediction potential for problem types, given ratio of equivalent alternate signals

    - finding solvability limit of a problem, without being given the answer
      - example: standard 'psychic' magic trick like guessing number of fingers held behind back, or which number people will choose
        - connected structural info:
          - when they choose the number
            - physical motion rules
              - how arms/joints move 
              - how their eyes move (indicating remembering or creative process or a local distraction or another input)
          - default input rules
            - hand motion dynamics, like how fingers interact & which motion types are favored/prioritized/likelier
        - general rules
          - alternative selection rules
            - how people make decisions from a set of similar alternatives (familiarity, understandability, simplicity, standard vs. non-standard choices)
          - intent rules
            - agent intents (trying to surprise the magician by subverting expectations of their choice)
        - related variables
          - attention
      - limits of solvability occur with non-interchangeable (not equal) alternatives that can't be distinguished with the given info, without being given the info of the answer (or info that makes it identifiable or possible to filter/reduce other options)
        - indicates that the interaction of the available variable info: 
          - is too low-dimensional
          - includes info about too distant/indirect variables/rules
          - includes info that cant capture/derive approximations/actual values of the variation/patterns of the output variable or its proxy variable
          - doesnt have a vertex variable or connectable interfaces/variables

        - there may be some combination of movement, rule selection, default config, attention & memory that produces difference choices without giving clear info signaling this difference (limit of solvability is reached)

    - finding optimizability of a problem, given resource limits (market, time, info about alternative, related, & interactive products)
      - buttons vs. configuration (headphones with buttons)
        - variables
          - hardware
          - alternative/related/interactive products
          - usage patterns
          - sound functions (play, skip, switch to voice commands, reduce noise, highlight bass, use more capacity to clarify sound quality, change relative volume, predict lost sound)
          - buttons
          - attachability/detachability/migratability
          - compartmentalization/isolatability
          - buildability
          - configuration options
          - simplicity
          - memorizability
          - adaptability
          - app
          - higher-variation alternative interfaces
            - sound input/output (alternative input to a button)
          - probability (commonness of a usage pattern)
          - demand (need for a button, configuration, usage pattern, or a function)
          - variable structures (combination of variables, like a particular set of variables or a set of interaction rules between variables)

        - implementations
          - find common usage patterns & assign to buttons
            - buttons for common functions
          - find memorable button structures & assign to common usage functions
            - find memorable combinations & sequences, like double-click of a button, or a button combination click, and assign to common usage functions
          - inject crucial high-variation function in higher-variation interface
            - configurable button functions (configure options of how buttons connect to functions), using an app (higher-variation interface, allowing more buttons)
          - inject crucial high-variation function into a button
            - configuration button (configure options of how buttons connect to functions), by clicking a config button
          - embedded menus in buttons
            - access menu (list of functions) with a button or button structure (combination, sequence)
          - alternate input with higher-variation potential
            - voice commands rather than or in combination with buttons
          - allow buttons to be attached like legos
          - allow buttons/functions to be coded & switched out to do any function the hardware (or connected hardware) can support, including functions from other alternative products
          - integrate with existing hardware like glasses/hat/shirt (use materials to conduct sound, attach speakers/microphones to glasses rather than having wires, attach buttons to glasses)
          - allow each alternative to be selected so they can choose which config/button/sound interaction rules to apply to those variables

        - optimized mathematized implementation for intent (simplicity, highest features given simplicity, maximized features)
          
          - simplicity: assign common (high-probability) functions to buttons & simple button structures (low-dimensional buttons & button structures)
            - variables: button count, button function, button structure (combination, set, sequence), function probability, simplicity

          - highest feature count, given filter of 'simplest implementation': highest number of functions possible to implement simply (low-dimensional memorization)
            - variables: function count, memorization, simplicity, abstraction (type), button usage structure (scale like repeated clicks of a button, sequence like buttons clicked in sequence)
            - variable interaction rules:
              - 'when function count increases absolutely (all other variables being equal), memorization decreases'
              - 'when count increases but is organized simply (like accessing functions organized by type or scale with successive button clicks), memorization is constant'
            - variable structure: 
              - intersection of independent variable changes (function count & memorization)
              - alignment of simplicity & memorization changes
              - alignment of abstraction (type) & simplicity changes
              - substitution of proxy variables (substitute more measurable variable like simplicity for memorizability)
              - substitution of more measurable variables
                - substitute simplicity-filtering rules to identify complexity rather than using complexity identification rules
                - substitute similarity-filtering rules (what something is) to identify similarity than difference identification rules (what something is not)

            - optimized variable structure: 

              - maximized 
                - parameterization of variables that change on similar input
                - intersection of variables to optimize (intersection of highest function count and highest simplicity)
                - alignment of related variables (aligning memorizability & simplicity) that should be similar
                - opposition of variables that should be different
                - compression/merging/selection of variables that act interchangeably

              - structure application
                - sequence structure applied to causative variation (input/output)
                - topology structure applied where changes in variable values of a variable set can be mapped to distance (different changes do not produce equal points)
          
          - maximized features: use highest-variation interface as input to generate temporary/editable config (app configuring which implementation to apply, which custom functions to use, which hardware to combine when ordering/updating)
            - variables: config input (voice, button), variable variation, config adaptability, config source (custom user-defined function, open source/multi-vendor libraries)

        - how to generate optimized mathematized implementations for intents
          - apply structural definitions of components (rules, variables, intents, concepts)
          - find interface where these structural definitions of components can be depicted according to their variation (dimensionality), interactions (substitutability, causation), & metadata (accuracy)
            - interface where variable structures (constant, sequence, input) and function structures (interactions/alignments) can be found & connected as needed

        - identify interaction structures (like trade-offs) between optimization metrics
          - find maximization of metric-optimization in those interaction structures

    - vertex variable structures
      - quantum physics, prediction/derivation tools, build automation tools, testing tools, learning/adaptation tools, system rules, computation power are all vertex variables of information - they can generate/derive/find information
      - which structure (sequence, network, set, or cycle) of vertex variables is most efficient

    - add to markets:
      - examine net effect of competition on markets
        - does allowing companies to fail have a net negative effect thats biggest on the risk (insurance/debt) industries, organization/analysis (ratings, group investing), info markets, govt industry, or is the negative effect exported to other countries or used as an input (legal precedent, example to use for future legislation) or do negative effects continue to be transferred to end-nodes of debt chains (those oppressed by stacked inequalities)

    - add to internet optimizations: add local data backup centers to cache copies of critical data just like backup electricity generators to methods of recovering or rebuilding crashed systems with alternate data sources

    - add to govt:
      - in order to prevent "info genocide", where groups that dont adapt quickly (bc of lack of group self-awarenesss & resulting adaptation, or alternatively a lack of lighter/temporary/optional connections allowing competition in a free market of group membership, requiring adaptation in group market to survive) are eliminated by groups with better organization/cooperation/adaptation/self-awareness or freedom given to members, you can:
        - distribute power limits to prevent any group from acquiring more power than other groups (more resources in the form of info, tech, land, supply chain dominance, market share, innovation advantage, organization)
        - distribute power artificially to offset naturally occurring imbalances from randomness
        - delegate power to tech automation
        - prevent power from accruing (prevent info from being storable/transferrable)
        - help all groups achieve self-awareness & independence and distribute it to members

    - finish core component metadata
      - identify any missing attributes/functions that cant be reduced further
        - example: 
          - everything that exists (has structure, either implied or verified) has an opposite/different version, so 'opposite' is a core attribute
          - everything that has structure can be verified to some degree, so 'verifiability' is a core attribute

    - add to science: 
      - examine whether imaginary numbers are a structure of uncertainty (bc of structural unverifiability), producing reversals of info with application of self-similarity (like time reversals) when interacting with other systems like physics
      - example of aligning & standardizing to interfaces to identify optimal methods to solve a problem:
        - use of non-structural information (randomness, imaginary numbers, & other sources of uncertainty) as an input for intents like 'exploring rules of high-variation structures like energy, info, or space-time'
        - example accidental application of this: https://phys.org/news/2021-03-imaginary-quantum-resource-theory.html
      - examine peak/valley of space-time wave as flow between energy (info) storage/usage types, possibly acting as opposite ends of a spectrum representing a trade-off (on liquidity, direction & other attributes)
      - examine magnetic/gravitational/electrical/other forces determining relationships of space-times
        - forces allowing:
          - non-adjacent & multi-directional space-times to be connected
          - space-times that arent efficient enough to be used as input to be left behind/dissolved rather than crystallized/connected
        - finding structures of lack where forces arent triggered bc there arent particles or other structures of energy there, to allow for uncertainties to develop & be used as input

    - add to bio system analysis: examine what types/positions of intentionally triggerable DNA damage can be used as a way to produce pathogen DNA sections at scale to generate immunity-producing immune response (mutation stack/factory)
      - structural (DNA/cell) damage/change triggers: mutations from toxins, exercise, animal pathogens, enzymes, competition for energy, & other types of DNA mutations
      - structural (DNA/cell) division/growth triggers: hormones, extra energy (energy imbalance based on need)
      - structural (DNA/cell) repair/recovery/regulation triggers: like bypassing digestion with amino acids to help recovery, timing cycles & alignment
      - other sources of structural change/standardization: 
        - gaps in cell types/attributes
        - sets of attributes
        - clusters of attribute changes/values
        - structural interaction levels
      - once you identify a section of existing DNA/RNA that, when isolated & edited, would produce a useful section of pathogen DNA to trigger immunity with minimal & possible editing (adjacent change) given exposure to a chemical or other stressor:
        - identify position in bio system where this change could be triggered by exposure in such a way that production of the DNA section is scalable (like in a cell that is about to be copied or a root/memory/template/stem cell) & where immune response would be quick
        - identify filter/containing structures necessary to give exposure/immune responses the time they need
        - identify type of exposure possible (injection, nanoparticle) and assemble components
      - identify evolution triggers (like cycles & variation of stressors) & use as a supply of change requests to trigger adaptive mutations for pathogens or pathogen types


# content/config

    - import insight history data to identify insight paths (info insight paths like 'lie => joke => distortion => insight', system insight paths like 'three core functions + combine function with this definition + n distortions to nearest hub')
    - define default & core objects necessary for system to function (out of the box, rather than minimal config necessary to derive other system components & assemble)
      - add default functions to solve common problem types
      - alternate utility function implementations have variation potential in the exact operations used to achieve the function intents, but there are requirements in which definitions these functions use because they are inherent to the system. For example, the embodiment may use a specific definition of an attribute (standardized to a set of filters) in order to build the attribute-identification function using a set of filters - but the general attribute definition is still partially determined in its initial version by requirements specified in the documentation, such as a set of core attribute types (input, output, function parameter, abstract, descriptive, identifying, differentiating, variable, constant), the definition of a function, and the definition of conversion functions between standard formats.
    - document time structures (concave time explaining compounding similarities up to a point of maximum concavity, a structure that can separate from the other space-times)
    - systematize your definitions of info objects, to include analysis that produces relationships of core objects like opposites to their relevant forms (anti-symmetry) in addition to permuted object states (asymmetry), such as an anti-strategy, anti-information, anti-pattern
      - organize certainty (info) vs. uncertainty objects (potential, risk, probability)
      - make doc to store insight paths, counterintuitive functions, hidden costs, counterexamples, phase shift triggers
      - add technicality, synchronization, bias, counterintuition, & certainty objects leading to inevitable collisions
        - the collision of compounding forces producing a phase shift
        - lack of attention in one driver and false panic in a second driver leading to a car crash given the bases where their processes originate
      - define alignment on interfaces (compounding, coordinating, parallel, similar, etc)
      - start with these info object transforms that filter the most info: opposite, invalidating, symmetric, core, aligning, boundary-breaking, phase shift activating, structure stabilizing, constant changing, converging
      - add core info objects (core strategies, core assumptions) so you can make a network of graphs for a system
    - concept analysis:
      - how new concepts (gaps in network rules) evolve once structure is applied to prior concepts 
    - interface analysis:
      - limitations of interfaces & how to derive them
      - how rules develop on stability & how foundations are connected & destroyed
      - explainability as a space limited by derivable attributes from data set & cross-system similarity
      - vertex definition & give examples (as an intersection/combination of interface variables, such as determining/description(compressing)/generative/causative/derivation variables), around which change develops
    - change analysis:
      - generated object change types
        - constant to variable
        - variable to removal of assumption in variable type/data type

    - examine implementing your solution type (constructing structures (made of boundary/filter/resource sets) to produce substances like antibodies, using bio system stressors)
    
    - merge definitions into docs/tasks/implementation/constants/definitions.json
      - add to definitions.json
        - meaning
          - structure:
            - relevance (to a position/intent)
              - importance
                - utility value
                - uniqueness
              - similarity
            - system fit
              - understanding

    - clarify/resolve terms that can be conflated: 
      - shape/structure
      - rule/test/metric/limit/threshold/boundary/state change/phase shift
      - intent/priority/motivation/incentive
      - method/function/rule/pattern (pattern is a sequence of specific objects)
      - path/route/trajectory/traversal/order/list/sequence
      - object/entity/item/component
      - type/class/category/group/subset
      - closed/isolated/independence/unique/orthogonal
      - model/perspective/filter
      - standard/interface/index/symmetry
      - dimension/variable/axis
      - space/system/context
      - perspective/filter/standard/index & relationship to variables/operations on the interface
      - filter vs. rule is a similar question to attribute vs. rule - sometimes one format is better based on the info you have, sometimes its worth it to transform the format
        - interface network: a set of standardizing filters applicable to format information in way that it can be analyzed with interface-specific logic, 
        - a query of the interface network may also be a problem-solving automation workflow, if problems can be solved with the format sequence indicated by the interface traversal

        -  For a prediction function problem, the solution space is the range of likely prediction functions. 
        - The problem space is the route between independent variables and the dependent variable on a network - it can also be framed as the route between common prediction function terms for a data set like the input data set, and the prediction function. The original problem structure is also depicted as a subset of this problem space visualization.
        - The solution function can be a route on the problem space if the problem space is formatted as a network, for example.
        
        - interface: a useful standard for comparison consisting of the filtering object's definition routes, conversion function, core functions, objects, & attributes, and related objects like patterns & metadata specific to the interface. Abstract interfaces include cause, concept, structure, etc, whereas specific interfaces are other foundations where change develops in a clearly defined range that can be found in specific systems. The traversal of an interface implies finding a map between objects, functions, & attributes inherent to that interface to the problem objects, functions, & attributes. The application of an interface is an operation in an interface combination, mapping, injection, or other operation. 
        - function: a set of inputs, a sequential list of rules or rule lists (logic tree) applied to the input set, an output set created by changes to the input set executed by the sequential rule list, optionally including side effects from execution. A function may be formatted in a different way, such as a list of attributes, filters, or a network. The function definition includes: 
            - attributes: 
                - alignment: enforced/optional, core, required, emergent/output (built from core functions, with or without associated intent) 
                - interaction: cooperative/conflicting 
                - intent: generative, filtering, grouping, organization/delegation/ distribution/matching/grouping/filtering, classification, differentiation/ transformation 
                - scope: use case, context, range, host system 
                - related objects (like host spaces/systems & object positions in those) 
                - types: 
                    - core functions 
                    - meta (rule-modification/generation rules) 
                    - attribute rules (state, scope) 
                    - interaction rules (competition, binding, combination, sharing, collaboration, intersection, conflict resolution, trade rules) 
                    - assessment rules (metric, difference, definition, validation) 
                    - processing rules 
                    - change rules (update, distortion, maintenance, adjacency, conversion) 
                    - filtering rules (find, identify, define, alternate, organize, learn) - matching rules (fitting a structure, filling a structures) 
                    - application rules (inject, embed, apply) 
                    - derivation rules (structure, navigate, abstract) 
                    - decision rules (prioritize, select, compare) 
                    - formatting rules (standardize, isolate, cluster) 
                    - destruction rules (replace, invalidate, neutralize, remove, merge, de- duplicate) 
                    - government rules (monitor, correct, enforce, maintain, stabilize) 
                    - system rules (incentives, variance handling, optimization) 
                    - interface rules (change, intent, type, pattern, concept) 
                    - info rules (problem, strategy, insight, game, perspective) 
                    - variance (injection, leaks, combination, replacement, causal direction, uncertainty, risk, potential, probability, prediction) rules 
                    - information handling (storage, versioning, replacement, merging, monitoring, indexing, communication, interpretation, processing) 
                    - solution rules (variance/stressor/error detection, tracing, identification & handler) 
                    - structure rules (gap, boundary, system, limit, hub, object, link, network, filter)     
        - intent: any of an abstract goal with direction, a reason to use something, or an output such as the intended result or an unintended side effect, which can be an abstract priority like fairness, a concrete goal, and can have a starting & ending position. 
        - game: a set of intents/alternatives/limits/incentives/exploits/rules/risk & a definition of distance from intent fulfillment (position), usually resulting in the resolution of a clearly optimal route. The game definition includes: 
            - a game is a type of system & a mixed set, which can exist as a component of a system 
            - games can have many different structures like: 
                - a directed graph with a vector set representing possible agent intents/ functions/resources 
                - a system of nodes & links where agents need function input resources to traverse 
                - a decision tree where certain tree info becomes accessible only at certain nodes (adding uncertainty/risk) 
                - a set of trade options between nodes with different info change/update rules in a system to optimize a resource/trade/market metric 
        - concept: set of unique objects remaining once objects from other spaces have their context & contradictory attributes removed. For example: power is the object left when objects implementing it: resources => energy => input => potential) have their context removed, navigating up the abstraction stack from: 
            - the info layer (resources & energy), removing their contextual attributes/rules - to the abstract structural layer (input) 
            - to the abstract layer (potential, which is a related concept of power) 
            - so that the final object is defined in terms of other abstract objects on the top layer 
        - problem: may include any context or condition that causes a negative position or state determined by a metric for an agent in a system. The problem definition includes problem types like dependencies, leaks (variance, resource/info),  injection (assumptions/variance/control/randomness), mismatches, conflicts, imbalances, inefficiencies, incorrect metric, misidentification, gaps, limits, side effects: whether it's a closed system or leaks variance (function side effect example: before execution: pre-computing, during: memory access/overflow, after: process re-starting), specific problems like an enforcement gap (should have enforced rule but did not), an unintended use (involves integrated third party tech not under review), a malicious alternative route to get same output, a legitimate/alternative route to get malicious output. 
        - problem space: context relevant to a problem; the containing system(s) of a problem that may include related problems 
        - solution: may include any combination of events, methods, or steps that reduces the negative position or state for the specified agent. The solution definition includes solution types: 
            - solution-metadata solution: evaluating & comparing solution metadata for solution selection 
            - problem-metadata solution: evaluating problem metadata to evaluate metrics like problem-solving postponement 
            - generative solution: solution that generates solutions 
            - solution framework: provides starting point & structures for solutions to be built in/with 
            - problem decomposer: solution that reduces a problem's root causative (as opposed to just varying) parameters 
            - solution automator: solution that automates solutions of a type 
            - interim solution: clearly suboptimal solution while optimal alternative is built 
            - solution query constructor: solution that builds new solutions out of known solution types (existing structural solutions or core functions) 
            - structure-finding solution: solution that assigns a structure to information 
            - structure-fitting solution: solution that matches the gaps/limits in a problem structure to neutralize them 
        - solution space: set of possible solutions in a problem space, which may be reduced by applying interface traversals like solution space-reducing insight paths 
        - network: standard network graph containing nodes (sometimes called vertices) & linking functions (sometimes called edges), with or without node attributes, function relationship determining function shape, and direction as an indicator of intent or another metric. 

        - component: functions/attributes/types/objects/systems 
        - input information: can refer to original information input to the initial interface traversal, or traversal output information that has been converted, enhanced, formatted, or otherwise altered in a prior interface traversal, stored as a possible version of the original input information, and sent as input to another interface traversal 
        - interface: 
        - function: a set of inputs, a sequential list of rules or rule lists (logic tree) applied to the input set, an output set created by changes to the input set executed by the sequential rule list, optionally including side effects from execution. A function may be formatted in a different way, such as a list of attributes, filters, or a network. 
        - intent: any of an abstract goal with direction, a reason to use something, or an output such as the intended result or an unintended side effect, which can be an abstract priority like fairness, a concrete goal, and can have a starting & ending position. 
        - concept: set of unique objects remaining once objects from other spaces have their context & contradictory attributes removed.  
        - network: standard network graph containing nodes (sometimes called vertices) & linking functions (sometimes called edges), with or without node attributes, function relationship determining function shape, and direction as an indicator of intent or another metric.  

       - info conceptual relationships:
          priority = direction
          observation = insight = function = result = relationship
          conclusion = ordered_list(observations) + guess = coefficients + bias
          strategy = ordered_list(insights)
          strategy = insight + context
          problem = (combination of intents having different priorities) or (an resource distribution imbalance)
          intent = strategy + priority
          solution = (combination of strategies operating on variables with insight functions that reduce dimensions of problem (function-combination) or (resource-imbalance))
          type = combination(attributes)
          intents = function outputs, including unintended/emergent/unforeseen side effects (target/avoid)
          roles = functions
          relationships = treatments, intents, functions, insights, strategies, mechanisms, patterns, systems
          components = compounds, symptoms, treatments, metrics, conditions, stressors, types, variables

    - update links

    - integrate archive_notes/finder_info/functions
      Terms:
      - objects: a data set, function set, attribute set, class definition, type hierarchy
      - attribute value: value held by the attribute like True/False
      - attribute property: conceptual metadata property of the attribute like unique, identifier, static, etc
      - decisions:
        - choosing to execute one section of code over another; 
        - for example a conditional statement, design patterns, emergent usage/behavior 
          of user/system, bugs, assumptions, & possible input values are decisions since
          they may result in calling different code
      - relationship types: sub-type, causal factor, cooperating equal, different version
      - strategy: rule used to make decisions, possibly for a particular context
      - solution: strategy implemented for a particular context & problem type