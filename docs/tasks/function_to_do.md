# to do

    - this isnt a war against a country or religion or ethnicity, or a specific group of criminals, or other powerful entities or people - its a war against the suffering of others who are oppressed, vulnerable & deserving - against inequality, against easy, against cruelty, greed & all other vices that cause their suffering, and against the self-oppression of anyone who stands in the way of us saving the others - a war that we fight with tools of love, in giving solutions away to those in need, finding new solutions as needed, trying new strategies where the old ways don't work, distributing power wherever it's hoarded & otherwise abused
      - I will cry for the lost when I have time to spare

    - add to error type structures as a quick solution filter (solution automation workflow)
      - error interaction structures
        - structures (like set/opposite/combination/sequence) of error structures
        - cross-interface structures
          - error structures that are interactive across interfaces
          - structures that form error structures when allowed to interact

      - analyzing errors on a different interaction layer applies the insight 'interaction layer is often a relevant variable (like other important system structures) determining outputs'
      - other variables (including system structures) applied to errors
        - core:
          - components of error structures
        - ambiguity:
          - errors that are equally likely to be solutions (useful functions/attribute structures)
        - default:
          - errors that are defaults are likely to have useful components or be an output of useful components

    - finish attribute structures associated with problems/solutions
      - add to attributes of solutions/problems can be used to identify error types & causes of errors
        - if something is unnecessary (not required), it is likely to produce more errors than something that is required
        - if something is highly variable, it is likelier to produce errors than more constant structures
        - if something is inefficient, it is likelier to produce errors than structures that are efficient
        - if something is not aligned with an interacting structure, it is likelier to produce errors than alignments (mismatches, imbalances, incompleteness)
        - if something is highly connective/interactive, it is likelier to produce errors bc it introduces other error-increasing structures like variability
        - if something is reusable, it is likely to be useful, so it has more attributes of a solution than of a problem

    - add to solution automation workflows
      - identify overlap of problem/solution definitions (when a problem is a solution and vice versa) to identify contexts where a problem should be framed as a solution instead & solution structures should be applied (like solution metrics or insights like causes of why it works for a problem) instead of problem structures (like questions to change/resolve it)
      - identify solution spaces based on problem/solution metadata
        - pre-filter solution space by identifying structures in a system that fulfill general solution metrics (efficiency, reusability, etc & structures like combinations of these) to reduce the solution set to search for specific problems
        - generate/find/derive structures (like combinations) of a solution automation relationship structure (connection, reduction, removal, building) & construct (probable, relevant, useful, adjacent, interactive, efficient) solutions from those, then use as a default solution space to search
          - example: function sequences & state sequences can be used as components of a 'connecting' solution automation workflow that connects origin/target structures

    - identify error structures & components (components like attributes, such as 'error position') by:
      - missing or lower than expected required components (like cost)
        - rarely this might not be an unidentified error if it's just an efficiency
      - error-related or required components in a non-optimized system
        - any structure that is sub-optimal for an intent is a possible error

    - add to determining function interaction structures like sequence
      - for some functions, there are requirements & limits on what other functions they can interact with, in what structures
        - example: for 'compare' and 'standardize' intents, examples of basic interactions are:
          - sequence: standardize, then compare
          - sequence of subset/total: standardize systems components to compare systems
      - the cause of the function sequence requirement for an intent like 'compare to find differences' is that the standardization (when applied first) reduces irrelevant differences, so the relevant differences are clearer & easier to identify
      - the concept of a common base/standard that both objects have is associated with the definition of 'compare', as a way to anchor calculations, to reduce differences in calculations (calculations of difference will be more accurate & easier when the calculation can start from the same position & take the same steps in both objects)
      - the above intents are relevant to functions like compare to improve accuracy of metrics:
        - 'reducing differences in calculations of a function (like compare)'
        - 'reducing irrelevant differences' or 'isolating relevant differences'
      - apply opposite structure
        - if standardization was not applied, an equivalence check could not be reliably executed without using abstractions like input-output patterns or other metadata than mapping the inputs/outputs themselves
      - apply related functions
        - 'equate' is a similar function to 'compare'
          - standardization is a useful function for both equalizing & comparing objects
      
    - add to solution automation workflows

      - apply structures based on their definitions in relation to the definition of a solution/problem or the problem-solving process

        - depending on the solution automation workflow applied, it will involve various functions, like:
          - generate possible solutions & filter
          - break into sub-problems, solve them, & integrate

        - example with a particular solution automation workflow function 'filter':
          - the definition like 'filter' is 'remove items from set based on metric', so functions that support intents like the following sub-functions, which fulfill the 'solution filter' intent (identify if it's a solution or not) can fulfill sub-functions of the 'filter' function definition 'remove items from set based on metric':
            - determining difference
            - determining metric value

        - structures that fulfill the solution automation workflow function, like 'filter':
          - apply opposite structures as a solution filter structure (exclude what a solution is not)
          - apply error structures as a solution filter structure (avoid errors)
          - apply possibility structures as a solution filter structure (exclude impossibilities or improbabilities, include common solutions)

        - structures that fulfill the solution automation workflow function 'solve different problem'
          - apply similar structures as an alternative problem/solution structure or solution base structure (solve alternate similar problem, start from similar origin, base changes on existing solutions)

        - structures that fulfill the solution automation workflow function 'build solution' or 'solve for the components of a solution'
          - apply core structures as a solution subset or solution building structure (build solution from core components or solve subsets (core components) of solution)

    - add to determining relevant components
      - components that are:
        - adjacent in interaction degree/directness
        - controllable
        - low-cost to implement
        - specific to that context
        - required/unique
        - enforcing/robust (no matter what changes you make, it will always have an attribute/function)

    - interface query types can be an alternative to interface query design
      - use patterns of interface query types, parameters (like origin interface & input problem type), & input-output connections to identify query types that are useful for solving specific problem types

    - add to ai tests
      - questions/tasks that are typically framed as unable to be answered by anyone other than a human, like:
        - 'what is the meaning of life'
        - 'find a new system to predict events'
        - 'what will be the next big invention'
        - 'when will the end of the world happen'
      - these are relegated to human philosophy & endeavor bc theyre considered too complex to answer, requiring many contributors over many generations
      - example of how my system would approach these questions:
        - problem: 'find an answer to the question: what is the meaning of life'
          - the answer is 'protecting potential of the universe'
          - an example of an interface query to get to that answer is:
            - standardize problem:
              - 'what is the purpose/intent of life'
              - 'how does it fit into the contextual system in which it develops'
            - alternate queries:
              - apply definition & system interface
                - a definition route of 'life' is the 'ability to change' (learn/adapt)
                - a definition route of 'intent' is what something can be used for
                  - sub-problem: what can life be used for:
                    - all functions of the human brain
                  - apply 'system context' interface to this sub-problem (sub-question, or sub-query)
                    - when a question like 'what can x be used for' or 'what intents does it support' is asked, the intent of the question is often finding the most differentiating intent from other components, rather than listing all intents
                    - the most different intent supported by 'human brain functions' is 'protecting entities with potential who cannot reward them'
                    - the reason this is the most different intent is that its the:
                      - rarest intent
                      - aligns with responsibilities (sources of potential have responsibility & power to protect other sources of potential)
                      - most difficult intent
                      - an intent that requires unlikely conditions, like being taught to prioritize it, or deriving that its the right intent to prioritize, by deriving an ethical system prioritizing it
                      - associated with intelligence, a proxy of potential
              - apply definition & conceptual interface
                - 'meaning' has a structural system definition route 'fit in a system'
                - 'intelligence' is a proxy for 'potential'
                - 'potential is uncertain ability'
                - 'a contradictory component to potential is certain ability or certain inability'
                - 'intelligence is power'
                - 'power' distributes when it's misused (used to preserve itself, at the cost of power distribution)
                - intelligence has functions like:
                  - can change a component to fit into a system (create meaning)
                  - distributes its power bc it can generate power/meaning under any conditions
                  - identifies that:
                    - potential is the rarest & most valuable resource that is a similar input to meaning to intelligence (itself)
                    - protecting sources of potential is top priority
                    - delegation of power is equal to delegation of responsibility
                    - delegating both power & responsibility is more efficient than other methods, as other entities will learn to solve their own problems with help
                    - distributing power in the form of intelligence does not contradict any sources of potential & enables sources of potential
                  - concludes that:
                    - not only is it efficient to distribute intelligence, it is also ethical (does not destroy sources of potential)

    - identify error types quickly

      - apply insight 'related components of a component can cause changes (including sub-optimal changes like errors or improving changes like solutions) in that component bc of interactivity' to problem/solution definitions

        - some error types are caused by errors in other components

          - example: 
            - if a dependency has a vulnerability, all its dependent components might inherit it through usage or inclusion
          - solution:
            - the solution could involve:
              - fixing the other component
              - communicating info to help the component fix itself
            - a general solution could involve:
              - delegating error-type identification to components in positions that can identify error types
          - relevant interface component: 
            - perspectives
              - in a system with optimal component communcation, solutions built/derived/found/identified by other components can prevent error types bc different perspectives of other components can identify errors before the origin component identifies its own errors (applying the concept of 'self-awareness' can also generate this insight)
            - function
              - similar components may be related by position, so they might have similar functionality which can be shared to fix adjacent components

      - interface query to solve the problem of 'finding new error types' or 'finding new ways to find new error types':
        
        - applying core functions to interface components of the problem system (or to related components) can identify error types quickly (and associated solutions)
        - this query can solve the problem of identifying:
          - sub-problems of finding new error types' like:
            - lack of info (about variable interactions/changes)
          - by identifying causes of the sub-problems like:
            - limits of info in specific positions/angles

        - apply interface components to origin system (standard cross-interface query), then apply core functions to those components to run another interface query to:
          - solve the problem of 'identify new error types' for different versions of them (change)
          - solve the problem using a different origin position (build starting from different origin position of components to build with)
          - solve the problem of connecting problem & solution (derive)
          - solve the problem of filtering possible error types (find)

          - example: 'perspective' mapped to a 'driving' problem system can have structures like:
            - 'position' bc its a physical system where differences in 'position' change perspective definition components (like 'visibility' or 'priority')
            - 'role' bc it involves agents where differences in 'role' may change 'focus' or 'priority'
        
        - build: 
          - the intent of 'building an error-free system' (like a sub-system of the origin system) can quickly identify new error types, if using non-standard building functions or other components
        
        - derive: 
          - deriving error types from problem spaces or problematic systems (rather than deriving from core system components or from core error components) can identify error types of a system
        
        - find: 
          - finding difference structures with intents that contradict approved intents can identify error types quickly
          - find interface component variables of the problem system (or versions of it or its compoments produced by 'change' function or other functions, like a 'related system') to identify new error types
            - system:
              - find a system where it's not an error and the cause of the error to fix (or cause of other error types) in the origin system will be a structure of difference between the two systems
                - example: 'bowing' is a social error in some systems - the difference between those systems and a system where it's not an error is a difference in the 'culture' sub-system
                  - error types involved include: 'culture', 'sub-system', 'interaction', 'social interaction'
        
        - change:
          - changing interface component variables of the problem system can identify error types quickly
            - structure: 
               - changing common structures of difference between similar components like instances of a type)
            - perspectives:
              - switching perspectives can identify problematic differences between solution metrics & actual values bc of the info obvious or focused on by another component
                - just like another car may be able to see if a car has a flat tire before the user driving from a perspective of the car with the problem
              - switching perspectives is a way to find error types faster, if the error is adjacent to or equals info that is focused on or obvious to another perspective
              - switching primary interfaces is one way of switching perspectives, but you can also switch variables in the origin system:
                - switch positions of agents or components with info-gathering functions (sensory functions) with a particular focus on info that may be in error
              - calculating the possible errors (like by determining variables that are difficult for the origin component to check, so errors can involve structures of those variables) is a useful process to run before identifying a perspective that can see errors in that set of possible errors
              - how to calculate a perspective that can see a possible error, once a possible error structure is identified
                - find a perspective that interacts with info related to the variables/structures/components of the possible error, by:
                  - intent perspective: focusing on or prioritizing the info
                  - input/specific perspective: using/implementing the info
                  - causal perspective: generating the info
                - construct a perspective that has one of the above attributes/functions as a solution structure, and find existing perspectives that match that perspective
            - intent: 
              - switching intent can find intents that are possible error type causes, for the original component, other components, or the system enabling them to exist
              - example: 'cause error' intent rather than 'solve problem' intent can solve the problem quicker in some cases 
            - change: 
              - change change components like variable types (what's required or default for some components may be intended or optional or not possible for others)
            - cause:
              - switching causes can make a component more robust
              - finding a way to build/execute a function given alternate causes can make the function more robust to changing inputs
              - this can be an error type in some cases
            - abstract:
              - mixing abstractions with specific examples/implementations the problem system can result in a quicker identification of error types
            - definition:
              - switching definitions of error/solution can identify possible error types of other systems that wouldnt define another system's survival as 'success', where their error would be 'failing to destroy another system'
                - this can identify possible error types like 'attack from a system with this definition of error'
      
      - solution success cause: 
        - this works bc some solutions can be used to solve similar problems, so solving for a similar problem instead can be more efficient & find a solution to the original problem
        - applying solution insights like 'solutions may solve similar problems as the origin problem' can find new solution automation workflows
      
      - identifying error types is important for functions like:
        - 'find solutions by avoiding known error types'
        - 'prevent errors'
        - 'identify error interactions, so the interaction of changes to one error & changes in related errors can be predicted'

    - indexing solutions by the 'reason why it worked or didnt work' (solution success/error cause) is a quicker way to select/filter solutions in some cases
      - if the 'reason why the solution worked' (or its associated 'reason why the problem exists') is present in the problem system, that may help filter solutions more efficiently than other methods like:
        - 'try existing solutions'
          - reason why it may work: 
            - the problem space may not have changed sufficiently or the problem may not be new to invalidate existing solutions
        - 'try adjacent modifications to existing solutions'
          - reasons why it may work: 
            - existing solutions may be similar enough to a working solution that minor modifications (like by adjacent conversions built from core functions) may be sufficient
            - the problem space may not have changed sufficiently or the problem may not be new to invalidate every component of existing solutions
        - 'derive solution requirements from problem statement & filter solutions'
          - reasons why it may work:
            - the problem has enough info to derive sufficient filtering requirements
      - a reason to use a particular solution often relies on structural system components (like similarities/alignments, such as structural similarities or input/output alignments) & other important interface components
        - there is a structural similarity between the above solution & problem, indicating a reason to use it:
          - existing (non-changed) solutions fit with an existing (non-changed) problem space or problem
          - the usage intent may be to reduce cost of solving the problem
        - the more important interface components that exist connecting a solution & problem, it may be likelier that the solution is optimal for that problem
        - a reason to use the solution indicates its optimal in some way for that problem, as in it solves the problem efficiently according to some metric
        - examples
          - opposite structure:
            - an opposite structure connecting a problem & solution may indicate a reason to use a solution, if the problem-solving intent is to negate, reduce, invalidate or destroy the problem, which are structures that relate to 'opposite' structures
              - a problematic structure can be solved with an opposite ('structure-destroy') solution function
            - the usage intent (reason a solution is used, like a solution metric it fulfills, such as 'minimizes cost') is different from the reason why a solution worked (why it was better than other solutions for the solution metrics, such as:
              - 'structural similarity between problem/solution where problem-solving intent was alignment'
              - 'opposite structure between problem/solution where problem-solving intent was neutralization'
      - example:
        - structural reasons why a solution worked
          - info reason
            - bc the solution was the fitting structure to the problem structure
          - system reason
            - bc structural similarities are a useful structure for solving 'fitting' interaction problems
          - direct reason
            - bc the inputs to the solution already existed in the system
          - cause reason
            - bc the solution addressed a root cause of the problem
          - abstract reason
            - bc the solution solves the problem type of the problem

      - components of 'reasons why solutions work for a problem' can be inputs to interface operations (to combine/filter reasons, or build interface queries or solution automation workflows) to:
          - find the reason why a particular reason is relevant to a problem/solution
          - design a reason why a solution should work & then test it
          - derive a reason why a solution worked
          - filter solution automation workflow insight paths

    - application variables of an interface
      - different versions of an interface can be used in place of the entire interface, just like different formats of an interface can be applied instead of the whole interface
      - interface components can be used to generate different applications of an interface
      - speed-optimizing interface applications:
        - core interface application:
          - include core components that can be used to construct other components on the interface
          - also optimizes for 'build' and 'change' intents
        - basic interface application:
          - include standard components of the interface (common components, components on the most-used interaction layer, etc)

    - causative error types of sub-optimal solutions

      - over-simplification error sub-type, relating to interface components/queries

        - one/basic/quick interface-based solution, when multiple are optimal, given the structures (false similarities on that interface) and attributes (complexity) & other components involved
        
        - example of this error type:
          
          - applying the simple version of the pattern interface in isolation, in a complex system that has false similarities on the pattern interface
          - a solution that only identifies patterns (& not other relevant interface components, like errors in pattern-structure mapping) will not identify false similarities where the position of similarities is in the pattern, but not the structures of the pattern implementation, where they should be in order for the pattern to be applied

          - solutions to this error:
            - you can still apply the pattern interface in isolation, if you map other interface components to the pattern interface
            - examples of solutions:
              - map structural, conceptual & system components to the pattern interface, such as 'false similarities', so that conversion to the pattern interface includes identifying 'patterns of false similarities', which would prevent this error type
              - map intent to the problem system before applying the pattern interface
                - query for patterns with associated valid/invalid intents, connecting the inputs/outputs by intent as well as patterns, to determine how different the intents are that a pattern can be associated with
              - query for patterns in errors applying pattern interface components

            - a 'simple' or 'quick' application of the pattern interface would apply an AI algorithm to the problem & consider it solved

          - causal paths/source nodes of this error:
            
            - reason this would be identified as an acceptable solution:
              - reason: 'there are patterns in the data between input/output, so a solution that identifies patterns & converts them into an efficient function is acceptable'
            
            - reason its not an acceptable solution: 
              - reason: 'there are other relevant structures in the system than just patterns between input/output from the data set'
              - other relevant structures include:
                - the above error-related components: 
                  - false similarities, complexity, structures associated with the pattern implementation
                - other causative or interfering variables not in the data set
                  - alternate causes of the data set variables
                  - contradictory emerging or conditional functions that will soon interfere with the data set interactions

    - value isnt created/lost by companies in the timespan of hype/short cycles, so stock market price swings aren't reflective of reality from a macro perspective
      - it takes years to build value, it doesn't happen overnight, excluding almost magical insights that create cascading efficiencies like my system
      - losing value also happens slowly, excluding extreme natural disasters, like the value of a community still being relatively high despite shared losses, bc of social network effects & organization/coordination effects
      - value can be calculated differently, using metadata like the lifetime & total possible value of a product
        - what is the total supply of the product inputs (fossil fuels)
        - what is the usability lifetime
        - what are the costs
        - what are the product intent alternatives (can intents fulfilled by the product be fulfilled by other products)
        - what is purchased with revenue from a product (research, insights, other more valuable resellable products, etc)
        - if this pricing method is applied to fossil fuels, oil companies would be paying people to use them

    - all primary interfaces can act like the problem-solving interface (start solving problem from the concept or structure interface and integrate all info back into that interface & frame the solution in terms of that interface) but the meaning interface (the interface interface) is the most powerful

    - apply an interface as different formats for different intents, like:
      - a filter for cross-interface intents that fit with a filter structure, like mapping inputs/outputs
      - a function network for performing interface operations, like converting/standardizing objects
      - a composition of other interfaces when those interfaces are more adjacent to inputs
      - a convolution when deriving what intents are supported by the interface
      - a subset of paths on a language map when handling agent-formatted queries
      - a map when used as a connecting interface to other interfaces
      - a variable network when describing the interface
      - a query on other interfaces when solving a problem in another interface

    - add to structure finding/selecting rules
      - select a structure that:
        - preserves relevant info
          - input/output variables should have their position preserved bc there are few cases where input/output flag is not relevant
        - isolates differences & combines similarities as needed
          - variable groups should be differentiated from individual variables bc variable groups are on a different interaction level
          - input/output variables should be connected in some way (like constant position or adjacence or connecting path) but should also be clearly isolated, unless interchangeable
        - choose a base that fits & is relevant to data meaning
          - connecting variables based on original position adjacence if no position changes are necessary
          - connecting states in original sequence based on time
        - avoids assigning arbitrary structure
          - distance/position that doesnt indicate info about a function, attribute, or identity

    - question structures (missing info error type)

      - question-predicting rules
        - filter by relevant intents to primary intent to identify probable questions
          - proxies for determining where info is unlikely to be distributed as needed
            - high ambiguity/complexity/specificity/variation or inaccuracy rate
            - info distribution gaps (where info is not distributed due to distribution barriers, lack of intent, or alternative distribution paths)

      - format for 'required questions to info state':
        - structure like a network/sequence/combination of sub-problems, or missing connections between existing/known problem space network nodes, preventing movement from origin to destination on info network
          - movement for an intent requires knowing connections, bc the connections allow navigation/planning of movement on the network oriented toward a goal like the destination info state
      
      - question structures

        - deriving missing connections between relevant components ('how does x relate to y')
          - 'to get output variable y info, you need filter variable x info & variable z info'
          - finding correct position of a component in a structure ('where does x fit in y')
            - 'x is an input to y'
          - deriving usefulness of structures for intents ('is x interactive with y as a possible input')
            - 'x can be an input to y with changes 1-3'
          - deriving reason for a functionn/change ('why does x change y')
            - 'x changes y bc the structure of y is not stable when x is an input'
          - filtering structures for an intent ('what is the best path from x to y for an intent z')
            - 'x as an input to function 1 is the best path to y for intent z'

    - database polling/prompting user for update & predicting updates or searching for & receiving user-approved updates from other services, rather than being a passive receiver of input from user
      - based on local usage/change patterns or integrated usage patterns to identify expected transactions with other services
        - once a credit card is marked as lost in a banking service, a change of credit card numbers is expected by other services which can poll for updates to this flag
          - user option like 'yes, allow other approved databases containing my address poll to collect this update'
        - once a renters insurance policy is changed in an insurance service, a change of address might be expected by other services

    - other structures to use as problem/solution structures

      - these are highly relevant/useful cross-interface structures

        - function structures
          - connecting/conversion/comparison structures

        - understanding structures
          - empathy (as a prediction tool bc its an output of understanding)
          - language (as a structural approximator of meaning)
        
        - sufficient/threshold or partial/subset structures (vs. completely aligning structures)
          - requirement structures
          - similarity (approximation/alternative) structures
            - as not all inaccuracies are errors & some level of error can be acceptable in some cases, structures like similarities, proxies, approximations & aligning/adjacent alternatives can take the place of the original problem/solution structures
            - error types that can be useful for more optimal solutions for a metric
              - false similarity
                - where a sub-optimal method has false similarities with an optimal method (like similarities inputs/outputs of another solution, even though its logic differs and other metadata like the reason why it works differs), but the false similarities are all that matters for a particular metric (like having resources to use the sub-optimal method) and it doesnt create side effects that contradict other methods, it can be a temporary/contextually optimal method
        
        - change/learning inputs
          - standard structures
          - cost structures
            - the patterns of costs/benefits as a way to determine investment structures (what alternatives to invest in, for what cause/reason/intent, to what degree, etc) as a way of determining uncertainty resolution
              - investments (exploring a possibility) are a structure of resolving uncertainty problems, like 'exploring very different strategies until one pays off' as a way to find good solutions when selecting between solutions is ambiguous or other structures of uncertainty like lacking in info
              - when an object 'earns' their resources (does the work necessary to acquire them), theyre likelier to be able to maintain those resources & acquire/generate new ones, so theyre likelier to have those resources, as opposed to random distribution of resources
                - if it's earned it's likelier to be a stable structure (a component of truth) bc everything has a benefit/cost (so when the right investment matches the right costs, its likelier to achieve the goal)
        
        - determining/relevance/causation structures
          - power structures
            - the location & interaction of sources of power (like importance, usefulness, interactivity)

    - apply structures from relevant system (like comedy) to a problem space (like 'correcting behavior' or 'fixing social norm violation')
      - if its a joke that means its by definitio at least partly untrue so is less likely to be a structure of truth & more likely to a structure of a combination of truth/falsehoods
      - surprising
        - different
        - opposite
        - extreme/exaggerated
        - nonsense
          - not incentivized
          - not normal
        - unusual/weird/unlikely
      - safe
        - reduce common experience/problem/fear or other negative emotion until ridiculous/unimportant/powerless
      - relevant
        - multiple alignments of relevant structures
          - self-fulling prophecy
            - multiple layers of relevance
              - prediction function
                - repeated concepts used in different ways
                  - add 'usage' concept while applying 'usage' function: use prediction function to predict usage
                - relevance cycle: 
                  - prediction function used to determine discussions, which are used to determine usage, which are an input to prediction function to predict usage
                - function usage makes it better at its usage intent
                  - 'prediction function of usage being used as an input to discussions which are an input to usage, so the function/paper is used more often, and becomes more accurate at predicting usage bc its usage predictions made it used more'
                - relevance in the form of usefulness/efficiency structures:
                  - function output (usage predictions) created a function input (usage)
                - the opposite would be ridiculous self-defeating structures:
                  - function output (high access & site crash from server overload) prevented a function input (using the paper)
        - aligning
          - actual intent & stated intent align (sincerity)
          - relevance structures align (at same intervals/points)
        - useful
          - connected
          - common/relatable
          - timely
          - efficient
          - similar
          - true
            - obvious
            - sincere
      - important
        - emotional
        - petty
        - serious
      - easily understood
        - brief
        - uses references that are commonly known
      - ridiculous
        - invalid/illegitimate
        - self-defeating
        - pointless/not useful
        - irrelevant
        - ineffective
        - drastically/obviously false
          - conspiracy theories connect objects that are obviously not connected

      - insight paths
        - unlikely hypothetical
          - several degrees of assumption chains to generate an unlikely hypothetical (sequence of assumptions from a starting assumption/premise, generating a background story/context)
            - serious + petty + important: 'none of us can figure out why he tucks in his tie'
              - implies that the problem was so serious that a discussion happened to investigate & research it to fix it
              - implies that no one is allowed to ask him or has the courage to ask him directly, implying he's powerful in some way & cannot be questioned, which implies these are his subordinates who are not doing work in order to discuss this, which implies this could cause their work arrangement to be invalid 
            - 'none of us ever figured out why he tucked in his tie'
              - repeated + important: implies that the discussion was repeated bc it was such an important matter
            - 'none of our lawyers or R&D staff ever figured out why he tucked in his tie'
              - important: adds another level of importance in that they hired an expensive legal team to investigate the matter for liability/indemnity/litigation potential as if it made the company look so bad they had to hire a legal team
            - "the tie-tucking survived ex-girlfriends' interventions"
              - important: it has ruined multiple relationships with people who cared about him who tried to stop him from doing this to himself
              - briefer than previous version & uses more evocative verb
              - different: 
                - add assumption: assumption that the audience is rooting for the tie-tucking to continue
                - add concept of 'agency': attributing personhood to the tie-tucking, which is fighting for its life against cruel monsters
            - 'even after being accused of being a double-tucker who tucks his tie but not his shirt, he persisted'
              - important + petty + similar: fashion is a petty thing to care about this much, and a special jargon term 'double-tucker' implies a whole community or sub-culture based on or caring about this issue or related issues, which he has caused controversy in, with added importance by association from term 'double-agent', typically reserved for high-stakes situations like foreign wars, as if he's betraying someone or his heritage or group or people who rooted for him, and rhymes with a curse word
            - 'the mysterious tie-tucker left the board of directors' 
              - important + reduced: condensing the entire story into a brief structure like a nickname and casually referencing it despite the importance implied in a problem that generates a nickname
        - topics
          - conspiracy theory (a muffling device to prevent the Chinese from listening to his balls chafe for blackmail material)
          - cults/ex's (definitely worshiping the wrong things)
        - total opposite: 'your fatal flaw wasn't so much all the excessive drunk online shopping purchases at the police store & the corporate sabotage so much as the curtains from korea that spied on us & posted our arguments to porn sites' (it was absolutely the excessive spending at the police store)
        - changing definitions to very different alternate definition
          - 'tucked in his tie' or 'used unnecessary protection' or 'packed heat'
        - resolving awkwardness
          - 'i dont hate your dick pics (introduces the problem, 'uh oh does she hate my dick pics'), I just think theyre (foreshadowing something that seems like a difference but is actually similar) more optimal when directed at enthusiasts (or professionals), such as doctors/researchers, who might appreciate it more than I ever could (optional: from a curiousity perspective)'
        - mixed contexts/styles
          - talking about an unimportant matter in the same terms used for important matters
            - 'his parents couldnt deal with the idea of confrontation so they gently let him lose touch rather than disowning him outright' 
        - adding relevant structures of meaning like:
          - aligning layers like double entendres
            - calling him a 'magician' bc they have a function of 'hiding scarves' which is similar to 'tucking a tie' bc 'tucking' has a related output of 'hiding'
        - defeating the purpose/self-defeating
          - listing all the manipulations youre using, while using them, to the target 
        - false dignity/over-generousity
          - calling him a 'international man of mystery' bc its a very dignified way to portray having mysterious fashion habits that defy analysis from subject matter experts
          - 'he must be doing it to scare away women bc theyre always chasing him'
        - injecting stupidity/extremes
          - he thought it would act like a talisman to protect him from rape or unwanted pregnancy
          - he was told by a foreign holy man (has association with 'wise foreigner' stereotype) that it would protect him from fertility like a 'cosmic condom' (repetition, catchy) 
        - removing a point/agency (its not an intent, he just had the clingiest underwear/reproductive organs known to mankind)
        - fitting with existing systems without obvious contradictions
          - 'using existing phrases in a new way with minimal distortions' is surprising bc its unlikely to find a new distortion of an existing component that someone hasnt tried, so the simpler the better for this type

      - these can be used to filter for other non-comedy problems
        - surprise as a learning/prediction tool
          - structures of surprise & truth are useful insight paths to generate solutions
          - structures of surprise & falsehood are useful solution filters
            - conspiracy theories are so unlikely bc they go against incentives or apply an inefficient connection path
              - why would someone go to all that trouble to do that when its way easier to use this other method
        - structures of disincentives (that go against incentives) can be used to find info hiding spots
        - agent behaviors that are extreme in most ways (extremely dignified, pointless, ineffective) are less likely (uncommon) so theyre a source of surprise/comedy
        - structures of safety/stability can be used as a filter to identify possible/probable interactions

    - add to solution automation workflow

      - generating problem/solution structures in a problem space or a system

      - generating problem structures of a problem space like 'find a function for an intent':
        
        - apply error type definition routes
          - error type: missing component
            - if this error type is relevant to the problem space, that means the component was relevant in some way (like being required)
        
        - apply error type-generating functions
          - error type-generating functions:
            - 'change components'
              - components
                - variable values
                  - inputs
                    - to generate a problem type of 'missing input', apply 'change' function or 'opposite' structure to 'input' structure
                  - attribute values
                   - to generate a problem type of 'missing attribute' (such as an attribute required for a solution metric), apply 'change' function or 'opposite' structure to 'attribute' structure

      - example: identifying structural causes of problem type 'false success info signals': 

        - problem type of 'excess specificity' can create a problem of 'false success info signals'

        - granular/specific solutions are often insufficient, where the granularity can take the form of problem structures:
          
          - handling problematic output instead of input: fixing a specific instance of a problem (an output generated by a problem-generating function call, like a particular position of a problem side effect) instead of all instances of a problem (the problem-generating function)
          - position on a problem network: fixing a problem without regard to other related problems, such as causative problems, adjacent problems, or problems that will replace or re-generate the problem once its fixed/removed
          - specific instance of a type: fixing a specific type of a problem instead of all possible types
          - multiple intents: fixing one particular problematic usage of a function, without fixing other problematic uses of a function
          - lack of unique cause: fixing one cause of a multi-cause problem without fixing other causes
          - artificial constant: assigning one constant value when a variable is required to fix the problem
          - unhandled potential: fixing the problematic function without handling the adjacent problematic function it can be adjacently converted into
          - unhandled context: fixing the problem in a particular problem space context, without handling the adjacent problem space the original problem space is about to become
          - specific state: fixing the problem for a specific state in a data flow rather than all possible states
          - specific success definition: fulfilling one metric when multiple metrics are needed to assess solution success

        - you can generate the above problem structures (like 'multiple intents') for a problem type by:
          
          - applying interface components to the problem type concept of 'specificity' (with general problem type 'excess' applied to this concept for a resulting problem type 'excess specificity') in useful (common/general/interface) problem spaces like 'finding a function'
          - then filtering the resulting structures by which structures would qualify as problems, given the definition routes of the concept of 'problem' (like 'structures that are sub-optimal for some legitimate intent, like fulfilling a particular metric')
          
        - to find specific problem structures of a general problem type, apply other useful problem spaces than 'finding a function' (finding a 'connection' structure)

          - where a 'problem space' can be the context associated with having a problem, like how the problem space of the problem of 'finding a function' is the set of systems where that problem would occur, systems potentially including a network of related problems like 'finding connections' and 'predicting outputs' such as:
          
          - problem spaces specific to an interface:
            - cause: find cause (as an indirect input to a function)
            - structure: find limits/filters of function inputs/logic
            - system: find assumptions of function (as a related input to a function)
          
          - problems applying interface components (like applying 'abstraction' concept to the 'finding a function' problem space to create the abstract version 'finding a structure')
            - apply 'abstraction' concept to the 'finding a function' problem space to create the abstract version
              - problem space: finding/fitting a structure
              - apply intent component & related concepts like 'useful':
                - problem space: finding a useful structure for an intent
              - apply 'abstraction' concept to 'structure' ('definition' is an abstraction of 'structure', just like 'constant' or 'info' are other abstractions of 'structure')
                - problem space: finding a definition
               - apply 'abstraction' to all components until it reaches the 'interface' interaction level
                - find an interface component in a structure ('find a concept like relevance in a structure')
            
            - apply 'interface' interface concepts ('organization' being a related concept of 'structure' & 'interface', just like 'integration' and 'relevance' are related concepts of the 'interface' interface, where concepts related to 'disorder' like 'random' are the opposing concepts of 'organization') to interface components ('structures')
              - organize/randomize structures
            
            - apply abstract core 'info' interface components related to the abstraction of the problem (like problem/solution types, formatted as abstract core functions), instead of a specific problem's ('find connecting function') component interaction structures ('functions connecting input-output')
              - select between solution types (generate/derive/find)
            
            - apply 'combination' structure and 'complete' concept and 'system context' component
              - find all the possible ways to connect two structures & all the info structures necessary to connect them with those methods
            
            - apply 'interaction' concept to 'connection' structure
              - find all the possible structures (like networks) that could convert a 'find a connection between input-output' problem into a 'integrate input-output connection methods with these other structures so they can coexist' problem
                - example: 'find a function' problem can interact with a network of problems, like the 'prevent logic injection' problem, 'prevent execution interruption' problem, etc, so it becomes a problem structure that is not simply finding a connecting path between inputs/outputs but a layered network structure of 'finding the connecting structures, while preventing interfering interactions from this problem network'

    - add to nn

      - youre always using multiple formats in a graph, even when trying to depict one format (a variable network always has core structures & conceptual structures even when it's intent is to depict variable interactions)
        - even a conceptual network has conceptual (and other interface) structures depicted on it that overlap with other structures (like concept nodes & interaction functions)
        - the formats used can be side effects of the primary format, indicating adjacence
        - the reason theyre included by default is bc interfaces are fundamental

      - why cant you just apply a good ai algorithm with probable predictive value to data, once data is standardized to an interface format?
        - example: format data as concepts, and apply an ai algorithm to predict concepts in a data set, or predict concept interactions in a concept set
        - you certainly can, I suggested doing so in my patent for coverage, as it's the obvious existing solution, but only as a short-term sub-optimal solution to connect input/output while the interface logic was being built
        - its also manually applying interface analysi instead of incorporating it into an algorithm
          - by manually applying the definition of a 'concept' to fulfill 'data processing' intents like 'standardization', you are manually applying interface analysis, which is still my invention even if you do it manually
        
        - interfaces have logic specific to them that may be more useful/efficient than an ai algorithm
          - formats have interaction logic specific to them that may not fit with the input/output relationships of a particular algorithm
          - examples:
            - functions/intent/cause/pattern/logic/change have inherent sequential structures that other interfaces dont
              - this is bc they are objects that map inputs/outputs
            - concepts have an inherent tree & net (capturing evolutions of definitions before fully structured) structure that other interfaces dont (concepts capture openings, overlaps, definition evolutions)
              - this is bc the interface object ('concept') is by definition a definition structure (a structure that describes definition structures, like definition routes)
          - an algorithm that applies the more powerful interface interactions & structures inherent to interfaces to quickly identify important variables, group membership, & other important structures would be a better goal than trying to pretend you didnt steal my work
            - the work of 'stealing my work' and 'pretending not to' doesnt produce efficient brains with a good grasp of concepts like 'meaning', so it emerges as an inefficiency bc the type of brains developed wont be good at finding solutions to output problems generated by granularly copying/pasting to a specific problem/solution & hoping it works better
            - 'understanding my work' is a better goal if you cant look away bc youre not done experiencing awe
              - once you understand it, you wont need to watch me work, youll be able to generate my work
        
        - ai automates learning, like identifying structures such as important variables, why cant you use it for everything
          - some learning algorithms are sub-optimal (as in slow, or missing important info) or cant derive the required info (as in limited in possible accuracy achievable) so theyre not fitting for everything & cant derive the missing info
          - interface analysis can automate identifying important variables by applying an interface:
            - to apply interface component definitions
              - like identifying variable structures, such as vertex variables
            - to convert to a format where the data is framed in terms of these structures & has the interaction logic rules applied (like rules governing interactions between variable types, like how a vertex variable is often an input to other variables bc its causative)
        
        - learning method
          - ai applies updates to learning parameters to adjust a function until its a good predictor
          - interface analysis can apply other methods of learning, like applying:
            - error structures to derive a function from opposite structures to those error structures, for intents like 'create an accurate prediction function'
            - vertex structures, which are an interface structure related to 'important variables', for intents like 'identify important variables'
            - organization structures, which are relevant for intents like 'finding the optimal position of a structure in another structure' and 'finding useful structures'
          
          - related intents of ai can have different adjacent algorithms
            - 'create an accurate prediction function' (apply function, base, component, subset, filter & limit structures)
            - 'avoid errors' (apply error structures)
            - 'identify important variables' (apply vertex structures)

          - however the methods for one intent can act as proxies for another related intent

          - how to identify related intents
            - 'avoiding errors' is an intent that coordinate with intents like 'find a connecting function' (like 'find a prediction function')
            - the reason they are related is bc of interface structures (definition, structure, & functionality):
              - definition
                - errors are by definition a component of learning
              - intent
                - the 'prediction' intent is helped by intents like 'learning new info'
              - structure & functionality
                - the inputs/outputs of 'avoid errors of this type (inaccurate prediction types, as inaccuracy/difference types)' and 'find a connecting prediction function' are similar

          - alternative structures to filter function network (other than variable/object/state network)
            - limit network
              - format data in a way that it can be input into a limit network and the limits will perform intents supported by limits:
                - identify it or what it is not
                - find its optimal position
            - combination network
              - network of subsets/combinations of components (like variable subsets/combinations)
                - applying functions to nodes in this network can identify optimal combinations quickly, if functions applied align with outputs (applying the functions produces useful info to determine functionality)
            - mixed network
              - combination of network structures
                - route data to other network structures when its determined by a routing network structure that other structures cant use it (like routing info to another interaction layer, if its a network of interaction layers)
              - network of mixes of structures
                - network of mixes (highly variable combinations) of structures, like a network of cross-interface structures
            - similarity (adjacent/proxy) network
              - replace components with adjacent components for intents like 'find alternatives'
            - difference network
              - a network of difference structures (like extreme, opposite, specific, value, structure, & pattern differences) for intents like 'find alternatives' or 'find interactions between a specific difference set'
            - relevance/irrelevance network (for what contexts & problems would info be useful/useless)
              - system context network
                - systems where info would fit into the system or be useful
                - related contexts & their interactions
                - spaces where info is structural (graphable) or has an attribute like difference structure (difference type/degree)
            - point sets (like threshold values/centers/origins to use as references)
            - cross-interface maps

          - alternate variable set structures
            - isolated aligned variable changes as a map (stack of differences) between types/thresholds

        - structures identified by interface analysis
          
          - learning structures (including by definition variables, types & differences)
            - error/solution structures
              - adjacent (sub-problem, related problem, available/known/possible) error/solution structures
            - guess-answer interaction structures (structures of difference/similarity between very wrong or almost correct guess & actual answer)
              - prediction-answer interaction structures (structures of interaction between informed prediction, uninformed prediction, pattern-informed prediction, etc)
            - question-answer interaction structures (structures of interaction between question, info retrieved by question, difference between info retrieved so far & answer, and the answer)
            - adjacent learning structures
              - change structures are adjacent to learning structures bc learning involves change types (like between initial/interim/final states, inputs/outputs)
            
          - interface structures (intents, concepts, patterns)
            - system structures like incentives, ambiguities, & efficiencies
            - meaning structures (reasons why something worked, how an insight fits in a system, how components can be organized in a useful way, how a structure is relevant for an intent)
          
          - useful interface interaction structures 
            - function sequences with alignment in inputs/outputs
            - core functions as a component for 'build' intents
            - interaction layers (coordinating, competing, contradicting, coexisting & other interaction structures)
            - definition structures
            - change potential
            - conversion adjacence
            - structures of interface interactions (intent-function maps, logic/cause/state networks)

          - core interface interaction structures (apply interface structures to interface structures)
            - to generate core intent structures:
              - apply structure interface: structure intents like direct uses
              - apply concept interface: conceptual intents like priorities
        
        - structures identified by ai
          - type (group membership)
          - difference
          - important variables

        - questions unanswered by ai
          - does the definition of difference make sense for this problem/solution components (algorithm, data, intent)
          - what are the intents (structure intents like direct uses & conceptual intents like priorities) supported by the algorithm/parameters
            - can this algorithm fulfill the intent of connecting the input/output differences in the data
              - is it capable of mapping the inputs/outputs, given the difference structures in the data (difference types, lack of sufficient differentiation, etc)
            - what other intents (like adjacent/contradictory intents to the primary intent) are supported

      - ai has added concepts since its first implementation bc the first implementation (multi-layer perceptron) was not enough & other functions needed to be embedded to optimize for certain tasks
        - which functions/components need to be added for which tasks is still not a solved problem in the ai space, whereas my system does solve that

      - ai has still not derived the concept of an interface & generated its own interface structure to solve a problem, without being fed the definition of an interface, which is an input to my system
        - if ai was the optimal structure, it would have quickly identified the useful components of my system (like trade-offs, exploits, efficiencies, ambiguities, definitions & interfaces) & applied them to solve any problem, but most ai algorithms/parameters cant do even one task with perfect accuracy (or total coverage, like 90% accuracy & an explanation of why it cant achieve higher accuracy - like 'insufficient data')
        - my system can identify when minimal info to solve a problem isnt reached & can generate explanations of its processes (interface queries, which are trajectories on the 'interface' interface)

      - ai depends on insight path algorithms like 'trial & error' to accomplish some tasks like in grid search to find optimal algorithm parameters, but still must be told to do so by a human who has decided that exploring all parameter combinations is needed
        - theyre wrong to think that, they should have come up with my method to filter a solution space using interfaces & solution automation workflows
        - a 'function network' is only useful if a human puts it in the right system & applies it in the right way to solve the problems its optimized for, and retires it when better methods are implemented - the function network doesnt get better at solving all problems just by being fed more problems
        - my system self-optimizes as its given more problems to solve

      - a function network can sometimes be replaced by an object (interface components) or variable network (of interface variables) but ai wouldnt figure this out if it was given a function network as its origin algorithm, bc while learning how to optimize for a particular solution, ai is not evaluating how to optimize its own algorithm, input, & parameters and would need to be instructed to do so
        - then it would encounter error types and it would need to be instructed to identify & handle error types
        - then it would be linked with other models, data, & function networks, and other interaction error types would emerge and it would need to be instructed on how to handle new data, integrate with other function networks for useful agent intents without merging with other function networks (which would remove its connection to the original tasks it solved), help other models avoid new error types while identifying & handling them itself
        - it wouldnt just identify that it should apply concepts like 'meaning' in its integrations with other automation components, it would have to be told to do so & told how to do so
        - a structural definition of 'meaning' is an input to my system, so my system does have methods to handle complex integration/organization tasks bc these are components of meaning

      - ai depends on my system in order to predict error types better, integrate common sense, apply definitions of concepts, etc

      - my system can generate error types & apply different solution automation workflows as needed to solve a problem, and identify the workflow likeliest to be useful before applying it

      - a function network depends on input data, whereas my system depends on problems, definitions, the logic of interface queries, & an internet connection to find new info as it identifies its own need for new info

      - examples of functions that are sub-optimal for a task but get it done (or appear to do so) without immediately invalidating side effects
        - an approximation method isnt as useful as a correct method built on cross-interface understanding
        - attacking a known security vuln by deploying a code fix specific to that vuln doesnt address the problem of identifying/preventing vulns automatically or identifying/preventing hackers from having/using reasons to hack
        - playing whack-a-mole with exploit structures & exploitative agents doesnt address the causative problems of a conflict between agent intents & a lack of coexistence/cooperating/coordination structures
        - paying ransomware hackers as a 'recover lost data' function doesnt address the related problems of risks like that they wont or cant return data or will return it in error (partial/unusable) state & common hacker intents like making money rather than fixing problems and the incentive to move on to next victim or next scam rather than helping victims without ability to enforce data recovery
      
    - what generates understanding? specific interface concepts integrated into the solution, with examples showing understanding (of interface components like interactions/systems in general, & of the problem space), like:
      - abstraction: 
        - handle the problem type 'unhandled problem variants of a problem type' by abstracting the solution
      - intent: 
        - handle the problem type 'conflicting agent intents' by restricting the intent applicability of the solution (what intents are supported by the function)
      - system:
        - handle the problem type 'solution used in different context to enable malicious intents' by applying system context filters to enable applying the solution in specific contexts
      - change: 
        - handle the problem type 'unexpected changes to inputs, logic changes at execution time, or changes applied to change usage of outputs' by enforcing validation of function version, input validation, and validation of output integration with other solutions
      - organization: 
        - handle the problem type 'sub-optimal interaction of solution with other components' by applying simulations of interactions with other components

    - a good solution shows that it was built with understanding of these interface components, including components like:
      - concepts like 'malicious intent', 'organization', 'relevance', 'probability', and 'integration'
      - problem types like 'conflicting incentives' and 'contradictory neutralizing functions' and 'structure vs. flexibility trade-off'
      - system components like 'similarities', 'standards', 'opposite structures', 'interaction layers'
      - function structures like 'useful input-output sequences' & 'core functions'
      - change components like 'vertex variables' and 'adjacence'
      - common/useful structures like 'maps between interfaces'

    - the relevant structures for a problem (like related problem types & structures of those related problem types) should be generated & applied until understanding is reached
      - at this point, once it has understanding, a neural net can solve problems like:
        - why is the user using a neural net to solve this problem
          - example: 
            - why is the user using an AI to solve a problem of differentiating cat/dog photos, if the photos are very clearly separable, meaning the problem doesnt require AI
            - bc the process of using AI is solving a different problem for the user than sorting cat/dog photos, such as different outputs of an AI model, like:
              - time usage: looking busy at work
              - authority: using AI as a source of truth/authority ('the AI said it was true so it must be true')
            - by knowing about system & related system components like 'usage' and 'context' and 'agent', as well as other related interface concepts like 'intent', the AI can infer that AI model outputs (given a definition of AI models) might be the intent of the user
            - alternatively, by knowing that sometimes a problem type of 'different origin/target (like a different cause/reason/intent) is more relevant than the direct/stated origin/target' applies to a context, it can infer that the user has a different origin/target (like a different output of the AI than the AI model itself, or the completion of the task)

    - with regard to using the structure of a filter network as a filter for useful info contributing to a function, other info & info formats are useful & derivable which can be derived with faster means (definitions, bases, subsets, concepts, error types, intents, opposite structures, efficiencies, alternatives)
    
    - nn to derive error types & bias incorporated into other nn data/parameters/algorithms/structures/models

  - visualizing higher dimensions with changes in a network of visualizable variable subsets like:

    - dimension subsets: displaying dimension subsets in groups of sizes that are already visualizable (from 1 - 4 dimensions), where orthogonality is preserved across the network of subsets
    - dimension groups: grouping similar dimensional changes into a change type across a dimension subset, to visualize the change types
    
    - relevant (robust) dimensions
      - dimension invalidations: grouping invalidating/neutralizing change types
      - causative dimensions: just visualizing higher-impact/causal dimensions
      - vertex dimensions: graphing variables as differences from vertex variables
    
    - mapping dimensions: group value sets as other structures like points or networks in a space where change types like 'continuous change' are supported
      - embedded dimensions: dimensions graphed visually using extra dimensions as parameters
      - base dimensions: dimensions standardized to a base and graphed in alignment, like multiple functions on a graph with a common base
      - mapping other dimension metadata: interactions between dimensions units/change types/limits/definitions are graphed
      - abstract dimensions: abstract value structures are graphed ('a point on a line') instead of specific values in a dimension
      - constant dimensions: adjacent limiting constant dimensions are graphed instead of dimensions of change

    - dimension interactions: 
      - interactive dimensions: dimensions that interact are condensed into an input/output of the interaction structure, and input/output dimensions are graphed instead
      - dimension interaction structures: structures of interactions between variables (like direction/circuits/networks) are preserved, where values may be lost
        - dimensional difference: difference between dimensions is graphed instead of different dimensions & values, where dimension values are structures associated with graphed dimension interactions
        - conversion requirements: conversion requirements to a visualizable shape are graphed instead of actual dimensions/values
        - interaction structures between value structures like positions on dimensions when graphed as a standardized shape
          - example: with dimensions formatted as a standardized form like 'lines of equal length, & values as points on these lines', the interaction structure would be the lines connecting the points on the dimension lines, when arranged in any order

  - possible components of a scalable definition include components framed in terms of interactions with other components that can be used with a consistent measurement (like a stable structure) & can also scale (boundaries), rather than framing them in terms that can have different meanings at different parameters (closed, hollow)

  - apply solutions and/or associated error types as a way to derive the origin component type
    - given solutions (with associated error types solved by the solution), derive what problem types existed to trigger the application of the solution (can be constructed from those error types, where error types can cause/build the original problem or address sub-problems of the original problem or related problems)
    - example:
      - given that an agent delegates instead of trying to solve a problem, it is implied that: 
        - 'their previous alternate solution methods have caused error types rather than resolving them'
        - 'delegation has worked for them before'
        - the fact that either of these are likely explanations can be derived with additional information like:
          - their decision patterns
          - adjacent information like:
            - 'having more info about delegation processes'
            - 'more info about alternate solution method error types than delegation error types'
      - given an error type of "delegation problems (like 'misallocation', 'uneven distribution of work', or 'micromanagement')", we can infer that:
        - 'alternate solutions to delegations have been tried'
        - 'delegation was an adjacent solution at the time of solution selection'
        - 'this is a problem not suited to delegation'
        - 'excess work requirements is an origin problem type'

  - why are certain structures of structures more useful
    - bc by definition (of usefulness), they reduce differences between origin & target
    - a 'function that identifies causative ability of a change type (variable)' is by definition useful to solving a problem of 'find causes of dependent variable' bc it connects the component 'cause' of the problem with interim objects like independent variables, which interact with other problem components like 'dependent variable'
    - some structures are more useful in general (rather than for a specific intent) bc the intents they are useful to are themselves more general or more common
    - 'finding structures of alignment' is useful in general bc structures of alignment solve problems of difference/conflict, which are common problem structures
    - useful problem-solving structures can be found by which structures of structures solve common problem structures

  - another useful concept is 'improvement of a problem metric' vs. 'solving a problem'
    - where the problem is that a spectrum metric like accuracy/robustness is not equal to or beyond a correct value, a solution can take the form of improvement
    - 'a component that improves a problem but doesnt solve it' is a useful interim or alternative structure to position as the target, when error/solution types are not structural
    - example: 
      - an approximation function improves a 'missing information about dependent variable y' problem but doesnt solve it (the 'actual prediction function for y' would solve it)
      - a buoy improves a 'drowning' problem but probably doesnt solve it (a 'method of getting to land' would solve it, which the buoy is unlikely to be except in rare contexts or with extreme/distorted/stretched definitions)
      - a 'fitting structure' improves a 'gap' problem but doesnt solve it (a 'method of preventing & correcting gaps' would solve it, like a 'method of preventing slices/knots & other structures that qualify as gap error types')

  - map math terms to problem components as default connecting structures other than core/interface structures
    - cycle: error type of a structure, involving a unique variable subset that can be used to derive the original structure when combined with other unique variable subsets
    - knot: structure with a gap error type where the structure's subset forming the gap allows other subsets of the structure to fill the gap
    - manifold: structure that preserves its error types when a specific set of change types are applied
    - topology: structure connecting subsets & a set, with core components of structural changes having no gap error types (continuous), having:
      - including limits in the form of including subset combinations & subset intersections determining included structures
      - excluding limit error type structure: 'combined/intersecting elements being excluded', or the opposite structure of the limit error type 'non-combined (isolated), non-intersecting (non-common) elements being included'
    - solving a problem by applying filters to the solution space converts the problem into a sorting/set problem structure, applying organization to the definition of the problem & solution so they can be accurately related
    
  - core relationship structure types between problem/solution, by applying core structural relationship structures (relevant to core general abstract-intent functions like apply/find/build/organize/derive)

    - the relevant (meaning core/causative/determining/abstract/invalidating) difference type between the problem/solution can point to an adjacent function to correct the difference
    - example for problem 'too many variables (too much complexity)' and solution 'method of reducing variables without losing accuracy or robustness'
      - a core difference type between problem & solution: variable count
      - a causative difference type: lack of understanding
      - a determining difference type: whether additional variables add accuracy or robustness
      - an abstract difference type: whether these function types (a complex prediction function and a variable reduction function) can interact without additional changes (a variable reduction function can be a generator of a prediction function)
      - an invalidating difference type: whether complex & simple solution types (function types) can both be useful for the same problem

    - core problem-solution relationship types:
      - organize
        - position
          - the solution is the problem components in the right position in a structure (like an object-function or variable network)
        - sequence: 
          - the problem is the solution with a 'sort' applied
      - apply
        - usage (space used vs. allowed by structure)
          - gap: 
            - the problem is the solution with a 'gap' error type corrected
            - the solution is the removal of the problem 
            - the solution resolves the problem of a lack
          - limit
            - the solution is some change applied to the problem that doesnt intersect with a limit or exist on a particular side of the limit
        - change
          - the solution is some structure of change applied to the problem
        - context
          - the solution is some context applied to the problem, so that the problem is not a problem
      - find
        - identify
          - inclusion/exclusion
            - subset/set: (partial/complete)
              - the solution is the problem with a 'filter' applied (a subset of the problem)
              - core structure
                - the solution is the core components of the problem
            - group (combination):
              - the solution is some combination of problem components
          - fit (count/value)
            - reduce/expand
              - the solution is a subset/superset of the problem variables
              - abstract structure:
                - the solution is an example/type of the problem
          - comparison:
            - equal (balance):
              - the solution is some change applied to the problem and/or solution that equates the solution to the problem (as opposed to 'connecting' the problem/solution)
              - connect (path): 
                - solve the problem by connecting the problem & the solution
            - difference structure:
              - the solution is differences between the solution & the problem reduced/expanded or added/removed (as opposed to 'connecting' the problem/solution)
              - opposite: 
                - the problem is the opposite of ('not') the solution
                - the solution is different from error structures
              - invalid
                - the solution is a lack of a valid version of the problem in the problem space (the problem cant exist in the problem space given a definition of 'valid' including validation rules)
              - undefined
                - the solution is a lack of problem definition (the problem is abstract rather than clearly defined, or structural, in the problem space)
              - empty
                - the solution is a lack of the problem (the problem has no possible value in the problem space)
            - similarity (alignment):
              - the solution is some change applied to the problem that convert the problem into a useful component (an alignment with a useful intent)
              - the solution makes the origin position more similar to the target position
              - the solution is some coordinating structure (like a complement) with the problem that converts the problem into a non-problem
      - build/cause:
        - input/output      
          - the solution is some change applied to the problem that produces or is produced by a structure (like an interaction)
          - origin/target structure (sub-structure of input/output)
            - the solution is some change that resolves the difference (reduces distance) between origin/target, connects origin/target, or makes conversion between origin/target trivial
            - the solution is changing the origin or target position/structure so the problem is more solvable or reduced
      - derive
        - abstract reverse input/output direction
          - the solution is the generalized path from an example solution to the problem definition

  - ml explanation of finding coefficients of prediction function by applying distortions to coefficients & ruling out distortions that dont contribute to prediction accuracy
    - can be optimized with reductions like:
      - 'calculating the most different distortions that will reduce possible values the quickest & applying those distortions'

  - add other interfaces to ml problem space (beyond intent interface)
    
    - interface interface
      
      - calculating perspectives (interfaces with intent, including interface components like origin-target differences & important concepts/priorities/filters) of the ml problem/solution space and applying them to generate a structure that applies multiple perspectives, like the:
        - possibility perspective
          - random/corrupted: the possibility that each or a subset of data points is incorrect/corrupted or random
          - incomplete: the possibility that variables are missing
          - distorted/extreme: the possibility that variable ranges are misrepresented by the data
          - conditional functions: the possibility that multiple alternate functions of the input variables apply in different conditions which can be parameterized
        - opposite x intent perspective
          - rather than solving the problem of 'trying to differentiate between categories', solve problem of 'trying to merge categories'
        - opopsite x direction x abstract (type) perspective
          - rather than trying to categorize from image, try to derive image template types from category & definitions
        - difference x pattern perspective
          - apply difference type interaction patterns to augment data to strengthen prediction function
      
      - finding variables enabling the selected perspectives & generating network algorithm/structure from those variables

    - structure interface
      - alignment
        - what alignments exist between ml network algorithms/structures and:
          - problem components like 'uncertainty reduction' intents (networks that have differentiation, missing info derivation, or de-randomizing side effects)
          - boundaries of interacting solution metric requirement structures
    
    - core interface
      - what components of algorithms exist that can be used to construct algorithms on demand
    
    - function interface
      - what input/output interactions exist between ml network structures/config/algorithms that allow for functionality to develop
    
    - cause interface
      - what causal structures (dependencies, direct/unique/ambiguous causation, alternate causes, proxy causes, causal metadata like degree) exist between ml network structures/config/algorithms, such as:
        - input-output sequences where each component causes (builds, leads to, enables, activates/triggers, supplies requirements of subsequent components)
        - core components which can be used to construct a system/object
    
    - concept interface
      - specificity of ml solutions, which can be generalized to handle more cases
        - unsupervised classifiers identify difference type as defined by a distance definition (distance from center/average/nearest neighbor)
          - generalized form:
            - classifier that identifies multiple difference types (differences within variable subsets, distance from other clusters/average/neighbors, etc) to support various intents (like probability of accuracy in identification/differentiation)
        - supervised classifiers identify difference type as defined by difference from labeled training samples
          - generalized form:
            - classifier that identifies multiple differences, within labeled attributes & category/type definitions, between type definitions, and difference patterns between types

  - is a network the best structure for implementing ml?
    - standard: an ANN network has: 
      - causation: direction linking input/output
      - changing parameters, starting from a standard origin: weight distortions
      - solution filters: applied distortion filters to select the distortions that contribute to prediction accuracy
    - alternate: 
      - other networks can be added to handle conditions where alternate functions can be applied
      - a decision network can be applied to determine when decisions are made to switch to an alternate network (where data contributes to prediction accuracy of an alternate function instead of the current one)
    - subset/core: 
      - sub-networks or core network components can be added to handle resolution of subset/core component interactions
      - a decision network can be applied to determine when sub-sets or core component interactions need resolution, like reducing common factors of input variables with standardization
    - combination:
      - integration structures can include a decision network to determine when components should be combined
    - filters:
      - filters or limit structures can be used to reduce what doesnt contribute to prediction accuracy or cant be applied by default (solution cant merge variables from alternate functions)
    
    - the core structure of a network is 'connection', with related structures 'position', 'direction', and 'filters'
      - a problem & solution can be 'connected' using a structure (like a sequence or network) of formats
      - other structural insight paths can be used to derive solutions
        - find solution by applying solution metric structures like structures of a priority
        - find solution by applying core structures available in problem space
        - find solution by applying system structures like ambiguity & incentive
      - these can also be applied to the ml problem space

  - add to reasons why variable or object network (including all terms like a language map, or a subset of relevant terms to the problem) can be insufficient/inefficient, while it can be used as a format to solve problems in general just like vectors can
      - a language map of operators used by a set of functions would have many overlaps & complicated paths between operators, resulting in unclear directions that functions move in or move inputs toward
      - an object network cannot clearly show all the possible object states (or the system contexts producing those object states)
      - the network is an absolute reference structure with static positions of terms/variables/objects, with a definition of difference or interaction applied to the objects to determine position, a position that may not be ideal for making a particular solution path or interaction sub-network clear

      - variable networks may illustrate attributes & direction of cause, but they dont illustrate:
        - why something is true
          - 'structure of an input' may cause a variable like the 'output of an interaction with another structure', but why is that true - bc:
            - structure enforces limits on interaction potential
            - structure allows similarities & alignments between fitting structures to interact
            - structure allows contradictory structures to damage other structures
          - these are system objects that arent displayed in a variable network with an arrow between an input structure & another structure, with an arrow leading to the side effects & other outputs of that interaction
        - you can add other layers to the variable network to show variables on other interfaces like cause to display reasons why something is true, other than a factual variable network displaying known interactions of components of facts, but this makes it not just a variable network, but a stacked/layered variable network, like how a state network has multiple layers and isnt restricted to one network
        - if you illustrate all interface interactions on one network, it might be unusable bc of the density of interactions
          - the above example has many patterns associated with it, many possible intents, many attributes/functions, many adjacent potential interactions & states & other interface objects
          - these objects can be indexed on the same network, but for quick queries, sorting through all of these objects may not be efficient
          - its also not efficient to store possible adjacent states of an object or its many sets of objects that can generate it or be generated by it in the same network
        - an object network is good for showing known interactions between objects, just like a variable network is good for showing known interactions between variables
        - the merging of all these networks is not efficient, for example when displaying an attribute like 'usefulness' 
          - this attribute may be a property of many objects, and it may be a property of structures of objects (like a system of objects)
          - the attribute also has definition routes associated with it
          - these interactions would be inefficient to display on the same network
          - the structure of the attribute definition routes (on a network of standardized concise definition components like concepts on a language network) would require different structures than objects with that attribute as a property
          - the structures of usefulness defined as the attribute's definition routes may not show up exactly the same on an object or other network 
          - a definition route of usefulness may interact with concepts like relevance & alignment, concepts that may not be displayed on a merged network in a clear way that shows the definition route
            - relevance & alignment are fundamental & therefore common concepts/structures that will show up frequently in a variable or other network, in structures that dont align with their definition routes
          - 'alignment' may involve pairs of objects that make up most of the network - showing how 'usefulness' is defined in terms of 'alignment' (connecting 'usefulness' to those pairs of objects indicating alignment structures) will look differently on that network than on the language network of definition routes
          - so a query to find 'alignment' in a merged variable/object network (that includes all interface components) would have to select between the language network version of 'alignment' (definition routes between concepts) and the structures of 'alignment' found on the object/variable network (pairs of objects), which is less efficient and clear than designing an interface query to select these sub-queries beforehand (like 'standardize object network to concepts & match concepts with alignment definition route')
        - a merged network implies that all possible useful info has already been generated & added to the network, whereas interface queries involve operations that can find/derive new info

    - make diagram of absolute reference connections with metadata structures like networks/paths

  - determine core graph variables (definition of adjacence/difference, connectivity, dimensions, info storage methods, interactivity of structures like sequences)

  - crypto as community consensus, where a decision can have value if backed by a community

  - interfaces that are important bc of generative concepts/structures
    - 'core' interface's generative concept 'simplicity' and related attribute 'composability'
    - 'interface' interface's generative concepts 'interactivity' and 'balance' (how does info from each interface integrate or interact to produce meaning, balancing influence of interfaces in a way thats indicates contribution)
    - 'cause' interface's generative concept 'power' (ability to trigger other components)
    - 'concept' interface's generative concepts 'uniqueness' and 'applicability'
    - 'info' interface's generative concept 'stability' producing info
    - 'intent' interface's generative concepts 'functionality' and 'direction' (functionality develops when there's a reason for it to develop, like a direction of change)
    - 'function' interface's generative concept 'connection' (connecting inputs/outputs)
    - 'pattern' interface's generative concepts 'similarity' (powerful patterns are repeated and patterns develop in similar ways, producing similarities across interfaces)
    - 'logic' interface's generative concept 'alignment' (aligning logical connections with info as a supportive foundation)
    - 'change' interface's generative concept 'difference'
    - 'structure' interface's generative concept 'info' (info about other interfaces with potential for structure)
    - 'potential' interface's generative concept 'adjacence' (what is probable is more adjacent)

    - the generative attributes (simplicity, interactivity, balance, power, uniqueness, applicability, stability, functionality, direction, connection, similarity, alignment, difference, info, adjacence) reflect core structures (unit, value, force, direction, equivalence, distance, rate, ratio, input-output, type, dependency, constant)

  - add to useful concepts

    - bitcoin and ai both benefit from integrating the concept of time into existing inventions (tx history, weight updates)
    - what other concepts could be equally powerful if injected into structures of existing inventions
    - why is time (or the structure of sequence) a powerful concept in those problem systems
      - historical info integrated into current & imminent info was a pre-existing gap in relevant info structures of the problem system
      - the usefulness of historical info wasnt identified or wasnt identified as integratable into existing inventions
      - the related concept of:
        - 'connection' could have served as a replacement, indicating relevance of previous info to new or derived info
        - 'position' could have also replaced 'time' or 'sequence', given the relevance of 'position' as a predictor of financial transactions and connecting one info state to another, given data that can access the destination from that origin
      - its also inherently relevant to know how space-times (states) connect (like in a sequence structure) in order to predict adjacent imminent space-times (or states) as imminent members of the sequence

  - structures like origin/destination points, loops, layers, boundaries, & paths for solving problems (like logistical resource allocation, adding variable to a function, or finding search path (sorting))
    - give examples of problems with relevant structures
      - a question/variable/cause pattern
      - a connected function sequence
      - a set of filters & limits

  - how to identify that more normal language is likelier to contain factual statements

    - multiple interrelated reasons, from the insight path
      1. facts often have simpler connections
      2. language patterns have intents
        3. agents apply language patterns to achieve intent
          4. linguistic intents are often to change meaning until its false (out of the full set of intents to 'communicate info')
          5. agent often over-think how to emphasize/reduce language components and it creates unnatural language patterns
          6. agent-changed language (newly created patterns) is rarely more efficient than normal language patterns (inherited patterns)
            7. when it is more efficient, it is quickly adopted until its normal
            8. more efficient language patterns are likelier to be true, bc of the normally simpler connection patterns of facts 
          9. it takes work to make a set of falsehoods or mix of falsehoods & facts seems like a fact, and the work has side effects like lack of normality (sounding unnatural in structure) or simplicity (using fewer resources to connect components)

    - relevant concepts
      - the concept of 'simplicity' interacts with connections 1, 5, 8, & 9
      - the concept of 'normality' interacts with connections 5, 6, 7, 8, & 9

    - these concepts can be used as almost interchangeable alternatives in generating the interface query generating this insight path

    - despite their differing definitions, simplicity & normality are connected by the concept of efficiency, because what is simple often becomes normal because of the efficiency of simplicity, so efficiency can be used as an interchangeable concept of both of these in some cases

    - interface query to generate the insight path to 'derive an attribute to identify facts'
      - apply concept interface
        - identify important concepts (simplicity, efficiency, emphasis, reduction, falsehood, change, connection, pattern, normality, agency) of the problem system of 'identify facts'
        - apply relevant concepts to problem system
          - agents change language to achieve intents
            - apply intent interface by mapping to intents ('change info' for intent of lying, or 'false similarity to fact')
              - connect intents to original relevant concepts
                - connect problem system component derived from intent interface of 'agent-changed language' to concepts of normality & falsehood

  - add to definitions
    - reason as source cause node ('this happened because of this causal factor')
    - intent as target cause node ('this happened because this intent was the goal used as a cause of the agent's decisions')

  - add to causation variables
    - ability to change (if a variable cant be changed, it is less causative for problem-solving intents)

  - add to problem type structures as 'indistinguishable cause'

    - multiple causes of the same variable

      - example: gravity (no agency, just granular intent of 'apply force to relevant objects') can cause an object to fall, just like throwing it down (concept of agency and intent to 'move object down' or 'move object to ground') can cause it to fall

  - add to false similarity examples
    - set of interactions that are unrelated but appear correlated

      - examples
        - system B has an output that is structural similar to outputs of system A
          - interactions of system B that happen at a later time but their interim outputs may have a structural similarity to the outputs of system A
        - system B may cause a similar or equal output to that of system A, for a different intent/reason
          - if the output is used as a metric, they will seem similar or related

      - efficiencies are a reason (source cause node) that structural similarities occur
        - efficient structures follow patterns that may produce similar structural outputs

  - add to connect function examples
    - how to map connections between two systems
      - standardize structures (like sequential structures such as time), standardizing to either system's structures, interim structures, common structures, interface (like system or core) structures, contextual system-containing system's structures, etc
      - abstract to patterns (like type, cause, system structures)
      - conversion functions (like remove, apply, connect, define)

  - map gravity to similarity (in position) as a calculation efficiency, where calculation efficiencies (like how to minimize surface area or how to apply a key to decrypt info) are an input to information
    - gravity between bulk/boundary creating the mapping of equivalent attributes
      - gravity as:
        - the average or highest-weighted path of interacting paths
        - structure of efficiency through organization 
    - definition: 'structure of minimized surface area as a component of 'entanglement' connecting function of two boundary points'
      - reduced mapping (minimized surface area) is a calculation efficiency to determine boundary position
        - this reduced mapping could be used to connect boundary positions (or their components like an attribute)
    - entanglement as an efficiency to handle risk of information destruction or to handle over efficiency (distribute efficiency (in the form of information) across multiple points)
      - use a mapping efficiency to connect distributed info with structural similarities
    - particles lose their adjacence/similarity bias/efficiency inside the black hole
    - "highest-weighted path from point a to b is the most efficient space-time path, which is not always equal to the 'classical physics' space-time path" (find examples of intents that classical physics is not efficient for)
      - is quantum physics using a different definition of efficiency/similarity or is it using another priority (like energy storage vs. energy usage)
      - how do weighted quantum paths interact with the weighted paths of other particles
    - nonlocality/entanglement as a calculation efficiency in the form of the replica trick
    - wormholes as:
      - calculation efficiencies
      - radiation given off of calculation efficiencies, removing information or filters preventing possibilities
      - sequence of a lack of filters preventing possible paths
      - interfaces (connecting standardizing functions)
      - hidden variables/differences (masquerading as similarities)
    - 'replica trick' as:
      - a way of transferring energy stored in sequential repetition (one coin outcome repeated a number of times in a sequence structure) to energy stored in distributed equivalence (two coins having equal outcome)
    - time as:
      - energy store
        - if time exists, it means change is possible, because energy has been organized in a structure that allows change to occur, meaning structures have developed, meaning efficient structures have been found (organization of energy formats)
        - can you attract other spacetimes so theyre adjacent by storing energy in a way that is adjacent to their storage methods

  - give example of deriving formula with definitions of components 

    - problem metadata

      - problem statement (formula to derive):
        - expected value of the random variable f(x) = actual average of distribution

      - definitions of components:

        - average definition: 
          - sum of all values divided by number of values

        - expected value definition: 
          - average of all possible values, weighted by probability of each possible value
          - expectation is linear

        - p(x) probability density 'distribution sample' definition
          - independent & identically distributed values

      - solution statement:
        - independently & identically distributed samples (data points) from a distribution inside the boundary of the area to estimate, divided by the total number of data points in the distribution is a way to fulfill intent 'approximate area inside boundary'

    - definition connections

      - identify 'probability' as a useful concept to map to problem space:
        - because of structural similarity in probability structures & problem definition (proportion)
        - or as a useful method to find a representative subset to avoid trial & error (or combinationatorial) calculation of area

      - connect concepts of core components ('probability', 'average value', 'sample size', 'data points', 'area') using definitions
        - this should produce the concept of 'convergence' as sample size variable is changed & average value approaches actual area

      - definitions of concept interations
        - 'area' is a related concept to 'probability' when:
          - data points are mapped to possible outcomes
          - problem-solving intent is either:
            - general structure: estimate the proportion of a subset relative to a whole
              - specific structure: estimate the probability of a subset of possible outcomes relative to all possible outcomes

    - alternate routes to derive formula

        - apply conceptual structures

          - apply 'opposite' structure
            - probability of being in the area to estimate
            - probability of not being in the area to estimate

          - apply 'random' structure
            - reduce 'trial & error' solution structure in this problem space of 'testing all possible points' to a subset of all possible points
              - how to select a subset of points
                - extreme points
                - evenly distributed points
                - random selection of points would produce a representative sample of points in a bounded area with increasing accuracy given increasing number of points
                  - randomly distributed points are a way around trial & error of all possible points

        - generate counter-arguments (questions) as filters to reduce error types

          - question every decision, with decision defined as 'variable selections that impact future decisions (future variable selections)'

            - variables

              - method of selecting points
                
                - beginner question: 
                  - why not just generate integer or .1 points starting at origin until all possible outcomes have been covered by an even lattice of points
                - beginner answer:
                  - this introduces bias in the form of an anchored starting point & applies unnecessary meaning to the sequence of points added, which means estimates with low number of points would be biased towards the area around the origin graphable with that number of points
                  - this bias represents a structure of certainty, rather than a way of estimating probability, which by definition is uncertain
                - generate beginner question
                  - apply error type "lack of concept of 'probability'" (indicating an uncertainty like a random distribution, rather than a certainty like a constant in the form of an origin)
                - generate beginner answer
                  - generate differences in between structure posited by beginner and actual requirements
                    - meaning assigned to the origin/sequence is unnecessary and even the opposite of what is required (independent samples that are not connected to subsequence samples in the sequence)
                
                - advanced question:
                  - wouldnt this take a lot of data points to converge to the actual mean

        - apply concept of 'probability' to 2d graph problem space to solve the problem of 'estimating 2d scalar multiplication or summing of 2d scalar multiplication' 

          - probability definition route: 
            - observed x outcomes in proportion to all possible outcomes = probability of x outcome

          - applied concept of 'probability' to 2d graph problem space: 
            - subset of 2d structures (points) in proportion to total set of 2d structures (points) = bounded area


  - resolve definitions of components so you can finishing organizing useful structures like combinations of concepts such as "format sequence", "solution automation workflow", "insight path", "reverse-engineer solution from problem requirements or opposite structures", "connect problem & solution"
    - example useful structures with type stacks
      - format sequence
        - type of structure
        - type of structure that is useful for connecting origin/destination formats 
        - type of structure that is useful for connecting problem/solution formats 
      - solution automation workflow
        - type of insight path
        - type of insight path that is useful for connecting problem/solution
      - insight path
        - useful rule to derive/find/generate insights in a system
      - reverse-engineer solution from problem requirements or opposite structures
        - specific example of a general insight path (like a structural strategy)

    - example connections between useful structures
      - a format sequence can be used to connect any structures
      - an insight path can be used to connect some structures relevantly/efficiently/usefully (like problem/solution structures, input/output structures, origin/destination structures)
      - a solution automation workflow can be formatted as a format sequence

    - example meaning of connections between useful structures
      - because a format sequence can be a connecting structure, it can be used to implement functions with 'connecting' intents

    - change variables to check & complete definitions of interactions between components
      - variables
        - components used:
          - structures: filters, sequences, formats
            - variables: variable selection sequence
            - structures: format sequence
            - functions: conversion/connecting function sequence
        - origin/destination points
          - connect context to problem/solution:
            - start from system in which problem & solution occur (given solution potential) and fit/connect systems gap structures to problem/solution structures, rather than starting from problem & navigating to solution or connecting them in the middle or working in reverse
              - 
          - connect solution components to solution
            - start from existing solution structures & apply filters or other structures to reach solution
          - general form of 'filter connecting sequence': 
            - apply structures of standards such as filters to both/either problem & solution until theyre equal (meaning connected, or similar in structure like position/variables)
    - change variables to complete definitions of interactions between components
      - origin/destination points
        - connect context to problem/solution:
          - start from system in which problem & solution occur (given solution potential) and fit/connect problem/solution structures to system, rather than starting from problem & navigating to solution or connecting them in the middle or working in reverse
        - connect solution components to solution
          - start from existing solution structures & apply filters or other structures to reach solution
        - general form of 'filter connecting sequence': 
          - apply structures of standards such as filters to both/either problem & solution until theyre equal (meaning connected, or similar in structure like position/variables)

  - example of how to generate monopoly case arguments
    - change variable 'location of power':
      - spotify is welcome to build their own app store with their own phones or team up with their coalition to do so
      - add variable 'time sequence' to 'location of power' change:
        - if spotify operates an app store someday, they will set rules to benefit themselves too, just like theyve done in the past
      - offer an alternative to charging app store rate
        - is there a one-click button to migrate from spotify to apple that could replace any difference in taxes on spotify
    - apply conceptual definition filter 'does concept of persecution (and related components of the definition like focus) apply to the behavior (does behavior have a specific target that is the focus of persecution)'
      - are apple's rules applied exclusively to spotify? if not, it's not anti-competitive behavior
    - apply intent filter
      - is spotify's mission nobler than apple's
    - apply system cost-benefit analysis
      - what features were improved bc spotify exists? are those features worth anything or required needs? did they develop those features better than competitors?
      - if spotify is just charging rent on a catalog, are they adding value to the market, so they should be allowed to dictate the market at all?
      - what products/features would apple develop if they didnt have to pay a fine, and what are those features worth, and are those features required?
    - apply logical fallacy filters
      - apply 'hypocrisy' filter
        - apply 'anti-competitive' conceptual definition structures & test if these structures fit the opponent
          - does spotify plan on raising prices at some point or will they keep prices low even if the app store rate holds? are they only keeping prices low to dominate the market & plan on raising prices later? isnt that anti-competitive behavior?
          - if they are so concerned about anti-competitive behavior, why arent they trying to compete by building their own app store? isnt there a risk that the apple app store is sub-optimal and needs to be improved with competition from spotify

  - example of calculating possible functions with core functions applied to function structures like combinations (convolution of function structures)
    - ai functions
      - categorize
      - generate text
      - falsify realistic data
      - identify anomaly
    - core functions applied to ai function structures
      - ai function structures
        - ai function combination
          - categorize & generate text
          - structures generated by core function applied (a convolution of a function structure using core function operations)
            - categorize text generated by an algorithm
            - generate text of a category function input
            - generate missing interim category text
        - ai function sequence
          - falsify realistic data, categorize, generate text
            - falsify realistic image to fool a categorizer used to generate standardized text

  - example of calculating possible questions/problems that are solvable using metric filters
    - convolution of metric structures to determine what can be measured
      - example metrics
        - specificity of solution
        - reusability of solution
        - accuracy of solution
      - example metric structures
        - apply metric filter combination as equal priorities
          - specificity of solution & reusability of solution
        - apply metric filter sequence
          - reusable solution, specific solution
      - example problem structures that can be solved with metric structures
        - a problem of 'find approximation' can be solved with metric structures like accuracy & specificity':
          - apply filters of specificity (to make sure the problem solved is the right problem to solve, like 'find an approximation for a prediction function' rather than finding an approximation for another object)
            - apply filters of accuracy (to make sure input/output values are within a range that can be fit to the definition of accuracy in the problem space)
          - in other words, because we can measure specificity & accuracy, we can solve problems like 'find an approximation function'

  - example of calculating possible error types 
    - error type:
      - alignment of structures can from an unpredicted error
        - core example: stacking layers in a filter opening can eventually fill the opening, preventing the filter from working (arteries lined with fat)
    - apply structure of error type to AI problem space
      - multiple stacked or sequential pre-processing alignments of data that standardize data too much and make the data so homogeneous (self-similar) & similar to the filter node's threshold value that everything passes or fails, or pass/fail is equally likely

  - exploit filter structure examples:
    - anomaly
      - non-standard data flows
        - does data normally follow this pattern
    - requirements
      - is there a required basis for communicating info
    - intersection:
      - data * time/sequence
        - state/content of a data flow intersecting with a possible access chain
    - code x time/sequence
      - state of a build to check intent multiple times during build phase of code

  - bio system general strategies
    - calculate & inject vulnerability in pathogen dna language
      - trial & error implementation example: 
        - use dna code switcher to apply change to all positions in pathogen dna
      - common pattern implementation example:
        - inject known dna error types to see if any work on new pathogen
    - standard pathogen dna to host dna language

  - a nn that fails when its original training set 'clues' are gone can identify:
    - alternate variable sets to generate predictions to use in cases without information
    - differentiating functions to separate those variable values to make them clearer & the predictions more accurate
    - variables, variable operations & variable structures that can be applied to generate more accurate predictions, given a lack of information

  - calculating a flow field numerically can be optimized by calculating:
    - possible/probable/fitting components of functions 
      - connections between prior calculations, to find connection structures that re-occur, as the output of a function
        - find core connection structures like waves, peaks, inflection points
      - connections between connection structures, to find: 
        - patterns in connections between:
            - identified patterns of difference, like degree of difference observed between adjacent points
            - structures of approximation & accuracy (what kind of structure could add prediction accuracy, in what contexts)
            - base functions & base function components & useful/stable functions
            - similarities in structures of difference, between function structures like variables & error structures like distortions
          - variables of & distortions to those variables common to connection structures & connections of those structures
        - connection components that coordinate for some intent
          - intents like calculation in an input/output sequence, or fitting into a structure that is efficiently compressed or retrieved
            - incentivized connections that are optimal for some calculation intent
      - generate & test predictions of future calculations, to find local/adjacent prediction functions
        - generate set of prediction functions to test predictions
          - apply operations & structures known to produce common connection structures to calculations in reverse to derive possible function components
        - generate set of prediction function filters (extreme prior connection structures) to select prediction functions
        - generate set of opposite structures (like non-adjacent points) to test predictions
    - filters of functions (reduce solution space of possible function & function components)
      - filtering functions by these connection structures & patterns, filtering out functions that wouldn't adjacently produce these connection structures
    - interaction structures of functions & function components
      - function components that can interact by coordinating, vs function components that invalidate each other & can't coexist absolutely or be adjacent locally/directly
    - function & function component causal structures
      - apply patterns of causation between functions (function of structure A causes function of structure B) to identify the level of cause a function is based at

  - relevance attribute filters to determine cause of x
    - exclusivity/specificity
      - could this component be the cause
      - what else also has this attribute/function/component without the cause (what else doesnt have the component but still causes x)
    - intent
      - does this component indicate agency or other direct/clear intent
      - could this component be accidental (not useful or not used) vs. intended (is it useful to some degree for some goal)
    - requirement
      - is this component required or optional
      - could the requirement be the cause
    - expectation
      - what is the expected/standard component
      - could the standard or the distortion from the expected/standard component be the cause
    - commonness/uniqueness
      - is this component common or unique
      - are unique components the cause, if common components don't cause x
    - input/output
      - is this an input or output
      - can the output be the cause, if the goal causes it
      - can the input be the cause, if another input wouldn't cause it
      - can the function be the cause, if any input would cause it
    - system context
      - can the system be configured to not need the component (is the system or system configuration the cause of x)
      - would the component be re-generated if you removed the component or the direct cause of the component
        - would the component be created anyway, even with a minor barrier
        - is the component incentivized in the system
        - how much work would you have to do to prevent the component from being generated in the system (it would be created unconditionally, or in what percent of conditions)
        - does that work change the system to an extreme degree (changing its identity/type/intent)
    - change.structure:
      - opposite: can the component be changed to not cause x
      - symmetry: do changes to the component still cause x
    - potential.structure
      - alternatives: are other structures like combined errors capable of causing x
      - are those structures possible in the system (do they exist in the system)

  - identify probably useful (relevant) structures of organization that integrate interface objects for a problem type
    - standard structure for solving a 'find variable connection' problem
      - variable structure in a common format or standard format with connection structures (network) 
      - using 
          - equal as a base function to generate the origin network structure differences (position)
          - causal direction
          - type
          - core functions as sub-components

    - how to generate a standard useful cross-interface structure of organization
      - find connection change structures (variables):
        - type is relevant bc variable types have direct connections (like 'variable of one data type like boolean likely to be connected to another variable of a data type like condition')
      - find connection core structures (components):
        - core functions are relevant to build new connections where info is missing about a connection
      - find connection interface or structure structures (standards, filters):
        - equal positions of variables are likelier to find differences (distortions from equal) faster than starting from an extreme positioning function
      - find connection structures associated with interfaces (direction structure associated with intent):
        - causal direction is directly defined to be relevant in the 'connection' definition, which implies an input/output connection, inputs being liked to 'dependency', which is linked to 'cause'

  - integrate objects/.md text with interface implementations

  - apply to structures

    - concept of attention in structures
      - mixed interim high-variation & high-similarity structures tend to maximize attention
    - examine conflating intent & requirement
    - consciousness as choice to move between neural nodes (rather than being directed) required:
      - the development of alternative node paths performing equal/similar functions, requiring:
        - the development of excess resources, delaying required decision time (making immediate decision unnecessary, avoiding a forced decision), requiring:
          - the existence & application of previous efficiencies & functions for alternative evaluation, energy storage, storage-checking, & energy requirement-identifying
      - the cause could be framed as structures such as an 'efficiency stack' or 'energy maintenance functions' or 'alternative options' or 'navigation/motion control' or 'lack of requirement/need'
    
    - examine similarity (alignment/overlap) structures between: 
      - extremely different components (when an error type is an incentive or a function used for other intents) 
        - when the solution format of some problem has similarities to the error type, like when you need randomness so errors generating randomness are a possible function to use for that intent
        - contradictory/opposite components (have some metric in common, with opposite values)

  - finish organizing lists of examples, functions, info objects (insight paths, definitions, questions), components for configuration

    - organize examples

      - label examples so they can be queried more structurally
      - query for logic in examples when implementing functions
      - organize examples of useful structures & questions in index.md
        - identify useful questions in notes
        - check reduced language components for any other useful functions (what terms cant be adjacently, clearly & accurately framed in terms youve defined) for completeness


## examples

  - examine the distortion vector paths that adjacently decompose a data set into a prediction function from a base point/function set

  - give example of mapping to structures & identifying contradictions its safe to ignore for applying a structure

  - example of permuting assumption: "reports of power consumption have to be exact measurements" 
    - a temperature monitor sensitive to a hundredth of a degree might provide similar but non-specific power reporting for important/extreme usage patterns without revealing such specific information as that which could infer exact operations being done, bc the interval of temperature measurements allows for greater variation in calculations that could explain it
  
  - query examples for use cases like:
    - lack of information stored (match problem of type 'information lack' with interface query 'check pattern interface for similar patterns')
    - query problem breakdown & integration diagram
    - calculating various different problem breakdown strategies first before executing normal query-building logic for each
  
  - add examples of system/object/rule/type change patterns
  
  - include example workflows with example problems
    - include example of how to generate other workflows (different starting/ending points & trajectories)

  - example of using set theory in query operations:
    - edges as core organizing/formatting operations (find/apply) & interfaces (connecting/explanatory concepts/functions)
    https://en.wikipedia.org/wiki/Hypergraph

## diagram
  
  - diagram with error types
  - diagram of the network of formats
  - make efficiency map
  - diagram of alternate interfaces (information = combination of structure, potential, change or structure, cause or structure, system)
  
  - give structural query example diagram for GANs + image compression problem

  - chart type: overlaying multiple 2-dimension variable comparisons to identify common shapes of variable connections (density of points added with a visible attribute like more opacity)

  - finish core function structure example diagrams

  - diagram with joke types
    - 'annoying when they bring up human rights in a conversation'
      - conversation system context
        - functions
          - change topic 
            - change topic structure (sequence)
              - introduce a topic (first time topic is included in conversation)
          - expected interaction functions
            - criticism of a behavior
              - 'conversation with dictator' system context
                - criticism of power abuse (law violation, specifically human rights violation, which are a related object to dictators)
                  - interpreted as right in the 'conversation with dictator' system context
                    - expected interaction in this context
                      - 'should bring up human rights to a criminal'
            - norms:
              - for low-stakes interactions & interaction errors (manners, annoyance, disrespect)
            - laws: 
              - for high-stake interactions & interaction errors (rights violations)
        - placing a norm (or related objects) in the place where a law (or related objects) would normally go:
          - 'its annoying when someone doesnt let you end the conversation'
            - 'its annoying when someone keeps going on & on about your previous conversations where you ordered deaths of a dissident'
              - 'its annoying when someone keeps going on & on about your previous conversations where you ordered deaths of a dissident for being annoying & then abruptly stops without explanation'
            - 'its rude when someone doesnt let you end a conversation with a laywer interrogating you for war crimes' 

  - diagram for structures of emergence
    - example: 1-1 input/output relationship up an interaction layer, where extra resources that dont dissolve immediately on the higher interaction layer aggregate & form core structures like combinations, where interactions between combinations & sequences have different dynamics than the individual output interacting with other individual outputs
    - emergent functionality/attributes come from interaction structures (sequences & layers)

    - add diagram for intent-matching
    - add structures to diagram: interface overflow (to sub-interfaces), interface foundation
    - diagram for workflow 1: 
      - function to determine relevance filter ('functions', 'required') from a problem_step ('find incentives') for a problem definition, to modify problem_steps with extra functions/attributes ('change_position') to be more specific to the problem definition ('find_incentives_to_change_position') for problem_steps involving 'incentives', so you know to use the function_name to modify the problem step if it's between the type 'functions' and the object searched for 'incentives'
    - add conceptual math interface query diagram
      - use lattice multiplication as standard example, other than core operations (add/multiply mapped to language, concepts like irreversibility/asymmetry mapped to math)
    - interface conversion, matching, starting point selection (applying structure, checking if relevant information is found)
    - diagram to document sub-functions of core functions with distortions
    - make diagram for dimension links higher than 3d that are depictable in the same network space
      - should show variables that impact other variables, the change rates of these relationships
      - overall impact should be calculatable from these relationships
      - should show similar movements for correlated variables
      - should show skippable/derivable variables (variables that can be resolved later than they normally are)
      - should show meta forces for overall trends in change rules (direction of combined variable forces)
      - should show limits of measurability & threshold metrics

    - diagrams for specific concepts, core functions, concept operations (combine, collide, connect, merge, apply), ethical shapes
        - variable accretion patterns (how an object becomes influenced by a new variable, complex system interaction patterns, etc)
        - make diagram of potential matrix to display the concept
          - map parameter sets to potential matrix shapes 
        - finish diagrams for cause (shapes & ambiguity), concept (evolution of concepts, networks, distortion functions)
        - diagram for argument
      - make a system layer diagram for each interface to allow specification of core interfaces & other interface layers (interface interface)
        - make a system layer diagram for structures to include layers of structures 
          (beyond core structures like curves, to include n-degree structures like a wave, as well as semantic output structures like a key, crossing the layer that generates info structures like an insight, a probability, etc)

    - map variable structures to prediction potential for problem types, given ratio of equivalent alternate signals

    - vertex variable structures
      - quantum physics, prediction/derivation tools, build automation tools, testing tools, learning/adaptation tools, system rules, computation power are all vertex variables of information, since they can generate/derive/find information
        - which structure (sequence, network, set, or cycle) of vertex variables is most efficient

    - core component attributes: identify any missing attributes/functions that cant be reduced further

# content/config

    - import insight history data to identify insight paths (info insight paths like 'lie => joke => distortion => insight', system insight paths like 'three core functions + combine function with this definition + n distortions to nearest hub')
    - define default & core objects necessary for system to function (out of the box, rather than minimal config necessary to derive other system components & assemble)
      - add default functions to solve common problem types
      - alternate utility function implementations have variation potential in the exact operations used to achieve the function intents, but there are requirements in which definitions these functions use because they are inherent to the system. For example, the embodiment may use a specific definition of an attribute (standardized to a set of filters) in order to build the attribute-identification function using a set of filters - but the general attribute definition is still partially determined in its initial version by requirements specified in the documentation, such as a set of core attribute types (input, output, function parameter, abstract, descriptive, identifying, differentiating, variable, constant), the definition of a function, and the definition of conversion functions between standard formats.
    - document time structures (concave time explaining compounding similarities up to a point of maximum concavity, a structure that can separate from the other space-times)
    
    - systematize definitions of info objects, to include analysis that produces relationships of core objects like opposites to their relevant forms (anti-symmetry) in addition to permuted object states (asymmetry), such as an anti-strategy, anti-information, anti-pattern
      - organize certainty (info) vs. uncertainty objects (potential, risk, probability)
      - make doc to store insight paths, counterintuitive functions, hidden costs, counterexamples, phase shift triggers
      - add technicality, synchronization, bias, counterintuition, & certainty objects leading to inevitable collisions
        - error of the collision of compounding forces producing a phase shift
        - lack of attention in one driver and false panic in a second driver leading to a car crash given the bases where their processes originate
      - define alignment on interfaces (compounding, coordinating, parallel, similar, etc)
      - add core info objects (core strategies, core assumptions) so you can make a network of graphs for a system
    - concept analysis:
      - how new concepts (gaps in network rules) evolve once structure is applied to prior concepts 
    - interface analysis:
      - limitations of interfaces & how to derive them
      - how rules develop on stability & how foundations are connected & destroyed
      - explainability as a space limited by derivable attributes from data set & cross-system similarity
      - vertex definition & give examples (as an intersection/combination of interface variables, such as determining/description(compressing)/generative/causative/derivation variables), around which change develops
    - change analysis:
      - generated object change types
        - constant to variable
        - variable to removal of assumption in variable type/data type
    - examine implementing your solution type (constructing structures (made of boundary/filter/resource sets) to produce substances like antibodies, using bio system stressors)
    - resolve & merge definitions into docs/tasks/implementation/constants/definitions.json
    - update links
    - integrate archive_notes/finder_info/functions
    - de-duplicate logic
      - organize interface analysis logic definitions
        - organize functions in problem/interface definitions, before organizing functions in implementations/*
      - integrate problem_solving_matching.md
      - integrate find/apply/build/derive logic from system_analysis/ & maps/defs*.json
      - separate interface analysis logic into implementation/functions (functions dont need unique info)
      - add functions from workflows & analysis (to do list, questions answered, problems solved, interface definition & functions) as files in functions/ folder
        - organize into primary core functions & list sample parameters (like objects to identify for the identify function)
      - integrate rules from diagrams in patent applications to relevant documents
            
