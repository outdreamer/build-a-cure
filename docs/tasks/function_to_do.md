# to do

  - nn structures displaying concepts like 'fear':
    - fear of learning being too difficult (high cost) prevents investment in further pursuit of information
    - in a neural network, the concept of fear shows up in the structures designed for cost-minimization

  - determine what general intents to analyze, in what structure (sequence, combination, network)
    - determine what structures (dimension sets like vertex variables, core functions or interaction layer objects, formats like definition, networks like attribute graph) can solve what problems optimally
    - determine what problems need to be solved
    - determine what work needs to be done to solve input problems
    - determine priorities
  - then you can organize analysis to fulfill those intents
    - core analysis
      - what are the core components?
        - what are produced by core structures applied to core components?
          - what are the useful products of core structures applied to core components, for which relevant intents?
    - system analysis
      - what are the system components (opportunities, efficiencies, incentives)
    - interface analysis
      - how does this fit with other intents & problem space changes while analysis was running? 
      - can work be reduced using problem space changes like new tech?
      - should this analysis continue or switch to another intent?

  - generate nn of every core structure (like a combination structure to aggregate features into groups) having a useful intent for 'generating prediction function' intent

  - generate starter pack of solution automation methods by applying core structures to problem objects
    - apply subset & group structures to problem/solution
      - break problem into sub-problems, solve sub-problems, and aggregate sub-solutions

    - apply filter structure to problem
      - filter problem until its a solution object

    - apply variable structure to problem
      - find variable(s) that capture the most or most important variance across problem objects
      - format problem objects in terms of those variables

  - apply structures to interfaces
    - list points of overlap & connection between interfaces & use that network as a primary/default interface query structure

  - define the application of interfaces to interfaces
    - structural concept definition
      - repeated, stable structure in a system that develops its own functions/attributes from interactions with other structured concepts rather than being definable solely as a set of components in isolation

  - example algorithm output by system analysis
    - find incentives of a system
      - apply structural incentive definition (cost-minimization, profit-maximization) - meaning applying 'cost-minimization' to interaction objects, indicating structures in the:
        - general interaction layer of 'input-minimization'
        - granular interaction layer of 'work-minimization'
        - interim interaction layer of 'feature minimization'
        - emergent interaction layer of 'output/profit maximization' (in the form of maximizing remainder profit)
      - find relationships in system
      - find primary inputs (work, cost, movement) and outputs (rewards) in system
      - find input-minimizing (cost-minimizing) points/routes in system (points/routes that minimize work)
      - find concepts in system (remainder profit after required features are built)
      - find interaction layer & objects in system (profit, work, features, contract)
      - find strategy to allocate interaction objects (minimize features) in a way that achieves an input-minimizing point (minimize work) - meaning inputs of interaction objects
        - filter strategies by those that minimize cost or maximize profit 
          - identify sub-incentives of an incentivized strategy applied to interaction objects (sub-incentives of related objects like inputs)

      - example: fixed-cost contract
        - identify relationships
          - increased number of features have a negative correlation with increased profit
            - identify interaction object inputs: work is an input to features
          - identify concepts & relationships: 'remainder profit' is maximized if work to fulfill required features is minimized
        - identify incentivized (profit-maximizing or cost-minimizing) interaction object allocation method
          - the primary incentive is to minimize features to just the required features
            - sub-incentive to minimize work

  - weather tool: deploy prediction algorithms to CDN servers instead of data - if actual data varies more from predicted data above a threshold as determined by calculation servers higher up pipeline, force query of actual data rather than predictions to downstream servers & update prediction functions' outlier handlers

  - initial automated tests of a data set (to apply an associated architecture/algorithm to) can answer questions like "can a set of variables produce the level of variance needed to contribute information to complete a task (like prediction of an output variable), determined by matching the level of variance in the output (like the most different examples in a category)"
    - additional layers of analysis: 
      - can a distortion of the variables provide the needed variance
      - can an extra variable provide the needed variance
      - can this architecture/algorithm form structures needed to explain (connect) these causal links (describe/derive the causal network) or hold the relevant concepts (like how the structure of 'evolution from a common ancestor' has a corresponding structure in the divergence of cat/dog graph clusters when you add an extreme value of the time variable), given the complexity & variation & change potential involved

  - game automation 

    - choose a system with enough complexity to allow many change types (rule changes, injection of other systems, changing system context, etc)
      - information system
        - information objects
          - story: a sequence of events with a perspective focusing on a subset of events, interacting with agents & their objects (goals, lifetimes, problems), & their communication objects (conversations, stories, jokes, research, reports)
      - function interface
        - rules
          - social rules
            - court: a decision node, operated by an agent having information about rules (limits, protections of freedoms) & rule types (preferences/norms/laws), priorities (justice, avoiding giving justification/permission to legislate other unintended laws), interactions (impact on markets, diplomacy challenges, deals), change types (allowing a change type that triggers other changes), & concepts (precedent) of government
      - system interface
        - closed rule-based systems
          - system objects
            - objects with direction (incentives, goals, optimizations, range of potential changes)
              - game: low-stakes goal in a discoverable system

    - choose a level of variation to allow interactions with other systems
      - variation in interaction layer (stories interacting with stories, human interaction laws interacting with physics laws of space-time)

    - choose structure of this interaction
      - can be a containing structure like a context, a platform like a background/foundation, or an object in a combination/sequence set

    - choose agents with
      - high change potential (no hard-coded biases that make their perspective static, like avoiding information)
      - relatable problems (family problems, seeking a resource, etc)
      - powers that add to their potential/freedom for escapist games
      - new combinations of agent objects (powers that have problems, permuting assumptions, abstracting/invalidating definitions of game objects)

  - testing tool to identify bias in algorithms as litigation profit opportunities
    - biased algorithms use the incorrect 'reason' for their decisions
      - example: using a race as a 'reason' - a factor determining a decision like a criminal categorization or assigning a risk probability
      - the race shouldnt be the reason determining the decision, though it can be included in the data set to identify concepts like oppression
      - if an illegitimate reason decision-determining factor is identified, the algorithm can do more analysis to:
        - figure out why thats a determining factor
        - find counterexamples (permuting race variable) to verify the illegitimacy of its predictive power
      - the reason for a decision about something as important as criminality/recidivism probabilities should be:
        - an agent's conscious response to incentives (they chose to commit a crime, but were not pressured or forced to do so)
        - involuntary attributes/functions (inability to have impulse control, inability to empathize, other mental disability)
      - the primary factors causing crime are:
        - incentives (reasons to do crimes, such as injustice or boredom)
        - potential in the form of intelligence (giving them other options to get resources than through crime)
      - these factors can be approximated by factors associated with victims of injustice (oppressed groups) which do tend to have associated physical attributes
      - so theres a feedback cycle over-rewarding use of these physical attributes as causative factors, bc the algorithm misses the connecting variables:
        - oppression/injustice historically directed at groups having certain attributes
        - intelligence (stupid people make hasty decisions & choose a career where they'll be forced to make hasty decisions, relying on easily accessible rules in quick decisions - rules like physical attribute assessments, or over-aggressive/protective fear responses)
      - when in reality these physical attributes are nearer to outputs of that causal cycle:
        - stupid people seeking powerful positions => quick decisions usually using illegitimate rules, depending on side effects of stupidity (lack of emotional regulation or planning or quick adaptation, or seeking/being exposed to bias-enforcing information, like focusing on criminals of a particular attribute) => biased decision => enforcement of power to hide biased decision (punish victim anyway, hide evidence of biased decision) => stupid people see another person of that attribute go to jail & miss all the causative factors involved (injustice, intelligence gaps) => more bias cycles are triggered/repeated (stupid brains make more simple single-attribute decisions bc they got rewarded for this one), resulting in hardened assumptions that theyre not biased, resulting in increasing lack of self-awareness/self-correction/learning potential & more stupidity/simple decisions/hard-coded rules/rewards for acting out of fear & bias => repeated oppression of people with those attributes => lack of meaning/justice in lives of oppressed people => stop trying to see the point of being good & start justifying criminal activity for basic needs => punished for fulfilling basic needs, resulting in more injustice cycles => retaliation of family for injustice => stupid people seeing more people with that attribute go to jail, as families/loved ones often share attributes => more stupid people conclude they need to control people with that attribute => stupid peopl seeking powerful positions

      - algorithm tests:
        - a good algorithm will identify these factors (incentives to do crime & potential/intelligence) as the primary determining variables creating crime, and will also be able to output the structure of the above causal cycle/network
        - the algorithm should identify sub-reason causal structures, like
          - boredom/entertainment
          - feelings like power to correct their emotional imbalances
          - cycles of criminal activity (victims seeking street/vigilante justice, unlucky people seeking to allocate their problems to perceived luckier people)
        - concepts & relevant structures capturing them:
          - intelligence
            - functions of intelligence like impulse control, skills learning
            - side effects of intelligence like steady income
          - justice cycles
          - lack of justice, leading to lack of meaning (they never got protected/justice so they cant see why innocent people should, given that there must be no absolute meaning)
          - forgiveness/trust/understanding: tools of crime-correction that should not be enforced on victims
          - victim complex: tendency of social agents to see themselves sympathetically & as passive victims, especially criminals
          - lack of empathy/hypocrisy: criminals who cant empathize dont achieve self-awareness, dont correct their errors in judgment, and dont exhibit unnecessary concern for others' well-being, so they see themselves as victims while being unable to see other people like their victims as victims
          - needs vs. desires: criminals dont separate needs & desires, and crimes of fulfilling needs like life-saving medicine shouldnt be categorized as crimes

  - list examples of applying structure to create new neural network structures for an intent & how to generate them

    - example: 
      - cnn = apply 'subset' structure to 'adjacent features', given that 'position/adjacence' is an attribute determining a definition of 'relevance' in the form of 'local relevance to other local features, & other feature interaction layers built by local features', or 'size relevance'
      - the cnn prioritizes the 'subset' groups of local features, promoting this set as its own emerging feature serving as input to the next layer.
    
    - to generate other examples, identify structures like the 'local adjacent feature subset' or 'size relevance' in an image as an approximation of meaning aggregation/filtering/construction/injection, to calculate global meaning/relevance across the whole image, relevant to a task (identification/categorization/differentiation)
      - this is a good standard example of how structure (position/subset) can have meaning when applied in other structures (image)

      - algorithm to generate these structure changes for an intent (sample output of interface analysis):
        1. determine a structural definition of meaning/relevance for a problem (with associated info/formats & target solution info/formats)
          - adjacence as a definition of meaning for local features in an image info format
        2. find a structure that fulfills that definition of meaning
          - subsets of adjacent local features capture adjacent information
          - adjacent information may be relevant information, given the definition of relevance used
        3. apply that structure to the algorithm
          - inject the subset structure in the input structures, adding an iteration to capture additional subsets
          - injecting the subset structure is a proxy for injecting the structural relevance definition of adjacence

    - another example: 
      - given that reverse weight trees are a standard neural network structure, is there a structure that would help prune the trees, connect the leaves across different weight trees, or convert the trees into a useful network/cyclical structure that could be applied in any direction?
      - should neural network support pivots in other directions, so rather than optimizing for the original final target layers, they can have or add layers in other directions, after discovering patterns in loss/activation/weights that point to other dynamics than originally configured to identify? (star or cyclical structure, with different final target layers)

  - apply ddos against hackers by keeping them busy hacking decoy servers & fending off malware attacks to IPs that use the most security tools that arent associated with white hat communities

  - apply patterns of hacker decisions
    - examples:
      - when to attack an exploit (when its posted to a particular dark web forum, when their brute force tools discover it, when an exploit is discussed on a white hat chat)
      - when to mimic benevolent signals compared to time of discovery/attention of benevolent signals (how soon after hearing a suggestion of mimicking white hat hackers do they apply it)
      - level of effort applied to benevolent signals (do they tend to complete standard/benevolent config/is it implemented better than average configurer)

  - apply system analysis to current investments to detect imminent problems (conflicts, inefficiencies, exploit opportunities, incentivized laws/loopholes, incentives to use sub-optimal strategies or exploits, mismatch in demand/supply) and suggest corrections that will optimize investments
    - the right algorithm will identify structures like interaction layers of highest-variation inputs that produce highest-variation outputs to identify where high-impact changes can be made
      - then it will filter for optimizations like lowest-cost, lowest-side effect, highest-impact changes
      - the highest-variation input structure is probably the network of technologies followed by the network of markets
      - the highest-variation output structure is probably the networks for emergent (high-separation degree) high-value opportunities (produced by such inputs as innovation-generators, risk-generators, and exploit opportunity-generators, such as compounding problems like edge case side effects) with connecting interim dimension sets like:
        - the network of priorities (common priorities like respond to selfish incentives, fix problems, distribute power)
        - the network of common problems being relatively low-variation (mostly incentive conflicts, inefficiencies, lack of information producing risks, and inequalities
        which generate output exploit opportunities
      - high-impact changes can be made on the combination interface of cause-system-structure-potential interfaces, solving for tech that invalidates markets which depend on problems like inequalities

  - example of function metadata query to find function for a target intent 
    - build function with intent to 'clear misfolded proteins'
      - trigger hormong production 
        - hormones support 'growth' intent 
          - 'growth' intent has related functions to support 'finding resources' and 'using resources' to support relevant growth intents like 'build new structures'
          - 'misfolded proteins' are a resource providing protein components
          - 'clear misfolded proteins' in the form of 'breaking them down & using thmm to build new structures' can be identified as a supported intent of 'growth hormone' objects and triggering functions
    - then apply filters to check for other side effects neutralizing target intent

  - nn explanation example:
    - neural network as a reverse tree of weights
      - each network layer has coefficients mapped to sub-trees of weights, where feedback prunes the trees, differentiating them further & deactivating branches with weights that dont contribute given feature positions & variation
      - iterations that adjust the weight trees amount to logic exacting conditions on the input set of component functions building the prediction function
    - generating the most-different sets of weight trees likeliest to get an answer about their contribution quickest is more efficient than the standard training process to incrementally adjust weights

  - structural interface query example
    - apply structures to structural components & operations to generate new solution object to format/organize/structure information for a given intent
      - select structure (network, tree, sequence, position, path, combination, filter, value)
      - select structural component (definition, base, variable, constant, coefficient, rate, change, type, function)
      - select structural operation (build, apply/change, derive/connect, test, find, organize)
    - example: 
      - start from a network of bases, apply changes of types supported by that base to generate variable networks for each base, then test each variable network with intent to find most useful base & variable network to solve a problem structure like 'finding relevant variables quickly'

  - variables can be represented better in other structures (probabilitistic networks/trees) than their original structures (spectrum representing full possible value range)

  - example intent implementation for a priority like 'security'
    - accessing a particular site by stating intent, where intents are mapped to a static network/route/server set, so that content cant be replaced with malicious content
      - a browser accepting a request for a site can only deliver values specified in the intent map for that site key
      - keys in the map represent partitioned content
        - requested intents like 'whatsapp.myuserid' can only deliver content from the values associated with the key path map['whatsapp']['myuserid'] (server/database/network/content values)
      - the integrity of the universal intent map as a source of truth/legitimacy/trust is the main point where requests/responses can be compromised, and if its enforced by lack of editing ability & verified with local copies, it cant be compromised
      - edits to the intent map are supported by continuous & coordinated 'voting' as legitimate mappings, so new request intents can be supported, with increasing degree of readonly capacity as the new intent entry is more confirmed by votes
      - paths (IP addresses, usernames/handles/email addresses, paths in the mapping, id numbers) in this system wouldnt change (changes such as inheritance/editing/randomizing/sharing)
      - users & the requests they make would be intrinsically linked, and would be trusted with content relevant to them, including inputs like voting requests (they can vote on legitimacy of content relevant to them)
        - intents would be evaluated by context, to sync/fit them into the absolute system of meaning
          - intents like 'deactivate/hack encryption tools on the server associated with this site they just visited' would be fulfilled if the context was justified, such as contexts like 'in a location where encryption has been abused, like a porn or ransomware distribution site', where new intent requests support a particular change/difference/variation ratio & other metrics associated with calculating justifiability like 'intent (ability in the form of a justified actionable plan) to prevent harm'
          - the browser would be the primary enforcing agent in this system, confirming the integrity of the intent map & edits made, as well as determining justified contexts of intent requests not specified in the map (allocating them to voting agencies in cases of uncalculatable justifiability)
        - this implements a centralized source of truth, applied in a decentralized way (everyone can view the keys of the map & has a local copy of the keys & the value hashes), synced with definitions of meaning & understanding (like how requests from a particular user follow patterns specific to their decision history, and how intents can seem but not be similar to other intents, and common manipulation patterns like using ambiguous intents to hide malicious intents)

  - example of applying structures like 'approximation' and 'adjacence' to achieve intents like 'create proxy identification functions' fulfilling core alternate high-level intent functions like 'derive' rather than 'find'
    - monitor accessible signals (user showing signs of detecting anomalies like staring at a phone number or frowning in concentration) surrounding the inaccessible target signal (attack)
    - the relationship between core structures (like core functions such as apply/derive, core objects like implications/assumptions/conclusions/definitions) can provide a first-level data source on rules to design interface queries (try find information first, otherwise try alternatives to find like derive/build/test information or proxy information, with the assumption that proxy signals amount to the target signal)

  - organize system in a structure optimizing for 'security' priority:
    - with rules like:
      - a function that can edit signals of an attack (request logs) should not be the same function as (or an accessible function to) a function that can cause damage
      - the delete function can only be applied to file content, not file metadata or request logs
      - any rules about a function also apply to any functions that amount to that function when combined
    - these are abstract rules about structures like functions & concepts like organization/integration that offer a new layer of testing for system optimization
    - workflow testing is another type of testing that is not fully supported/automated (by tracking expected side effects of a task set, having conditions to select tests to execute, and having accepted range of variability in outputs like timestamps)

  - abstraction as a method to capture variation in the form of change/difference types

  - ratios of change across connecting structures like interaction layers/types as a way to predict error probabilities & locations
    - example: code change ratio vs. config change ratio vs. user event/workflow change ratio
    - when the dimension of change exceeds dimension of abstraction to handle change, errors will occur

  - halting problem (given n rules, what is the maximum number of operations needed to solve a problem, like 'find the lowest integer having factors that fulfill a condition')

    - finding structures of 
        - recursion (operation sets that trigger themselves)
        - equivalence (operation sets that equal operation sets)
        - neutralization (operation sets that counteract effects of another operation set)
        - efficiency (operation sets that minimize required operation sets)
        - symmetry (operation sets that dont lose information)
      that generate 
       - repeating structures like cycles/waves
       - combination structures of these structures that compound the repetition of rule network traversals
      can help identify which rule sets will not halt (if the rule sets support a case that would encounter a barrier in the form of a neutralizing condition to prevent halting under any traversal)
    
    - some rule sets will never achieve information bc the change types they support cant produce it (information-neutral or lossy), implying structures of randomness will be supported by the rule network (equivalent probability of alternate paths)
    - structures of neutralization: opposites, infinities, extreme high distances, extreme base differences (anything that negates the progress of a previous operation toward an answer)
    - structures of recursion: (anything requiring more information to move toward output)
    - structures of repetition: (anything requiring more operations)
    - rule set distortions can be used to approximate busy beaver halt positions, given the positions of adjacent computations
    - halt condition: a reason to stop checking for examples/counterexamples bc a sufficient one was found
    - equivalent question: 
      - does the rule set move faster than the information-neutralizing capacity of the example numbers involved (is there a force injecting so much distance between examples that it can outrun the rule set under any circumstances)
    - related question: what combination of efficiency, randomness, symmetry, equivalence structures in a rule network can compute which information types minimally & maximally?
    - math is standardized relationships, where a number is a relative position compared to other relative positions
      - the patterns in changes of attributes across numbers can be computed
        - example pattern: 'increment one integer, relatively nearer to next prime than previous integer, exponentially higher number of factors, occupies position in fibonacci sequence, sum of a standard series'
        - where the steps in the pattern are changes to attributes, and the pattern steps can be used to predict value patterns, vertex numbers, as well as attribute dead zones/blind spots

  - add abstract keyword search support (find objects of an abstract type), like 'find all customers impacted by attack' will return results including all specific customer names in search result snippets
    - apply 'all' definition to return unique complete results
    - apply 'abstract' or 'specific' definition or identify an object type (customers) to list specific customer names

  - identify high-impact structures on an interface
    - causal loop: 
      - entities in a dependency loop where each supplies an input that the other needs (like a security product from a security product provider and a software resource product like a cloud server provider, where each product is not supplied by the other entity) offer an opportunity to take out both entities & their dependencies while conflating root cause & minimizing impact
    - meta cause: 
      - dependencies (like security/deployment tools of security provider) of the same type/level of dependencies for other entities (security provider product)
    - balance structures
      - a position with the most contradictions is the most balanced position
    - combination structures
      - a meta cause injected in a causal loop can cause cascading conflated outages where structure & source is difficult to determine
        - examples
          - disrupt deployment tool of a security product used for auth process
          - disrupt neutral abstract tool (update/deploy/networking) used by security provider
          - disrupt logging mechanism of a log search tool used by many companies for incident response
          - disrupt default trusted response (string returned from ip checking service that may be queried & accepted without validation)
          - disrupt trust root nodes like security providers & authorities
            - 'trust' being a conceptual definition of the concept of 'risk', and 'lack of input validation' being a structural definition
            - 'lack of required trust' having 'user risk-minimizing' structures like 'protecting/providing/cooperating with/lowering switching costs for alternative options' (no trustworthy provider requires exclusivity from demanders)
        - these structures can be used to identify the function nodes/positions/structures that would be highest-impact, to apply increased security in those function positions & their relevant structures (inputs/outputs)
    - high-impact functions
      - are permitted to access other high-impact functions

    - anomaly detection methods to identify differences have vulnerabilities in single-metric threshold structures that can capture one difference type
      - a threshold identifies aggregated resources crossing that threshold, but does not identify aggregations across different thresholds to build similar functionality from multiple sources
      - a combination structure of anomalies like an anomaly chain/network can escape detection using manipulation of multiple threshold-governed signals
      - example: monitoring just file modifications in isolation without monitoring file content modifications

    - malicious structures
      - have structures of variation like similarity ratio that follow patterns compared to legitimate variation structures
        - malicious structures will have structures of legitimacy (like a whitelist/blacklist) to mimic legitimate structures that have components to defend themselves against attack
          - however these structures of legitimacy used to signal similarity wont be implemented in the same way as legitimate components
          - legitimate components implement structures of legitimacy in ways like:
            - applying default config bc of budget constraints
            - not finishing configuration & making errors in configuration bc of budget constraints
          - malicious components implement structures of legitimacy in ways like:
            - applying config that is not enforced (has a whitelist file but doesnt import it anywhere)

  - examine structures of randomness
    - lack of information from:
      - position (cant access information)
      - adjacent information (cant derive information from adjacent information)
      - time (information was not generated yet or its generation is disincentivized or theres no structure that can contain/stabilize it)

  - identify 'relevance' mismatch in irrelevant components (interfaces like intent & structures like causal loop)
    - example: 
      - intent: when a default/required value is used, that may indicate the action was not intentional from the user position, and intent interface should not be used to capture variation in user changes
      - cause: when two events are often/always found occurring in a sequence, that doesnt necessarily indicate a cause
      - change: 
        - a static prediction function or data set contradicts the concept of 'generalizability' or 'robustness' which have the concept of 'change' as a dependency
      - meaning:
        - an 'isolated' function/data set (that does not have access to other functions/data sets as sources for an inference function) contradicts an integrated analysis of structures of meaning and structures allowing derivation of understanding

    - structures that dont match 'relevance' definition
      - these irrelevant structures contradict some component of the definition of the component, like where the default/required assumption doesnt offer/require a choice, which is an input to intent
    
    - to do: identify other important mismatches occurring in meaning/understanding and other fundamental attributes like similarity

  - document optimal filter & other structures (sequences, combinations)
    - filter sequences
      - "all combinations, then possible, then similar, then position" = find "missing components"
    - change type sequences
      - input: 'switch priorities' applies function 'find perspective with validation as lower priority' to generate output: 'reduce validation checks'

  - examing how replacing a function producing stressors (like hormones & byproducts) with an artificial solution (birth control) to reduce variation (in hormone supply) also reduces stressor & stressor-byproduct variation & imbalance (in hormone-related cell supply) by delegating function calls to artificial solution, reducing original function calls in the process

  - example of queries to find opportunities to position an intent like 'phishing attempt'

    - finding legitimate relationship structures on an interface, such as other relevant intent types:

      - prior intents like 'receving legitimate email triggering risk-aversion process involving a step containing a link click' to target intent of 'clicking link'
      - related intents like 'permuting assumption or variable like authentication status that would trigger a related process, in the form of sending email about related process with a step containing a link click that wasnt triggered like disabling account authentication'
      - required/important intents like 'maintaining account security' or 'avoiding risk' or 'minimizing risk' 
        ('if my account was hacked and someone disabled auth, I need to fix it right away')
      
    - finding rule enforcement gaps, like required priority-switching triggers, such as:

      - where priorities such as 'rule enforcement' are ranked lower than other priorities, like 'speed', such as when handling a high volume of emails
      - where intents are over-prioritized, intents like 'contradicting lies', which could trigger a priority switch
        ('no, I did not disable account authentication')

    - whats the query that could generate both examples of exploit opportunities to inject this malicious intent?
      - find causes (triggers, sequences) of change types (switching, change sequence) of core interface structures (relating/connecting functions, requirements, rule gaps, rule enforcement gaps)
    
    - whats the query that could generate the generative query?
      - find structures (causes) on a generative interface (cause) of generalized (apply pattern, core, or abstract interface) core structures (types) a high-variation interface (change) of core interface structures

  - add to definitions.json
    - meaning
      - structure:
        - relevance (to a position/intent)
          - importance
            - utility value
            - uniqueness
          - similarity
        - system fit
          - understanding

  - give examples of matching network structures & algorithmic traversal structures that are good at solving certain problem structures 

    - example of problem structure matching network architecture/algorithm:
      - function sets aggregated into a prediction function (one input set following one weight path through the network layers, representing one function set that could be the inputs to the prediction function), as a unit for comparing structures like combinations of function subsets/subcomponents/versions to fit the data
        - initialize with weights at a probable distorted position (like average + some wave frequency A & magnitude B to capture variation), then adjust with iterated network layer weights on the weight path toward a good approximation of the prediction function

    - problem structures
      - bounce between limits representing function versions, slowly correcting to similar line as regression line
      - bounce around a symmetry, finding distortion that matches data the best
      - combine common sub-function components or variables, slowly adjusting with common distortions to get to prediction function
      - find local points of slowing change (inflection points) given differences in change rates
      - find variables maximizing difference in difficult to determine (high similarity) cases for identification
      - aggregating isolated variables & other variable structures like generative/combination variables like nature does into a produced function
    
    - training an ai on these can match problem structure to solution architecture & algorithm structures
      - the network algorithm structure represents the solution automation workflow from problem format to solution format, implemented with a specific interface query
      - the network architecture structure represents the resources that can be traversed/combined (interfaces, definitions, functions, information, queries)

  - give example of how to select query among good alternatives (without priorities or other requirements/constraints) to solve a problem structure optimally:
    - applying structures of randomness, difference, and cause to generate structures of relevance
    - patterns of function sequences filling in gap between structures with known positions in a system
    - applying different problem formats
    - identifying sub-problems best solved on different interfaces & starting from a solution aggregation method to connect them 

  - give example tying solution automation workflows to specific queries & query metadata 
    - tie specific queries (content) to solution automation workflows (structure) that generate or apply them optimally
      - the solution automation workflows specifically connecting a problem to solution, and the queries connecting any interface objects

  - apply information organization methods as solution aggregation methods
    - solutions act as structures of organization/relevance in contrast to problem structures of randomness
    - information organizes itself according to various metrics like energy-sharing (efficiency) & energy ratios/stability (balance)
    - structures generating randomness can be used as a default data source for identifying problem causes
    
  - give example of how to identify a vertex interface like randomness out of all the interface structures like combinations & subsets
    - definition: equal probability distribution across outcomes
    - queries to identify the vertex interface as important/explanatory
      - change assumption of core objects (interface)
        - lack of a primary interface 
          - lack of cause, having a structural similarity with the problem space (appearance of lack of organization in the form of cause)
          - lack of the interface interface (relevance/organization)
          - lack of structure (equal distribution having minimal structure)
          - lack of information (randomness revealing minimal information)
      - apply a core structural concept's (similarity) insight function ('like attracts like', or 'equivalence can cause other equivalence'): 
        - equivalence of conflicting forces generating another type of equivalence (in outcomes)

  - make interface query output diagram

  - identify counterarguments: remove assumptions/parameters until it contradicts a required parameter of the statement to contradict

  - identify fake news: find attention-generating objects (default responses to incentives (hypocrisy/selfishness), emotional/belief-based statements, low-cost statements (virtue-signaling), stupidity/misunderstanding/repetition, obvious facts/lies/reductions/jokes, oversimplifications, falsehoods, unprovable statements, controversial statements, mixed types (statements of opinion as fact), irrelevant statements, distortion chains, nonsense)

  - identify fallacious arguments: arguments with at least one parameter in common with facts, or structures (logical fact-connection methods/priorities) of a good argument

  - identify ambiguous arguments: arguments with undefined/conflated terms, abstract terms, lack of clear references, applicability to multiple situations

  - give example of mapping an insight to math interface, and structures that can hold/generate the insight, as well as content that can describe the insight

    - example insight: 
      - gradient descent: moving in direction of steepest descent of slope
        - math version: moving toward highest negative slope
        - system version: incentives moving toward efficiency 
        - structural version: moving toward lowest-cost motion
        - information version: with an information constraint, find information relevant to adjacent optimal according to optimal definition
        - physics version: minimizing energy expenditure in the form of motion & calculation
        - physical version: a ball circling toward a drain

      - what structures can execute the following core operations for this insight
        - describe: increase of a parameter in the same direction as a function exerting force (move vertically lower, like gravity)
        - hold: a structure that can support various optimal points (like a set of peaks that stabilize to a certain amplitude range), and a similarity between a parameter increase & the function force direction
        - replace: a function exerting force in the same direction (vertically lower) or towards the optimal point (horizontally toward the center represented by the optimal point)
        - generate: a structure that can generate the supporting structure & either the function or the parameter increase

      - why would you do this calculation? to find:
        - a relevance structure in the form of patterns of coordinating differences across change types (moving horizontally toward a point and vertically to a point) with a priority (constraint)
        - a definition of optimal/efficiency/cost/limit/error
        - alternative objects to seek (valleys, centers created by similar change on both sides, slowing change speed, points where slope = 0 and y is less than current y) to solve optimization problem
        - alternative methods of finding optimal points: 
          - using patterns in another change type (multi-dimensional, converging) or other difference parameters (distance, sign, direction, dimension, slope, angle) to find optimal points
          - method to navigate an optimization topology by navigating a proxy topology, like an error topology with adjacence determining likely error types/values, a pattern topology, or a change topology
          - method to differentiate relevant objects by minimal parameters that can be used as a map to navigate the function to find optimal points
            - differentiate error, cost, and optimal by a parameter set that reduces calculations (like potential/change types of errors/costs/optimals)
              - change type of error is exponential reduction, in parallel with cost change type
              - optimal change (identifying new optimal points) increases marginally with parallel (positive) cost change 
              - optimal points in a function with change types (change speed changes, change speed change changes, change type change speed changes) follow patterns with change types (continue change type, stabilize at lower cost change type, stop change)
        - other structures/formats that can be used to calculate the original optimization solution (reducing dimensions, switching to progression/vector format) and pull relevant insights that may be more efficient at calculating the optimization (patterns of efficiencies/overlap/similarity/alignment/convergence)

  - link to stressor model
    - is stress being routed to brain from elsewhere in bio system bc it can handle this type better given its response to free radicals, which may be similar to other stressors routed to brain
    - can other forms of stress be converted to a similar format/structure as free radicals or other stressor types handled best in the brain?
    - what other stressor formats/structures/types are handled optimally in a particular system, and are those stressor routed there by some existing mechanism?
    - what is the relationship of free radicals to learning? (causes anxiety, creating demand for brain network organization & integration)
    https://medicalxpress.com/news/2020-12-free-radicals-good-brain-insights.html
    - CD38 benefiting recovery from stroke but feeding hostile cell types elsewhere through cooperation/connectivity, which is sub-optimal in regions prone to hostile cell types but useful in other places like between neurons: https://phys.org/news/2020-12-nad-nicotine-adenine-dinucleotide-super.html
      - can hostile cell types prioritize/protect CD38, leading to increased inflammation
    - lack of protective bacteria may allow substances to accrue in brain that interfere with organization/connection/cooperation/clearance activities, substances that are not positive stressors for the brain  https://medicalxpress.com/news/2020-12-gut-microbiome-disturbances-linked-major.html
      - can these be combined with anxiety-triggering stressors to increase stress handling in brain?

  - organize examples
    - label examples so they can be queried more structurally
    - query for logic in examples when implementing functions

    - structural query example diagram for GANs + image compression problem

  - generate default function list

  - add mapping for data sci use cases => tools

  - add example of how to generate the full set of unit definition routes of a concept
    - generate different structural routes using core structure, like how cost is a core structure of incentives, so generate incentive structural definition routes by permuting types of cost in the relevant variation format
    - give example of how to translate structural route to other interfaces

  - code generation example

    - abstraction levels including:
      - plain language translation: "for item in iterator, set val = item" => "for item in list, set val to item"
      - low abstraction
        - translate actual logic to one layer of abstraction (for item in list, set val to item => "get value from json data source")
      - medium abstraction
        - high-impact functions to examine (interacting with os, changing memory usage/buffer/queue interactions, etc)
        - translate actual keywords (for loop/equals/if) to core logic keywords (find/assign/filter/check)
      - high abstraction
        - business/application intents in user terms (change "filter for loop by if attribute condition" to "find user in group with most recent updates")
      - graphs for systems of interacting objects (queues, buffers, memory locations) on different layers (memory retention/caching/cleanup, location reliability, performance, data structures & other inputs)

  - nn structure generation example

    - default objects/functions/concepts in a neural net 
      - aggregation
      - filter
      - combine
      - compare (conflict problem type)

      - these functions are relevant to various problem-solving automation workflows, such as:
        - break a problem into sub-problems and aggregate solutions
        - start with core functions & apply distortions to build solution structure

      - neural nets can be built to implement these variants of solution automation workflows
        - they can vary on other parameters, like
          - structures to start from 
            - interaction layer 
            - causal structures
            - problem type structures
          - definitions
          - direction to move toward (intent, priority)

      - neural nets can be generated for a particular problem-solving intent using combinations of these objects with these variants

  - give example of basic structure-intent map with db key-val structure used to store nested structures
    - intent of a key-value store is for lookups of info with unique keys in a map
    - lookups of nested values would otherwise have to be stored in rdbms or existing nesting-supporting formats like json, given that a 'nested' structures implies an intent to store relationships to associated objects
    - key structure can store strings - path in nested structure can be converted into a string
      - nested structures can add delimiters & type tags to resolve ambiguities like unnamed/unordered lists
      - by adding organization through type tags, info in nested structures can be stored in a map, with the intent of preventing information loss

      - structure intents
        - map: information organized by position
        - key: a string to find information at a position
        - string: a sequence (like a path in a nested structure)
        - concatenate: combine into a set with different dimension values (value count, delimiter count, position)
        - concatenated string: preserve order of list (like a list of path steps in a nested structure)
        - delimiter: differentiate within a set concatenated into a string or within a list/set
        - nested value: information associated with other information by position
        - nested structure: structure organizing information with non-intersecting (unique) sequences of steps

      - you can see how you can query for objects with intents that would link input (like a json object) with output (info indexed in a db) formats, given the intents using standardized terms above

  - give example of deriving 'protein folding' as a key interface in the bio system, given the stability & interaction level with other systems

  - function to translate interface query logic into interface language (combination of core functions (find/build) & other core components)

  - de-duplicate logic
    - organize interface analysis logic definitions
      - organize functions in problem/interface definitions, before organizing functions in implementations/*
    - integrate problem_solving_matching.md
    - integrate find/apply/build/derive logic from system_analysis/ & maps/defs*.json
    - separate interface analysis logic into implementation/functions (functions dont need unique info)
    - add functions from workflows & analysis (to do list, questions answered, problems solved, interface definition & functions) as files in functions/ folder
      - organize into primary core functions & list sample parameters (like objects to identify for the identify function)

    - integrate rules from other diagrams not included in patent applications to relevant documents
        [0010] Example embodiments will be described and explained with additional specificity and detail through the use of the accompanying drawings. 
        [0011] FIG. 1. 'User Interface Module' illustrates a diagram of a user interface that can accept user input about a problem & program configuration. 
        [0012] Fig. 2. Interface Analysis Module 140 is a diagram of example components (such as functions & constants) of a program to automatically apply information formats to achieve an input intent. 
        [0013] Fig. 3. Machine learning system 120 is a diagram of an example wrapper component that would call a machine learning system to predict a variable. 
        [0014] Fig. 4. API finding/calling system 130 is a diagram of an example wrapper component that would call an API finding/calling system to retrieve data. 
        [0015] FIG. 5. 'Structure Application Function - Apply Function' illustrates applying a structure to another structure. 
        [0016] FIG. 6. 'Problem space visualization' illustrates an example visualization of a problem space. 
        [0017] FIG. 7. 'Network of related problems' illustrates an example of a network of related problems. 
        [0018] FIG. 8. 'Problem Types' illustrates a set of common problem types formatted as information or structural problems. 
        [0019] FIG. 9. 'Problem formats, with matching solution formats of problem formats' illustrates an example of various problem formats & solution formats that match them. 
        [0020] FIG. 10. 'Problem-solution structure-matching: apply a solution function to a structure containing the problem to find specific solution structures for that problem' illustrates an example of matching a problem with a solution. 
        [0021] FIG. 11. 'Finding alternate solution formats that fulfill different metrics' illustrates an example of selecting a solution format that fulfills a solution metric. 
        [0022] FIG. 12. 'Network of problem sub-problems, breaking a problem into components problems' illustrates an example of breaking a problem into a set of sub-problems, which once solved, can be aggregated with a solution-aggregation method as shown. 
        [0023] FIG. 13. 'Causal structure-matching' illustrates a method of matching causal structures to a variable set. 
        [0024] FIG. 14. 'Design Interface Query' illustrates a method of assembling input information into structural meaning relevant to the input intent, using a structure containing information formats. 
        [0025] FIG. 15. 'Concept definition network' illustrates a network of related concepts. 
        [0026] FIG. 16. 'Alternate definition routes' illustrates a set of definition routes for a concept. 
        [0027] FIG. 17. 'Match structure for a definition of a concept' illustrates matching a structure to a concept. 
        [0028] FIG. 18. 'Intent-matching' illustrates matching intent to structure & vice versa. 
        [0029] FIG. 19. 'Insight path application' illustrates insight path examples and an example of applying an insight path. 
        [0030] FIG. 20. 'Interface conversion & matching' illustrates an example of selecting an interface to traverse. 
        [0031] FIG. 21. 'Interface & traversal diagram' illustrates an example of a diagram indicating an example interface, & a diagram indicating which interfaces to traverse in what sequence (forming an interface query). 
        [0032] Fig. 22 is a diagram of a process that describes the general workflow for implementing interface analysis. 
        [0033] Fig. 23 is a diagram of an example usage of the system. 
        [0034] Fig. 24 is a diagram of an example environment in which systems and/or methods, described herein, may be implemented, including interface analysis module 220 in FIG. 22. 
        [0035] Fig. 25 is a diagram of example components of one or more devices of FIG. 22. 
        [0006] Figs. 1A - 1J contain diagrams of an overview of an example implementation 100 described herein. 
        [0007] Fig. 1A User Interaction Module 110 is a diagram of an example user interface implementation to gather input about a problem & program configuration for Solution Automation Module 140.
        [0008] Fig. 1B Solution Automation Module 140 is a diagram of example components (such as functions & constants) of a program to automatically find/derive/generate a solution for a problem, to implement the general execution workflow of Fig. 4. 
        [0009] Fig. 1C Machine learning system 120 is a diagram of an example wrapper component that would call a machine learning system to predict a variable. 
        [0010] Fig. 1D API finding/calling system 130 is a diagram of an example wrapper component that would call an API finding/calling system to retrieve data. 
        [0011] Fig. 1E Solution Output 150 is a diagram of an example output of the process in Fig. 4 that could be displayed & edited in the User Interaction Module 110. 
        [0012] Figs. 1F - 1I contain diagrams of an example problem-solving automation workflow (such as problem space structurization (formatted as filters/limits/functions/networks/vectors)) detailing a particular interface traversal format sequence that can be used to solve most problems. 
        [0013] Fig. 1F Finding matches between problem & interface components is a diagram of an example implementation of step 404 - 406 of the process of Fig. 4 (converting a problem to an interface, mapping between components of the problem & interface). 
        [0014] Fig. 1G Applying matching interface components to relevant problem system components is a diagram of an example implementation of step 407 of the process of Fig. 4 (applying matching mapped objects from the interface to the problem system). 
        [0015] Fig. 1H Applying solution metric structures to solution structures is a diagram of an example implementation of step 408 of the process of Fig. 4 (applying solution metric structures to solution structures). 
        [0016] Fig. 1I Example Object Definition Structures is a diagram of example structures forming the definition routes of an example system object on the structural interface. An example of a definition route is documented here: https://github.com/outdreamer/build-a-cure/blob/52c3461fdd3ff38284b63f8c2e71542f415d88d9/find_existing_solutions/system_analysis/maps/definition_routes.json 
        [0017] Fig. 1J is a diagram of an example usage of the system. 
        [0018] Fig. 2 is a diagram of an example environment in which systems and/or methods, described herein, may be implemented, including solution automation module 220 in FIG. 2 which refers to solution automation module 140 in FIG. 1. 
        [0019] Fig. 3 is a diagram of example components of one or more devices of FIG. 2. 
        [0020] Fig. 4 General Execution Workflow is an overview of an example process 400 for implementing problem-solving automation workflows in steps 402 - 410, from initial problem formatting to solution matching to solution application & analysis. 
          

  - using set theory in query operations:
    - edges as core organizing/formatting operations (find/apply) & interfaces (connecting/explanatory concepts/functions)
    https://en.wikipedia.org/wiki/Hypergraph


  - AI that identifies complexity requiring other structures to be added/embedded in analysis network
    - example: identifying a 'map' structure to store a set of definitions (like to contain a language/dependency graph), and a 'filter' structure to store a set of standards (like to standardize to that language)

  - create https temp server/cert for request sessions on sites that arent https already, after filtering content for immediate malware/attacks on temp server

    - invariant vs. symmetry

    - applying 'combination' structure to type patterns:
      https://www.technologyreview.com/2020/10/30/1011435/ai-fourier-neural-network-cracks-navier-stokes-and-partial-differential-equations/

    - energy stored in information/structures has stability physics, where information in a certain structure can support other information of different structures, including structures allowing variation in change/potential

    - config manager that allows specifying conditions/processes (check for approval from Artemis), data source (url or queries) & UI components/graphs (template or queries) to build apps/pipelines  automatically
    
    - migration/integration automation using app architecture/code/config search: searching other stack resources (application code, API, data store, resources, security & pipelines) in a repository of stack resources of existing or optimal applications, to test the original app test cases to see if a particular codebase/database/config/pipeline will work for the users' needs, without having to manually code a migration or integration to another stack (either migrating code, cloud, pipeline, data store, security tools, or all of the above), and using incremental tuning of the application code (mixing in code components, injecting dependencies, executing adjacent transforms, etc)
      - the primary work involved on the dev side would be ensuring the test cases covered all user needs
      - the migration/integration logic would involve search filters in the form of exit conditions that would skip to the next resource stack if a particularly important test doesnt pass, rather than trying to fix the resource stack that is clearly too different from user needs to be adjacently useful
      - it could also start from a standard set of application resource stacks in various stack combinations and add logic/config/schema until it fulfills the test cases
      - identifying probably successful transforms of code/config can be done with code queries if indexed by intent, or by translating code to the currently iterated resource stack given pre-defined mappings

    - ml explanations: embedded interface structures (causal structures, type paths, problem types, change types/bases), function subsets/alternate functions composing the prediction function

    - core operators in math space
      - structure
        - format (as a series, function, function set, coordinate set, vectors, matrix, aligned values, base, on dimensions, as an embedded parameter)
      - differentiate
      - set
        - include (add, increase, multiply, combine)
        - exclude (subtract, decrease, divide, filter)

      - focused information with values
        - when you inject information (value set) into a structure (dimension), what happens?
          - the limits & functions of the dimension, combined with other dimensions & rules of the space, are activated as causes of those value outputs
          - the intent of a value set combined with a format can be to highlight connections between these causes


    - structures of difference: chaining difference types (like randomness, core operations & definitions) across different component types like objects/variables are a quick way to identify new objects/systems to explain or fill rule gaps

    - identifying randomness vs. false illusion of randomness (temporary equivalence)

    - pattern matching/anomaly detection/noise reduction in finding relevant information eliminates information based on:
      - commonness/similarity to patterns (focus on common patterns)
      - similarity to other data (isolate anomalies)
      - reducing equivalence from randomness (isolate non-random processes that follow rules)

## examples

  - example: to identify false information across user requests:
    - example of applying intent interface: 
      - check with intent provider (site) if a request for an intent (request password) was just made, to validate messages
    - example of applying pattern interface: 
      - check if user access patterns (like 'navigate to site, then check email for site password reset') match the intent of a message

  - example of permuting assumption: "reports of power consumption have to be exact measurements" (platypus)
    - a temperature monitor sensitive to a hundredth of a degree might provide similar but non-specific power reporting for important/extreme usage patterns without revealing such specific information as that which could infer exact operations being done, bc the interval of temperature measurements allows for greater variation in calculations that could explain it

  - example of applying problem-structure interface: https://en.wikipedia.org/wiki/Anti-pattern
    - these are examples of contradiction/error types of the system-optimizing insight 'align relevant intents', which have the structural problem type 'misalignment' of the concept 'relevance':
      - local & global intents (local efficiency/fulfillment of local incentives/priorities, at the expense of global inefficiency/lack of fulfillment of global priorities/requirements/incentives, by allocating local solution side effects to global entities)
      - misaligning prioritization & intent (over-prioritize job duties like monitoring, to benefit the manager) that doesnt align with other intents (subordinate productivity) which benefit the company
      - imbalance/missing/disconnection from related objects (criticism & solution, solution & responsibility)
      - mis-aligning functionality (learning/potential) with requirement (repeating task)
      - mis-aligning intent of a product (making customer independent) with dependency structures (requires customer to use it beyond its value to them)

  - finish dilemma problem type example formats
  
  - query examples for use cases like:
    - lack of information stored (match problem of type 'information lack' with interface query 'check pattern interface for similar patterns')
    - query problem breakdown & integration diagram
    - calculating various different problem breakdown strategies first before executing normal query-building logic for each
  
  - give interface math examples, like standardization of all distinct components into their own interfaces, rather than within a system context
      - rather than framing the behavior of objects in a system, you can:
        - remove the assumption of the system limits forcing interactions
        - frame each object on its own interface (containing all its possible forms, variables, attributes, generators, cooperative contexts, etc)
        - compute the interactions of those interfaces
  
  - give example of generating problem types by applying structure
    - for instance, a common problem type is a mismatch/imbalance
      - by applying the 'mismatch' to the cost/benefit relationship, you get an 'inefficiency' problem type, which can be defined as a mismatch/imbalance between the cost & benefit, favoring the cost side (the negative object out of (cost, benefit), associated with problems)
  
  - add examples of system/object/rule/type change patterns
  
  - include example workflows with example problems
    - include example of how to generate other workflows (different starting/ending points & trajectories)


## diagram
  
    - add diagram for intent-matching
    - add structures to diagram: interface overflow (to sub-interfaces), interface foundation

    - diagram for workflow 1: 
      - function to determine relevance filter ('functions', 'required') from a problem_step ('find incentives') for a problem definition, to modify problem_steps with extra functions/attributes ('change_position') to be more specific to the problem definition ('find_incentives_to_change_position') for problem_steps involving 'incentives', so you know to use the function_name to modify the problem step if it's between the type 'functions' and the object searched for 'incentives'
    - add conceptual math interface query diagram
      - use lattice multiplication as standard example, other than core operations (add/multiply mapped to language, concepts like irreversibility/asymmetry mapped to math)
    - interface conversion, matching, starting point selection (applying structure, checking if relevant information is found)
    - diagram to document sub-functions of core functions with distortions
    - make diagram for dimension links higher than 3d that are depictable in the same network space
      - should show variables that impact other variables, the change rates of these relationships
      - overall impact should be calculatable from these relationships
      - should show similar movements for correlated variables
      - should show skippable/derivable variables (variables that can be resolved later than they normally are)
      - should show meta forces for overall trends in change rules (direction of combined variable forces)
      - should show limits of measurability & threshold metrics
    - structurize (apply structure to) definitions of objects specific to interfaces
      - example: info asymmetry is associated with an info loss in a particular direction between info types/formats, rather than just an info imbalance or mismatch
      - diagrams for specific concepts, core functions, concept operations (combine, collide, connect, merge, apply), ethical shapes
        - variable accretion patterns (how an object becomes influenced by a new variable, complex system interaction patterns, etc)
        - make diagram of potential matrix to display the concept
          - map parameter sets to potential matrix shapes 
        - finish diagrams for cause (shapes & ambiguity), concept (evolution of concepts, networks, distortion functions)
        - diagram for argument
      - make a system layer diagram for each interface to allow specification of core interfaces & other interface layers (interface interface)
        - make a system layer diagram for structures to include layers of structures 
          (beyond core structures like curves, to include n-degree structures like a wave, as well as semantic output structures like a key, crossing the layer that generates info structures like an insight, a probability, etc)

# content/config

    - import insight history data to identify insight paths (info insight paths like 'lie => joke => distortion => insight', system insight paths like 'three core functions + combine function with this definition + n distortions to nearest hub')
    - define default & core objects necessary for system to function (out of the box, rather than minimal config necessary to derive other system components & assemble)
      - add default functions to solve common problem types
      - alternate utility function implementations have variation potential in the exact operations used to achieve the function intents, but there are requirements in which definitions these functions use because they are inherent to the system. For example, the embodiment may use a specific definition of an attribute (standardized to a set of filters) in order to build the attribute-identification function using a set of filters - but the general attribute definition is still partially determined in its initial version by requirements specified in the documentation, such as a set of core attribute types (input, output, function parameter, abstract, descriptive, identifying, differentiating, variable, constant), the definition of a function, and the definition of conversion functions between standard formats.
    - document time structures (concave time explaining compounding similarities up to a point of maximum concavity, a structure that can separate from the other space-times)
    - systematize your definitions of info objects, to include analysis that produces relationships of core objects like opposites to their relevant forms (anti-symmetry) in addition to permuted object states (asymmetry), such as an anti-strategy, anti-information, anti-pattern
      - organize certainty (info) vs. uncertainty objects (potential, risk, probability)
      - make doc to store insight paths, counterintuitive functions, hidden costs, counterexamples, phase shift triggers
      - add technicality, synchronization, bias, counterintuition, & certainty objects leading to inevitable collisions
        - the collision of compounding forces producing a phase shift
        - lack of attention in one driver and false panic in a second driver leading to a car crash given the bases where their processes originate
      - define alignment on interfaces (compounding, coordinating, parallel, similar, etc)
      - start with these info object transforms that filter the most info: opposite, invalidating, symmetric, core, aligning, boundary-breaking, phase shift activating, structure stabilizing, constant changing, converging
      - add core info objects (core strategies, core assumptions) so you can make a network of graphs for a system
    - concept analysis:
      - how new concepts (gaps in network rules) evolve once structure is applied to prior concepts 
    - interface analysis:
      - limitations of interfaces & how to derive them
      - how rules develop on stability & how foundations are connected & destroyed
      - explainability as a space limited by derivable attributes from data set & cross-system similarity
      - vertex definition & give examples (as an intersection/combination of interface variables, such as determining/description(compressing)/generative/causative/derivation variables), around which change develops
    - change analysis:
      - generated object change types
        - constant to variable
        - variable to removal of assumption in variable type/data type
    
    - research implementing your solution type (constructing structures (made of boundary/filter/resource sets) to produce substances like antibodies, using bio system stressors)
    
    - merge definitions into docs/tasks/implementation/constants/definitions.json

    - clarify/resolve terms that can be conflated: 
      - shape/structure
      - rule/test/metric/limit/threshold/boundary/state change/phase shift
      - intent/priority/motivation/incentive
      - method/function/rule/pattern (pattern is a sequence of specific objects)
      - path/route/trajectory/traversal/order/list/sequence
      - object/entity/item/component
      - type/class/category/group/subset
      - closed/isolated/independence/unique/orthogonal
      - model/perspective/filter
      - standard/interface/index/symmetry
      - dimension/variable/axis
      - space/system/context
      - perspective/filter/standard/index & relationship to variables/operations on the interface
      - filter vs. rule is a similar question to attribute vs. rule - sometimes one format is better based on the info you have, sometimes its worth it to transform the format
        - interface network: a set of standardizing filters applicable to format information in way that it can be analyzed with interface-specific logic, 
        - a query of the interface network may also be a problem-solving automation workflow, if problems can be solved with the format sequence indicated by the interface traversal

        -  For a prediction function problem, the solution space is the range of likely prediction functions. 
        - The problem space is the route between independent variables and the dependent variable on a network - it can also be framed as the route between common prediction function terms for a data set like the input data set, and the prediction function. The original problem structure is also depicted as a subset of this problem space visualization.
        - The solution function can be a route on the problem space if the problem space is formatted as a network, for example.
        
        - interface: a useful standard for comparison consisting of the filtering object's definition routes, conversion function, core functions, objects, & attributes, and related objects like patterns & metadata specific to the interface. Abstract interfaces include cause, concept, structure, etc, whereas specific interfaces are other foundations where change develops in a clearly defined range that can be found in specific systems. The traversal of an interface implies finding a map between objects, functions, & attributes inherent to that interface to the problem objects, functions, & attributes. The application of an interface is an operation in an interface combination, mapping, injection, or other operation. 
        - function: a set of inputs, a sequential list of rules or rule lists (logic tree) applied to the input set, an output set created by changes to the input set executed by the sequential rule list, optionally including side effects from execution. A function may be formatted in a different way, such as a list of attributes, filters, or a network. The function definition includes: 
            - attributes: 
                - alignment: enforced/optional, core, required, emergent/output (built from core functions, with or without associated intent) 
                - interaction: cooperative/conflicting 
                - intent: generative, filtering, grouping, organization/delegation/ distribution/matching/grouping/filtering, classification, differentiation/ transformation 
                - scope: use case, context, range, host system 
                - related objects (like host spaces/systems & object positions in those) 
                - types: 
                    - core functions 
                    - meta (rule-modification/generation rules) 
                    - attribute rules (state, scope) 
                    - interaction rules (competition, binding, combination, sharing, collaboration, intersection, conflict resolution, trade rules) 
                    - assessment rules (metric, difference, definition, validation) 
                    - processing rules 
                    - change rules (update, distortion, maintenance, adjacency, conversion) 
                    - filtering rules (find, identify, define, alternate, organize, learn) - matching rules (fitting a structure, filling a structures) 
                    - application rules (inject, embed, apply) 
                    - derivation rules (structure, navigate, abstract) 
                    - decision rules (prioritize, select, compare) 
                    - formatting rules (standardize, isolate, cluster) 
                    - destruction rules (replace, invalidate, neutralize, remove, merge, de- duplicate) 
                    - government rules (monitor, correct, enforce, maintain, stabilize) 
                    - system rules (incentives, variance handling, optimization) 
                    - interface rules (change, intent, type, pattern, concept) 
                    - info rules (problem, strategy, insight, game, perspective) 
                    - variance (injection, leaks, combination, replacement, causal direction, uncertainty, risk, potential, probability, prediction) rules 
                    - information handling (storage, versioning, replacement, merging, monitoring, indexing, communication, interpretation, processing) 
                    - solution rules (variance/stressor/error detection, tracing, identification & handler) 
                    - structure rules (gap, boundary, system, limit, hub, object, link, network, filter)     
        - intent: any of an abstract goal with direction, a reason to use something, or an output such as the intended result or an unintended side effect, which can be an abstract priority like fairness, a concrete goal, and can have a starting & ending position. 
        - game: a set of intents/alternatives/limits/incentives/exploits/rules/risk & a definition of distance from intent fulfillment (position), usually resulting in the resolution of a clearly optimal route. The game definition includes: 
            - a game is a type of system & a mixed set, which can exist as a component of a system 
            - games can have many different structures like: 
                - a directed graph with a vector set representing possible agent intents/ functions/resources 
                - a system of nodes & links where agents need function input resources to traverse 
                - a decision tree where certain tree info becomes accessible only at certain nodes (adding uncertainty/risk) 
                - a set of trade options between nodes with different info change/update rules in a system to optimize a resource/trade/market metric 
        - concept: set of unique objects remaining once objects from other spaces have their context & contradictory attributes removed. For example: power is the object left when objects implementing it: resources => energy => input => potential) have their context removed, navigating up the abstraction stack from: 
            - the info layer (resources & energy), removing their contextual attributes/rules - to the abstract structural layer (input) 
            - to the abstract layer (potential, which is a related concept of power) 
            - so that the final object is defined in terms of other abstract objects on the top layer 
        - problem: may include any context or condition that causes a negative position or state determined by a metric for an agent in a system. The problem definition includes problem types like dependencies, leaks (variance, resource/info),  injection (assumptions/variance/control/randomness), mismatches, conflicts, imbalances, inefficiencies, incorrect metric, misidentification, gaps, limits, side effects: whether it's a closed system or leaks variance (function side effect example: before execution: pre-computing, during: memory access/overflow, after: process re-starting), specific problems like an enforcement gap (should have enforced rule but did not), an unintended use (involves integrated third party tech not under review), a malicious alternative route to get same output, a legitimate/alternative route to get malicious output. 
        - problem space: context relevant to a problem; the containing system(s) of a problem that may include related problems 
        - solution: may include any combination of events, methods, or steps that reduces the negative position or state for the specified agent. The solution definition includes solution types: 
            - solution-metadata solution: evaluating & comparing solution metadata for solution selection 
            - problem-metadata solution: evaluating problem metadata to evaluate metrics like problem-solving postponement 
            - generative solution: solution that generates solutions 
            - solution framework: provides starting point & structures for solutions to be built in/with 
            - problem decomposer: solution that reduces a problem's root causative (as opposed to just varying) parameters 
            - solution automator: solution that automates solutions of a type 
            - interim solution: clearly suboptimal solution while optimal alternative is built 
            - solution query constructor: solution that builds new solutions out of known solution types (existing structural solutions or core functions) 
            - structure-finding solution: solution that assigns a structure to information 
            - structure-fitting solution: solution that matches the gaps/limits in a problem structure to neutralize them 
        - solution space: set of possible solutions in a problem space, which may be reduced by applying interface traversals like solution space-reducing insight paths 
        - network: standard network graph containing nodes (sometimes called vertices) & linking functions (sometimes called edges), with or without node attributes, function relationship determining function shape, and direction as an indicator of intent or another metric. 

        - component: functions/attributes/types/objects/systems 
        - input information: can refer to original information input to the initial interface traversal, or traversal output information that has been converted, enhanced, formatted, or otherwise altered in a prior interface traversal, stored as a possible version of the original input information, and sent as input to another interface traversal 
        - interface: 
        - function: a set of inputs, a sequential list of rules or rule lists (logic tree) applied to the input set, an output set created by changes to the input set executed by the sequential rule list, optionally including side effects from execution. A function may be formatted in a different way, such as a list of attributes, filters, or a network. 
        - intent: any of an abstract goal with direction, a reason to use something, or an output such as the intended result or an unintended side effect, which can be an abstract priority like fairness, a concrete goal, and can have a starting & ending position. 
        - concept: set of unique objects remaining once objects from other spaces have their context & contradictory attributes removed.  
        - network: standard network graph containing nodes (sometimes called vertices) & linking functions (sometimes called edges), with or without node attributes, function relationship determining function shape, and direction as an indicator of intent or another metric.  

       - info conceptual relationships:
          priority = direction
          observation = insight = function = result = relationship
          conclusion = ordered_list(observations) + guess = coefficients + bias
          strategy = ordered_list(insights)
          strategy = insight + context
          problem = (combination of intents having different priorities) or (an resource distribution imbalance)
          intent = strategy + priority
          solution = (combination of strategies operating on variables with insight functions that reduce dimensions of problem (function-combination) or (resource-imbalance))
          type = combination(attributes)
          intents = function outputs, including unintended/emergent/unforeseen side effects (target/avoid)
          roles = functions
          relationships = treatments, intents, functions, insights, strategies, mechanisms, patterns, systems
          components = compounds, symptoms, treatments, metrics, conditions, stressors, types, variables

    - update links

    - integrate archive_notes/finder_info/functions
      Terms:
      - objects: a data set, function set, attribute set, class definition, type hierarchy
      - attribute value: value held by the attribute like True/False
      - attribute property: conceptual metadata property of the attribute like unique, identifier, static, etc
      - decisions:
        - choosing to execute one section of code over another; 
        - for example a conditional statement, design patterns, emergent usage/behavior 
          of user/system, bugs, assumptions, & possible input values are decisions since
          they may result in calling different code
      - relationship types: sub-type, causal factor, cooperating equal, different version
      - strategy: rule used to make decisions, possibly for a particular context
      - solution: strategy implemented for a particular context & problem type

      Abstract functions to code:
      1. identify an attribute of an object (lookup definition of attribute, create logical tests based on definition)
      2. identify & list all attributes of an object (database table fields)
      3. identify & list all rules related to an object (entries in 'functions' database field)
      4. determine if an attribute is new or fits into an existing attribute & whether its an ancestor or descendant of other attributes
      5. add an attribute to a list of attributes of an object (add column to table)
      6. identify all possible values of an attribute (alphanumeric, numbers, a value from a list)
      7. identify all rules defining the list of possible values of an attribute (max length, string data type, contains limited characters)
      8. identify all possible properties of an attribute (static/regularly changed, required, unique, identifier, causal, determines other attributes)
      9. identify attribute/rule/type/object relationship rules (attribute A is used to calculate how attribute B should be updated or deleted)
      10. identify rank/priority of attributes used to make decisions like classification in entity group, identification of unique entity
      11. classify a field as a particular type (by category or data format or other identifying or deciding attribute having multiple possible values)
      12. build a class definition 
        - retrieve any known rules describing the object's interactions
        - build a list of probable attributes which could be inherited from type ancestors or shared with other objects interacted with in rules
        - retrieve the type hierarchy position based on attribute/rule similarity to ancestors/descendants
        - filter possible attributes by which attributes can be used to identify it, which will be tagged with the 'required' property
          - identifying attributes are those that maximize variance
        - retrieve the values for these attributes required to qualify as an instance of the class
        - assemble attribute-identification functions for each attribute if not already in database table 'functions'
        - derive any additional interaction rules to describe interactions with other objects (if interaction data is available)
      13. convert data from one format to another
        csv/graph to database, csv to graph/functions, functions to patterns/objects, log to csv/database
      14. identify data relevant to the same object
      15. prioritize which version takes precedence over other versions (updated more recently, better design, etc)
      16. determine intent (of data, function, design, convention, protocol, decision, change)
      17. identify a change that should be entered into the 'functions' table as:
        - a 'conversion' function type, which converts from one usable format to another
        - a granular 'operation' function type doing a single operation on an input
      18. identify a pattern 
        to store in the 'functions' table as a 'pattern' function type
      19. identify which operation or combination of operations can convert one object into another
        to know which linking changes to look for when trying to connect two objects
      20. derive a relationship using list of possible operation sets that convert an object into another or explain their interaction rules
        - identify if one object is a sub-type, causal factor, cooperating equal, different version, etc of the other object
      21. identify if a relationship fits into an existing network or if it contradicts a relationship in the network
      22.identify if a strategy is a good fit to compress a problem & addresses its causal metrics without causing bigger problems
      23. compare two input objects & return a list of similarities & differences,
         as well as possible inferred similarities based on network position with probability,
         and a list of ordered functions to convert one object into the other
         - raw % difference between attribute values & attribute properties
         - weight of attribute value differences based on attribute priority
         - create attribute-rule network graph for each object & calculate raw degree of difference
         - identify equivalent attributes & weight degree of difference between them & their corresponding relationships across graphs
         - check equivalence of composite scores
      24. identify minimum information needed to make a decision (identify required inputs to make the right decision 100% of the time)
      25. identify operations to attain minimum required information (generate required inputs for decision)
      26. optimize code (spot inefficiencies in code & fix them automatically, like redundant conditions)
      27. identify field usage/query requirements in UI, request data, & code base
        ex: 'code commonly queries by name field so create a separate index for that'
