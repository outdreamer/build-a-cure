  - fix indexing 'NNP NN NNS1 of JJ JJ JJ2' or postpone to pattern evaluation time
  - fix missing alts
      pattern_index::verb_phrase::plays a |VB NN| role::a NN role
  - fix one-letter alts
      pattern_index::phrase_identifier::ALL_N DPC ALL_N |VBG VBD|::N D N V
  - generalize alt logic to use embedded pair finding
  - add formatting to allow multiple items as keys in json and maintain order for interface network paths

  - fix supported stem assignment (endings like 'is': {'functions a', 'acts a', 'plays a', 'operates a', 'works a'})
  - fix charge function ('edit' is assigned positive score)

  - add core clause patterns 
  - fix pattern matching functions
  - finish pos, clause, modifiers code from find implementation
  - finish network creation function
  - strategy/insight graph
  - add a standard system diagram with radiating layer diagram
  - add other causal structures

  - analyzing just by change rate makes it less likely to spot other patterns like overlap/intersection of patterns

  - add diagram for question derivation for service list

    - deriving the questions customers will ask for a set of services

      - which processes are complicated or not optimized (need to be in person for certain transactions that people would rather do online)
      - which processes involve changing information (account balance, transaction approval)
      - which processes are likely to have errors (auth)
      - which processes people will likely be interested in using the most

    - what percent of changes are just from finding efficiencies, using those as a foundation for common distortion types (random change, directed change, connecting change, etc)

    - what system of core objects/functions/attributes generate a space where:
      - circles & squares are fundamental or standard objects
      - there is a continuous spectrum of values (real numbers) around which alternate number types rotate (complex numbers, etc)
      - comparing change generated by two variables (one independent value function determining the dependent value) has patterns of measurement potential
      - isolating by attributes (like isolating direction & scale to transform to a vector space) or framing information in different structures (sets, matrixes, sequences) allows patterns that are calculatable (implying the framing filter is determining, so matrix attributes can be determined by its definition)

    - what objects describe lack of information like ambiguities or lost information, other than randomness (difficult to identify randomness), variance (lack of patterns), and infinities (lack of information being difficulty of computing the sequence except in terms of other infinities if it doesnt converge, or lack of guarantees that the sequence can be maintained/stabilized to continue)

  - insight path to find out that the error is the goal in a curiosity algorithm, where the primary intent is 'maximize learning', defined by 'maximum number of new rules added to rule set'
    - curiosity definition is 'finding new things and how they work'
    - 'finding out how they work' can be reduced to 'derive' function
    - a related term to 'derive' is 'learn'
    - example of learning in an agent space occurs when 'new information doesnt match existing information'
    - definition of error is 'when measured information doesnt match predicted information'
    - 'new information not matching existing information' can be classified as an error, if 'new information' is replaced by 'measured information' and 'existing information' replaces 'predicted information' (predicted by existing rule sets)
    - so 'maximized error' is the goal as a proxy for 'maximized learning'

  - other routes to automate solving the problem (of 'which objects/functions/attributes should be maximized in order to maximize learning')
    - an insight path that derives that differences/mismatches/imbalances/asymmetries are associated with learning (rather than just errors) & maximizes those
    - an insight path that derives the full set of likely combinations in a space (like the full set of species combinations) and aims at the most different combination to maximize learning

  - the above is a specific insight route composed of insights - generalizable to the insight path:
    - lookup definition of algorithm type (curiosity), given that the algorithm type includes associated intents
    - decrypt definition to core functions/objects/attributes
    - find related terms to core function terms that are relevant to the problem space (learning is a relevant term to machine learning algorithms that automate finding/discovering/predicting) in order to take advantage of related term definitions as a method of finding objects/functions to automate the solution, given that related terms provide alternate routes/interpretations of a process
    - translate the related term to the problem space (make it relevant to agents & information)
    - find related terms that match the relevant related term definition (definition of error, definition of surprise, definition of change)
    - classify related term (learn) as the most similar relevant related term (error)
    - replace term in target intent with relevant related term (target of a curiosity algorithm is to maximize learning/error)

  - now youve described core methods to decrypt changes within systems, high-level tasks that are next (after building core functions like attribute identification function)
    - mapping function to map problems to structures
    - solution decomposition function
    - solution aggregation function

  - after identification functions

    - import rules for selecting interfaces to solve a problem on

      Function helped find unused functions
      Intent helped predict system priorities & find exploit opportunities
      System helped find efficiencies
      Pattern helped find insight paths/similarities

    - once you build function/attribute identification function
      - import insight history data to identify insight paths 
        - info insight paths like 'lie => joke => distortion => insight'
        - system insight paths like 'three core functions + combine function with this definition + n distortions to nearest hub'

  - extra tasks

    - add precomputing if a sub-pattern was already computed:
               'ALL_N ALL_N of ALL_N ALL_N'
         'ALL_N ALL_N ALL_N of ALL_N ALL_N ALL_N'


  - abstract functions

      - derive combinations & make sure you have full function coverage of all important combinations

          operations = ['find', 'get', 'update', 'apply', 'build', 'combine', 'connect', 'convert', 'balance', 'map', 'match', 'fit', 'filter', 'derive']
          objects = ['strategies', 'questions', 'incentives', 'efficiencies', 'metadata', 'definitions']
          structures = ['paths', 'limits', 'boundaries', 'bonds', 'gaps', 'layers']
          system_objects = ['attributes', 'objects', 'systems', 'sub_systems', 'types', 'functions']

        - check codebase function index for combinations
        - check that you have sample data in json for each combination

      - attribute/object/function match functions
      - specific interface identification function
      - standardization network-framing function to describe a system as a network (the standard structure) & position each object, identifying connecting functions
      - system analysis function (identify boundaries, gaps, limits, layers, incentives/intents/questions, & other system objects)
      - isolation function, representating function/attribute changes independent of system context with respect to position or time (snapshot/state or subset)
      - function to define (isolate an object/concept/function for identification, identify definition routes)


  - give example of each type of problem-solving workflows

    - workflow 1:

      - finish function to determine relevance filter ('functions', 'required') from a problem_step ('find incentives') for a problem definition, to modify problem_steps with extra functions/attributes ('change_position') to be more specific to the problem definition ('find_incentives_to_change_position') for problem_steps involving 'incentives', so you know to use the function_name to modify the problem step if it's between the type 'functions' and the object searched for 'incentives'

      - finish function to get all codebase functions & store them in a dict with their type, context/usage, and intents, just like functions are stored in the problem_metadata.json example for workflow 1
      - finish common sense check
      - finish defining objects in object_schema.json
      - finish organizing functions.json by type, with mapping between general intent functions like 'find' to specific info-relevant terms like 'get'
      - add common phrase check & filter problem steps by repeated combinations with common phrase check
      - finish get_type function to map info to structure using the new functions.json organization
      - finish apply_solution to problem_definition using problem_steps
        - involves building a function to evenly distribute objects (like information/types), given problem positions/agents/objects
      
  - types can be represented as directions (going farther from origin goes further up type stack, where similar types are adjacent)

  - need to fill in content:
    - finish intent/change type calculation for a system intent
    - selecting optimal combination interfaces to start from when solving problems 
      (how many degrees away from core functions, specific layers or sub-systems, what position on causal structures)
    - key questions to filter attention/info-gathering/solution
    - key functions to solve common problem types
    - development of key decision metrics (bias towards more measurable/different metrics rather than the right metric)
    - trajectory between core & important objects
      - example of choosing inefficiencies/exploit combinations in a system
    - research implementing your solution type (constructing structures (made of boundary/filter/resource sets) to produce substances like antibodies, using bio system stressors)
    - emergent combinations of core functions (include derivation of invalidating contexts for core functions)

  - change phases for causal analysis (interim, changing, diverging, standard, efficient state, constant, interacting, converging, on the verge of obsolescence, outlier, etc)
    - superficial cause, alternate cause in the case of a function, addressing input/output causes
  - framing on interfaces, decomposing causation, then identifying parameters of problem on layer & matching solution
  - independence (closed trade loops) as time storage
  - vertex as a pivot point for an interface



- notes

    - if something can generate a change predictably/consistently, it's a change supply - otherwise it's a change request, so output as well as causal position relative to the output is important when determining category
      - time may be a variance gap (a space where change is possible) to resolve a question/problem set - so not resolving it can preserve time, unless resolving it will allow for more potential or moving on to other variance gaps
