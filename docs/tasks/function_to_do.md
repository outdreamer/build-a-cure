  - fix indexing 'NNP NN NNS1 of JJ JJ JJ2' or postpone to pattern evaluation time
  - fix missing alts
      pattern_index::verb_phrase::plays a |VB NN| role::a NN role
  - fix one-letter alts
      pattern_index::phrase_identifier::ALL_N DPC ALL_N |VBG VBD|::N D N V
  - generalize alt logic to use embedded pair finding
  - add formatting to allow multiple items as keys in json and maintain order for interface network paths

  - fix supported stem assignment (endings like 'is': {'functions a', 'acts a', 'plays a', 'operates a', 'works a'})
  - fix charge function ('edit' is assigned positive score)

  - add core clause patterns 
  - fix pattern matching functions
  - finish pos, clause, modifiers code from find implementation
  - finish network creation function
  - strategy/insight graph
  - add a standard system diagram with radiating layer diagram
  - add other causal structures

  - if the point of the universe is not to find the initial filters but to prevent that information from being discovered, that could keep open options for other change sources

  - analyzing just by change rate makes it less likely to spot other patterns like overlap/intersection of patterns

  - add diagram for question derivation for service list

    - deriving the questions customers will ask for a set of services

      - which processes are complicated or not optimized (need to be in person for certain transactions that people would rather do online)
      - which processes involve changing information (account balance, transaction approval)
      - which processes are likely to have errors (auth)
      - which processes people will likely be interested in using the most

    - what percent of changes are just from finding efficiencies, using those as a foundation for common distortion types (random change, directed change, connecting change, etc)

    - what system of core objects/functions/attributes generate a space where:
      - circles & squares are fundamental or standard objects
      - there is a continuous spectrum of values (real numbers) around which alternate number types rotate (complex numbers, etc)
      - comparing change generated by two variables (one independent value function determining the dependent value) has patterns of measurement potential
      - isolating by attributes (like isolating direction & scale to transform to a vector space) or framing information in different structures (sets, matrixes, sequences) allows patterns that are calculatable (implying the framing filter is determining, so matrix attributes can be determined by its definition)

    - what objects describe lack of information like ambiguities or lost information, other than randomness (difficult to identify randomness), variance (lack of patterns), and infinities (lack of information being difficulty of computing the sequence except in terms of other infinities if it doesnt converge, or lack of guarantees that the sequence can be maintained/stabilized to continue)


  - now youve described core methods to decrypt changes within systems, high-level tasks that are next (after building core functions like attribute identification function)
    - mapping function to map problems to structures
    - solution decomposition function
    - solution aggregation function

  - identify attribute

    - attributes can be reduced to 'position', implemented as a:

      - relationship type (relative difference/importance)
      - structure type (shape)
      - change type (generators of difference)

    - the structural network can frame these position differences to capture all attributes

  - identify function

    - a function can be reduced to a 'change unit'

  - identify object

    - an object has attributes/functions and is not itself either of those (for standard definition of object, even though both attributes/functions can be framed as objects)

  - after identification functions

    - import rules for selecting interfaces to solve a problem on

      Function helped find unused functions
      Intent helped predict system priorities & find exploit opportunities
      System helped find efficiencies
      Pattern helped find insight paths/similarities

    - once you build function/attribute identification function
      - import insight history data to identify insight paths 
        - info insight paths like 'lie => joke => distortion => insight'
        - system insight paths like 'three core functions + combine function with this definition + n distortions to nearest hub'

  - theres an inherent structural mismatch between some algorithms (decision tree, neural net) and some problem types (prediction) given the intent & abstraction layer 

    - example: 

      - some algorithms are too specific or have a structural mismatch (decision tree has structural split, specify & direction intents) with the problem type (predicting a set of variables that is about to change)

      - the decision tree can be hacked with various edge case, phase shift & boundary manipulations

        - if two variables on different layers are about to converge, they should have been on the same layer or in the opposite causal direction or treated as one variable - the model will be increasingly wrong until it's updated or until these ambiguities and likely relationships are accounted for in the design

        - the reason algorithms can be hacked is bc of the structural mismatch between the algorithm and the problem type

      - the intents resulting from the decision tree's layers, direction, and thresholds can only contain so much variation in the data 

      - generated varied data with permutations of data objects (loops, sets, alternates) can be used to make the tree more robust to adjacent/likely changes

  - algorithms should produce a set of solutions (an obvious/simple answer, a pattern-compliant answer, a common answer, a robust answer)

    - how could you build an algorithm that wouldnt overidentify a race as being a potential criminal?

      - query maps & causal shapes:
        - query for data on related word sentiment (if theres a negative association with a word related to that race)
        - query for data on intent ('identifying potential criminals' is the intent of the training process, which needs to be an input to the algorithm)
          - why would identifying an individual by a related attribute to a negative related term be useful for the 'identify potential criminal' intent?
          - if the intent is to 'identify potential criminals', which is a high-stakes intent, the algorithm should identify that a causal loop would be dangerous to treat as an input, given that a causal loop (like mistreatment or persecution of minorities leading to poverty which leads to crime) can hide original inputs (root cause being mistreatment)

      - alternatively, it could use inference:
        - 'if the answer is obvious, it must not be true bc otherwise I wouldnt have been asked to do this task'

      - or hard-code insights like above to be consulted if a variable is mistakenly identified as significant

  - rather than using data & the training process as an indicator of consensus, they can use patterns as an indicator of consensus

  - algorithm based on problematic adaptive systems like cancer bc theyre learning faster than the host system

  - extra tasks

    - add precomputing if a sub-pattern was already computed:
               'ALL_N ALL_N of ALL_N ALL_N'
         'ALL_N ALL_N ALL_N of ALL_N ALL_N ALL_N'

  - causal shapes integrated with networks (patterns of aggregation matching causal shapes like trees & circuits)

    - integrating system analysis with networks
      https://twitter.com/remixerator/status/1150578597339340805
      https://twitter.com/remixerator/status/1205724743741014018

    - system of causal types (integrated with type path example as a version of weight paths)
      https://twitter.com/remixerator/status/1156860484294852609

    - causal types
      twitter.com/remixerator/status/1126040476023279616

    - applying causal shapes to a network
      https://twitter.com/remixerator/status/1004579263507566592

    - position on causal type network
      https://twitter.com/remixerator/status/1018540899859607552

  - abstract functions

      - derive combinations & make sure you have full function coverage of all important combinations

        - check codebase function index for combinations
        - check that you have sample data in json for each combination

      - attribute/object/function match functions
      - specific interface identification function
      - standardization network-framing function to describe a system as a network (the standard structure) & position each object, identifying connecting functions
      - system analysis function (identify boundaries, gaps, limits, layers, incentives/intents/questions, & other system objects)
      - isolation function, representating function/attribute changes independent of system context with respect to position or time (snapshot/state or subset)
      - function to define (isolate an object/concept/function for identification, identify definition routes)

  - give example of each type of problem-solving workflows

    - workflow 1:

      - finish function to determine relevance filter ('functions', 'required') from a problem_step ('find incentives') for a problem definition, to modify problem_steps with extra functions/attributes ('change_position') to be more specific to the problem definition ('find_incentives_to_change_position') for problem_steps involving 'incentives', so you know to use the function_name to modify the problem step if it's between the type 'functions' and the object searched for 'incentives'

      - finish function to get all codebase functions & store them in a dict with their type, context/usage, and intents, just like functions are stored in the problem_metadata.json example for workflow 1
      - finish common sense check
      - finish defining objects in object_schema.json
      - finish organizing functions.json by type, with mapping between general intent functions like 'find' to specific info-relevant terms like 'get'
      - add common phrase check & filter problem steps by repeated combinations with common phrase check
      - finish get_type function to map info to structure using the new functions.json organization
      - finish apply_solution to problem_definition using problem_steps
        - involves building a function to evenly distribute objects (like information/types), given problem positions/agents/objects

      
  - types can be represented as directions (going farther from origin goes further up type stack, where similar types are adjacent)

  - need to fill in content:
    - finish intent/change type calculation for a system intent
    - selecting optimal combination interfaces to start from when solving problems 
      (how many degrees away from core functions, specific layers or sub-systems, what position on causal structures)
    - key questions to filter attention/info-gathering/solution
    - key functions to solve common problem types
    - development of key decision metrics (bias towards more measurable/different metrics rather than the right metric)
    - trajectory between core & important objects
      - example of choosing inefficiencies/exploit combinations in a system
    - research implementing your solution type (constructing structures (made of boundary/filter/resource sets) to produce substances like antibodies, using bio system stressors)
    - emergent combinations of core functions (include derivation of invalidating contexts for core functions)

  - change phases for causal analysis (interim, changing, diverging, standard, efficient state, constant, interacting, converging, on the verge of obsolescence, outlier, etc)
    - superficial cause, alternate cause in the case of a function, addressing input/output causes
  - framing on interfaces, decomposing causation, then identifying parameters of problem on layer & matching solution
  - independence (closed trade loops) as time storage
  - vertex as a pivot point for an interface



- notes

    - if something can generate a change predictably/consistently, it's a change supply - otherwise it's a change request, so output as well as causal position relative to the output is important when determining category
      - time may be a variance gap (a space where change is possible) to resolve a question/problem set - so not resolving it can preserve time, unless resolving it will allow for more potential or moving on to other variance gaps
