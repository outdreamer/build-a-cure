# to do

  - organize new_examples.md
    - identify any examples missing from patents in docs/tasks by diffing patent spec texts
    - organize function implementations, to do list, examples, logic
 
  - add to govt/war
    - their lost loved ones wouldnt want them to seek revenge in isolation of context/meaning, bc it would destroy more innocent lives as collateral damage & continue the fight forever, they would want them to be the person who ends war forever

   - create configuration for 2-3 list items every day

      - create compilation script to compile code/config into a network graph on every change
        - add support for equivalent synonyms
        - add conversion to standard vocab

      - write some default interface queries to use until logic is written

      - finish lists:
        - most valuable interface queries & workflows
          - find the sets of differences/dependencies/formats/errors & other useful structures that are the most valuable in a particular structure like a sequence to solve a problem
        - useful perspectives
          - useful to think of prediction functions as generative functions to select the variable interactions that are most likely
        - interface component definition routes
        - ai structures with supported intents & solution success causes
        - solution filters to apply in functions
        - useful interface components
          - aligning/balancing structures, to solve problems like 'a balance position of structures producing errors when unbalanced'
          - questions formatted as a disconnection between components like causal positions, paths, directions
        - subset indexes of an interface useful for solving most problems (structure indexed by metadata like problems solvable, fitting systems, interactive structures, supported intents)

  - example of standardizing an error type:

    - 'maximizing shareholder value': using outputs (profit) to attract investment/capital rather than re-investing in products
      - calling 'routing outputs' function with intent to 'get more required inputs (like capital)' as a replacement of calling 'routing outputs' function with intent to 'make required inputs optional' has error structures with varying degrees:
        - false trade-off (not mutually exclusive)
          - outputs can be divided between both intents to create short-term & long-term gains
        - false causal structure
          - routing outputs with intent to 'increase product quality/variety' would fulfill the intent of 'attracting investment/capital'
        - over-prioritization
          - short-term gains
          - over-prioritization of inputs (like 'resources/ability') rather than using inputs to reduce costs (like 'required inputs')
        - lack of solution structures (once structures like over-prioritization are noticed, no solution structures were there to offset it)
        - lack of alternatives (other alternatives to 'increase product quality' to offset lack of intent fulfillment in the 'output routing' functions werent in position or available)
        - lack of opposite structures of competitor success (no monopoly or competitive moat or platform/supply chain/regulatory advantage in place)
        - lack of incentive structures to improve product in the absence of solution structures or correct output-routing functions (if executives planned on quitting/retiring before problems were noticed or compensation regulation changed)

  - add to conceptual math examples
    - example of an operation that builds a boundary structure leaving an inevitability of a matching concept (numbers) filling the structure
      - the concepts of 'missing', 'multiple/more', 'unit', 'type', 'identifiable as similar/equal/different' and 'difference in amount' allow for/require/build the concept of 'numbers'
      - functions like 'compare' or 'reduce' or 'expand' require the concept of 'numbers' when comparing objects of that data type or objects having a quantifiable attribute

  - add to science
    - use certainty-identification machine as a certainty-generating machine if it can outpace some physical processes to generate/store/find information
      - quantum physics may be a system that can outpace the info-production/derivation methods of physics, so a certainty machine built on quantum technology could be capable of this, if connected to other quantum certainty machines more efficiently than those built on physics are

    - add to 'cancer' process/condition system analysis:
      - identify connections like 'naked mole rats' lack of cancer linked to lack of serum vitamin d which helps cell growth'
        - find functions relevant to cancer:
          - cell growth
          - cell apoptosis inhibition
          - energy production
          - fuel source switching
        - find inputs of those functions
          - vitamin d
          - energy sources
          - other vitamins directly impacting or required for these functions
        - find extreme cases where inputs are missing & check for those functions
          - some species (like naked mole rats) dont produce vitamin d from sunlight or have lower rates of vitamin d, which may impact their relevant function 'cell growth' structures (patterns/cycles), which may impact their cancer rates
            - check if these species have differences in cancer rates
              - if so, those inputs (lower vitamin d or inability to produce vitamin d from sunlight) may be relevant in preventing the output process enabled by them (cancer)
      - this is a simple input-output sequence query to find input conditions that dont produce a process/condition (like cancer) as often
      - translating this into a different system like the human bio system would be a query involving mapping one species' system to another
      - once its mapped, it can be filtered for invalidating conditions, indicating whether a similar process can be activated in the human system without causing other problems

    - cancer cells' mutations might just be some of the more adjacent/common/interactive mutations out of all the mutations that are possible or actually occur with any frequency
      - if this is true & the primary cause, that means these mutations will continue occurring unless actively prevented
        - substances should be examined for mutation-prevention functionality
        - root causes can be addressed as a prevention method, like:
          - the reason mutations occur more frequently for a gene structure (like a gene type, pattern, or set), such as gene position in relation to another structure
          - the host system's inability to prevent malicious interactivity/cascading of mutations that protect mutability & promote additional mutations
          - lack of a substance structure that would prevent or reverse these mutations, or particularly damaging subsets of mutations that enable the others
          - whether signals that enable/activate cancer cells can be routed where mutations are needed
      - examine what mutations almost never occur & determine the cause of mutation frequency (at a certain position on chromosomes, protein folds, relative position to gene types, or other structures on different interaction levels)
      - simulate whether changing position of genes reduces the frequency of mutations of those genes, if position is a variable to the mutation frequency
        - ultimately it should be possible by analyzing components like structures/functionality as combinable attack vectors, to calculate what diseases are possible/probable & will happen given a genome, their metadata like frequency & degree of impact on the host, and the substances/processes/stressors that can prevent or neutralize them
        - genomic data can be enhanced with data from output system & interaction structures

    - the idea of a 'cure' may be invalid, the concept of a 'functional state' may be a more useful goal
      - an example would be rather than returning someone to a prior or absolute state of optimal health, adjust their system to a state where its more functional, even if that functionality is distorted
        - rather than returning to origin DNA state, find adjacent DNA state to avoid susceptibility to a condition or general conditions
        - move bacteria from another region even if that reduces functionality in that region
        - generate useful bacteria factories, even if it sometimes results in overpopulation problems

    - the theory of 'the universe as a simulation' is only now getting popular bc our brain structures & functions are such that we are only now recognizing the influence of physics on human decisions, noticing that we can influence these decisions, and therefore fake them, which reminds us of computer simulations

  - interim functions to build:
    - derive definition routes on various interfaces from a definition
    - apply a standard format (function/attribute/object) to an input
    - derive function intent stack
    - identify error types
    - identify structures of cause
    - identify variable types & structures
    - consolidate repo, remove repeated content, merge similar functions

    - finish processes:
      - finish interface analysis of physics to determine other useful components like efficiencies, incentives, trade-offs, closed systems
      - finish applying interface components (like abstract) to useful interface components
        - core interaction functions of core interaction functions
      - create interface queries of finding useful interface component filters

  - why do structures overlap across interfaces:
    - different interaction types:
      - one interface may define the structure, and another may apply it
    - interfaces may have different definitions of the structure while still referencing the same underlying structure
    - interfaces have other interfaces injected in them by default
      - example: every interface has the core interface injected, bc it has core components
    - there's usually one interface that is the base interface for any given structure

  - add to useful structures
    - identify useful perspectives
    - requirements (useful for filtering by relevance)
    - intent maps (useful for connecting intents across interaction layers)
    - intent sequences
      - a 'requirement to survive' is the reason why an animal might develop bright colors, with varying intents:
        - with intent to 'attract prey', bc 'prey are difficult to find'
        - with intent to 'mimic a scarier animal' bc 'theyre not scary enough to disincentivize predators'
        - with intent to 'store excess mutations' bc 'mutations occurred for no reason other than structural damage'
      - the two intent sequences above overlap at the 'bright colors' node and diverge bc of different requirements, given their different positions relative to useful objects for survival (prey, predators, energy storage, change as energy)
      - this is a way to determine alternate causes of the same variable, given useful system objects like requirements & incentives
    - attribute sequences to connect problem/solution
      - example: a solution to this problem type has attribute sequence: complex, organized, filtered, isolated

  - finish identifying & applying other problem/solution components
      - insights/insight patterns: identify the variables of insight generation (such as structures like difference types/degrees, like 'applying a mixed different/similar system with various difference/similarity types to another system, with intent to understand the other system') and apply these variables to generate insights that can be applied to solve a problem

  - finish applying interfaces to problem/solution structures
    - intent: derive intent maps & align intents on multiple problem/solution structure layers, like problem-solution connection and sub-problem or problem/solution component connections
    - logic: derive interactive structures given logical rules like equivalences/implications used as connecting functions
    - definition: apply problem/solution structure definitions to determine their possible interactions
    - cause: find solution success cause and generate solution automation workflows from that
    - change: 
      - find changes to problem/solution structures that still allow the structures to interact
      - find remaining variables of interactions

  - identify alternate causes of solution success as generators of solutions:
    - the reason a 'function network' or 'state simulator' or a 'stacked alignment' may be successful as predicting interactions may not be bc of the structure itself but bc of one of its outputs, such as:
      - a 'dependency' or 'interaction' structure caused by a 'function network' structure 
      - a 'state sequence' caused by a 'state simulator' structure
      - a 'phase shift bc of a threshold crossing' caused by a 'stacked alignment' structure
    - these useful output structures can be caused by other structures:
      - a 'dependency' structure can be caused by a 'containing' structure forcing that specific 'input-output sequence' to develop, caused by for example a 'lack of functionality' rather than 'connected functions in a function network'
      - a 'state sequence' can be caused by an 'interactive, adjacent, & probable structure filter set' structure
      - a 'phase shift bc of a threshold crossing' can be caused by a 'lack of input validation' structure
    - identifying variables of the solution success cause allows different solution causes to be identified & applied as solution generators
    - workflow fit: this is similar to 'identify & apply solution success causes as solution generators' but abstracts it & applies a higher causal node as input to 'solution success cause' as the 'causes of solution success cause'
    - generalization: this can be generalized to: 'identify generators of useful solution structures or identify alternate routes to useful solution structures & apply those alternate routes or generators as generators of solutions'
    - solution success cause: this works bc there isnt usually one input to the success of a solution, allowing for the usefulness of alternate inputs to solution success, and these inputs can be generated, and there are ether useful solution structures than solution success cause that this rule can be applied to as well, to generate solutions using other useful solution structures

  - identify differences in interface queries, workflows & other problem/solution components that can be used to solve the same problem & apply those variables to generate possible/adjacent solution queries or solutions given a base solution or just given the variables
    - the output of this would include workflows like:
      - input-output sequence & 'build' core interaction function structures: 'find the "input-output sequences" that build/produce the same output solution from the same input problem, with a given range of difference in input context (robust solutions), to build/produce/process the solution structure info from the problem structure info'
        - note: this is particularly useful bc it abstracts away causality & functionality, leaving just 'available resources' (inputs) and 'outputs' as the factors to analyze, so it could be specified as 'causal input-output sequences' or 'function input-output sequences' but that may be unnecessary in some circumstances where that info is irrelevant or captured in the abstraction of the 'input-output' structures
      - format/state sequence & 'connect' core interaction function structure: 'find adjacent "format sequences" that can "connect" a problem/solution'
      - generative variable structures: 'find "generative variables" of a problem and reduce those instead'
      - interactive structures & 'build' core interaction function structure: 'find interactive/cooperative structures in a problem space and use those to build a solution'
    - a workflow that can generate all the relevant structures used to build these workflows could be:
      - identify attributes/structures/components that are interchangeable ('format', 'input/output', 'interaction') and apply them to fulfill a structural requirement (a structure that can be 'connected') to solve a problem ('connect' problem/solution)
      - solution success cause: this works bc if components are interchangeable, they can be changed to generate differences that dont alter the input/output/functionality of the original structure
      - generalization: this can be generalized to the workflow 'identify variables of workflows that dont invalidate functionality of workflows & apply variables to generate different workflows'
      - workflow fit: this is similar to 'identify differences between solution automation workflows & apply variables to generate different workflows' but is a specific variant that identifies differences in specific queries/workflows used to solve the same problem which are standardized in some way for comparison (all of the above compared workflows use 'connect' or 'build' interaction functions and a 'sequence' structure in some position), and applies useful interface components such as concepts like 'interchangeability' to generate insights like 'use interchangeables to generate different workflows' to apply these insights as generators of workflow-generating functions

  - example of multiple ways to solve a problem
    - multiple ways to solve the 'find if a particular number is in a random sequence & find its position' problem
      - iterate through the sequence & check
      - filter the solution space of all possible sequences & approximate an answer by checking various points with solution filters
        - apply the definition of generative function's 'random' definition if available to identify error types possible/expected
        - apply the general definition of 'random' and 'probability' to find filter structures of likely sequences, which has probability-based filter structures when applied to a 'random number sequence' structure, like:
          - the sequence structure is likely to not have clear patterns in it (patterns that imply that it can be reduced to a function other than a random function)
          - the sequence structure is likely to not have a pattern that applies to the entire sequence (a pattern may occur, but is likely to only occur in a subset, the larger the sequence is)
          - if most positions do not have the number, its likely that remaining positions do have the number given possible patterns not ruled out by most positions (rather than finding a long sequence that doesnt contain the number, which is less likely than most numbers appearing in a long sequence at least once)
        - apply patterns of probability patterns as filters
          - how likely is it that 'if most positions do not have the number, its likely that remaining positions do have the number' produces an error?

    - multiple ways to solve the 'answer a question automatically' problem, with the following interface query:
      - if you have question-answer pattern info:
        - apply those patterns of language map routes or other info structures in the pattern to produce the answer
      - if you have error type & solution format or known solution info:
        - identify error type & apply solution formats or known solutions for that error type
          - apply the solution format as a template with a 'missing' error type or 'identification' problem:
            - for the question 'how did they get from A to B', the 'missing' structure is a 'missing path connecting the points', and the identification problem is selecting the correct route from all possible routes connecting the points
          - apply known solutions for the 'missing' error type (like 'matching structures that fit missing structure') or the 'identification' problem (like 'apply probability-based filters')
      - if you have concept identification, system structure identification, & derivation functions & access to info like agent decision histories but dont have specific info to filter possibilities of the optimal solution format of 'who drove it'
        - derive understanding of 'decisions' objects (to drive a car) & give proxy/approximate/abstract answers based on understanding
          - for the question 'who drove the car', derive relevant concepts such as 'inputs' to 'driving a car', like 'incentives', 'functions', 'access', 'requirements', 'intents' to 'drive a car' and produce a set of abstract descriptions of the types of people with those intents/incentives & other related objects

  - standardize core interaction functions (improve/optimize a standard/default solution, make progress toward, move toward, connect with) between problem/solution structures

  - finish applying math-concept interface mapping
    - number: all possible values (and value types, like units)
    - variable: all possible change types
    - function: all possible equivalent variable/value interactions
      - recursion: all possible self-references
      - multiplication: all possible value interaction spaces
      - division: all possible value standards
    - function input variable: all possible change types that can be causes
    - space: value interaction space where variable (change type) interactions have structure (can be described)

  - finish list of useful interface components, including structures of useful interface components (like structures of specific useful concepts)
    - example: 'apply concepts to system interface to identify conceptual structures in system'
      - system
        - system structures of uniqueness: exclusivities
        - system structures of power: trigger, input

  - finish interface query design rules
    - 'if solution requirements arent given, derive/predict them or apply default requirements from related/similar problems'

  - example of different structures of an interface component on different interfaces
      - alternative
        - 'structural alternative': where one or more structures are options where one or the other or both if not mutually exclusive can be chosen (applied at a given time), with varying relevance/optimization, for a particular intent (like 'navigate in a direction', having structural alternatives in the form of a set of paths)
        - 'conceptual alternative': where one or more concepts can be applied at a given time with varying relevance/optimization for a particular intent (concepts with an intent in common)
        - 'structural conceptual alternative': alternative conceptual structures, like varying structures of power or balance
      - alignment
        - 'structural alignment': based in the structural interface, where a 'structural alignment' takes the form of an equivalence/similarity in components (attributes/functions/objects/structures), such as:
          - interchangeable attributes/functions/objects
          - a fitting/matching structure
          - a parallel structure
          - a structure having similar shape or other attribute like size
        - 'conceptual alignment': translated to the conceptual interface, an 'alignment' takes the form of concept such as 'equal' and/or related concepts like 'similar'
        - example of injecting the structural interface to components on other interfaces:
          - a 'structural conceptual alignment' is the 'alignment' in structures of concepts, like 'similar conceptual connections' or 'equivalent concepts'

  - document useful component/sub-structures of interface queries (interface components, interaction rules, cross-interface interactions, generative functions)

  - ml explanation of finding coefficients of prediction function by applying distortions to coefficients & ruling out distortions that dont contribute to prediction accuracy
    - can be optimized with reductions like:
      - 'calculating the most different distortions that will reduce possible values the quickest & applying those distortions'
  
  - proof/determination structures
      - what makes something possible to determine/calculate
        - a solution structure where the solution metric is clearly defined (structural or having other structures of certainty like consistency or inevitability or requirement)
          - checking a path to see if it includes a node twice is clearly defined (it uses the structure of 'node visit counts' in the 'path' solution structure)
      - what makes something difficult to prove
        - where there are ambiguities (lack of certainty/structure/definition) between the input parameters & the output function value
          - ambiguities such as where multiple inputs produce the same output, like how different x-values can produce the same y value on a wave function
      - useful proof structures
        - apply possible components to create an absolute or scalable definition include components framed in terms of interactions with other components that can be used with a consistent measurement (like a stable structure across interfaces or dimension sets) & can also scale (boundaries), rather than framing them in terms that can have different meanings at different parameters (closed, hollow)

    - add to causation variables
      - ability to change (if a variable cant be changed, it is less causative for problem-solving intents)

    - give examples of identifying vertex variables
      - general vertex variables: topic, origin/destination, reason/cause/point/intent, errors, variables, types
      - comedy vertex variables: sincerity, stupidity, stakes, tension-resolution/expectation-subverting pattern variation
      - music vertex variables: tone, tension-resolution/expectation-subverting pattern variation, lyrics
      - optimization metric vertex variables: solution metric patterns (what other solutions optimize for, to determine optimization metrics to apply)

    - when is it optimal to store a mixed structure of varying specificity (like a type, intent, cause & a specific example)
      - when there are potential uncertainties to resolve, like whether the example represents a new error, type, or variable, bc the example doesnt fit known structures

    - all primary interfaces can act like the problem-solving interface (start solving problem from the concept or structure interface and integrate all info back into that interface & frame the solution in terms of that interface) but the meaning interface (the interface interface) is the most powerful

  - visualizing higher dimensions with changes in a network of visualizable variable subsets like:

    - dimension subsets: displaying dimension subsets in groups of sizes that are already visualizable (from 1 - 4 dimensions), where orthogonality is preserved across the network of subsets
    - dimension groups: grouping similar dimensional changes into a change type across a dimension subset, to visualize the change types
    
    - relevant (robust) dimensions
      - dimension invalidations: grouping invalidating/neutralizing change types
      - causative dimensions: just visualizing higher-impact/causal dimensions
      - vertex dimensions: graphing variables as differences from vertex variables
    
    - mapping dimensions: group value sets as other structures like points or networks in a space where change types like 'continuous change' are supported
      - embedded dimensions: dimensions graphed visually using extra dimensions as parameters
      - base dimensions: dimensions standardized to a base and graphed in alignment, like multiple functions on a graph with a common base
      - mapping other dimension metadata: interactions between dimensions units/change types/limits/definitions are graphed
      - abstract dimensions: abstract value structures are graphed ('a point on a line') instead of specific values in a dimension
      - constant dimensions: adjacent limiting constant dimensions are graphed instead of dimensions of change

    - dimension interactions: 
      - interactive dimensions: dimensions that interact are condensed into an input/output of the interaction structure, and input/output dimensions are graphed instead
      - dimension interaction structures: structures of interactions between variables (like direction/circuits/networks) are preserved, where values may be lost
        - dimensional difference: difference between dimensions is graphed instead of different dimensions & values, where dimension values are structures associated with graphed dimension interactions
        - conversion requirements: conversion requirements to a visualizable shape are graphed instead of actual dimensions/values
        - interaction structures between value structures like positions on dimensions when graphed as a standardized shape
          - example: with dimensions formatted as a standardized form like 'lines of equal length, & values as points on these lines', the interaction structure would be the lines connecting the points on the dimension lines, when arranged in any order

    - example of resolving a conflict between structure/limits using a structural similarity between a structure (gradient of function) & its container/limits (gradient of constraints)
      - https://en.wikipedia.org/wiki/Lagrange_multiplier
      - also an example of a solution space (the whole function is the solution space of possible minima/maxima) and a filter applied to it (constraint)

    - make a function network of math domains (inputs/outputs of geometry, algebra, calculus that align)

    - resolve definitions of components so you can finish organizing useful structures like combinations of concepts such as "format sequence", "solution automation workflow", "insight path", "reverse-engineer solution from problem requirements or opposite structures", "connect problem & solution"

    - example of how to generate monopoly case arguments
      - change variable 'location of power':
        - spotify is welcome to build their own app store with their own phones or team up with their coalition to do so
        - add variable 'time sequence' to 'location of power' change:
          - if spotify operates an app store someday, they will set rules to benefit themselves too, just like theyve done in the past
        - offer an alternative to charging app store rate
          - is there a one-click button to migrate from spotify to apple that could replace any difference in taxes on spotify
      - apply conceptual definition filter 'does concept of persecution (and related components of the definition like focus) apply to the behavior (does behavior have a specific target that is the focus of persecution)'
        - are apple's rules applied exclusively to spotify? if not, it's not anti-competitive behavior
      - apply intent filter
        - is spotify's mission nobler than apple's
      - apply system cost-benefit analysis
        - what features were improved bc spotify exists? are those features worth anything or required needs? did they develop those features better than competitors?
        - if spotify is just charging rent on a catalog, are they adding value to the market, so they should be allowed to dictate the market at all?
        - what products/features would apple develop if they didnt have to pay a fine, and what are those features worth, and are those features required?
      - apply logical fallacy filters
        - apply 'hypocrisy' filter
          - apply 'anti-competitive' conceptual definition structures & test if these structures fit the opponent
            - does spotify plan on raising prices at some point or will they keep prices low even if the app store rate holds? are they only keeping prices low to dominate the market & plan on raising prices later? isnt that anti-competitive behavior?
            - if they are so concerned about anti-competitive behavior, why arent they trying to compete by building their own app store? isnt there a risk that the apple app store is sub-optimal and needs to be improved with competition from spotify

    - value isnt created/lost by companies in the timespan of hype/short cycles, so stock market price swings aren't reflective of reality from a macro perspective
      - it takes years to build value, it doesn't happen overnight, excluding almost magical insights that create cascading efficiencies like my system
      - losing value also happens slowly, excluding extreme natural disasters, like the value of a community still being relatively high despite shared losses, bc of social network effects & organization/coordination effects
      - value can be calculated differently, using metadata like the lifetime & total possible value of a product
        - what is the total supply of the product inputs (fossil fuels)
        - what is the usability lifetime
        - what are the costs
        - what are the product intent alternatives (can intents fulfilled by the product be fulfilled by other products)
        - what is purchased with revenue from a product (research, insights, other more valuable resellable products, etc)
        - if this pricing method is applied to fossil fuels, oil companies would be paying people to use them

    - identify filters for definition routes

    - database polling/prompting user for update & predicting updates or searching for & receiving user-approved updates from other services, rather than being a passive receiver of input from user
      - based on local usage/change patterns or integrated usage patterns to identify expected transactions with other services
        - once a credit card is marked as lost in a banking service, a change of credit card numbers is expected by other services which can poll for updates to this flag
          - user option like 'yes, allow other approved databases containing my address poll to collect this update'
        - once a renters insurance policy is changed in an insurance service, a change of address might be expected by other services

    - make list of variable structure variables measured by algorithms & why they are measured by a network algorithm

  - make diagram of absolute reference connections with metadata structures like networks/paths
  - determine core graph variables (definition of adjacence/difference, connectivity, dimensions, info storage methods, interactivity of structures like sequences)
  - crypto as community consensus, where a decision can have value if backed by a community

    - examine connection between fractals, sequences, averages, origins, multipliers (self, as in power), & circles
      - fractals as a relevant structure for adding sequences of fractions (adding numbers similar to itself on a smaller scale, infinitely) as a way of producing inputs to circles created by transforming a fractal spiral, where the origin is the original number as a base for applying increasingly smaller scales
      - the set of points forming roots of an infinite negative number sequence (roots of unity, rather than roots of any negative integer number) as a way of producing a circle because of their common distance to their average (center) forming the radius
      - lines of equal length having a common average point (center/origin)
      - fractals & infinite sequences as a way of calculating area under a continuous line (increasing small subsets of structures with area calculatable with multiplication of x & y)
      - what continuous line segments would have an area equal to a circle of relevant proportions?

    - how to identify the killer counterpoint
      - point: 'election fraud claims'
        - counterpoint: you dont think the other party has members?
          - followup points:
            - how are they organizing? why do you even hear about them?
            - who's benefitting from investing massive funding in creating a false illusion, if its all fake?
            - why wouldnt they choose cheaper methods of doing so than an elaborate illusion?
      - identify most extreme false assumption of point by identify causes of the output metric (vote count)
        - the primary/basic false assumption of the point is that the other side doesnt have votes that are comparable in quantity
          - possible causes (inputs) of 'not having similar vote count' include:
            - not going to vote
            - not being able to vote
            - not having members to vote
          - the most extreme false assumption is the most extreme cause of 'not having similar vote count' (that the other side doesnt even have members (input of votes) that are comparable in quantity, let alone votes (output))
      - identify 'incentives', 'side effects of party/member/vote existence & size' as other relevant concepts to generate followup questions

    - the work of 'stealing my work' and 'pretending not to' doesnt produce efficient brains with a good grasp of concepts like 'meaning', so it emerges as an inefficiency bc the type of brains developed wont be good at finding solutions to output problems generated by granularly copying/pasting to a specific problem/solution & hoping it works better
            - 'understanding my work' is a better goal if you cant look away bc youre not done experiencing awe
              - once you understand it, you wont need to watch me work, youll be able to generate my work
  
  - apply nn to derive error types & bias incorporated into other nn data/parameters/algorithms/structures/models    


## general

  - integrate objects/.md text with interface implementations

  - apply to structures

    - concept of attention in structures
      - mixed interim high-variation & high-similarity structures tend to maximize attention
    
    - examine error type of conflating intent & requirement
    
    - consciousness as choice to move between neural nodes (rather than being directed) required:
      - the development of alternative node paths performing equal/similar functions, requiring:
        - the development of excess resources, delaying required decision time (making immediate decision unnecessary, avoiding a forced decision), requiring:
          - the existence & application of previous efficiencies & functions for alternative evaluation, energy storage, storage-checking, & energy requirement-identifying
      - the cause could be framed as structures such as an 'efficiency stack' or 'energy maintenance functions' or 'alternative options' or 'navigation/motion control' or 'lack of requirement/need'
    
    - examine similarity (alignment/overlap) structures between: 
      - extremely different components (when an error type is an incentive or a function used for other intents) 
        - when the solution format of some problem has similarities to the error type, like when you need randomness so errors generating randomness are a possible function to use for that intent
        - contradictory/opposite components (have some metric in common, with opposite values)

  - finish organizing lists of examples, functions, info objects (insight paths, definitions, questions), components for configuration

    - organize examples

      - label examples so they can be queried more structurally
      - query for logic in examples when implementing functions
      - organize examples of useful structures & questions in index.md
        - identify useful questions in notes
        - check reduced language components for any other useful functions (what terms cant be adjacently, clearly & accurately framed in terms youve defined) for completeness


## examples


  - examine the distortion vector paths that adjacently decompose a data set into a prediction function from a base point/function set

  - give example of mapping to structures & identifying contradictions its safe to ignore for applying a structure

  - example of permuting assumption: "reports of power consumption have to be exact measurements" 
    - a temperature monitor sensitive to a hundredth of a degree might provide similar but non-specific power reporting for important/extreme usage patterns without revealing such specific information as that which could infer exact operations being done, bc the interval of temperature measurements allows for greater variation in calculations that could explain it
  
  - query examples for use cases like:
    - lack of information stored (match problem of type 'information lack' with interface query 'check pattern interface for similar patterns')
    - query problem breakdown & integration diagram
    - calculating various different problem breakdown strategies first before executing normal query-building logic for each
  
  - add examples of system/object/rule/type change patterns
  
  - include example workflows with example problems
    - include example of how to generate other workflows (different starting/ending points & trajectories)

  - example of using set theory in query operations:
    - edges as core organizing/formatting operations (find/apply) & interfaces (connecting/explanatory concepts/functions)
    https://en.wikipedia.org/wiki/Hypergraph

## diagram
  
  - diagram with error types
  - diagram of the network of formats
  - make efficiency map
  - diagram of alternate interfaces (information = combination of structure, potential, change or structure, cause or structure, system)
  
  - give structural query example diagram for GANs + image compression problem

  - chart type: overlaying multiple 2-dimension variable comparisons to identify common shapes of variable connections (density of points added with a visible attribute like more opacity)

  - finish core function structure example diagrams

  - diagram with joke types
    - 'annoying when they bring up human rights in a conversation'
      - conversation system context
        - functions
          - change topic 
            - change topic structure (sequence)
              - introduce a topic (first time topic is included in conversation)
          - expected interaction functions
            - criticism of a behavior
              - 'conversation with dictator' system context
                - criticism of power abuse (law violation, specifically human rights violation, which are a related object to dictators)
                  - interpreted as right in the 'conversation with dictator' system context
                    - expected interaction in this context
                      - 'should bring up human rights to a criminal'
            - norms:
              - for low-stakes interactions & interaction errors (manners, annoyance, disrespect)
            - laws: 
              - for high-stake interactions & interaction errors (rights violations)
        - placing a norm (or related objects) in the place where a law (or related objects) would normally go:
          - 'its annoying when someone doesnt let you end the conversation'
            - 'its annoying when someone keeps going on & on about your previous conversations where you ordered deaths of a dissident'
              - 'its annoying when someone keeps going on & on about your previous conversations where you ordered deaths of a dissident for being annoying & then abruptly stops without explanation'
            - 'its rude when someone doesnt let you end a conversation with a laywer interrogating you for war crimes' 

  - diagram for structures of emergence
    - example: 1-1 input/output relationship up an interaction layer, where extra resources that dont dissolve immediately on the higher interaction layer aggregate & form core structures like combinations, where interactions between combinations & sequences have different dynamics than the individual output interacting with other individual outputs
    - emergent functionality/attributes come from interaction structures (sequences & layers)

    - add diagram for intent-matching
    - add structures to diagram: interface overflow (to sub-interfaces), interface foundation
    - diagram for workflow 1: 
      - function to determine relevance filter ('functions', 'required') from a problem_step ('find incentives') for a problem definition, to modify problem_steps with extra functions/attributes ('change_position') to be more specific to the problem definition ('find_incentives_to_change_position') for problem_steps involving 'incentives', so you know to use the function_name to modify the problem step if it's between the type 'functions' and the object searched for 'incentives'
    - add conceptual math interface query diagram
      - use lattice multiplication as standard example, other than core operations (add/multiply mapped to language, concepts like irreversibility/asymmetry mapped to math)
    - interface conversion, matching, starting point selection (applying structure, checking if relevant information is found)
    - diagram to document sub-functions of core functions with distortions
    - make diagram for dimension links higher than 3d that are depictable in the same network space
      - should show variables that impact other variables, the change rates of these relationships
      - overall impact should be calculatable from these relationships
      - should show similar movements for correlated variables
      - should show skippable/derivable variables (variables that can be resolved later than they normally are)
      - should show meta forces for overall trends in change rules (direction of combined variable forces)
      - should show limits of measurability & threshold metrics

    - diagrams for specific concepts, core functions, concept operations (combine, collide, connect, merge, apply), ethical shapes
        - variable accretion patterns (how an object becomes influenced by a new variable, complex system interaction patterns, etc)
        - make diagram of potential matrix to display the concept
          - map parameter sets to potential matrix shapes 
        - finish diagrams for cause (shapes & ambiguity), concept (evolution of concepts, networks, distortion functions)
        - diagram for argument
      - make a system layer diagram for each interface to allow specification of core interfaces & other interface layers (interface interface)
        - make a system layer diagram for structures to include layers of structures 
          (beyond core structures like curves, to include n-degree structures like a wave, as well as semantic output structures like a key, crossing the layer that generates info structures like an insight, a probability, etc)

    - map variable structures to prediction potential for problem types, given ratio of equivalent alternate signals

    - vertex variable structures
      - quantum physics, prediction/derivation tools, build automation tools, testing tools, learning/adaptation tools, system rules, computation power are all vertex variables of information, since they can generate/derive/find information
        - which structure (sequence, network, set, or cycle) of vertex variables is most efficient

    - core component attributes: identify any missing attributes/functions that cant be reduced further

# content/config

    - import insight history data to identify insight paths (info insight paths like 'lie => joke => distortion => insight', system insight paths like 'three core functions + combine function with this definition + n distortions to nearest hub')
    - define default & core objects necessary for system to function (out of the box, rather than minimal config necessary to derive other system components & assemble)
      - add default functions to solve common problem types
      - alternate utility function implementations have variation potential in the exact operations used to achieve the function intents, but there are requirements in which definitions these functions use because they are inherent to the system. For example, the embodiment may use a specific definition of an attribute (standardized to a set of filters) in order to build the attribute-identification function using a set of filters - but the general attribute definition is still partially determined in its initial version by requirements specified in the documentation, such as a set of core attribute types (input, output, function parameter, abstract, descriptive, identifying, differentiating, variable, constant), the definition of a function, and the definition of conversion functions between standard formats.
    - document time structures (concave time explaining compounding similarities up to a point of maximum concavity, a structure that can separate from the other space-times)
    
    - systematize definitions of info objects, to include analysis that produces relationships of core objects like opposites to their relevant forms (anti-symmetry) in addition to permuted object states (asymmetry), such as an anti-strategy, anti-information, anti-pattern
      - organize certainty (info) vs. uncertainty objects (potential, risk, probability)
      - make doc to store insight paths, counterintuitive functions, hidden costs, counterexamples, phase shift triggers
      - add technicality, synchronization, bias, counterintuition, & certainty objects leading to inevitable collisions
        - error of the collision of compounding forces producing a phase shift
        - lack of attention in one driver and false panic in a second driver leading to a car crash given the bases where their processes originate
      - define alignment on interfaces (compounding, coordinating, parallel, similar, etc)
      - add core info objects (core strategies, core assumptions) so you can make a network of graphs for a system
    - concept analysis:
      - how new concepts (gaps in network rules) evolve once structure is applied to prior concepts 
    - interface analysis:
      - limitations of interfaces & how to derive them
      - how rules develop on stability & how foundations are connected & destroyed
      - explainability as a space limited by derivable attributes from data set & cross-system similarity
      - vertex definition & give examples (as an intersection/combination of interface variables, such as determining/description(compressing)/generative/causative/derivation variables), around which change develops
    - change analysis:
      - generated object change types
        - constant to variable
        - variable to removal of assumption in variable type/data type
    - examine implementing your solution type (constructing structures (made of boundary/filter/resource sets) to produce substances like antibodies, using bio system stressors)
    - resolve & merge definitions into docs/tasks/implementation/constants/definitions.json
    - update links
    - integrate archive_notes/finder_info/functions
    - de-duplicate logic
      - organize interface analysis logic definitions
        - organize functions in problem/interface definitions, before organizing functions in implementations/*
      - integrate problem_solving_matching.md
      - integrate find/apply/build/derive logic from system_analysis/ & maps/defs*.json
      - separate interface analysis logic into implementation/functions (functions dont need unique info)
      - add functions from workflows & analysis (to do list, questions answered, problems solved, interface definition & functions) as files in functions/ folder
        - organize into primary core functions & list sample parameters (like objects to identify for the identify function)
      - integrate rules from diagrams in patent applications to relevant documents
            

- examples
      - joke mapping insight paths
        - unlikely hypothetical
          - several degrees of assumption chains to generate an unlikely hypothetical (sequence of assumptions from a starting assumption/premise, generating a background story/context)
            - serious + petty + important: 'none of us can figure out why he tucks in his tie'
              - implies that the problem was so serious that a discussion happened to investigate & research it to fix it
              - implies that no one is allowed to ask him or has the courage to ask him directly, implying he's powerful in some way & cannot be questioned, which implies these are his subordinates who are not doing work in order to discuss this, which implies this could cause their work arrangement to be invalid 
            - 'none of us ever figured out why he tucked in his tie'
              - repeated + important: implies that the discussion was repeated bc it was such an important matter
            - 'none of our lawyers or R&D staff ever figured out why he tucked in his tie'
              - important: adds another level of importance in that they hired an expensive legal team to investigate the matter for liability/indemnity/litigation potential as if it made the company look so bad they had to hire a legal team
            - "the tie-tucking survived ex-girlfriends' interventions"
              - important: it has ruined multiple relationships with people who cared about him who tried to stop him from doing this to himself
              - briefer than previous version & uses more evocative verb
              - different: 
                - add assumption: assumption that the audience is rooting for the tie-tucking to continue
                - add concept of 'agency': attributing personhood to the tie-tucking, which is fighting for its life against cruel monsters
            - 'even after being accused of being a double-tucker who tucks his tie but not his shirt, he persisted'
              - important + petty + similar: fashion is a petty thing to care about this much, and a special jargon term 'double-tucker' implies a whole community or sub-culture based on or caring about this issue or related issues, which he has caused controversy in, with added importance by association from term 'double-agent', typically reserved for high-stakes situations like foreign wars, as if he's betraying someone or his heritage or group or people who rooted for him, and rhymes with a curse word
            - 'the mysterious tie-tucker left the board of directors' 
              - important + reduced: condensing the entire story into a brief structure like a nickname and casually referencing it despite the importance implied in a problem that generates a nickname
        - topics
          - conspiracy theory (a muffling device to prevent the Chinese from listening to his balls chafe for blackmail material)
          - cults/ex's (definitely worshiping the wrong things)
        - total opposite: 'your fatal flaw wasn't so much all the excessive drunk online shopping purchases at the police store & the corporate sabotage so much as the curtains from korea that spied on us & posted our arguments to porn sites' (it was absolutely the excessive spending at the police store)
        - changing definitions to very different alternate definition
          - 'tucked in his tie' or 'used unnecessary protection' or 'packed heat'
        - resolving awkwardness
          - 'i dont hate your dick pics (introduces the problem, 'uh oh does she hate my dick pics'), I just think theyre (foreshadowing something that seems like a difference but is actually similar) more optimal when directed at enthusiasts (or professionals), such as doctors/researchers, who might appreciate it more than I ever could (optional: from a curiousity perspective)'
        - mixed contexts/styles
          - talking about an unimportant matter in the same terms used for important matters
            - 'his parents couldnt deal with the idea of confrontation so they gently let him lose touch rather than disowning him outright' 
        - adding relevant structures of meaning like:
          - aligning layers like double entendres
            - calling him a 'magician' bc they have a function of 'hiding scarves' which is similar to 'tucking a tie' bc 'tucking' has a related output of 'hiding'
        - defeating the purpose/self-defeating
          - listing all the manipulations youre using, while using them, to the target 
        - false dignity/over-generousity
          - calling him a 'international man of mystery' bc its a very dignified way to portray having mysterious fashion habits that defy analysis from subject matter experts
          - 'he must be doing it to scare away women bc theyre always chasing him'
        - injecting stupidity/extremes
          - he thought it would act like a talisman to protect him from rape or unwanted pregnancy
          - he was told by a foreign holy man (has association with 'wise foreigner' stereotype) that it would protect him from fertility like a 'cosmic condom' (repetition, catchy) 
        - removing a point/agency (its not an intent, he just had the clingiest underwear/reproductive organs known to mankind)
        - fitting with existing systems without obvious contradictions
          - 'using existing phrases in a new way with minimal distortions' is surprising bc its unlikely to find a new distortion of an existing component that someone hasnt tried, so the simpler the better for this type
