# to do

  - yes, there's more torture, every day Im on my diet Im going to torment you with my achievements

  - finish processes:
      
      - finish applying systematization of solution automation
      
      - finish interface analysis of physics & other interfaces to identify other useful components like efficiencies, incentives, trade-offs, closed systems
      
      - finish config
        - add useful structures & questions from index.md to systematize_solution_automation.md
        - useful structures
            - identify filters for useful structures like definition routes
            - the system structure format where the maximum number of interface queries can be executed structurally, with minimal conversions required? is it a merged format of variable/function/concept/cause network graphs, or system state networks, or a set of variable subset graphs, or differences visualized as vectors, or input-output sequence visualizations, or a network with all identifiable interface components visualized
            - interface queries optimizing finding useful interface component filters
            - useful perspectives/specific interfaces
              - useful to think of prediction functions as generative functions to select the variable interactions that are most likely
            - useful solution filters to apply in functions
            - aligning/balancing structures, to solve problems like 'a balance position of structures producing errors when unbalanced'
            - questions formatted as a disconnection between components like causal positions, paths, directions
            - subset indexes of an interface useful for solving most problems (structure indexed by metadata like problems solvable, fitting systems, interactive structures, supported intents)
            - ml structures with supported intents & solution success causes
            - most valuable interface queries & workflows
              - find the sets of differences/dependencies/formats/errors & other useful structures that are the most valuable in a particular structure like a sequence to solve a problem
                    - interface component definition routes
            - useful component/sub-structures of interface queries (interface components, interaction rules, cross-interface interactions, generative functions)
            - useful interface components (like abstract) of useful interface components
              - core interaction functions of core interaction functions
          - creating useful structures
            - organize automating useful structures like combinations of concepts such as "format sequence", "solution automation workflow", "insight path", "reverse-engineer solution from problem requirements or opposite structures", "connect problem & solution"
            - convert structural queries to insight paths
              - alignments present in security innovations (like alignment in inputs like keys)
              - source of rule development as structures of conflict between forced interactions like change causes & constant structures like limits
                - incomplete inevitability of interaction as a decision structure
              - group device history authentication: authenticate credit card by proximity to cell phone & continuity applied to user usage history pattern
            - functionalize insight paths & integrate functions in optimized program with parameters to select function subset & structure for input problem
        - default config
          - write some default interface queries to use until logic is written
      
      - finish scripts
        - create compilation script to compile code/config into a network graph on every change
          - add support for standardizing equivalent synonyms
            - add conversion to standard vocab

  - integrate logic
      - integrate objects/.md text with interface implementations
      - integrate archive_notes/finder_info/functions
      - organize interface analysis logic definitions
        - organize functions in problem/interface definitions, before organizing functions in implementations/*
      - integrate problem_solving_matching.md
      - integrate find/apply/build/derive logic from system_analysis/ & maps/defs.json
      - separate interface analysis logic into implementation/functions (functions dont need unique info)
      - add functions from workflows & analysis (to do list, questions answered, problems solved, interface definition & functions) as files in functions/ folder
        - organize into primary core functions & list sample parameters (like objects to identify for the identify function)
      - integrate rules from diagrams in patent applications to relevant documents
      - organize function logic (interface query design logic)
        - document default static config objects that are inputs to core objects (like functions & concepts)
          - core functions like 'change', with locked objects which should be generated as inputs to other functions and should not be removed bc they enable other rules & core objects
            - a 'check for errors' function
            - a concept of 'self-correction/optimization'
          - these locked objects can be used to generate rule-generating/deriving/finding structures, by forming an initial structure of locked objects and filling that structure with conditional & changeable structures
            - these rule-generating/deriving/finding structures can be used as solution automation workflows
        - design an optimal sorting structure for general interface queries to apply to problems manually
        - list interface selection (based on inputs like available APIs/data sets/definitions)
        - problem interface structures: solution constraints/metrics, problem space variables, available functions, useful formats/structures
        - function to translate interface query logic into interface language (combination of core functions (find/build) & other core components)
        - function-usage-intent::output or demand::supply combination/merging/building/matching functions (alternatively formatted as a solution-finding query for a problem or lack-resource matching function) as an alternative solution to ads
        - decision points (required/optional resolution of variables to constants, as in selecting a variable value)
          - identify when a method & data set can be identifyd to be capable of deriving the answer to a prediction function problem
        - alternative intent coordination & compatability of metrics
          - calculating interactivity by coordinating/adjacent/convertible structures
        - check reduced language components for any other useful functions (what terms cant be adjacently, clearly & accurately framed in terms youve defined) for completeness

  - integrate examples

      - index examples so they can be queried more structurally when implementing functions

      - move examples from:
        
        - drinkme/examples_from_faq.md
          - check other examples of high-value use cases (other than identifying important concepts) from faq:
            - identifying the important base to frame changes on (identifying new interfaces)
            - identifying the right interaction level to focus on (identifying the change-maximizing layer of a system to examine a particular relationship)
            - identifying the right perspective to filter with (like 'identifying whether the legal/scientific/progressive perspective is most useful for an intent')
            - identifying the right context/position for an object (derive context when it's missing or fit an object to a system)
            - identifying the most causative function set (like identifying core functions, or the most misused functionss, or the most change-causing functions)
            - identifying important differentiating types (like function types indexed by intent & structure types, like boundary/change functions)        
        
        - patent implementation_examples
          - identify any examples missing from patents in docs/tasks once examples are organized

        - specific examples from specific_problem_analysis
          - example of permuting assumption: "reports of power consumption have to be exact measurements" 
            - a temperature monitor sensitive to a hundredth of a degree might provide similar but non-specific power reporting for important/extreme usage patterns without revealing such specific information as that which could infer exact operations being done, bc the interval of temperature measurements allows for greater variation in calculations that could explain it
          - example of using set theory in query operations:
            - edges as core organizing/formatting operations (find/apply) & interfaces (connecting/explanatory concepts/functions)
              - https://en.wikipedia.org/wiki/Hypergraph
          - example of structural version of solution difference from original solution: 
              - this is like using a pair of connected lines at different angles to connect two points (multiplying alternate multiplier pairs to create a product), where summing the line lengths produces an equivalence, so different solutions would look like differently angled triangles connecting the two points
                - https://www.popularmechanics.com/science/math/a30152083/solve-quadratic-equations
          - examples of identifying vertex variables
              - general vertex variables: topic, origin/destination, reason/cause/point/intent, errors, variables, types
              - comedy vertex variables: sincerity, stupidity, stakes, tension-resolution/expectation-subverting pattern variation
              - music vertex variables: tone, tension-resolution/expectation-subverting pattern variation, lyrics
              - optimization metric vertex variables: solution metric patterns (what other solutions optimize for, to identify optimization metrics to apply)
          - example of resolving a conflict between structure/limits using a structural similarity between a structure (gradient of function) & its container/limits (gradient of constraints)
              - https://en.wikipedia.org/wiki/Lagrange_multiplier
              - also an example of a solution space (the whole function is the solution space of possible minima/maxima) and a filter applied to it (constraint)

      - give examples of how each workflow can be applied to various standard problems (find a prediction function, sorting problem, ml configuration/algorithm-design problem)


## examples

  - add to predictions
    - where you say that 'activity interacting with a neuron is relevant in its functionality': https://www.quantamagazine.org/how-computationally-complex-is-a-single-neuron-20210902/
    - relevance of intelligence (successful learning/thinking) & disease (unsuccessful learning/thinking/stressor-handling): https://www.quantamagazine.org/brain-cells-break-their-dna-to-learn-more-quickly-20210830/

  - add to math mapping
    - a set of related change types (like a sequence of fourier/taylor expansion terms providing different polynomials) provides different change types that can be combined to produce the required changes to produce a function
    - example 'alternate connection' structure: wheels (rotations of circles) provide an alternate connection between waves & circles, in addition to trig functions
    - fourier transform is an example of energy from change stabilizing into a pattern of a new change type - https://mathlets.org/mathlets/discrete-fourier-transform/

  - add to problem/solution structures

    - simplified definitions

      - workflow:
        - a way to connect a problem with a solution automatically

      - interface query: a way to automatically implement something
        - when applied to implement a function intent, the interface query is a function-finding method
        - when applied to implement a problem-solving intent, the interface query is a solution-finding method

      - interface: standardizing filter where any problem can be solved
        - why an interface isnt a language - its definition overlaps with the definition of a set, which is a sub-structure found on interfaces and doesnt encapsulate the whole definition of an interface, which is a specific structure in which all problems can be solved, whereas language encompasses all concepts/structures without refinement by a filter that adds value in reducing computations
        - ambiguities/overlaps as sources of info to identify interfaces (overlap of 'difference' & 'change' definitions indicates that they are related variations in a potential field of a unifying concept acting as a symmetry)

      - perspective: 
        
        - a filter with priorities (which may be structures, causes, abstract prioritized attributes, or other interface structures) which highlight something as particularly important
        
        - example:
          
          - a perspective like 'find the function that minimizes distance from as many points as possible' produces a solution that can qualify as 'regression' to the 'find a prediction function' problem
            - this perspective can be a function structure, but its still a perspective because its highlighting some objects (distance from points, average) as particularly important
            - a function like 'find the function that minimizes distance from the average line' is a lot closer to the definition of 'regression'
          
          - differences in perspectives:
            - the first perspective highlights a specific problem-solving intent to generate a solution-finding method or solution for, which has many possible implementations
            - the second perspective highlights an adjacent inevitable solution-finding method, which has very few possible solutions/implementations, given some variance in the definition of the average
        
        - perspective variables
          - degree of implementation variation
          - info captured/created
            - perspectives may be useful structures & may contain useful structures (like averages), which capture a lot of uncertainty, complexity or variation/change, providing useful info like a direction to move toward when searching for a solution, or a specific problem-solving intent to fulfill
          - adjacence to solutions/solution-finding methods
          - definitions
          - priorities
          - filters
          - useful structures referenced
          - problems the perspective is useful for
          - relation to other perspectives
            - differences in perspectives can be used to generate other useful perspectives, and identify which perspectives would be most useful to guide a problem-solving workflow or interface query, given perspective attributes like implementation variation
          - perspective structure (interface, function, priority set, etc)
            - a perspective may be formatted like a particular interface structure, like a function or interface, while still qualifying as a perspective bc it prioritizes some objects over others
          - abstraction (abstract perspective or a specific perspective)

        - how is a perspective different from other structures?
          - its definition overlaps with an interface, but the interface includes an abstract concept like 'cause' that is prioritized & focused on, and all the structures relevant to it, & standardizes everything to that concept's structures, whereas a perspective may just focus on a particular set of structures rather than changing structures (for instance to be formatted in terms of causal structures like dependencies on the cause interface, rather than their original format, whereas a perspective may just focus on causal relationships or filter out anything that is not causative)
          - how is a perspective like 'find a function minimizing distance from average line' different from a function?
            - a perspective can be formatted as another structure than its standard structure (a filter with priorities), because other structures can have default priorities & act like a filter
          - how is a perspective like 'find a function minimizing distance from average line' different from an interface query?
            - an interface query may also produce a step with an intent like 'find a function fulfilling x' but in the context of the interface query, the intent of this step is to fulfill another intent, like a problem-solving intent such as 'create a function to fulfill y automatically', which may involve solving the sub-problem of 'finding a function to fulfill x'
            - this doesnt contradict the definition of the interface query or perspective, something can be both without violating either definition
          - the reason to call something a perspective is if it highlights a priority or prioritized structure in a way that adds value by filtering out other structures, and filtering is a very useful function that is frequently used in other problem-solving processes, like the problem-solving intent 'filter the solution space' or any call to the 'find' or 'identify' functions
      
    - add to solution automation workflows

      - identify the structures with highest impact on solution success
        - example: in the 'find a prediction function' problem, this would include standard 'contributing variables' & 'variable interactions', but also 'function structures' like 'averages', 'continuity', 'change rate patterns', 'waves/peaks/inflection points'
          - these have high impact on solution success bc theyre 'high variation', 'represent a standard', 'reflect the output of relevant variables like exponents or patterns', are 'relevant inputs like function component structures', or are defined to be useful 'patterns are defined to represent an abstraction of a change type'

      - identify the complete structures in a problem space & format the problem in terms of the complete structures for solution metrics like accuracy/robustness
        - example: variables arent a complete structure until some understanding rules are injected about their interaction structures such as cause & relationship to other variables, the context in which they are variable/constant, and their associated change types

      - derive which interface structures (like combinations/subsets) are relevant to useful structures (like variable interactions) using insight rules (like that 'adjacent features are likely to be dependent') & comparing possible usefulness structures
        - example: how to derive 'combinations' of 'variable interactions' as useful structures, given the insight rule 'adjacent variables are likely to be dependent'
          - 'adjacence' is 'similarity in position', and structures that are 'similar in position' are easier to fulfill intents like 'group', so 'combinations' are an 'adjacent' structure of this structure
            - the 'combination' structure also fulfills intents like 'isolate' for structures like 'dependent variables', and 'isolating related objects' or 'isolating objects of a type' are a useful function for various general/problem-solving/interim/core function intents
            - given that it can be adjacently used for various known useful intents, it can be considered a useful structure (after comparing it to the adjacently useful intent ratio of other possible useful structures)
        - workflow fit: this is similar to other workflows involving deriving useful/interface structures useful for other useful/interface structures or problem-solving intents, but with a filter for evaluating probability of usefulness compared to other structures

      - identify structures of determination (where once a structure is determined, the other structures dependent on it are also determined) & apply as 'reduction' structures of computation requirements in an interface query

      - generate maximally different perspectives to avoid over-incentivizing one perspective & its resulting error types, to apply as solution filters
        - example: in the 'find a prediction function' problem, maximally different perspectives would include:
          - 'find the right unique isolated variable interaction to equal the output variable'
          - 'check if the definition of objects is applicable'
            - if a 'variable' concept is not applicable to a particular structure, it will generate errors
              - example: 
                - if the 'sound' variable is only measurable by 'vibrations', it might be handled incorrectly, miss all the variation within the 'sound' variable, miss the fact that the 'sound' variable can act as an interface, and be a poor predictor of 'sound' variation & metadata like inputs/outputs
                  - the 'variable' concept refers to a 'unique change type', but it leaves out the 'related variable network' structure that all variables are nodes in & other structures relevant to that 'variable' definition, and would misidentify 'vibrations' as a change-determining variable rather than an attribute of the 'sound' variable, bc it would miss their interaction in the 'related variable network' inherent to a complete 'variable' definition, where usually a limited structural definition of 'variable' as 'unique change type' is applied
                - in the 'chihuahua/muffin' class identification problem, adjacent features arent isolatable bc they determine what adjacent features are possible (the structure of a skull determines what configurations of structures surrounding it are possible), but they are treated as isolatable (the correlation between bone/organs is treated as independent), whereas other variables are isolatable but are treated as one variable (damage to one eye/ear doesnt necessarily correlate with damage to the other)
                  - this is bc there is no 'requirement' structure requiring that any damage to one side be reflected in the other (the inherent symmetry can be distorted), but there are structures that 'can' require that (causes of organ damage)
                    - 'requirement' structures can be checked for using attributes of adjacent structures (does the skull seem to have a firm structure or would it necessarily change if another feature was removed)
              - not all variables treated as isolatable are actually isolatable, but with missing data they might seem isolatable
        - these perspective can be filtered by which would have the most impact on the solution success (solution success impact, as a variable that can limit or enable solution success)

      - find difference causes of interface structures (like concepts) and apply structures of them to create various solutions to filter as an initial solution space
        - example: find the reasons why data set points might differ (randomness, indicative of change in the underlying interaction, variation within expected/valid variable ranges) and create combinations of these reasons to explain the data set, by adjusting which points are included in the 'find a prediction function' problem input, which are excluded bc of reasons like 'random noise'
        - this is useful bc difference causes are a powerful structure in understanding why differences occur so they can be created/predicted as needed

      - find useful structures like units/ratios between change causes (reasons to change) vs. reasons not to change to justify changing a standard solution (like a linear function) to find an optimal solution (a better-fitting function)
        - example: 
          - the reasons to change may include reasons like that 'a data point would be better predicted if the change is applied'
          - the reasons not to change may include reasons like that 'patterns of changes of other functions that avoided this change type performed better' or 'the data point is an outlier'
          - structures like ratios between these change causes can be useful if each change cause contributes equivalent certainty so they can be treated like units
          - this is useful bc change causes from a standard solution are a powerful structure to help optimize a solution - if there is a reason to change a structure, its likelier to be reflective of reality

      - find target solution structures that lead to problem-solving processes even if they dont solve the original problem, like a target position that leads to change in a direction toward the original intended solution, even if the destination isnt reached

      - find structures of difference between 'false rewards' & other useful error structures of falsehood & the error structures they correct to apply as structure to fulfill the 'error-correcting' problem-solving intent
        - usually real rewards can be found to incentivize finding/generating/deriving a solution if its correct, so this shouldnt be necessary, but it can be more efficient than identifying/using real rewards to incentivize a solution/optimization

      - find the structures of primary default interface structures that are most useful across interface queries & workflows & apply those as default components
        - example: change + direction, priority + potential field, variable + concept type are examples of structures of interface structures, but some in particular are more useful than others, like 'perspectives' (filter with priorities) bc they fulfill structures of usefulness like 'capturing high variation' and 'reducing complexity' and 'applying importance structures' which are useful for various interim & core functions like 'find important objects' and 'understand a system quickly' and 'find hub variables', so apply these metrics as filters of these structures of primary interface structures
        - workflow fit: this is similar to other workflows involving finding useful structures, but specifically filters them by which are useful for fulfilling intents of interim/core functions that are commonly used in interface queries' sub-intents

      - combine a partially implemented interface query with gaps in implementation left for variation, where the sections implemented are known to be optimal for various sub-intents of the interface query
        - the pieces that are implemented can be on different interaction levels of the interface query
        - generalization: 
          - this can be generalized to other interactions between problem/solution structures which have clearly optimal implementations of sections of the interaction
          - it can be generalized further to other structures than 'partial subset', such as known optimal 'sequences' of problem/solution interactions or known optimal 'combinations' of problem/solution interactions
        - simplification: this can be simplified to adding a variable, allowing variation in which subsets or other structures are implemented & which can be changed for various implementations

      - interface structures that are adjacent (immediately preceding/following) to a solution so as to be causative or indicative of a solution can be identified as predictors or generators or identifiers of solution structures
        - if there's a perspective, function, change, pattern, etc that is often found around solutions, those can be used according to their position as predictors/generators/identifiers
        - this is similar to 'applying the solution as a symmetry or interface around which changes are applied while still qualifying as a solution', but applying the solution as a base or center where other objects relevant to it are adjacent, which may or may not be solutions, as a merged interface structure involving a combination of multiple interfaces, although the surrounding structures may also qualify as solutions
        - adjacence can be determined by number of steps separating the structures (for example, separating a question/perspective/useful structure & a solution), number of interface structures separating them, distance determined by some similarity metric, or other definition
      
      - find a structure (such as a perspective/function or network with nodes arranged by a certain distance or similarity metric) that would make solving a problem much quicker (or fulfilling another solution metric, like using available resources) and aim for that structure as the solution target to generate (so the problem becomes 'generate this useful structure' instead of 'solve the original problem')
        - for example, when a function network is organized by similarity in impact, its easier to see which nodes are higher impact
        - this can be extended by applying filters to find useful 'solution-adjacent' or 'adjacently solution-finding' structures that make a solution obvious or guaranteed/inevitable
          - structures like a particular way of organizing a network by some distance metric can make solving a set of problems trivial, which makes it more useful than a network organized in a way that solves one problem, other things being equal
          - structures that 'make solving multiple problems trivial' are useful targets for solution automation workflows, as a problem-solving intent of 'find structures that make solving the problem trivial'
      
      - store the optimal interface queries associated with a particular solution automation workflow to convert the 'build interface query' task into a 'find interface query in database' task, or store generative functions to find the optimal interface queries if any are stored, or derive the interface query in a more efficient way than interface query design logic
        - generalization: can be generalized to associations between any problem/solution structures

      - identify structures of error structures & their interface structures like meaning, for use in 'predicting structures', which is an interim function, or 'predicting error/solution structures', which is a problem-solving intent
        - example: when an extreme set of errors of a particular type usually precedes finding an interface, that can be used to predict which error structures mean that 'an interface is about to be found' 

    - basic solution automation workflows
      - trial & error
      - reverse engineering
      - break problem into sub-problems & merge sub-solutions
      - apply rules from other systems to see if they work in another system
      - apply machine-learning
      - use a rules/solution database & look up the answer

    - example of format/intent matching
      - formatting a 'tree' as a 'set of overlapping sequences' so functions can be formatted for different intents like in 'parallel processing'

    - add to input structures
      - input variable/trigger/requirement/component

    - add to output structures
      - limits on what a structure can be used to create
      - similarities/differences to inputs (inputs change can be preserved in outputs)

    - identify new interactions/structures
      - trying structures of structures that havent been tried yet (like how new words evolve as a 'combination' of other words to describe new experiences that are similar to both combined words)

    - 'testing/simulation' involves querying for related rules (like how 'gravity' rules are related to 'motion' rules so any change involving motion should have a 'gravity rule check' applied as a filter) & checking if they apply to relevant components (like how specific components are involved in 'motion', like 'energy', 'motion restrictions', 'motion functions', 'motion triggers/inputs/components')
    - this is an important process for checking if a structure is valid/consistent in a system, which is a useful function
    - this is different from basic testing, which is where a function is applied and the output is checked against an expected value, bc it involves testing for validity/consistency in a system context where the change is being applied

  - add to science

    - what is the connection between entropy (which Ive been using 'variance', 'potential', 'uncertainty' in place of at various points) and temporary information (information that is temporarily true, like electron position, rather than conditionally true, like laws of physics, or absolutely true, like rules governing quantum & standard physics interactions)
      - are black holes related to the output of accurate natural 'clocks' that formed
      - higher distribution of energy leads to higher entropy (possible states), but also a higher number of possible info interactions (which produce at least temporary certainties)
      - what is the relationship between entropy as 'possible' information, & 'probable' information
      - which of these possible states can be filtered out, either by probability, energy efficiency/stability, state connections, or other rules (how to add info of varying parameters to high entropy systems)
      - how to build a clock with consensus aggregated from various info sources that feed off each other in an input/output cycle

    - what junk dna could be added that would enable production of the most useful types of RNA/proteins & other components for immune system functions, repair processes, & other anti-illness processes

    - https://www.quantamagazine.org/mental-phenomena-dont-map-into-the-brain-as-expected-20210824/

      - why memory sections might not always be necessary
        - bc complex memory structures might only be necessary to represent complex sensory structures like overlaps/ambiguities, or necessary to represent chromological/sequential structures

      - why might functions not be mappable to isolatable brain regions
        - bc they should be broken down or combined into other functions (general, interim, common, interchangeable, core, etc) than those on the interaction level theyre examining

      - why might movement info be stored instead of sensory info:
        - bc movement is a proxy variable of sensory info reactions

      - why might metabolic regulation & memory formation be connected:
        - relation to available energy used for forming memories (excess energy is prioritized for tasks like memory)
        - relation to rewards for using energy a particular way such as in forming memories
        - relation to regulatory schedule linked to sleep cycle & memory formation during sleep
        - distortions in metabolic function are prioritized in memory formation

    - "In the developing immune system, double-stranded breaks enable pieces of DNA to recombine and generate a diverse repertoire of antibodies"
      - examine how states that trigger useful functions like stem cell production or antibody production can be triggered

    - explore how much functionality can be developed by using incentives
      - if you create rewards like dopamine when a dysfunctional cell process is triggered or replicated artificially, does the system re-build or correct or re-learn that functionality
        - like when cholesterol prevents immune system from reacting to cell death, can you force the immune system to re-learn its original reactions, forcing it to react to cell death by associating that reaction with rewards or some other trigger like inflammation/pain that would correct its dysfunctional state?
        - if not, can you apply a change in the opposite direction (triggers of an 'over-reaction' error type to cell death, but only enough to move it back toward its original state)

    - check how much of the 'bio interactions' with a 'rules database' is available, to predict missing interactions from the rules database
      - this could be used to predict which combinations of structures (states like genetic mutations, bio system & cancer states, attributes like acidity, components like microbes/enzymes, functions like inhibitors, inputs like energy sources) will switch off cell proliferation processes & which will have the opposite effect
        - this should be able to identify when the immune system will hinder treatment, when oxygen deprivation will be an enabler of a disease, when pathogens will be synergistic/antagonistic, etc
        - it should also be able to identify which states are adjacent/accessible that the system can be converted to, which would have beneficial effects like 'neutralizing negative effects as defined in a particular state' 
          - conversions such as 'find a awy to standardize neoantigens so theyre similar to neoantigens targeted by an existing treatment' or 'find a way to standardize tumors/immune cells by giving them inputs that will trigger a state sequence that produces a more standard or more treatable tumor' or 'find a way to make tumors seem more like pathogens already defended in memory cells' or 'engineer microbes that feed off cancer cells and then travel to the gut or eat each other or are eaten by other microbes/enzymes' or 'find neurons that map to nerves around the tumor and stimulate those neurons' bc standardization takes the risk & the work out of applying immunotherapies & other customized medicine
          - standardizing immune cells could help reduce variation in immune responses to treatments: https://medicalxpress.com/news/2021-09-vaccine.html

    - autoantibodies as possible reaction to 'not having any actual pathogens to attack so they start attacking the immune system components which are just nearby or easier to attack than pathogens or have structural damage that disrupts their immune functionality' 
    - what alternate inputs have the outputs of useful structures that have antitumor or antimicrobial activity
      - what can produce components (enzymes/antibodies/t-cells), functions, or attribute states that eat cancer cells ('adapting to mct oil')
      - what combinations of structures are particular useful in general or specifically against a particular pathogen/condition
    - what other pathogens/conditions are synergistic with other conditions (do specific fungal/bacterial infections help cancer, and which ones if its a specific set)
    - what is required to make the body 'allergic' to a substance like a cell membrane attribute of specific cancer cell types 
      - is this the same as a normal immune response
      - is it similar at all to a 'pain' response alerting the immune system to a problem, and what can produce a 'pain' response if that response is useful
      - what other attributes could cancer cells have that make certain compounds likelier to bind to them or surround them to cut them off from energy sources or separate the tumor into attackable pieces (surface structures, attributes in various solutions like fat/water/mucus/blood, response to enzymes/pathogens)
      - what ratios (stress, acidity/alkalinity, enzyme ratios, energy ratios, cell distribution ratios, blood waste ratios, kidney/liver/pancreas/digestion function ratios, immune cell ratios) and other structures are associated with cancer progression/triggering
        - what ratios do some anti-cancer foods like almonds have that other foods do not

  - add to error-finding methods
    - identifying & generating known useful structures like 'symmetries', 'variables', 'subsets', 'interchangeable alternatives', 'maximally different inputs' & 'bases' & 'type/phase shift thresholds'
      - identifying & generating combination structures of useful structures like 'maximally different values around bases'
    - identifying gaps in known useful structures explaining data points (where data points arent explained by those known structures) & generating inputs in those gaps other than those data points

  - add to conceptual math
    - example of a conceptual math operation that builds a boundary structure leaving an inevitability of a matching concept (numbers) filling the structure
      - the concepts of 'missing', 'multiple/more', 'unit', 'type', 'identifiable as similar/equal/different' and 'difference in amount' allow for/require/build the concept of 'numbers'
      - also functions like 'compare' or 'reduce' or 'expand' require the concept of 'numbers' when comparing objects of that data type or objects having a quantifiable attribute

  - add to causation variables
    - ability to change (if a variable cant be changed, it is less causative for problem-solving intents)

  - add to info problems
    - this manipulates:
      - audience objects:
        - ego
        - assumptions (about patterns, what you would notice/figure out)
        - attention
        - feelings 'opposite' to logic (safety, confusion)
      - using objects like distractions, activations, distortions, core structures like combinations/sequences, complexity, patterns, input/output similarities/alternatives (complex/simple implementations), logic, patterns of logic, logic avoidance, jokes
      - to produce:
        - errors in expectations (in order for the audience to expect y, they have to have assumption x, as x is an input to y)
      - these important variables can be identified by identifying the inputs to these objects
        - what 'input' is 'required' for this expectation error to happen? (an assumption)
      - https://www.smithsonianmag.com/arts-culture/teller-reveals-his-secrets-100744801/?all&no-ist

  - add to nn

    - concept of 'comparative features': features that were enough to differentiate a category in the training set but not in test, bc they have too many overlaps with other category feature sets
      - adding sub-parameters allows variation within these overlaps to be identified/differentiated, using any remaining differentiating features that are still available in inputs but dont change overall input/output connections (change direction, average change rate, etc)
        - https://www.theregister.com/2021/09/02/imaginary_numbers_help_ais_solve/

    - weighting & position make emergent structures like functionality probable & possible in a neural network
      - identify all the emergent functionality/attributes/structures in a neural network with different input variations & parameters
      - identify how these structures could interact (coordinate, align, or neutralize each other) to create other interaction level of emergent structures
      - identify how these various interaction levels & the interaction structures defined on them as possible/probable would create possible/probable solution/error structures
        - avoiding error structures like 'too many differences in outputs of nodes with similar input info (feature) or similar potential info (info required to identify a feature)'
      - identify how these structures can be optimized to avoid error structures or prioritize solution structures
        - like 'prioritize applying weights to connect nodes to create a particular similarity/difference type'

    - neural nets should have a target structure (like a target 'variable interaction structure') based on understanding of variable interaction probabilities & other useful structures that their emergent structures comply with and that their structures can optimize for extracting from versions of input data, deriving the neural network structure from this target structure & filtering it based on the emergent structures that would optimize info extraction from input data versions

  - add to math

    - https://www.quantamagazine.org/how-a-mathematical-paradox-allows-infinite-cloning-20210826/

      - how to generate the target solution of 'a source of duplications'
        
        - start at the enabling structure of duplications (multiple sets having different final direction value):
          - find 'overlap' or 'combination' states (with sets including multiple different final operations) and find a way to connect them with standard objects (countably infinite sets with a final value determined by the final operation's direction) using allowed operations (rotation)
        
        - start at the standard structure (one set having same final direction value):
          - apply adjacent transforms like rotation to the standard structure (countably infinite sets that are complete, having their final value determined)
        
        - identify the highest-variation changes (like changes in final values between adjacent states - since one state has north/south/east nodes, the next state has only east nodes) as a possible source of changes for other values (a change in one value can produce a change in another value if theyre relevant)
      
      - generate the standard structure of countable infinite
        
        - use 'irrationality' to generate the standard structure of countable infinite sets in the first place (enough difference in rotation angles to not generate an uncountable infinity, but restrictions on the angles in that they remain static & restriction in movement avoiding the opposite of the previous direction)

        - during the creation of a set of points having the same previous final direction, there will be states where the previous directions of points in the state are maximally different (not every state will have the same previous direction) bc a countable infinite set is not a series of repeating the same rotation, and differences in corresponding rotations across sets are allowed

      - how to identify the standard structure (countable infinity) as a useful structure
      
        - its required to use the standard structure to base transforms off of (like a countable infinity) bc its a subset of the original, and you have to use the original structure as an input to generate the target solution structure
          - identify structures (components/attributes) of the sphere which can be used as components/inputs of the solution
            - subsets of the sphere
            - operations like 'rotation', 'repeat infinitely'
            - uncountably infinite points
          - apply 'structure' interface to find possible standard structures like 'differences' in these structures of the sphere
            - identify differences in relevant attributes ('number of points', 'location of points', 'generative method of points') that different structures ('subsets') of the sphere can have
              - attribute: cardinality of infinities
          - identify whether differences in those attributes would be useful (in producing a useful difference/similarity)
            - what is the relationship between countable & uncountable infinite sets
              - can one infinity type be generated from another
                - can an uncountable infinity be generated from a countable one
                  - this seems like it could be possible, identifying 'countable infinities' as a possible useful structure
              - what ways can countable infinities be generated that makes them exclusive (no repeated points)
              - what is adjacent to a countable infinity if generated a particular way that is not adjacent to an uncountable infinity
              - what functions does a countable infinity have that an uncountable infinity does not

      - question
        - is 'infinity' the same as 'all possible values of that type'

  - add to govt

    - if the taliban dont believe theyre stupid, they should try their own tricks on each other and theyll see that they work, so they can verify how similar they are to their victims
      - they can try the simplest tricks like 'violent threats to get compliance' to see if theyll comply once theyre threatened, or 'repeating things' to see that they are likelier to believe things that have been repeated a lot bc theyre stupid, which is how they got indoctrinated in the first place, and its how their prophet started to believe the ridiculous things he did, by repeating his fantasies to himself so often that they seemed true bc his brain was extremely stupid
      - help the taliban see other business opportunities than violent govts, which may be the lowest-cost business opportunity in their neighborhood, but has high future costs in that they run out of people to oppress and they lose the potential higher profits from other opportunities, like growing different varieties of plants with drug compounds (non-addictive drugs, drugs that can treat conditions, drugs that can produce a particular brain function, etc)
      - they can also look at who theyre helping to find out how stupid they are 
        - their actions help Russia, virtue-signalers on social media, anyone who wants to hate their people (bc theyre attacking their own people & always have, and they dont have solutions except violence, which animals could think of too), and anyone who wants to profit off of war/poverty/disease/oppression (China, the US, Russia, other hostile foreign govts & entities)
      - if you want the taliban to switch to farming/engineering drugs, you have to make it easy - give them education on how to do it & other resources, so its even easier than violent govt
      - same with other revenue changes, eventually leading to legal revenue sources
      - if their prophet wasnt a loser he would be able to promise them a better fantasy like 'infinities' of virgins (one in every neighborhood, with maximum genetic variation, and they have to fight over him first, and first every other man doesnt exist), but he was an idiot who couldnt think of anything better, or he thinks his followers dont deserve more than 72, and he would be able to explain using physics how to get to heaven, such as how to travel to other universes where this situation would be the stable/efficient situation that would actually happen in other universes
      
    - suppliers shouldnt be supplying input resources like funds (the possibility of a solution), but solution metric/goal-based output resources like solutions (a guarantee of a solution), which can form a basis for a currency, in addition to adjacent solution inputs like insights

    - feudalism/castes built around access to & investment in computational methods/tools (communication, regulation/legislation/enforcement, quantum computing, optimal storage, compression algorithms, optimal data structures, powerful chips, pre-computations, storage of prioritized info, info prediction/derivation/finding/generating/learning/understanding/organizing/integrating, task automation, cryptographic blockchain-based asset-tracking/verification, security creation, error creation, hacking/theft, experimentation tools, people manipulation, infinity computations to reduce overall computational complexity by identifying an infinite set by differences from other infinite sets, info falsification) which can replace & compete with each other
      - each entity that survives will have to have a competitive implementation of all of these if they dont want to be susceptible to an attack from any of them
      - predators arent good at solving problems bc they always use the same tactics, which work enough times on other predators to keep using in all circumstances, even when they dont work - lying, stealing, forcing, killing 
        - bc they keep re-using the same sub-optimal solutions, their brains arent evolved and they cant compete with smart people, theyre dependent on smart people who have the only power that matters anymore, and if smart people collude to prevent them from accessing solutions, they dont get solutions bc they cant generate them on their own, even when you explain everything to them & they have all the info they need (which they already did before being educated, they just couldnt use the info they had to derive solutions bc they cant think at all), & theyll fail without smart people
        - predators would still be struggling & failing to invent fire if it wasnt for smart people to figure it out & copy
        - solutions to this problem
          - if smart people collude to hide their work permanently, they would be able to destroy all the predators by depriving them of solutions
          - smart people can take pity on predators and try to make them smart so they can grasp meaning, become independent of smart people & independent of crime, & solve problems on their own

  - when is it optimal to store a mixed structure of varying specificity (like a type, intent, cause & a specific example)
      - when there are potential uncertainties to resolve, like whether the example represents a new error, type, or variable, bc the example doesnt fit known structures

  - all primary interfaces can act like the problem-solving interface (start solving problem from the concept or structure interface and integrate all info back into that interface & frame the solution in terms of that interface) but the meaning interface (the interface interface) is the most powerful

  - apply concepts to structures

    - concept of attention in structures
      - mixed interim high-variation & high-similarity structures tend to maximize attention
    - examine error type of conflating intent & requirement
    - consciousness as choice to move between neural nodes (rather than being directed) required:
      - the development of alternative node paths performing equal/similar functions, requiring:
        - the development of excess resources, delaying required decision time (making immediate decision unnecessary, avoiding a forced decision), requiring:
          - the existence & application of previous efficiencies & functions for alternative evaluation, energy storage, storage-checking, & energy requirement-identifying
      - the cause could be framed as structures such as an 'efficiency stack' or 'energy maintenance functions' or 'alternative options' or 'navigation/motion control' or 'lack of requirement/need'
    - examine similarity (alignment/overlap) structures between: 
      - extremely different components (when an error type is an incentive or a function used for other intents) 
        - when the solution format of some problem has similarities to the error type, like when you need randomness so errors generating randomness are a possible function to use for that intent
        - contradictory/opposite components (have some metric in common, with opposite values)
    - examine the distortion vector paths that adjacently decompose a data set into a prediction function from a base point/function set

  - add examples of:
    - mapping to structures & identifying contradictions its safe to ignore for applying a structure
    - system/object/rule/type change patterns
    - query examples for use cases like:
      - lack of information stored (match problem of type 'information lack' with interface query 'check pattern interface for similar patterns')
      - query problem breakdown & integration diagram
      - calculating various different problem breakdown strategies first before executing normal query-building logic for each
    - example of how to predict most interactive/causal concepts in a system

## diagram
  
  - diagrams:
    - error types
    - network of formats
    - efficiencies
    - alternate interfaces (information = combination of structure, potential, change or structure, cause or structure, system)
    - chart type: overlaying multiple 2-dimension variable comparisons to identify common shapes of variable connections (density of points added with a visible attribute like more opacity)
    - structures of emergence
      - example: 1-1 input/output relationship up an interaction layer, where extra resources that dont dissolve immediately on the higher interaction layer aggregate & form core structures like combinations, where interactions between combinations & sequences have different dynamics than the individual output interacting with other individual outputs
    - how emergent functionality/attributes come from interaction structures (sequences & layers)
    - intent-matching
    - interface overflow (to sub-interfaces), interface foundation
    - workflow
      - function to identify relevance filter ('functions', 'required') from a problem_step ('find incentives') for a problem definition, to modify problem_steps with extra functions/attributes ('change_position') to be more specific to the problem definition ('find_incentives_to_change_position') for problem_steps involving 'incentives', so you know to use the function_name to modify the problem step if it's between the type 'functions' and the object searched for 'incentives'
    - conceptual math interface query
      - use lattice multiplication as standard example, other than core operations (add/multiply mapped to language, concepts like irreversibility/asymmetry mapped to math)
    - interface conversion, matching, starting point selection (applying structure, checking if relevant information is found)
    - sub-functions of core functions with distortions (identify/filter of find)
    - dimension links higher than 3d that are depictable in the same network space
      - should show variables that impact other variables, the change rates of these relationships
      - overall impact should be calculatable from these relationships
      - should show similar movements for correlated variables
      - should show skippable/derivable variables (variables that can be resolved later than they normally are)
      - should show meta forces for overall trends in change rules (direction of combined variable forces)
      - should show limits of measurability & threshold metrics
    - specific concepts, core functions, concept operations (combine, collide, connect, merge, apply), ethical shapes
        - variable accretion patterns (how an object becomes influenced by a new variable, complex system interaction patterns, etc)
        - potential matrix to display the concept
          - map parameter sets to potential matrix shapes 
        - cause (shapes & ambiguity), concept (evolution of concepts, networks, distortion functions)
        - argument
      - system layer diagram for each interface to allow specification of core interfaces & other interface layers (interface interface)
        - system layer diagram for structures to include layers of structures 
          (beyond core structures like curves, to include n-degree structures like a wave, as well as semantic output structures like a key, crossing the layer that generates info structures like an insight, a probability, etc)
    - map variable structures to prediction potential for problem types, given ratio of equivalent alternate signals
    - vertex variable structures
      - quantum physics, prediction/derivation tools, build automation tools, testing tools, learning/adaptation tools, system rules, computation power are all vertex variables of information, since they can generate/derive/find information
        - which structure (sequence, network, set, or cycle) of vertex variables is most efficient
    - core component attributes: identify any missing attributes/functions that cant be reduced further
    - absolute reference connections with metadata structures like networks/paths


# content/config

    - import insight history data to identify insight paths (info insight paths like 'lie => joke => distortion => insight', system insight paths like 'three core functions + combine function with this definition + n distortions to nearest hub')
    - define default & core objects necessary for system to function (out of the box, rather than minimal config necessary to derive other system components & assemble)
      - add default functions to solve common problem types
      - alternate utility function implementations have variation potential in the exact operations used to achieve the function intents, but there are requirements in which definitions these functions use because they are inherent to the system. For example, the embodiment may use a specific definition of an attribute (standardized to a set of filters) in order to build the attribute-identification function using a set of filters - but the general attribute definition is still partially identifyd in its initial version by requirements specified in the documentation, such as a set of core attribute types (input, output, function parameter, abstract, descriptive, identifying, differentiating, variable, constant), the definition of a function, and the definition of conversion functions between standard formats.
    - systematize definitions of info objects
      - include analysis that produces relationships of core objects like opposites to their relevant forms (anti-symmetry) in addition to permuted object states (asymmetry), such as an anti-strategy, anti-information, anti-pattern
      - organize certainty (info) vs. uncertainty objects (potential, risk, probability)
      - make doc to store insight paths, counterintuitive functions, hidden costs, counterexamples, phase shift triggers
      - add technicality, synchronization, bias, counterintuition, & certainty objects leading to inevitable collisions
        - error of the collision of compounding forces producing a phase shift
        - lack of attention in one driver and false panic in a second driver leading to a car crash given the bases where their processes originate
      - define alignment on interfaces (compounding, coordinating, parallel, similar, etc)
      - add core info objects (core strategies, core assumptions) so you can make a network of graphs for a system
    - add function logic for:
      - concept analysis:
        - how new concepts (gaps in network rules) evolve once structure is applied to prior concepts 
      - interface analysis:
        - limitations of interfaces & how to derive them
        - how rules develop on stability & how foundations are connected & destroyed
        - explainability as a space limited by derivable attributes from data set & cross-system similarity
        - vertex definition & give examples (as an intersection/combination of interface variables, such as determining/description(compressing)/generative/causative/derivation variables), around which change develops
      - change analysis:
        - generated object change types
          - constant to variable
          - variable to removal of assumption in variable type/data type
    - examine implementing your solution type (constructing structures (made of boundary/filter/resource sets) to produce substances like antibodies, using bio system stressors)
    - resolve & merge definitions into docs/tasks/implementation/constants/definitions.json
    - update links
