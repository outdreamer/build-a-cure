# to do

  - update links
  - integrate rules from diagrams to relevant documents
  - organize 'to do' items from analysis & code to to do list as function list with dependencies
  - integrate changes from solution_automation_analysis.py claims to repo
  - integrate logic from core_analysis/*
  - integrate problem_solving_matching.md & analysis_examples.md & specific_methods/*
  - de-duplicate logic
  - organize specific interface analysis definitions/logic/questions answered/problems solved/examples
  - write query to compile functions in interface definitions (after definition, functions & answer questions section), as well as identify/build/find/derive/change attributes/types/objects/structures in definition
  - use examples in repo as test cases
  - give example of generating problem types by applying structure
    - for instance, a common problem type is a mismatch/imbalance
      - by applying the 'mismatch' to the cost/benefit relationship, you get an 'inefficiency' problem type, which can be defined as a mismatch/imbalance between the cost & benefit, favoring the cost side (the negative object out of (cost, benefit), associated with problems)
  
  - examples of objects on different interfaces
    - potential (risk chain, uncertainty) 
    - causal objects (causal degree, cause, dependency)
    - information objects (contradiction, implication, perspective, similarities/differences)
    - structure objects (direction, boundary, node, connection, filter, extreme)
    - system objects (inefficiency, incentive, error, alternative, opportunity, conflict)

    - the reason these abstract objects fit on a particular interface is because they describe specific interactions:
      - a conflict may occur on every interface, but in the system interface, the interactions of a conflict with other objects are the clearest, closest to its most concise definition, & capture the most variation, whereas on other interfaces, the conflict object can take many forms


## define

  - expand on core math-language operation mapping (like add: combine, subtract: differentiate (isolate difference), multiply: expand by, divide: standardize by) with interface queries for core operations

  - diagram to document sub-functions of core functions with distortions

  - organize certainty (info) vs. uncertainty objects (potential, risk, probability)

  - document time structures (concave time explaining compounding similarities up to a point of maximum concavity, a structure that can separate from the other space-times)

  - document vertex definition & give examples (as an intersection/combination of interface variables, such as determining/description(compressing)/generative/causative/derivation variables), around which change develops

  - document questions to test system filters

    - why do phase shifts happen - bc of the ability for aggregated information to be measured as something else 
      - example: molecules identifiable as a set, data identifiable as a cluster, pattern identifiable as an emergency

    - what are the aggregate effects of many errors in selection of algorithms/parameters/processing/deployment - what phase shifts emerge from repeated or interacting error types?

    - why do you arrange dimensions at 90 degrees? to examine the full interaction space of all possible combinations of the two variables

    - why are polynomials with a leading coefficient of one & having optional zero coefficients capable of being multiplied & added to give the roots to the system of equations?

        - bc scaled versions (through multiplication) and combinations (through addition) can position leading coefficients to be 1 while also positioning trailing coefficients to be zero
        - is there a polynomial coefficient set that you cant multiply or add in a way that makes a coefficient in a position to be one and every coefficient after it except the solution coefficient to be zero? 
          no, bc that would mean the leading term cant be solved
        - once you have leading coefficients equal to one and the trailing coefficients equal to zero, the system is solved for each variable
        - why would you try to solve for each leading term in a matrix? bc they are ordered at that point (formatted to have the same positions in each row) and the solution is also ordered (on the right side)
          - using the concept of position to produce additional organization of information, you can benefit from the alignment of the variable positions by isolating each variable (transforming with multiplication & addition of coefficients until the variable solved for in each row has a coefficient of 1 and all other coefficients except the solution are zero)

  - definition import function

  - default definitions
  
    - alternate utility function implementations have variation potential in the exact operations used to achieve the function intents, but there are requirements in which definitions these functions use because they are inherent to the system. For example, the embodiment may use a specific definition of an attribute (standardized to a set of filters) in order to build the attribute-identification function using a set of filters - but the general attribute definition is still partially determined in its initial version by requirements specified in the documentation, such as a set of core attribute types (input, output, function parameter, abstract, descriptive, identifying, differentiating, variable, constant), the definition of a function, and the definition of conversion functions between standard formats.


  - define core operations: apply (expand one by the other), inject (input one to the other), embed (attach one as a component/attribute of the other)

      - power dynamics

          - rules: 
            - if a person abuses their power without contribution, the others will notice and take their power away

        - truth (type of power in the form of constant, reliable information) dynamics
          - the truth has a limit on how much it can be stretched or re-used before over-dependence will make it false or reveal its limits

        - trust (type of power in the form of delegation of an unenforced opportunity/responsibility) dynamics
          - rules:
            - there is an incentive to trust people in an absence of resources
            - there is an incentive to trust people to create resources (positive expectations, as an input to peaceful coexistence)
            - there is an incentive to not trust people if they have resources like:
              - information about signals of untrustworthiness
              - fear response or memory of untrustworthy behavior
              - logical knowledge of incentive structure to abuse trust

        - the operation of injecting truth into trust on the power interface means applying the truth dynamics as an input to trust dynamics
          - example: what happens when trust is embedded in a context, and one side has more information about untrustworthiness?

  - systematize your definitions of info objects, to include analysis that produces relationships of core objects like opposites to their relevant forms (anti-symmetry) in addition to permuted object states (asymmetry), such as an anti-strategy, anti-information, anti-pattern

      - add technicality, synchronization, & certainty objects leading to inevitable collisions
        - the collision of compounding forces producing a phase shift
        - lack of attention in one driver and false panic in a second driver leading to a car crash given the bases where their processes originate
      - define alignment on interfaces (compounding, coordinating, parallel, similar, etc)
      - start with these info object transforms that filter the most info: opposite, invalidating, symmetric, core, aligning, boundary-breaking, phase shift activating, structure stabilizing, constant changing, converging
      - add core info objects (core strategies, core assumptions) so you can make a network of graphs for a system

    - add object metadata:

      - spaces where the object can change:

        - attribute spaces: 
          - default space (probable default position in a system, etc)
          - potential/probable space
          - adjacent space (accessible positions using minimal work)
          - extreme space (attributes/functions at its limits)
          - partial space (attributes/functions with subsets of its definition)

        - object spaces:
          - interaction space (what it can interact with)
          - efficiency space (set of efficient positions)
          - perception space (what it can seem like)
          - system space (what contexts it can exist in)
          - query space (which queries can produce it or its changes)

  - space can mean:
      - the interface filter including structures for a given attribute/object like cause
      - the impact of the attribute/object on other interfaces (impact of cause on other interfaces, like info problems)
      - an interface applied to another to create a space (causal interface framed as a set of problem spaces)
      - a structure with its own prioritized directions or other rules specific to the structure

  - add note on evaluating object attributes, plus the ability to occupy invalidating positions/structures or fulfill invalidating intents of a system, and system requirements for those objects (invalidating position/structure/intent) to be possible

      - example: 
        - object attributes: a chemical on its own
        - system position: a chemical adjacent to another chemical in a system with high temperature
        - system structure: a system designed to make any adjacent chemicals explode, vs. a system that standardizes chemicals to a harmless format
        - system position & structure: a chemical with an extra electron at a position in the system where an extra electron would cause an explosion

        - "Similar logical patterns are absent in SARS-CoV-2, indicating that the virus evolved naturally." - the evolution of a virus to fit within certain systems confirms that changing the system metadata (inputs, structure, side effects, priorities, functions) invalidates the virus without invalidating the system
          - removing/adding the transforms that made the virus deadly/innocuous to a system
          - sending type signals within a contained limit around the virus to give the impression of systems that it wouldnt be deadly in
          - changing the position of a virus (so necessary bacteria interpret pathogens as energy sources)


## document 

    - document test questions

      - questions to test system filters

          - why do phase shifts happen - bc of the ability for aggregated information to be measured as something else 
            - example: molecules identifiable as a set, data identifiable as a cluster, pattern identifiable as an emergency

          - what are the aggregate effects of many errors in selection of algorithms/parameters/processing/deployment - what phase shifts emerge from repeated or interacting error types?

          - why do you arrange dimensions at 90 degrees? to examine the full interaction space of all possible combinations of the two variables

          - why are polynomials with a leading coefficient of one & having optional zero coefficients capable of being multiplied & added to give the roots to the system of equations?

              - bc scaled versions (through multiplication) and combinations (through addition) can position leading coefficients to be 1 while also positioning trailing coefficients to be zero
              - is there a polynomial coefficient set that you cant multiply or add in a way that makes a coefficient in a position to be one and every coefficient after it except the solution coefficient to be zero? 
                no, bc that would mean the leading term cant be solved
              - once you have leading coefficients equal to one and the trailing coefficients equal to zero, the system is solved for each variable
              - why would you try to solve for each leading term in a matrix? bc they are ordered at that point (formatted to have the same positions in each row) and the solution is also ordered (on the right side)
                - using the concept of position to produce additional organization of information, you can benefit from the alignment of the variable positions by isolating each variable (transforming with multiplication & addition of coefficients until the variable solved for in each row has a coefficient of 1 and all other coefficients except the solution are zero)

    - document explainability as a space limited by derivable attributes from data set & cross-system similarity

    - function for threshold value selection

    - examine whether new concepts (gaps in network rules) evolve once structure is applied to prior concepts 

    - make doc to store insight paths, counterintuitive functions, hidden costs, counterexamples, phase shift triggers

    - document how rules develop on stability & how foundations are connected & destroyed

    - document generated function types
      - decoy rules that consider probable usage, so usage follows the actual rule
      - cost-based system rules
        - avoiding assumptions or other objects where the cost of being wrong is too high to recover from 
          - in a case with multiple alternative explanations, but one is very high-cost if it's true or false, so assuming anything that rules it out cant be assumed without a high ratio of information or high number of indicators
        - cost as an aggregation/interaction rule (lowest cost routes should be assumed first)
        - cost that exceeds the value of intent should be assumed to be either false, unlikely, developing into a more efficient rule, being interacted with from another object/function/attribute, or being destroyed

    - organize notes on embedded/chained interfaces (which interfaces to use first when describing each primary interface, to produce the formatted & filtered information likeliest to be useful in the most situations to produce the default interface network)

    - document generated object change types
      - constant to variable
      - variable to removal of assumption in variable type/data type

    - document objects outside of system context

      - what types of objects/functions/attributes survive outside of a system that isn't closed by default, and to what extent

      - what interfaces capture the objects outside of a measurable system context with potential for information (maintenance of a fact for enough time & space to be measured or depended on)
        
        - potential

          - probability of being interacted with by a system
          - probability of decay without a host system
          - lack of information (lack of position, structure, time, etc) or lack of measurable information (changing too fast for an observer to interact with it)

        - attributes

          - opposite: everything outside of systems is:
            - not the system
            - not yet/anymore in the system
            - not compatible with the system (unmatching elements)
            - not valid in the system (like everything that cant be proved or controlled in/by a system)

        - cause 
          - generators of systems or generator side effects or system side effects

    - document interface math examples, like standardization of all distinct components into their own interfaces, rather than within a system context
      - rather than framing the behavior of objects in a system, you can:
        - remove the assumption of the system limits forcing interactions
        - frame each object on its own interface (containing all its possible forms, variables, attributes, generators, cooperative contexts, etc)
        - compute the interactions of those interfaces


## function list

  - after identification functions

    - import rules for selecting interfaces to solve a problem on

      - determine minimum information
      - query for rules making inferences from available information sets
      - Function interface helps find unused functions
      - Intent interface helps predict system priorities & find exploit opportunities
      - System interface helps find efficiencies
      - Pattern interface helps find insight paths/similarities

    - import insight history data to identify insight paths 
      - info insight paths like 'lie => joke => distortion => insight'
      - system insight paths like 'three core functions + combine function with this definition + n distortions to nearest hub'

    - network design favors an adjacency definition that differentiates features
      - to get around this, build in a concept of default core objects like boundaries/limits/intersections to the network structure or data propagation (send data on possible boundary line positions) to look for & focus on those first rather than continuous sets of adjacent high-variance, pattern-containing features
      - why would patterns like textures make it through as a semantic filter - bc the repetition is interpreted as significant by network design, or the texture is likely to be located in more data subsets than a shape
      https://www.quantamagazine.org/where-we-see-shapes-ai-sees-textures-20190701/

    - function to detect patterns in queries & outputs to optimize queries & find insight paths to improve response time

      - example: 3-step jumps with direction change, navigating across a certain pathway in standard structures across interfaces, starting with system then cause & intent, etc
      - this has to identify & remove unnecessary steps that dont change the output
      - identify & replace with faster ways to get to the output without changing the output
      - test cases to determine if output would be changed by removing a step and/or replacing it with another step

  - abstract functions

      - derive combinations & make sure you have full function coverage of all important combinations

        - check codebase function index for combinations
        - check that you have sample data in json for each combination

      - attribute/object/function match functions
      - standardization network-framing function to describe a system as a network (the standard structure) & position each object, identifying connecting functions
      - system analysis function (identify boundaries, gaps, limits, layers, incentives/intents/questions, & other system objects)
      - isolation function, representating function/attribute changes independent of system context with respect to position or time (snapshot/state or subset)
      - function to define (isolate an object/concept/function for identification, identify definition routes)

## content

    - finish intent/change type calculation for a system intent
    - selecting optimal combination interfaces to start from when solving problems 
      (how many degrees away from core functions, specific layers or sub-systems, what position on causal structures)
    - key questions to filter attention/info-gathering/solution
    - key functions to solve common problem types
    - development of key decision metrics (bias towards more measurable/different metrics rather than the right metric)
    - trajectory between core & important objects
      - example of choosing inefficiencies/exploit combinations in a system
    - research implementing your solution type (constructing structures (made of boundary/filter/resource sets) to produce substances like antibodies, using bio system stressors)
    - emergent combinations of core functions (include derivation of invalidating contexts for core functions)


## examples to make

  - include example workflows with example problems
    - include example of how to generate other workflows (different starting/ending points & trajectories)
  
  - give examples based on the same default example for each analysis type
    - the default example can be a prediction function
  
  - add examples of math automation

  - give an example of mapping an invention & insight on the abstract network

  - give intent combination example with actual functions

  - give example of each type of problem-solving workflows

    - workflow 1:

      - finish function to determine relevance filter ('functions', 'required') from a problem_step ('find incentives') for a problem definition, to modify problem_steps with extra functions/attributes ('change_position') to be more specific to the problem definition ('find_incentives_to_change_position') for problem_steps involving 'incentives', so you know to use the function_name to modify the problem step if it's between the type 'functions' and the object searched for 'incentives'

      - finish function to get all codebase functions & store them in a dict with their type, context/usage, and intents, just like functions are stored in the problem_metadata.json example for workflow 1
      - finish common sense check
      - finish defining objects in object_schema.json
      - finish organizing functions.json by type, with mapping between general intent functions like 'find' to specific info-relevant terms like 'get'
      - add common phrase check & filter problem steps by repeated combinations with common phrase check
      - finish get_type function to map info to structure using the new functions.json organization
      - finish apply_solution to problem_definition using problem_steps
        - involves building a function to evenly distribute objects (like information/types), given problem positions/agents/objects


## diagram

    - make core function graph (apply, find, build)

    - interface query visuals
    - interface traversal flow diagram
    - interface conversion, matching, starting point selection
      - checking if relevant information is found

    - make diagram for dimension links higher than 3d that are depictable in the same network space
      - should show variables that impact other variables, the change rates of these relationships
      - overall impact should be calculatable from these relationships
      - should show similar movements for correlated variables
      - should show skippable/derivable variables (variables that can be resolved later than they normally are)
      - should show meta forces for overall trends in change rules (direction of combined variable forces)
      - should show limits of measurability & threshold metrics

    - finish diagrams for specific concepts, core functions, concept operations (combine, collide, connect, merge, apply), ethical shapes
      - chaos & ethics graph
      - variable accretion patterns (how an object becomes influenced by a new variable, complex system interaction patterns, etc)
      - make diagram of potential matrix to display the concept
        - map parameter sets to potential matrix shapes 
      - finish diagrams for intent (more examples of matching structure with intent), cause (shapes & ambiguity), concept (evolution of concepts, networks, distortion functions)
      - diagram for argument

    - finish informal fallacy diagrams: https://en.wikipedia.org/wiki/List_of_fallacies

    - make a system layer diagram with interfaces to allow specification of core interfaces & other interface layers (interface interface)

    - make a system layer diagram for structures to include layers of structures (beyond core structures like curves, to include n-degree structures like a wave, as well as semantic output structures like a key, crossing the layer that generates info structures like an insight, a probability, etc)

    - add interface diagram & interface query map
      - interface query map indicates position of interfaces to query
        - the position of interfaces is determined by intent of problem/solution and cost/optimization metrics and available information or testing/derivation (information capture/generation) resources
        - filter (function structure as a base) & prioritized focus & potential ranges

    - integrate the concept of an 'interference network' - to always be calculating what something is not, so you have backups to interfere if one interface is sub-optimal or insufficient to host potential
      - if conceptual interface says to take a particular step, inject an opposing interface to add variance to the calculation approaching randomness (like emotions as a supplemental variance source to offset logic inadequacies)

    - add conceptual math diagrams
      - use lattice multiplication as standard example, other than core operations (add/multiply mapped to language, concepts like irreversibility/asymmetry mapped to math)
      - use intent & system filters & concepts as a way to reduce solution space from defaults (find space & shape limits where intents are supported) when looking for alternate efficient methods of calculation
        - example: a method of calculating area under the curve can be built with relevant concepts (subset, linearity, similarity (to curve) as a input to the conceptual trajectory to the concept of approximation) once those concepts are identified in the problem space, and combined with different structures, each having their own intents (prioritized metrics like efficiency)
      - quantify conceptual potential (how much change it can enable) and core operations on conceptual potential, & where potential objects occur or where they fit in to those operations
