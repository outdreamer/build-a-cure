# Summary

- now youve built some powerful functions, some of which need completion, debugging & generalization
    - the important next step is hooking up clause/relationship identification to those functions
    - since those are the foundation for the other more important semantic functions in get_medical_objects and get_conceptual_objects
    - key requirements to complete next:
      - find_type
      - find_definition - can pull from dataset for a type to build definition
      - consolidate pattern identification functions
      - test & update find_clause/relation logic
      - test & update derive_patterns logic to build a full pattern index to implement with clause/relation logic

- the relationships between object type layers (structural, conceptual, medical) means that you can re-use logic across layers:
    - example:
      - stressor identification logic can overlap with change/variance/variable identification logic
    - other type mappings to generalize:
      condition = state, symptom = function = side_effects, function = relationship, synthesis = build process, structure = pattern
    - at some point you need to identify this system of relationships between object types & layers 
      so that generation of additional layer interfaces is possible (physics system, math system, chemical system, in addition to medical/bio system)

- you can work on other tasks for a while before completing relationship/clause/pattern fitting:
  - insight identifier
  - dose prediction for a patient
  - fetch contraindications for a drug (find nth-degree side effects, outputs, high dose impact if not metabolized, conditions, interacting/synergistic/neutralizing drugs)
  - find most common adjacent compound (to make it likeliest that the person can find the common compound and synthesize the version they need)
  - fetch synthesis instructions for a drug from most common adjacent compound
  - treatment component identification function
  - drug reaction predictor
  - compound search from smile formula
  - math notes
  - function/directory organization

# Sources

  - check chembl search if you can search for a condition & return molecules known to treat it
  - chembl similarity function can tell you how likely it is that the generated compound mimics functionality of another compound
  - resolve local_database, get_data_store, derive_pattern, get_data_from_source logic & calls
  - pull these properties for compounds on wiki
  - find source of bio keywords & synonyms

# Examples

  - give an example of mapping an invention & insight on the abstract network


# Structural Objects

  - add complications object when querying treatments
  - resolve \n separator when not used as a new line separator
  - store definitions
  - fix conjugation
  - fix return from type_patterns

  - when evaluating interactions, check for other compounds that interfere with metabolism & de/activation (cytochromes it targets, liver enzymes it assists), 
    which can increase or decrease blood ratio of a drug
  - look for processes/intake of nutrients that could combine to form other compounds (berberine) given the output health factors (stable blood sugar)
  - fix order of assembled combinations:
      get_alts: all_alts [['suppose', 'assumed', 'thought'], ['DT', 'PDT', 'WDT', 'TO', 'PP', 'CC', 'IN'], ' that ', ['suppose', 'assumed', 'thought'], ' that']
      get_all_versions |suppose thought assumed| that DPC |suppose thought assumed| that
  - remove plural tags once you finish singularize function
  - make sure apply_pattern_map explores all versions of line, but returns one new line
  - add common patterns that have more than one index type to all index type lists - 'x of y', 'phrase of phrase', etc
  - identify lists in sentence and surround with parenthesis if embedded or insert as examples of an object ('such as', 'like', 'as in'), 'found in', 'including', 'having'
  - find functions should have definition logic & logic to rule out other types & type-specific logic since they're used as a backup to pattern-matching
    the order of find_* function application can take the place of this, if patterns are comprehensive enough
  - add pattern to standardize verb-subject to subject-verb: 'V DET noun_phrase ... ?' => 'DET noun_phrase V ...'
  - finish function to combine functions by intent get_net_impact(functions) & combined operators
  - verify that if not response false check is same as youve been using

  pattern alts:
  - repeated options shouldnt happen within an alt set: |NNS NNS VBZ2 VBZ3 NNS| 
  - implement pattern-mix matching to mix & match patterns of various types to find key patterns with mixed types not generated by current logic

  processing order:
  - examine iterations (lists/keys()/items()/config/if conditions) that determine processing order: (supported_pattern_variables, pos_tags, all_pattern_version_types, reversed keys, etc)
    - when identifying all objects, order can be from low to high
    - when classifying specific objects, order should be from high to low - return first match, or adjust line being analyzed with replacement for each match, starting with longest matches first
    - add ordered pos-tagging pattern_map to apply preference order to correct incorrectly identified word pos - isolate which tags would be identified as other objects first

  clause identification: 
  - add ordering logic in find_clause for special clause keywords:
    - 'as' can mean 'like', 'while', or 'because'
    - 'by' can indicate a process/mechanism "it works by doing x", "as"

  - support conversion between pos types like 'verb-to-noun':
    - 'subject1 verb clause because subject2 verb clause' => 'subject2 verb-to-noun causes subject1 verb-to-noun'
    - 'the process activated x because y inhibits b' => 'y b-inhibition causes the process to activate x' => 'y b-inhibition enables process to activate x'

  - fix rows csv format & read/save delimiter handling for get_objects - we are storing patterns with 'pattern_match1::match2::match3' syntax for example
  - write function to get semantic props of compounds (bio-availability, activation in the host species, etc) & get_common_property between objects
  - integrate conditions/symptoms and treatments/compounds schemas (this would be a nice way to test get_attribute function to find differentiating props)
  - remove len(0) checks for lists when possible & consolidate excessive chained response checks
  - make sure youre not assigning scores or other calculated numbers as dict keys or other identifiers anywhere 
  - add keyword processing to apply_find_function 


# Functions

  - function to predict a compound for a pathogen/condition requires data:
      - compound & pathogen attributes (compound metadata like metabolism/dose/interactions/effects)
      - variable/state impact (gene expression)
      - interaction rules with expected object types (in the bloodstream if taken orally, in the lungs if inhaled)
      - sub-components that could be altered through interaction to neutralize its functionality
      - dependency scope (volume of layers of relevance)
  - add get_common_properties function to do extra property-based searches after identifying objects with extract
  - add function to test chemical reactions: https://cheminfo.github.io/openchemlib-js/docs/classes/reaction.html
  - fill in keywords & patterns for objects (strategies/mechanisms used by an organism/on a compound)
  - find situations where systems dont act like objects in a system (despite similarities in object/system behavior like variance/definition gaps)
  - merge finder & builder notes
  - resolve terms that can be conflated: 
    - shape/structure
    - rule/test/metric/limit/threshold/boundary/state change/phase shift
    - intent/priority/motivation/incentive
    - method/function/rule/pattern
    - path/route/trajectory/traversal/order/list
    - metadata/attribute/variable/parameter/property 
    - object/entity/item
    - type/class/category/subset
    - independence/unique/orthogonal
    - model/perspective/filter/standard/interface/index/symmetry/dimension/variable

  - add variable accretion patterns (how an object becomes influenced by a new variable, complex system interaction patterns, etc)

  - add identification functions:
          - types (['structure', 'life form', 'organic molecule'] from 'protein')
          - topic/problem domain
          - objects (nouns like 'protein')
          - components (topical nouns that are found in another topical component, like organelles of a cell)
          - attributes (attribute metric/feature nouns like 'toxicity')
          - functions (verbs like 'ionizing', 'activate', inputs/outputs like subject/predicate nouns)
          - variables (function inputs like subject/modifier nouns)
          - then test on bio systems:
            - "adjacency as a definition of relevance can be used as a way to derive paths" + "path optimization can be used to get a drug to a location in the system"
            - "isolate a pathogen cell before destroying it so it cant communicate info about what destroyed it to other pathogens to help them evolve resistance"

      - functions to determine function system metadata:
        - position/role in a system
        - function to derive role (intended subset of intent stack)
        - function type associated with its core functions (change rules, boundary rules)
        - emergent side effects in edge cases, rule change states, & interacting with other system layers

      - function to derive core component functions for any system - then you can write functions to calculate function metadata:
        - determine equivalent functions or more optimal version of a function
        - determine function intent
        - alter core functions used to alter function intent
        - when generating solutions, change core functions to vary to describe any function set that builds any other function set in a system
          - set of binding/interaction/priority functions for element atoms


# Conceptual

  - explainability as a space limited by derivable attributes from data set & cross-system similarity
  - threshold mechanics for threshold value selection
  - give example of structuring problem in a certain format (optimal transport) as an interface to highlight key differences
  - give example of matching structure, mapping problem semantically, map from intent to structural algorithm design
  - examine whether new concepts (gaps in network rules) evolve once structure is applied to prior concepts 
  - all problem-solving automation methods have a variance assignment, allowing for variation to be explored in a certain location 
  - you can either map problems to fit that structure or design new automation methods based on the variance gap necessary to solve a problem

  - use distortion patterns of entities like atlases, templates, solution progressions to form a compressed version of the host system - https://techxplore.com/news/2019-11-medical-image-analysis.html

  - add stressor language patterns

  - for queries of functions like "disable a gene", you can include intent & function metadata to point to sets of compounds that could do the required edits:
    - find compound (protein, enzyme, etc) that unfolds DNA
    - find compound that modifies (edits, activates, removes) the gene once unfolded as specifically as possible 
      (can be a compound with a cutting subcomponent at the right length to target the dna if you can bind it to the first or last gene with another compound)
    - find compound with function = "refolds DNA"
    https://medicalxpress.com/news/2019-12-common-insulin-pathway-cancer-diabetes.html


# ML
  - the full data set should have numerical categories indicating condition(s) treated in the output label so it can be separated into sub-sets by condition treated
  - incorporate stacked autoencoders to leverage unsupervised learning to get initial weights
  - incorporate cosine loss rather than categorical cross entropy
  - add recurrent nn example code that can be copied & plugged in without modification
  - from a data set, it should be possible to compute which questions can be answered by the data set, with what confidence & specificity - if it matches user intent, you can proceed with the analysis
  - accretion of data set variables into types using info filters is one relationship that occurs on the interface network


# Programming

  - program to identify optimal use cases 
  - program to delegate optimized use cases to tools optimized for them (languages better at one task than another)


# Schema

- function
  - definition: a set of inputs, a list of rules or rule lists (logic tree) applied to the input set, an output set created by changes to the input set, and side effects from execution
    - side effect examples: 
      - before execution: pre-computing
      - during: memory access/overflow
      - after: process re-starting
  - attributes:
  - rules:
  - types:
    - neutralizing functions
- variable
  - definition: 
  - attributes:
  - rules:
  - types:
- dimension
  - definition: 
  - attributes:
  - rules:
  - types:
- type
  - definition: 
  - attributes:
  - rules:
  - types:
- system
  - definition: 
  - attributes:
  - rules:
  - types:
- filter
  - definition: 
  - attributes:
  - rules:
  - types:
- intent
  - definition: 
  - attributes:
  - rules:
  - types:
- strategy
  - definition: 
  - attributes:
  - rules:
  - types:
- insight
  - definition: 
  - attributes:
  - rules:
  - types:
- problem
  - definition: 
  - attributes:
  - rules:
  - types:
- solution
  - definition: 
  - attributes:
  - rules:
  - types:
- concept
  - definition: 
  - attributes:
  - rules:
  - types:
- structure
  - definition: 
  - attributes:
  - rules:
  - types:


# Diagrams

  - make diagram of potential matrix to display the concept
    - map parameter sets to potential matrix shapes 

  - make diagram for dimension links higher than 3d that are depictable in the same network space
    - should show variables that impact other variables, the change rates of these relationships
    - overall impact should be calculatable from these relationships
    - should show similar movements for correlated variables
    - should show skippable/derivable variables (variables that can be resolved later than they normally are)
    - should show meta forces for overall trends in change rules (direction of combined variable forces)
    - should show limits of measurability & threshold metrics

  - make diagram for variable accretion patterns

  - finish diagrams for specific concepts, core functions, concept operations, ethical shapes
  - finish schema for objects
  - finish informal fallacy diagrams: https://en.wikipedia.org/wiki/List_of_fallacies

  - consider using dimensionality reduction as a way to identify abstract patterns & functions to explain common deviations from patterns
      https://miro.medium.com/max/1659/1*nQrZmfQE3zmMnCJLb_MNpQ.png
      https://towardsdatascience.com/step-by-step-signal-processing-with-machine-learning-pca-ica-nmf-8de2f375c422

  - use this or similar as example when describing current state of problem solving: 
      https://miro.medium.com/max/462/1*X7dQgs1gsJ0Sktz3t7J21Q.png
      https://towardsdatascience.com/feature-extraction-techniques-d619b56e31be

  - solution type: balance info asymmetry
  - matching

# Questions
  - are pathogen receptors/membranes unique enough that you could design a substance to artificially bind with them to deactivate or puncture the membrane without impacting other structures?
