# Summary

- now youve built some powerful functions, some of which need completion, debugging & generalization
    - the important next step is hooking up clause/relationship identification to those functions
    - since those are the foundation for the other more important semantic functions in get_medical_objects and get_conceptual_objects
    - key requirements to complete next:
      - find_type
      - find_definition - can pull from dataset for a type to build definition
      - consolidate pattern identification functions
      - test & update find_clause/relation logic
      - test & update derive_patterns logic to build a full pattern index to implement with clause/relation logic

- the relationships between object type layers (structural, conceptual, medical) means that you can re-use logic across layers:
    - example:
      - stressor identification logic can overlap with change/variance/variable identification logic
    - other type mappings to generalize:
      condition = state, symptom = function = side_effects, function = relationship, synthesis = build process, structure = pattern
    - at some point you need to identify this system of relationships between object types & layers 
      so that generation of additional layer interfaces is possible (physics system, math system, chemical system, in addition to medical/bio system)

- you can work on other tasks for a while before completing relationship/clause/pattern fitting:
  - insight identifier
  - dose prediction for a patient
  - fetch contraindications for a drug (find nth-degree side effects, outputs, high dose impact if not metabolized, conditions, interacting/synergistic/neutralizing drugs)
  - find most common adjacent compound (to make it likeliest that the person can find the common compound and synthesize the version they need)
  - fetch synthesis instructions for a drug from most common adjacent compound
  - treatment component identification function
  - drug reaction predictor & compound search from smile formula
  - function/directory organization
    - first list & organize functions
    - ideally functionality would be organized by intent folders so permissions could be granted according to intent assessment


# Sources

  - check chembl search if you can search for a condition & return molecules known to treat it
  - chembl similarity function can tell you how likely it is that the generated compound mimics functionality of another compound
  - resolve local_database, get_data_store, derive_pattern, get_data_from_source logic & calls
  - pull these properties for compounds on wiki
  - find source of bio keywords & synonyms


# Examples

  - give an example of mapping an invention & insight on the abstract network


# Structural Objects

  - add complications object when querying treatments
  - resolve \n separator when not used as a new line separator
  - store definitions
  - fix conjugation
  - fix return from type_patterns

  - when evaluating interactions, check for other compounds that interfere with metabolism & de/activation (cytochromes it targets, liver enzymes it assists), 
    which can increase or decrease blood ratio of a drug
  - look for processes/intake of nutrients that could combine to form other compounds (berberine) given the output health factors (stable blood sugar)
  - fix order of assembled combinations:
      get_alts: all_alts [['suppose', 'assumed', 'thought'], ['DT', 'PDT', 'WDT', 'TO', 'PP', 'CC', 'IN'], ' that ', ['suppose', 'assumed', 'thought'], ' that']
  - remove plural tags once you finish singularize function
  - make sure apply_pattern_map explores all versions of line, but returns one new line
  - add common patterns that have more than one index type to all index type lists - 'x of y', 'phrase of phrase', etc
  - identify lists in sentence and surround with parenthesis if embedded or insert as examples of an object ('such as', 'like', 'as in'), 'found in', 'including', 'having'
  - find functions should have definition logic & logic to rule out other types & type-specific logic since they're used as a backup to pattern-matching
    the order of find_* function application can take the place of this, if patterns are comprehensive enough
  - add pattern to standardize verb-subject to subject-verb: 'V DET noun_phrase ... ?' => 'DET noun_phrase V ...'
  - finish function to combine functions by intent get_net_impact(functions) & combined operators
  - verify that if not response false check is same as youve been using

  pattern alts:
  - repeated options shouldnt happen within an alt set: |NNS NNS VBZ2 VBZ3 NNS| 
  - implement pattern-mix matching to mix & match patterns of various types to find key patterns with mixed types not generated by current logic

  processing order:
  - examine iterations (lists/keys()/items()/config/if conditions) that determine processing order: (supported_pattern_variables, pos_tags, all_pattern_version_types, reversed keys, etc)
    - when identifying all objects, order can be from low to high
    - when classifying specific objects, order should be from high to low - return first match, or adjust line being analyzed with replacement for each match, starting with longest matches first
    - add ordered pos-tagging pattern_map to apply preference order to correct incorrectly identified word pos - isolate which tags would be identified as other objects first

  clause identification: 
  - add ordering logic in find_clause for special clause keywords:
    - 'as' can mean 'like', 'while', or 'because'
    - 'by' can indicate a process/mechanism "it works by doing x", "as"

  - support conversion between pos types like 'verb-to-noun':
    - 'subject1 verb clause because subject2 verb clause' => 'subject2 verb-to-noun causes subject1 verb-to-noun'
    - 'the process activated x because y inhibits b' => 'y b-inhibition causes the process to activate x' => 'y b-inhibition enables process to activate x'

  - fix rows csv format & read/save delimiter handling for get_objects - we are storing patterns with 'pattern_match1::match2::match3' syntax for example
  - write function to get semantic props of compounds (bio-availability, activation in the host species, etc) & get_common_property between objects
  - integrate conditions/symptoms and treatments/compounds schemas (this would be a nice way to test get_attribute function to find differentiating props)
  - remove len(0) checks for lists when possible & consolidate excessive chained response checks
  - make sure youre not assigning scores or other calculated numbers as dict keys or other identifiers anywhere 
  - add keyword processing to apply_find_function 


# Functions

  - give example of each type of problem-solving workflows
    - workflow 1:
      - finish apply_solution_type

      - add a function to get all codebase functions & store them in a dict with their name, params, class, context/usage, and intents, just like functions are stored in the problem_metadata.json example for workflow 1

      - add function to map conceptual object to structural object

        - mapping 'info' to 'structure' can be done with a conceptual route:
          - info => clarify intent => structure

        - or a layer-traversing route, adding structure with each additional transform:
          - info => remove uncertainty => achieve constant state => structure

      - add function to map conceptual function to structural step:

        - in addition to mapping objects like 'info' to supported objects like 'structure' using the schema or definition derivation, 
          we also want to map concept functions like 'balance' to structural terms like 'evenly distribute',
          and map modifiers like 'evenly' to calculation operations like 'check distribution equal' so that 'evenly distribute' is translated to several options:
            - 'change distribution until equal for all positions'
            - 'remove all' (specific case which is a shortcut implementation of the 'change distribution until equal' operation

          - then 'check equal distribute' would be converted to 'check equal distribution'
          - then reversed to 'check distribution equal' since the 'equal' attribute applies to the 'distribution' object
          - the dependency for 'check' would be found to be 'change' if theres no other process changing it
          - this would create two steps to achieve the 'equal distribution' intent state derived from the step:
            - check if distribution is equal
            - if not, change it
          - then it would be derived that 'iteration' intent applies here since one change may not achieve the 'equal distribution' intent state, either by querying for insights about changes producing a state, or by checking if the goal is reached after one iteration, and then applying any available functions again (the same ones or a combination of other functions available, which is more computationally expensive and may not be allowed by the definition of 'improve') if not

          - the original options for 'evenly distribute' would be used as testing metrics, checking that either all objects were removed or that the remaining objects were distributed evenly

          - in order to build this concept-to-structure function, we need:
            - stored standard language maps & definitions
            - a function (or a dictionary) to standardize language to this system's terms (so distribute is converted to 'change position of objects in group until objects are not in the same position')
            - a function to convert non-supported functions into combinations of supported functions (standardize 'enhance' to 'improve' or 'increase')

              - you can create a 'definition' function and then apply it to test its impact to see if it matches

              - or you can also map intent to create a network for each stored definition, then see if you can optimize/standardize the network, and map it to a supported function network
                - enhance function:
                  - 'apply some process to improve or increase some attribute or process'
                  - intents: change, move in the direction of increasing a metric/object/process or minimizing distance to goal 
                - improve function:
                  - 'apply an optimization process to fulfill a metric' 
                  - intents: minimizing distance to goal, minimizing distance to metric, increase likelihood of minimizing distance to goal (optimize)
                - increase function:
                  - 'apply the add process until the quantity of an object is higher'

                - it also has similarity to 'compound' (which adds extra meaning of applying similar objects/functions to other objects/functions and synergy),
                  but 'improve' and 'increase' are supported core functions and we're trying to standardize the word to a combination or set of these
                - its clear that enhance has some relationship to both of the other functions, which would be even clearer with a network version of each definition

                - given the example input context 'enhance process A to produce a byproduct', we can derive that this is about achieving a goal that doesnt specifically or exclusively have 'increase' connotations, leaving 'improve' as the likely core function to map 'enhance' to, for this context

                - you can test the 'improve' definition on the input objects 'process A' and if it moves in the direction of the other object 'byproduct', it's a better candidate for the standardized function
                  - does 'improving' the objects in the original context have the same output as 'enhancing them'? which types of improvement produce an enhancing effect? 
                  - is there a way to improve some attribute of the objects in a way that doesnt improve the object enhanced in the original context?

                - you can do extra testing on the intent interface:
                  - does 'improve' fulfill 'enhance' intents or just a subset of them, and is that subset the more valid subset in a set of alternatives, or are the other subsets required for the definition?
                  - do 'improve' intents apply to the objects in the original context or do some of them not fit?

      - the concept-to-structure mapping functions can be used in other problem-solving automation workflows

      - finish apply_solution to problem_definition using problem_steps
        - involves adding a function to evenly distribute information types given problem positions/agents/objects
      
      - add function to determine relevance filter ('functions', 'required') from a problem_step ('find incentives') for a problem definition, to modify problem_steps with extra functions/attributes ('change_position') to be more specific to the problem definition ('find_incentives_to_change_position') for problem_steps involving 'incentives', so you know to use the function_name to modify the problem step if it's between the type 'functions' and the object searched for 'incentives'

        - as an alternative to traversing the dictionary, you can identify gaps in problem_step intents and look for functions to fill those gaps

          - if the preceding problem_step function is 'check new position (list object attributes)' and the next problem_step is the same function, you know there's a missing step to change position after the initial check, otherwise the repetition would be pointless, ignoring verification intents

          - if there's a function 'use incentives to change position' or if incentives are an input to 'change_position' function, you can derive that 'find incentives' is a prerequisite step to the change position function, which is how you can derive the 'find incentives' part of the missing step before applying the 'to change position' modifier
      
      - then add functions to derive metadata 
        - need dicts for this, including:
          - function chain intent relationships (in addition to function dependency relationships stored in function_order.json)
          - type hierarchies/network structures

      - add example of common sense check 
      - convert schema.md to object_schema.json
      - add organization to functions.json by type, with mapping between general intent functions like 'find' to specific info-relevant terms like 'get'
      - finish get_type function to map info to structure using the new functions.json organization

      - add common phrase check & filter problem steps by repeated combinations with common phrase check

  - trajectory between core & important objects
  - representation of a function/attribute in isolation with respect to time (snapshot or section)
  - emergent combinations of core functions (include derivation of invalidating contexts for core functions)
  - finish system analysis for VDJ recombination 
  - find other relevant immune processes to analyze
  - structure-finding function for an attribute/rule/information set
  - structure schema notes particularly object definitions as dict so you can import them

  - need to fill in content:
    - finish function index & add to functions.json
    - finish intent tree
    - finish intent/change type calculation for a system intent
    - optimal combination interfaces to start from when solving problems 
      (how many degrees away from core functions, specific layers or sub-systems, what position on causal structures)
    - key questions to filter attention/info-gathering/solution
    - key functions to solve common problem types
    - research implementing your solution type (constructing structures (made of boundary/filter/resource sets) to produce substances like antibodies, using bio system stressors)
    
  - coexist with definition
  - change phases for causal analysis (interim, changing, diverging, standard, efficient state, constant, interacting, converging, on the verge of obsolescence, outlier, etc)
  - superficial cause, alternate cause in the case of a function, addressing input/output causes
  - framing on interfaces, decomposing causation, then identifying parameters of problem on layer & matching solution
  - independence (closed trade loops) as time storage
  - development of key decision metrics (bias towards more measurable/different metrics rather than the right metric)
  - vertex as a pivot point for an interface
  - example of choosing inefficiencies/exploit combinations in a system

  - function to create graph from article
  - function to predict a compound for a pathogen/condition requires data:
      - compound & pathogen attributes (compound metadata like metabolism/dose/interactions/effects)
      - variable/state impact (gene expression)
      - interaction rules with expected object types (in the bloodstream if taken orally, in the lungs if inhaled)
      - sub-components that could be altered through interaction to neutralize its functionality
      - dependency scope (volume of layers of relevance)
  - add get_common_properties function to do extra property-based searches after identifying objects with extract
  - add function to test chemical reactions: https://cheminfo.github.io/openchemlib-js/docs/classes/reaction.html
  - fill in keywords & patterns for objects (strategies/mechanisms used by an organism/on a compound)
  - find situations where systems dont act like objects in a system (despite similarities in object/system behavior like variance/definition gaps)
  - merge finder & builder notes
  - resolve terms that can be conflated: 
    - replace:
      - shape/structure
    - rule/test/metric/limit/threshold/boundary/state change/phase shift
    - intent/priority/motivation/incentive
    - method/function/rule/pattern (pattern is a sequence of specific objects)
    - path/route/trajectory/traversal/order/list/sequence
    - object/entity/item
    - type/class/category/group/subset
    - closed/isolated/independence/unique/orthogonal
    - model/perspective/filter
    - standard/interface/index/symmetry
    - dimension/variable/axis
    - space/system/context

  - add variable accretion patterns (how an object becomes influenced by a new variable, complex system interaction patterns, etc)

  - add identification functions:
          - types (['structure', 'life form', 'organic molecule'] from 'protein')
          - topic/problem domain
          - objects (nouns like 'protein')
          - components (topical nouns that are found in another topical component, like organelles of a cell)
          - attributes (attribute metric/feature nouns like 'toxicity')
          - functions (verbs like 'ionizing', 'activate', inputs/outputs like subject/predicate nouns)
          - variables (function inputs like subject/modifier nouns)
          - then test on bio systems:
            - "adjacency as a definition of relevance can be used as a way to derive paths" + "path optimization can be used to get a drug to a location in the system"
            - "isolate a pathogen cell before destroying it so it cant communicate info about what destroyed it to other pathogens to help them evolve resistance"

      - functions to determine function system metadata:
        - position/role in a system
        - function to derive role (intended subset of intent stack)
        - function type associated with its core functions (change rules, boundary rules)
        - emergent side effects in edge cases, rule change states, & interacting with other system layers

      - function to derive core component functions for any system - then you can write functions to calculate function metadata:
        - determine equivalent functions or more optimal version of a function
        - determine function intent
        - alter core functions used to alter function intent
        - when generating solutions, change core functions to vary to describe any function set that builds any other function set in a system
          - set of binding/interaction/priority functions for element atoms


# Conceptual

  - explainability as a space limited by derivable attributes from data set & cross-system similarity
  - threshold mechanics for threshold value selection
  - give example of structuring problem in a certain format (optimal transport) as an interface to highlight key differences
  - give example of matching structure, mapping problem semantically, map from intent to structural algorithm design
  - examine whether new concepts (gaps in network rules) evolve once structure is applied to prior concepts 
  - all problem-solving automation methods have a variance assignment, allowing for variation to be explored in a certain location 
  - you can either map problems to fit that structure or design new automation methods based on the variance gap necessary to solve a problem

  - use distortion patterns of entities like atlases, templates, solution progressions to form a compressed version of the host system - https://techxplore.com/news/2019-11-medical-image-analysis.html

  - add stressor language patterns

  - for queries of functions like "disable a gene", you can include intent & function metadata to point to sets of compounds that could do the required edits:
    - find compound (protein, enzyme, etc) that unfolds DNA
    - find compound that modifies (edits, activates, removes) the gene once unfolded as specifically as possible 
      (can be a compound with a cutting subcomponent at the right length to target the dna if you can bind it to the first or last gene with another compound)
    - find compound with function = "refolds DNA"
    https://medicalxpress.com/news/2019-12-common-insulin-pathway-cancer-diabetes.html


# ML
  - the full data set should have numerical categories indicating condition(s) treated in the output label so it can be separated into sub-sets by condition treated
  - incorporate stacked autoencoders to leverage unsupervised learning to get initial weights
  - incorporate cosine loss rather than categorical cross entropy
  - add recurrent nn example code that can be copied & plugged in without modification
  - from a data set, it should be possible to compute which questions can be answered by the data set, with what confidence & specificity - if it matches user intent, you can proceed with the analysis
  - accretion of data set variables into types using info filters is one relationship that occurs on the interface network


# Programming

  - program to identify optimal use cases 
  - program to delegate optimized use cases to tools optimized for them (languages better at one task than another)


# Diagrams

  - make diagram of potential matrix to display the concept
    - map parameter sets to potential matrix shapes 

  - make diagram for dimension links higher than 3d that are depictable in the same network space
    - should show variables that impact other variables, the change rates of these relationships
    - overall impact should be calculatable from these relationships
    - should show similar movements for correlated variables
    - should show skippable/derivable variables (variables that can be resolved later than they normally are)
    - should show meta forces for overall trends in change rules (direction of combined variable forces)
    - should show limits of measurability & threshold metrics

  - make diagram for variable accretion patterns

  - finish diagrams for specific concepts, core functions, concept operations (combine, collide, connect, merge, apply), ethical shapes

    - chaos & ethics graph

  - finish diagrams for intent (more examples of matching structure with intent), cause (shapes & ambiguity), concept (evolution of concepts, networks, distortion functions)

  - diagram for argument

  - finish schema for objects

  - finish informal fallacy diagrams: https://en.wikipedia.org/wiki/List_of_fallacies

  - solution type: balance info asymmetry

# Questions
  - are pathogen receptors/membranes unique enough that you could design a substance to artificially bind with them to deactivate or puncture the membrane without impacting other structures?

