to do: organize into docs

  - physics vertexes
    - black hole unpacking function (allows information to develop)
    - universe overlap/collision/combination
    - lack of universe-preventing conditions (like how information can develop if black holes are far enough away)
    - variance injections & interaction rules allowing variance cascades to prop up a universe structure, allowing time to develop
    - upward arc on a wave or parabola (development of time marks the upward arc), where the downward arc is the unraveling of time back to the origin big bang (collapse into a black hole, eject variance, rebound universe), as material or structure allowing material of the universe is stretched temporarily to hold the variance injected via the entry point (whether black hole, universe collision, or something else)
      - what other types of universe are there, other than a universe allowing sequence between states (conditional/temporary truth) achieving/executing absolute truths?
        - other structures include:
          - state circuits/networks (illusion of time, but still on the same circuit/network, meaning the states are pre-determined in that theyre guaranteed to be on the circuit/network)
          - a universe of vertexes (generators/determinators/descriptors of other variables, like a set of constants such as identities of nodes on the abstract network), where the primary function is preventing change or routing changes to universes with the potential handlers to contain it in a stable way
            - a universe with a 'regulation' intent that prevents excess change from other universes
          - a universe with different fundamental definitions/dimensions of change/core components/interfaces
            - a universe that builds its foundation off of a different interface than the structural interface
            - a universe with a different definition of information/randomness/position/change
            - a universe with different dimensions of change than position/time/structure
          - universe with potential to switch off time with sub-interface alignment (coordinating changes on quantum interface like with a quantum chain reaction to prevent or reset variance)
          - universe with potential for extreme information states
            - at one extreme, truth can crystallize into a universe-determining rule if not prevented from doing so, and at the other extreme, structures allowing guaranteed variance to develop first can prevent truth from developing at all
            - universe where information (stable states) is not allowed to develop (a universe requiring distributed randomness, or lack of information), and measurable information is an abstract concept that the universe structure can never create a sub-structure to contain
    - calculation trajectory (calculations possible in this universe or space-time used to calculate position in regard to the others, given intents possible with those calculations
      - calculating position (knowing if your space-time is a pawn/knight & the pawn/knight functions, and deriving the existence of other positions) & possible intents of that position (& the ensuing functionality) enables determining the set of possible moves on the board, the limits of the board, the point of the game, and the optimal positions/moves/states in the game, giving you a direction to move in if you can coordinate with other players

  - ways to navigate space-time
    - alternate routes to arrange spacetimes in a way that makes origin & target space-times adjacent or traversible

  - variance generators (of noise) including objects on same interaction level and components that can build changes on interaction level as well as containing object interaction outputs that can cascade to lower interaction level changes

  - how to erase causation contributed by a prior/root cause to subsequent variables if root cause & subsequent variables are both included in the data set

  - example of intent mapped to structure: the outlier or data point in the middle of two categories isnt supposed to be categorized, its supposed to be identified as belonging to a different group (a group in a state of change), which can be used to derive group boundaries, but shouldnt necessarily be integrated into a categorization function

  - example of alternate explanations: for a pattern like why people have different responses to a pathogen, is it bc of coincidences like that:
    - the pathogen fits into the bio system in a way that requires the same functions used to protect it from another second condition, taking protection against that condition away
    - the pathogen coincidentally applies mutations that the bio system hasnt yet evolved to handle
    - the pathogen applies mutations that coincidentally spiral out of control bc theyre mutations to important/core change/regulation rules, or that it causes another error that triggers the second condition
    - the pathogen evolved in an animal that didnt have those vulnerabilities so it was able to live in the host indefinitely rather than killing the host
    - the pathogen needs a function that requires evolving other functions that are coincidentally harmful to the bio system
    - the pathogen misidentifies the genes to target or cant identify the right genes in different systems
    - how to generate the set of possible alternate explanations:
      - apply structures (evolution process of change sequences), concepts (identification function error, coincidence), functions (functions producing changes, such as mutations), and position them using other structures (causal network)

  - with information representing the constant vertices of a system, by representing information a certain way, efficiencies are gained in other information, like related calculation outputs 

      - what does the efficiency provide to uncertain/uncalculatable objects external to information?
      - with certain concepts as priorities or embedded in the structure (like orthogonality generating intersection spaces for mapping interactions), certain efficiencies in calculations are created
      - what filter set or subset of possible concepts can explain the information description system?
        - what other objects are explanatory, in addition to concepts (a slice of a system with a similar object or pattern), filters, core/generative functions, limits?
      - what connects the constants in this system, representing information behavior descriptions - are there system objects like validation/formatting filters, efficiencies aligning between information & uncertainty objects, or other objects beyond the conceptual layer of discoverable information systems?
      - given that information attracts information differently in different structures, what intents can those structures & the information rules be used for?
      - if paradoxes are representable as holes in logical value connections (gaps or jumps in the information system, like asymptotes are for values), what type of information values can occupy those holes, or do they act like a symmetry to connect different spaces?

      - does information withdraw into a superposition (structure with multiple potential information states) or an abstract generalization (generative structure of information or concept network trajectory of the information) or a compression (retaining some attributes of the information), once you remove its structure or remove it from a space where it can stabilize enough to attain a structure?

    - intent implemented on the web could look like approved workflows for accessing a site or across sites, where actions, requests or workflows can be pre-purchased and approved algorithmically 
      ('how to build a bomb' search isnt purchaseable with a 'purchase chemical' request or across purchase bundles)

  - tool to make bacteria grow until detectable & then represent with AR

    - this closes the gap in information:
      - the information needed for the product (a testing & display tool) was insufficient
      - the mechanism to make the information sufficient is accessible (solutions to feed bacteria)
      - rather than make the measurement tool better, you can make the information more accessible (change the position of information rather than the position of the measurement tool)
      - the AR component would augment the size to make it displayable to users without using the measurement tool (microscope) or indicate size/type of pathogen with standard data visualization rules

      - applying the testing tool to hub nodes (then inputs/outputs of hub nodes, and adjacent objects to hub nodes) to check with increasing certainty whether surfaces were compromised
      - redistributing resources based on immunity/infection status to avoid cleaning, like distributing unchecked, unsanitized, or contaminated goods to consumers with immunity/infection 
      - keeping an animal likely to develop fast infections in buildings and then using air conditioner to distribute viral RNA when the building is unused and checking remotely if the animal shows symptoms to see if a building is safe is one way around the limitation to detect live copies of the virus, since the animal symptoms are easier to measure than a pathogen, so the problem becomes ensuring the animal will develop symptoms rather than immunity, and making sure the symptoms show up faster than a test done on hub nodes or quickened with enzymes/sugar/cells that help the pathogen replicate

  - analyzing just by change rate makes it less likely to spot other patterns like overlap/intersection of patterns

  - difference develops where there's potential for new interactions to develop (so a steady or increasing rate of change) & intent (like a possible gain from the difference)

  - the object model may not be the right default to start from in most situations - there arent many whole objects in existence if there are any
    - even particles have sub-particles, and the extent of that chain isnt known, and may have a causal relationship where the smallest particles act as inputs or injection points
    - should ratios/bases or sets be used instead ('a set of particles' rather than a 'plant' as a standard unit)
    - when selecting a default, you should be checking for attribute matches (does a whole object make sense to describe a set)
    - the idea of a whole number may describe something that doesnt exist in 3-d physical reality - does that mean its a concept that will never occupy a form, or is it a goal physics will move towards, or it causally independent from other systems or interfaces that are known, or it evolves as brains can measure information

  - mask design can be optimized as a cover with one output flap like an esophagus preventing input on one nostril so the other can be used exclusively as an input with a filter 
    (better to sanitize at point-of-usage in environments with many unpredictable interactions like wind direction and interpersonal contact, which can get around most masks)

  - types can be represented as directions (going farther from origin goes further up type stack, where similar types are adjacent)
  - change phases for causal analysis (interim, changing, diverging, standard, efficient state, constant, interacting, converging, on the verge of obsolescence, outlier, etc)
    - superficial cause, alternate cause in the case of a function, addressing input/output causes
  - framing on interfaces, decomposing causation, then identifying parameters of problem on layer & matching solution
  - independence (closed trade loops) as time storage
  - vertex as a pivot point for an interface

  - when physics rules stabilize, they attract & generate information, which gathers into measurable numbers
  - if the point of the universe is not to find the initial filters but to prevent that information from being discovered, that could keep open options for other change sources

  - an infinite series implies a stabilized symmetry (a platform for change that goes on forever) - clearly there are different degrees of stability - how do these different degrees of stability relate to different infinities like infinite sets given by number groups
    - the chain of events mentioned here implies a stability in the energy preservation with each successive event
      - https://www.quantamagazine.org/what-goes-on-in-a-proton-quark-math-still-conflicts-with-experiments-20200506/

  - organize db by intent & features for quicker access - like if types are a common filter, organize a graph into type clusters, and store node id's to limit size of various different graphs to depict the same database, a subset of indexes represented per graph

  - product platform:
    - filters: predicting filters that will be used the most (features that differentiate products and alternate purchases the most)
    - products: product query language ('product with feature x and without component y')
    - supplies:
      - adjacent supply cost estimation ('adjacent product built from these suppliers would cost x')
      - estimate future demand & estimate cost of production methods (how many times will you need it? if above x, then its more cost effective to build it yourself, buy from these suppliers with price-lowering trends, buy this robot to make it regularly, or build a robot to do it - plus the timed sequence of those purchases for most cost effectiveness)
    - code as solutions:
      - code search (code as product solutions, like code to print a product or code to predict a compound or adjust vitamin combination as needed)
      - feature-to-code translation ('need a product with existing feature x and add new feature y')

  - explore how to map position (a state structure) to variable structures like networks/loops/trees (like how rank assigns standardized relative position to values - how would you assign a position to nodes in a network in a similarly standardized way - an attribute like connection count or node type, or a trajectory position, or another method)

    - how do rankings map to ratios, and what errors would result from direct mappings of various initial data types?

    - is there a standard set of structures like networks that should be applied to a sequence to get its probable prediction function the fastest (framing numbers as 1, a map from number type to node types, 2, a node's connection count, & 3, distance between nodes, in order to map the sequence in the most robust way)

  - type of chart: a map of the trajectory between low-to-high dimensional representations of a function

  - what attributes determine symmetries so you could differentiate between symmetries (distortion functions, origin)

  - manual code should only be used when there's an unsolved problem in a domain that doesnt respond to algorithmically determined solutions (when optimization of implementation is uncertain), otherwise algorithms should be selecting code

  - vertices: variables where once theyre assigned a value, the rest of the uncertainties are resolved or resolvable

  - data structures:

    - what kind of data structure would look like the original sequence from one angle, but look like its metadata (like the ordered sequence, or average value statistics) from another angle?
      - is the extra storage of a tree, network, or other structure with more than one dimension worth the computation gains
    - is the best storage format of a list where position would be checked later in code a map retaining order, with keys as ordered values & values as positions in original sequence (in case original position is significant and youre not just trying to find if the value is in the sequence)

  - if something can generate a change predictably/consistently, it's a change supply - otherwise it's a change request, so output as well as causal position relative to the output is important when determining category
  
    - time may be a variance gap (a space where change is possible) to resolve a question/problem set - so not resolving it can preserve time, unless resolving it will allow for more potential or moving on to other variance gaps

  - vitamin 3-d printer to print vitamins so that you can design your own multivitamin that:
    - fits your bio conditions & requirements
    - is released in the right order & timing
    - excludes interactions that are contradictory (antimicrobials & probiotics)

  - multiple servers/processors in one computer with one-way data transfers, so one server can be for local communication, one can be for offline work, one can be for browsing internet, and local/offline can communicate to internet-browing processor but not the other way around

  - rules-to-code translation tool - translating domain-specific plain language rules to robot code can be short-term useful for automation of service industry tasks like:
    - converting recipes/flavor-mixing strategies to cooking robot code (chefs can use a tool like this to make money short-term or sell their rules, if they have unique strategies)
    - converting new plant designs to genome editing code
    - converting local social insights to global code (avoid personalities like this, use these tactics to persuade, make this argument to get them to an insight position, etc)
    - converting adaptation insights to change-attracting system adaptation code
    - converting routing mechanisms/optimizations to drone code (short-term human insights like 'avoiding a particular street bc of construction' that data isnt adequate for)
    - the general task of converting rule sets (systems) or human-made visuals (graphs, blueprints) to code

    - machine learning can be used for initial conversion, then tweaked with coded filters like priorities, logic, organization, output
    - system analysis can be used to optimize beyond those standard filters
    - this needs to identify existing rules (or specific versions of abstract rules, distorted versions of standard rules) & filter them out
    - this is an alternative & and an interim step to raw code-generation given a set of intents

  - data viz can be automated using:
    - lie core function layer graph or individual lie type graphs, with an output intent layer (hide information, layer information, minimize information, obfuscate information)
    - intent-structure maps (this graph structure serves this intent stack, just like a function serves an intent stack)

  - each superposition contains components representing different possible filters for the physical laws they create at scale
    - some superpositions collapse into a particular attribute set
    - superpositions with different configurations may represent other interface queries or structures
    - knowing the internal structure of a superposition would mean we get to choose which queries come to life & become real
    - the design implies we shouldnt get to choose - but external forces (or unmeasurable/uncomputable forces inside the universe) should get to determine which configurations collapse & which differences are allowed
    - information has a lifecycle - its likelier to become more true the more its observed, up to a maximum - then it's likelier to erode as its depended on
    - observing a state (to produce the information of the observation) may initialize the static nature of that information, so other observers see either static information or lack of it depending on their perspective, as information becomes truer the more its observed, and they may focus on the lack of information or a different perspective than the initial state of the information


## search ideas:

      - inferring useful search filters based on customer usage history & intent
        - linked searches/user data with type/intent identification - if they are in a location with a certain pathogen and they search for cleaners, theyre probably trying to clean that pathogen so cleaners should be specific or at least an optional search results set should be linked to
      - automated attribute extraction/addition to search as a filter
      - search results as graphs: variables entered in search to display relationships found in data or graph images or graphetized articles
      - processed (aggregated) results - find the average/combined or plain language definition when searching for a definition
      - predicting what questions theyll ask next and adding those search results (or a summary) on the side
      - intent-based search guidance:
        - usually people who search for an answer are studying for a test, so additional widgets like suggested content could include snapshots of/links to: 'study guides', 'summaries', 'tutorials'
        - people searching for recipes are hosting a party & cooking other things, so suggested content could include snapshots of/links to: 'flavor graphs'
        - people searching for symptoms are trying to diagnose themselves or someone else, so suggested content could include links to diagnostic tools or graphs of symptom set frequency for conditions

      - automatic aggregated information formatting queries as an alternative to unstructured/keyword searches pointing to isolated content in manually entered formats like:

        - 'show me stock/financial instrument/cryptocurrency popularity data in graph format' and the output would be a graph of relative usage statistics available, with suggested content links to definitions of the financial instruments since that's a related intent to looking up their popularity, which implies an intent to invest/profit
        - 'show me product search data according to demos in a table with sorts' and the output would be a table with product search data by age group, economic group, in a table format, with sorts to sort each column
        - 'show me insights from language tutorials' would return a list of insights about learning a language, which is a primary implied intent of that search, with suggested content links to music in that language which is one way to learn a language

        - this would be done by:
          - using previous queries & feedback on search results
          - auto-formatting
          - aggregated data from existing content
          - pulling definitions of keywords like 'demos' to determine what supported keyword they mean, or create a new term out of core functions (groups separated by attribute & attribute value)

      - graph search (with queries like 'show me relationship between time and gdp' or show me relationship between using lysol and cancer')

        - could scan studies related to graph for logical fallacies and adjust graph accordingly, then present a composite graph of data found

        - data from searches & product purchases can be integrated into graph (buying lysol followed by searches for cancer symptoms)

        - 'deploy an AI model to do tasks: find/predict relationship, categorize, or rank' option can be included to train on public data based on plain language queries like the above

      - search data + verified purchases can be used to assess the value of a particular product solution for a problem (like a supplement to treat a health condition), to offset fake reviews or faulty recommendation/removal algorithm or account for product fixes over time, as well as customize it to the user (avoid this product if you have condition x, this product has correlation with onset of condition y

        - customization can also be done for user groups like intelligence - so people likelier to believe a story without checking it like anti-vaxx stories can be shown true stories with more repetition

        - example of a system object being useful for customatization (a false categorization):
          - busy can look like stupidity under certain circumstances - what are those circumstances and when are they most important to avoid 
            (if someone's too busy to check a news site, send them a notification about a pandemic so theyre likelier to see it)

  - shared custom meaning/dictionary maps so communication can be queries on their shared custom dictionary map - or a common map where queries specify pattern & sub-set to apply pattern to, and sub-sets are rotated

