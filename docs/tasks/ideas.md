to do: organize into docs

  - add 'because' operator to link each decision to an intent or assumption

  - example of how the physics system has structures preventing certain cascading change types (local scope bubbling) & allowing others (nuclear chain reactions), partially through forces like gravity keeping objects at a distance: https://www.sciencealert.com/time-travel-through-a-quantum-world-has-nothing-to-fear-from-the-butterfly-effect
  - physics vertexes
    - black hole unpacking function (allows information to develop)
    - universe overlap/collision/combination
    - lack of universe-preventing conditions (like how information can develop if black holes are far enough away) or potential to avoid destruction mechanisms
    - variance injections & interaction rules allowing variance cascades to prop up a universe structure, allowing time to develop
    - upward arc on a wave or parabola (development of time marks the upward arc), where the downward arc is the unraveling of time back to the origin big bang (collapse into a black hole, eject variance, rebound universe), as material or structure allowing material of the universe is stretched temporarily to hold the variance injected via the entry point (whether black hole, universe collision, or something else)
      - what other types of universe are there, other than a universe allowing sequence between states (conditional/temporary truth) achieving/executing absolute truths?
        - other structures include:
          - similar rules but different origin position, different rules (including most extremely different rule set) but similar origin position, & other permutations of universe constants/rules & generative structures like filters/containing sets
            - universe defined as a set of possible trajectories from the various different generative structures, or a space between the various different limiting structures
          - state circuits/networks (illusion of time, but still on the same circuit/network, meaning the states are pre-determined in that theyre guaranteed to be on the circuit/network)
          - a universe of vertexes (generators/determinators/descriptors of other variables, like a set of constants such as identities of nodes on the abstract network), where the primary function is preventing change or routing changes to universes with the potential handlers to contain it in a stable way
            - a universe with a 'regulation' intent that prevents excess change from other universes
          - a universe with different fundamental definitions/dimensions of change/core components/interfaces
            - a universe that builds its foundation off of a different interface than the structural interface
            - a universe with a different definition of information/randomness/position/change
            - a universe with different dimensions of change than position/time/structure
          - universe with potential to switch off time with sub-interface alignment (coordinating changes on quantum interface like with a quantum chain reaction to prevent or reset variance)
          - universe with potential for extreme information states
            - at one extreme, truth can crystallize into a universe-determining input rule if not prevented from doing so, and at the other extreme, structures allowing guaranteed variance to develop first can prevent truth from developing at all
            - universe where information (stable states) is not allowed to develop (a universe requiring distributed randomness, or lack of information), and measurable information is an abstract concept that the universe structure can never create a sub-structure to contain
              - where every possibility is equally likely, invalidating the concept of probability
            - universe where noise/randomness is an intent rather than a side effect of intent alignment & development, so reversing the intent development process to be an input rather than the output of interaction rules allows certain types of information & randomness to develop
            - universe where the ratio & types of information/time allowed to develop allows/prevents certain types of information derivation about universe manipulation/traversal, which if combined with other types from adjacent universes on a certain definition of distance, would invalidate origin or other types of universes
          - universe where potential (in the form of variance injection points) is evenly distributed as a constant condition, so certainty cant develop (in any form, including time/structure/priority)
          - universe where some calculation types are conditionally/contextually possible, like at regular intervals where variance drops below a certain level because of passing adjacent universes
          - universe where information derivation-loss ratio makes calculations irrelevant because of the symmetry types present, which make info loss from info asymmetries trivial (where symmetries can be combined to offset every asymmetry)
          - universe where efficiencies develop in a way that certain priorities are incentivized despite universal constants exerting limits on direction change
            - prioritizing similarity or optimization contradicting a universe constant ratio of variance
            - prioritizing calculation types that prevent measuring information of a particular type
          - universe that involves trajectories between bases as a way to measure change (a changing interface network vs. change on an interface network)
          - universe where external universes are determining, rather than internal states or generative rules
            - coordinating rules in universe development have compounding effects on potential of universe interactions
            - universes where the generative rules, other constants/metrics, and position with respect to other universes are changeable from inside/outside (input/output sides, reversing causation)
          - the influence of one universe on another implies a notion of universe-external time (if a state change occurs, time has passed, even if the state is a change to the set of generative rules), where in reality, the universe relationships might not change (a static game), unless it's possible to coordinate/hook up their dimensions to influence each other
            - but this type of time may not exist, or may only exist conditionally when two universes interact, which doesnt change the absolute rules governing their interactions because the change stabilizes reliably enough to invalidate the idea of change of that type, so universe-external time can only exist in universe-to-universe interactions, but not in universe-to-universe relationship interactions
          - universe where time (in the form of potential or energy) is possible while the universe is being used for calculations, but decays & disperses when not being used, potentially being stored as variance in adjacent universes while not being used
          - universe where time is determined by calculation potential 
            - if something can be calculated from something else & vice versa (independent variables generating a dependent variable), time has not passed while that relationship is true
            - if something cannot be calculated from something else (asymmetry or information loss), time has passed
            - the set of time-independent calculation relationships may determine the amount of time a universe has until it either decays, compresses, changes its determining factors, or finishes its original intended calculation
          - time defined as the potential to calculate trajectories around a universe's singularities, or the ability to arrange calculations in a way that doesnt make all information calculatable
    - calculation trajectory (calculations possible in this universe or space-time used to calculate position in regard to the others, given intents possible with those calculations
      - calculating position (knowing if your space-time is a pawn/knight & the pawn/knight functions, and deriving the existence of other positions) & possible intents of that position (& the ensuing functionality) enables determining the set of possible moves on the board, the limits of the board, the point of the game, and the optimal positions/moves/states in the game, giving you a direction to move in if you can coordinate with other players
        - derive information with rules like:
          - if there is a universe that can destroy yours when adjacent, you know that its not adjacent to you
            - similarly, if there is another pair/set of destroying universes when in certain positions that are related to your universe (inputs/outputs/alternatives of yours, or cooperating with yours), you know theyre not in those positions
          - if there are rules that are invalidating to particular types of potential/information/randomness/change that have been measured or determined to be valid in some measured or possible context, you know those rules are not absolute

    - structure-information interface:
      entanglement, as the accretion of possible information into a core function (information generator, like the physical component of an assumption - a defined relationship, with its own definition of difference (reducing distance type of difference between entangled particle positions)
      polarity, as the accretion of information into a core function
      wave-function collapse, as the angle at which information appears to have one dimension of change

  - ways to navigate space-time
    - alternate routes to arrange spacetimes in a way that makes origin & target space-times adjacent or traversible
    - navigating by symmetries as a guide to reversible routes through space-times; where theres a window of opportunity to reverse trajectory (on a space-time tree branch ending with a dead-end leaf) if a structure of symmetries like a foundation or net or symmetry-generating structure is within reach

  - browser optimizing web sites based on clear feature-execution mismatch created by malware or outdated code given origin code intent, a ratio of version/other change allowed, intent of site actions (not making changes that would break other functionality calculatable on the page)
    - browser configurations like versions/modes/settings applied for tabs

  - add structures to diagram: interface overflow (to sub-interfaces), interface foundation

  - program should be able to identify, predict, & finally calculate structures that will be useful for an intent, to avoid reducing/searching a solution set

    - identify with structure-matching (which of these structures can fulfill this goal)
      - example: finding a 'progression' structure for a function

    - predict with intent-matching (find structures matching these intents)
      - example: for calculating area, which structures fulfill that intent

    - calculate with intent structures (derive intent-structure relationships and find operation sequence that will produce target intents)

      - example: 

        - which structures simplify difference calculations (like area) extending the addition/core/unit operation (like how multiply is an extension of add) when increasing a parameter like number of dimensions, given that 
          - the add operation has a 'combine value' intent
          - multiply has a 'combine value with different direction' or 'describe interaction space' or 'find intersection area of limits' intent
          - length has a 'describe difference' intent for a dimension count of 1
          - and so on for other operations

        - the addition operation has an associated structure 'align with overflow in left direction' because inherent to the definition of values in their standard western depiction, higher digits are on the left, and the extra value from an operation like 8 + 3 (10) would overflow into the next digit because thats a unit of change that can be registered in the next digit's column, with no more than one digit to the left being able to register the excess change from addition two digits in a particular column (greatest value being 10, by adding 9 + 9)
          
        - tests:

          - this is a good unit test for whether your program can generate math methods by applying structure:
            - if the program can identify:
              - 'column as a digit store' (given that existing numbers use columns as a digit store, which could also be done with rows after converting numbers to row format)
              - 'alignment of digits'
              - 'adding digits in the same aligned column'
              - 'overflow extra value to the left'
              as concepts & operations that would respect inherent digit definitions/rules while executing the addition operation, and design the addition operation itself, that would be a successful basic test

            - an example trajectory using the interim objects:
              - insight paths:
                - 'compare relevant objects'
                - 'compare standardized objects'
                  - identifying the 'position' attribute as an input to the 'compare standardized objects' insight path (or identifying the 'comparison standard' object or 'standard as a required input for comparison' in the 'compare' definition route) which produces an input to the alignment process, as alignment is a process that should happen between similar objects (such as objects that have been standardized for comparison)
                - 'apply sequence to operations based on which operations enable other operations'
                - 'handle extreme cases'

              to generate the addition method would be:

              - 'compare relevant objects'
                - 'relevance = similarity on an interaction layer'
                  - 'compare objects that interact'
                    - 'digits in the same position (distance from right) interact'
                      - 'apply a standard that aligns objects that interact (digits), to compare digit object values'
              - 'execute the add operation after digits are aligned, for relevant comparisons' (this operation is enabled by the previous operations, which is why it comes after them)
              - 'handle extreme cases, where value cannot be described by the digit value range'
                - 'extra values of addition operation need to be routed to other digits'
                  - 'adjacent digits interact'
                    - 'extra values need to be routed to adjacent digits'
                      - 'adjacent left digits can hold extra values' (increasing from 9 to 10 moves value left)
                        - 'extra values need to be routed to adjacent left digit'
                          - 'add from right to left'
              - 'apply a default operation mode, limit to unit operation, or fulfill "isolatable operation" requirement':
                - 'add one pair of aligned digits at a time' so impact of each operation can be assessed & routed

          - other default operations, like multiplication (2 x 25) identifying 'multiply digits in one number (20, 5) by each digits in the other number (2) and add the output of each multiplication (40 + 10)' as a standard rule to execute multiplication operation, with a multiplication definition that doesnt include those rules, such as:
            - 'find the area of the space bordered by the limits generated by lower x bound = 0, upper x bound = x value, lower y bound = 0, upper y bound = y value'
            - 'add the x-value y times'
            - 'find an adjacent more calculatable or pre-computed value & subtract the difference'
            - lattice multiplication
            multiplication operation definitions which are also alternate outputs of the 'generate a multiplication method' query

          - 'find a structure where calculating the output of numbers multiplied by themselves (exponents) is a set of addition operations' (log function)

          - 'find the unit object of nonlinearity' which should have:
            - info output: x ^ 2
            - structural output: variable ^ (next value other than 1)
            - conceptual output: 'compounding change', 'multi-dimensional (multiplicative) change' (change of variable, and change of a dimension)

          - the program would integrate intent relationships like:
            - 'a unit change in this direction has x impact on change in other directions, and a change of degree n toward other change types & states'
              - which would help predict what impact a change would have on change metrics, which are also calculatable from other change types/states, such as estimating the impact on area from a unit change in one direction (of various change types, including a unit addition/multiplication/parameter change, etc), and include the impact on difference from related change types (impact on tangents, inflection points, subsets, and related objects), and related change states (difference from adjacent functions like with one-off parameters (constants/exponents one degree away)
              - where the intents are structural by default ('multiply by this constant' having intents like 'increase the scale of this function from the unit version, keeping this maximum as a center or this point as an origin')

  - joke insight path examples

    - expectations

      - hypothetical questions & question chains ('what if x') to generate assumptions
        - what if function x normally associated with object 1 is instead in object 2, which shows no evidence of function x

      - assumptions & assumption chains
        - not just "that inanimate object x has feelings" but also "and has tried to manage them but fell for a sock anyway" to fulfill an 'explanatory alternate route' intent of "how it got stuck"

        - permuting the assumption that a gender will be classified as an object of the gender classification system rather than an object of a different classification system, like race or social status or species
          https://www.twitter.com/alienbot1/status/1053376572558852100

    - intent
      - missing the point
        - the point of preventing animal cruelty is not "so they dont have obvious evidence to point to when justifying organizing criminal enterprise against humans"
      - invalidating the point
        - protesting animal cruelty using signs & bumper stickers made with glue made out of dead animals
      - making a point in an unexpected route
        - preventing animal cruelty so they taste better

    - structures
      - switching positions/structures
      - relevance cycles
      - efficiencies
      - similarities
      - extremes
      - bases
        - maintaining a base of reality is useful for highlighting differences
          - "reverse-engineering how an idiot came to a conclusion without the assumption that a cult got to them"
      - paths
        - alternate routes are a place to inject assumptions

    - logic
      - validity
        - illogical connections are a plact to inject assumptions
        - system has to make sense (have some organization) to maximize impact

  - variance generators (of noise) including objects on same interaction level and components that can build changes on interaction level as well as containing object interaction outputs that can cascade to lower interaction level changes

  - how to erase causation contributed by a prior/root cause to subsequent variables if root cause & subsequent variables are both included in the data set

  - example of intent mapped to structure: the outlier or data point in the middle of two categories isnt supposed to be categorized, its supposed to be identified as belonging to a different group (a group in a state of change), which can be used to derive group boundaries, but shouldnt necessarily be integrated into a categorization function

  - example of alternate explanations: for a pattern like why people have different responses to a pathogen, is it bc of coincidences like that:
    - the pathogen fits into the bio system in a way that requires the same functions used to protect it from another second condition, taking protection against that condition away
    - the pathogen coincidentally applies mutations that the bio system hasnt yet evolved to handle
    - the pathogen applies mutations that coincidentally spiral out of control bc theyre mutations to important/core change/regulation rules, or that it causes another error that triggers the second condition
    - the pathogen evolved in an animal that didnt have those vulnerabilities so it was able to live in the host indefinitely rather than killing the host
    - the pathogen needs a function that requires evolving other functions that are coincidentally harmful to the bio system
    - the pathogen misidentifies the genes to target or cant identify the right genes in different systems
    - how to generate the set of possible alternate explanations:
      - apply structures (evolution process of change sequences), concepts (identification function error, coincidence), functions (functions producing changes, such as mutations), and position them using other structures (causal network)

  - with information representing the constant vertices of a system, by representing information a certain way, efficiencies are gained in other information, like related calculation outputs 

      - what does the efficiency provide to uncertain/uncalculatable objects external to information?
      - with certain concepts as priorities or embedded in the structure (like orthogonality generating intersection spaces for mapping interactions), certain efficiencies in calculations are created
      - what filter set or subset of possible concepts can explain the information description system?
        - what other objects are explanatory, in addition to concepts (a slice of a system with a similar object or pattern), filters, core/generative functions, limits?
      - what connects the constants in this system, representing information behavior descriptions - are there system objects like validation/formatting filters, efficiencies aligning between information & uncertainty objects, or other objects beyond the conceptual layer of discoverable information systems?
      - given that information attracts information differently in different structures, what intents can those structures & the information rules be used for?
      - if paradoxes are representable as holes in logical value connections (gaps or jumps in the information system, like asymptotes are for values), what type of information values can occupy those holes, or do they act like a symmetry to connect different spaces?

      - does information withdraw into a superposition (structure with multiple potential information states) or an abstract generalization (generative structure of information or concept network trajectory of the information) or a compression (retaining some attributes of the information), once you remove its structure or remove it from a space where it can stabilize enough to attain a structure?

    - intent implemented on the web could look like approved workflows for accessing a site or across sites, where actions, requests or workflows can be pre-purchased and approved algorithmically 
      ('how to build a bomb' search isnt purchaseable with a 'purchase chemical' request or across purchase bundles)

  - tool to make bacteria grow until detectable & then represent with AR

    - this closes the gap in information:
      - the information needed for the product (a testing & display tool) was insufficient
      - the mechanism to make the information sufficient is accessible (solutions to feed bacteria)
      - rather than make the measurement tool better, you can make the information more accessible (change the position of information rather than the position of the measurement tool)
      - the AR component would augment the size to make it displayable to users without using the measurement tool (microscope) or indicate size/type of pathogen with standard data visualization rules

      - applying the testing tool to hub nodes (then inputs/outputs of hub nodes, and adjacent objects to hub nodes) to check with increasing certainty whether surfaces were compromised
      - redistributing resources based on immunity/infection status to avoid cleaning, like distributing unchecked, unsanitized, or contaminated goods to consumers with immunity/infection 
      - keeping an animal likely to develop fast infections in buildings and then using air conditioner to distribute viral RNA when the building is unused and checking remotely if the animal shows symptoms to see if a building is safe is one way around the limitation to detect live copies of the virus, since the animal symptoms are easier to measure than a pathogen, so the problem becomes ensuring the animal will develop symptoms rather than immunity, and making sure the symptoms show up faster than a test done on hub nodes or quickened with enzymes/sugar/cells that help the pathogen replicate

  - analyzing just by change rate makes it less likely to spot other patterns like overlap/intersection of patterns

  - difference develops where there's potential for new interactions to develop (so a steady or increasing rate of change) & intent (like a possible gain from the difference)

  - the object model may not be the right default to start from in most situations - there arent many whole objects in existence if there are any
    - even particles have sub-particles, and the extent of that chain isnt known, and may have a causal relationship where the smallest particles act as inputs or injection points
    - should ratios/bases or sets be used instead ('a set of particles' rather than a 'plant' as a standard unit)
    - when selecting a default, you should be checking for attribute matches (does a whole object make sense to describe a set)
    - the idea of a whole number may describe something that doesnt exist in 3-d physical reality - does that mean its a concept that will never occupy a form, or is it a goal physics will move towards, or it causally independent from other systems or interfaces that are known, or it evolves as brains can measure information

  - mask design can be optimized as a cover with one output flap like an esophagus preventing input on one nostril so the other can be used exclusively as an input with a filter 
    (better to sanitize at point-of-usage in environments with many unpredictable interactions like wind direction and interpersonal contact, which can get around most masks)

  - types can be represented as directions (going farther from origin goes further up type stack, where similar types are adjacent)
  - change phases for causal analysis (interim, changing, diverging, standard, efficient state, constant, interacting, converging, on the verge of obsolescence, outlier, etc)
    - superficial cause, alternate cause in the case of a function, addressing input/output causes
  - framing on interfaces, decomposing causation, then identifying parameters of problem on layer & matching solution
  - independence (closed trade loops) as time storage
  - vertex as a pivot point for an interface

  - when physics rules stabilize, they attract & generate information, which gathers into measurable numbers
  - if the point of the universe is not to find the initial filters but to prevent that information from being discovered, that could keep open options for other change sources

  - an infinite series implies a stabilized symmetry (a platform for change that goes on forever) - clearly there are different degrees of stability - how do these different degrees of stability relate to different infinities like infinite sets given by number groups
    - the chain of events mentioned here implies a stability in the energy preservation with each successive event
      - https://www.quantamagazine.org/what-goes-on-in-a-proton-quark-math-still-conflicts-with-experiments-20200506/

  - organize db by intent & features for quicker access - like if types are a common filter, organize a graph into type clusters, and store node id's to limit size of various different graphs to depict the same database, a subset of indexes represented per graph

  - product platform:
    - filters: predicting filters that will be used the most (features that differentiate products and alternate purchases the most)
    - products: product query language ('product with feature x and without component y')
    - supplies:
      - adjacent supply cost estimation ('adjacent product built from these suppliers would cost x')
      - estimate future demand & estimate cost of production methods (how many times will you need it? if above x, then its more cost effective to build it yourself, buy from these suppliers with price-lowering trends, buy this robot to make it regularly, or build a robot to do it - plus the timed sequence of those purchases for most cost effectiveness)
    - code as solutions:
      - code search (code as product solutions, like code to print a product or code to predict a compound or adjust vitamin combination as needed)
      - feature-to-code translation ('need a product with existing feature x and add new feature y')

  - explore how to map position (a state structure) to variable structures like networks/loops/trees (like how rank assigns standardized relative position to values - how would you assign a position to nodes in a network in a similarly standardized way - an attribute like connection count or node type, or a trajectory position, or another method)

    - how do rankings map to ratios, and what errors would result from direct mappings of various initial data types?

    - is there a standard set of structures like networks that should be applied to a sequence to get its probable prediction function the fastest (framing numbers as 1, a map from number type to node types, 2, a node's connection count, & 3, distance between nodes, in order to map the sequence in the most robust way)

  - type of chart: a map of the trajectory between low-to-high dimensional representations of a function

  - what attributes determine symmetries so you could differentiate between symmetries (distortion functions, origin)

  - manual code should only be used when there's an unsolved problem in a domain that doesnt respond to algorithmically determined solutions (when optimization of implementation is uncertain), otherwise algorithms should be selecting code

  - vertices: variables where once theyre assigned a value, the rest of the uncertainties are resolved or resolvable

  - data structures:

    - what kind of data structure would look like the original sequence from one angle, but look like its metadata (like the ordered sequence, or average value statistics) from another angle?
      - is the extra storage of a tree, network, or other structure with more than one dimension worth the computation gains
    - is the best storage format of a list where position would be checked later in code a map retaining order, with keys as ordered values & values as positions in original sequence (in case original position is significant and youre not just trying to find if the value is in the sequence)

  - if something can generate a change predictably/consistently, it's a change supply - otherwise it's a change request, so output as well as causal position relative to the output is important when determining category
  
    - time may be a variance gap (a space where change is possible) to resolve a question/problem set - so not resolving it can preserve time, unless resolving it will allow for more potential or moving on to other variance gaps

  - vitamin 3-d printer to print vitamins so that you can design your own multivitamin that:
    - fits your bio conditions & requirements
    - is released in the right order & timing
    - excludes interactions that are contradictory (antimicrobials & probiotics)

  - multiple servers/processors in one computer with one-way data transfers, so one server can be for local communication, one can be for offline work, one can be for browsing internet, and local/offline can communicate to internet-browing processor but not the other way around

  - rules-to-code translation tool - translating domain-specific plain language rules to robot code can be short-term useful for automation of service industry tasks like:
    - converting recipes/flavor-mixing strategies to cooking robot code (chefs can use a tool like this to make money short-term or sell their rules, if they have unique strategies)
    - converting new plant designs to genome editing code
    - converting local social insights to global code (avoid personalities like this, use these tactics to persuade, make this argument to get them to an insight position, etc)
    - converting adaptation insights to change-attracting system adaptation code
    - converting routing mechanisms/optimizations to drone code (short-term human insights like 'avoiding a particular street bc of construction' that data isnt adequate for)
    - the general task of converting rule sets (systems) or human-made visuals (graphs, blueprints) to code

    - machine learning can be used for initial conversion, then tweaked with coded filters like priorities, logic, organization, output
    - system analysis can be used to optimize beyond those standard filters
    - this needs to identify existing rules (or specific versions of abstract rules, distorted versions of standard rules) & filter them out
    - this is an alternative & and an interim step to raw code-generation given a set of intents

  - data viz can be automated using:
    - lie core function layer graph or individual lie type graphs, with an output intent layer (hide information, layer information, minimize information, obfuscate information)
    - intent-structure maps (this graph structure serves this intent stack, just like a function serves an intent stack)

  - each superposition contains components representing different possible filters for the physical laws they create at scale
    - some superpositions collapse into a particular attribute set
    - superpositions with different configurations may represent other interface queries or structures
    - knowing the internal structure of a superposition would mean we get to choose which queries come to life & become real
    - the design implies we shouldnt get to choose - but external forces (or unmeasurable/uncomputable forces inside the universe) should get to determine which configurations collapse & which differences are allowed
    - information has a lifecycle - its likelier to become more true the more its observed, up to a maximum - then it's likelier to erode as its depended on
    - observing a state (to produce the information of the observation) may initialize the static nature of that information, so other observers see either static information or lack of it depending on their perspective, as information becomes truer the more its observed, and they may focus on the lack of information or a different perspective than the initial state of the information


## search ideas:

      - inferring useful search filters based on customer usage history & intent
        - linked searches/user data with type/intent identification - if they are in a location with a certain pathogen and they search for cleaners, theyre probably trying to clean that pathogen so cleaners should be specific or at least an optional search results set should be linked to
      - automated attribute extraction/addition to search as a filter
      - search results as graphs: variables entered in search to display relationships found in data or graph images or graphetized articles
      - processed (aggregated) results - find the average/combined or plain language definition when searching for a definition
      - predicting what questions theyll ask next and adding those search results (or a summary) on the side
      - intent-based search guidance:
        - usually people who search for an answer are studying for a test, so additional widgets like suggested content could include snapshots of/links to: 'study guides', 'summaries', 'tutorials'
        - people searching for recipes are hosting a party & cooking other things, so suggested content could include snapshots of/links to: 'flavor graphs'
        - people searching for symptoms are trying to diagnose themselves or someone else, so suggested content could include links to diagnostic tools or graphs of symptom set frequency for conditions

      - automatic aggregated information formatting queries as an alternative to unstructured/keyword searches pointing to isolated content in manually entered formats like:

        - 'show me stock/financial instrument/cryptocurrency popularity data in graph format' and the output would be a graph of relative usage statistics available, with suggested content links to definitions of the financial instruments since that's a related intent to looking up their popularity, which implies an intent to invest/profit
        - 'show me product search data according to demos in a table with sorts' and the output would be a table with product search data by age group, economic group, in a table format, with sorts to sort each column
        - 'show me insights from language tutorials' would return a list of insights about learning a language, which is a primary implied intent of that search, with suggested content links to music in that language which is one way to learn a language

        - this would be done by:
          - using previous queries & feedback on search results
          - auto-formatting
          - aggregated data from existing content
          - pulling definitions of keywords like 'demos' to determine what supported keyword they mean, or create a new term out of core functions (groups separated by attribute & attribute value)

      - graph search (with queries like 'show me relationship between time and gdp' or show me relationship between using lysol and cancer')

        - could scan studies related to graph for logical fallacies and adjust graph accordingly, then present a composite graph of data found

        - data from searches & product purchases can be integrated into graph (buying lysol followed by searches for cancer symptoms)

        - 'deploy an AI model to do tasks: find/predict relationship, categorize, or rank' option can be included to train on public data based on plain language queries like the above

      - search data + verified purchases can be used to assess the value of a particular product solution for a problem (like a supplement to treat a health condition), to offset fake reviews or faulty recommendation/removal algorithm or account for product fixes over time, as well as customize it to the user (avoid this product if you have condition x, this product has correlation with onset of condition y

        - customization can also be done for user groups like intelligence - so people likelier to believe a story without checking it like anti-vaxx stories can be shown true stories with more repetition

        - example of a system object being useful for customatization (a false categorization):
          - busy can look like stupidity under certain circumstances - what are those circumstances and when are they most important to avoid 
            (if someone's too busy to check a news site, send them a notification about a pandemic so theyre likelier to see it)

  - shared custom meaning/dictionary maps so communication can be queries on their shared custom dictionary map - or a common map where queries specify pattern & sub-set to apply pattern to, and sub-sets are rotated

