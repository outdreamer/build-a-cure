    - add to solution automation workflows

      - apply intent interface specifically to derive specific problem-solving intents for a specific problem that would be useful in solving the problem
        - example: deriving the intent of 'reducing variables' as a useful problem-solving intent for the 'find a prediction function' problem involves applying the definition of concepts like noise/outliers as an indication of irrelevant variables
          - generalization: 'reducing variables' would be relevant specifically in 'reducing variables to unique change types', which is a useful structure, so applying useful functions like 'reduce' to important problem structures like 'variables' and connecting those functions with useful structures like 'unique change types' is a generalization of this workflow

      - apply core interaction functions (like 'reduce', 'connect') and other function types (like 'abstract') and other useful structures to all relevant structures of the problem space to find useful changes to relevant problem structures that would reduce the problem of fulfilling problem-solving intents for those structures
        - example: applying 'reduce' to a 'variable' structure in the 'find a prediction function' problem into its components/inputs/attributes/generator may make useful structures like 'structural similarities' between relevant structures like 'variables' more obvious so they can be 'reduced' into one variable like a 'type' for relevant specific problem-solving intents like 'reduce dimensions' or 'feature engineering'

      - identify the maximally different functions fulfilling a 'core interaction-interface' function (like 'reduce change types') from existing functions to begin a search for new solutions if existing solution functions produce errors
        - combinations of core interaction functions & interface structures would be likely useful in solving problems
          - examples: 'filter cause structures', 'connect interaction layers', 'sort useful structures'
        - this function type connects core interaction functions with interface structures, similar to interface functions like 'find a structure in a structure', or interim functions like 'organize' or 'predict'
        - the difference in this function type is that these functions are likelier to be useful than other function types like general functions, core interaction functions which must be combined in a structure in order to be useful, or interface functions which are likely to require their own interface query
        - this function type is similar to problem-solving intent functions, interim functions, & interface queries, and may be able to be used as a substitute of some interface queries
        - generalization: 
          - after generating the set of possible useful interface queries to solve a problem, identify the emergent functions that are the most often required in the interface queries, to identify new or temporarily/conditionally useful function interaction levels & their metadata (why theyre useful, what is required for them to be useful, useful variants, etc)

      - find cross-interface structures (like the 'intersection' of 'structures' and 'causes' and 'patterns' of 'variable interactions') that interact with important problem structures that are determining for the success of a solution in various error type conditions
        - example: for the 'find a prediction function' problem:
          - if a function has an error type of 'false similarity' (with different cause), the actual cause is different than the assumed cause allowing selection of that solution, so structures of variable interactions & causes would be useful in filtering out these solutions
          - 'variable interactions' are an important structure for the 'find a prediction function' problem, so applying interface structures to this important structure can identify useful structures for building a robust solution to error types
          - other important structures include the following, but 'variable interactions' are particularly important, as theyre the highest variation structure that is adjacent to the solution format ('a prediction function') & require fewer non-standard assumptions than function formats (subsets/alternate/component/conditional)
            - input structures: data points, variable ranges, data types
            - interim structures: data subsets, function filters/requirements
            - output structures: subset/alternate/component/conditional functions
          - functions like the following would identify useful structures of variable interactions & other interface structures that would determine success under various error type conditions
            - find multiple alternate functions that follow variable interaction patterns more adjacently than the original line or better align with variable interaction causes
            - apply changes to data set to find adjacent data sets with clear regression lines

      - change inputs/outputs to solve a different problem or change the sequence/structure of problems to be solved
        - example: rather than solving the initial problem to connect the original problem with a solution, solve a problem that is one-step closer to the solution & solve for a solution that is one-step away from the original solution, then apply changes to the inputs/outputs of that solution until it fits with the original problem/solution
          - rather than solving the problem of 'find a prediction function' for original independent variables, solve the problem of 'find a prediction function' for aggregate variables (like types that summarize the original variables), because an alternate intent of 'predict the data' is 'summarize the data', so starting from a summary as an input is a step closer to the original solution format, which is a prediction (or summarization) function
            - independent variables of data set => summarizing variables like types or aggregates or compressions => prediction/summarization function for dependent variables
          - once you have this 'inner' solution, fit it to the original problem/solution by applying changes to the 'inner' solution
            - apply changes to the summarization function of the summarized independent variables until it acts as a summarization function of the original independent variables that can predict the dependent variable
          - another example would be to change the dependent variable predicted (find a prediction function that predicts z instead of y) then apply changes to that solution until it predicts y
          - another example would be to abstract the inputs/outputs and solve for that prediction function instead, then applying specifying structures to the general solution, until it solves for the original problem that is an example of that generalization
        - workflow fit: this is a generalization of workflows that change inputs/outputs to solve a different problem, or solve a different sequence/structure of problems

      - identify alternate interchangeable structures that form an interchangeable solution to a problem in some condition, to cover as many conditions as possible
        - example: an 'explanation', 'description', 'generator/cause', 'compression', and 'summary' are alternate structures that can replace/approximate a 'prediction function' for the 'find a prediction function' problem, so if those can be solved for more quickly than a 'prediction function', they may be approximate/temporary/conditional substitutes for the 'prediction function' solution format
        - workflow fit: this is similar to the 'find an approximate solution' workflows, but involves applying the analysis to interchangeable structures in general & to as many conditions as possible to approximate/replace the original solution format

      - find/derive/generate 'counterintuition' & other 'complexity' structures that a solution-finding method should be able to handle & their associated difference structures from error & error-causing structures, using cause as a useful structure to find other relevant info that can be used to filter the solution space or differentiate between solutions/errors
        - example: distorting input so its maximally distorted but should still be identifiable as a category label in a categorization problem, and connecting it to differences from error structures (structures that would result in output of the incorrect or unknown label), or producing/expanding those differences in the input
        - 'alternate generative functions' of a species (like an agent building an artistic representation of a species) could produce 'structural similarities' resulting in an 'unknown' label error, so identifying features indicating alternate generative functions would be important to include in the solution-finding method (differences between a 'dog' and a 'drawing of a dog')
        - differences from structures of complexity like ambiguities would also be required to identify, as well as alternate feature sets that could differentiate between labels when some features are missing or unidentifiable
        - the highly distorted image isnt an error (it would be a complexity structure) but structures differentiating it from errors & errors that happen to also be complexity structures would produce a more robust solution-finding method, so the solution-finding method would have to included those differentiating structures
        - a 'photo of a cat with a cartoon in it' would be differentiable from a 'photo of a cartoon of a cat' by features like natural vs. agent-generated randomness & natural vs. agent-generated detail, so the solution-finding method would need to be able to identify those structures
          - this means the interface query would include 'find randomness structures' and 'find detail structures' and 'find agency structures' as calls to find/derive/generate functionality fulfilling those intents
        - by generating the distortions, we start by knowing the cause of the distortions ('an agent drew a cartoon'), and the related objects of those causes ('human error', 'limited time or attention span leading to lack of detail')
          - this means we know what features would differentiate these distorted inputs from error inputs of various types (incorrect output label, unknown output label), so error structures & error causes should be more identifiable given the extra info we have about solution structures that happen to be complex

      - the interface query is basically 'what questions need to be answered to solve this problem' - another variant would be 'what information could allow this problem to be solved with this solution-finding function'
        - example: in the 'find a prediction function' problem, this would take the form of 'finding what structures of information would have enough complexity to require a machine-learning algorithm to find a prediction function'
          - the 'find a prediction function for image categorization' problem would require complexity in the form of structures like ambiguities, similar alternative opposites, distortions, & randomness, so images with those structures should be expected & could be derived from the problem statement
          - a solution function that can determine the outputs from those inputs would have structures like 'variable isolation' (using 'feature engineering' functions) & 'complexity reduction' (using 'generalizing' functions) to connect those inputs/outputs
          - if a solution-finding function cant solve the problem given the expected inputs, changes can be applied until it can connect the expected inputs with the outputs
          - this means 'the solution-finding method requires the referenced 'variable isolation' and 'complexity reduction' structures, to resolve the ambiguities & other complexity structures requiring the solution-finding method in common image categorization data sets'
          - from the typical complexity & other problem-causing attributes of the problem, which would require using this solution-finding method (given the method intents like 'find a prediction function'), we can derive the structures the solution-finding method would need
          - all that is required to use this workflow is the problem statement 'find a prediction function to categorize images' and the solution format 'categorization labels', from which the structures required for the method can be derived given the implied complexity of the problem
          - this applies the logic interface to derive implications & requirements as well as the concept interface to derive complexity structures

      - apply various alternate formats like sequences, preceding/succeeding sequences, & adjacent subsets, & defining values like extremes as inputs to prediction functions, to predict the adjacent/next item in a structure having relevance by adjacence/order (like a sequence of y-values for an x-value sequence)
        - example: rather than 'trying to predict a line', the problem can be a problem of 'trying to predict the likelihood of a value, given the preceding values' and 'trying to predict whether the y-value sequence is likely given the prediction functions that succeed at predicting the next value'
          - predicting an initial value from the following values, predicting an adjacent value from neighboring values, and predicting local from global values are examples of predictions that can be made by applying prediction functions to find a likely prediction function
        - generalization: this can be generalized to applying prediction functions to predict various interaction structures, predict which functions will be useful, predict important variables, and other structures required by a particular workflow
        - another variant would be to 'apply probability & structure interfaces so that from structures that can be verified, identify probability of other structures until theres a structural interaction that cant be verified with some degree of certainty'
          - example: for the 'find a prediction function' problem, given that there's a structure of 'many change types' in a parabola as opposed to a line (one change type, as in constant/charged change), whats the probability of a cycle structure or intersection with zero in the same function (how often do 'many change types' occurring in a parabola defined locally occur with a cycle structure defined elsewhere in the function)
        - this is only applicable in cases where the structure being predicted has relevance to the input structure (values in a continuous function can be connected in a sequence structure or adjacence structure like a subset)

      - solution automation workflows can be derived from core structures like combinations, sequences, and variables & interface structures applied to these core structures like inputs/outputs, interactions, & types
        - example: 
          - 'combination' structures go with the workflow 'build a solution out of components', where components are interface structures that can be combined to create a solution
        - generalization: 
          - this can be generalized to 'find the core structures of a system, and apply interface structures to those core structures, then fit these applications to fulfill an interaction function of problem/solution structures'

      - identify causes like inputs/requirements of useful structures (like a 'question that triggers a useful structure like an optimization'), & connections with useful structures (like systems where useful structures are default), & system context structures that allow/incentivize useful structures to develop or dont prevent useful structures from developing (like a 'lack of limits'), and apply those structures as the adjacents/inputs to finding useful structures or the generative structures of useful structures
        - alternatively, apply the definitions of useful structures & their metadata, like that a useful structure is defined as:
          - having a structural alignment with an intent, making it useful for that intent
          - existing in a space with variation, allowing for the existence of non-useful structures that make it useful by comparison, like the existence of alternative sub-optimal routes
          - developing in a system where the system's existence is only achievable by developing a better way to fulfill an intent, incentivizing development of useful structures

      - apply solution structures that fulfill one problem-solving intent (like 'preventing a problem' or 'solving a related problem') to another problem-solving intent (like 'fixing a problem')
        - example:
          - preventative solutions like vaccines have a solution success cause (using the immune system to prevent infection) that allows for re-use across other problem-solving intents such as fixes (like immunotherapy treatments)
          - the 'golden rule' draws attention useful 'preventative' objects like empathy, but can also be used for other problem-solving intents like 'restitution' (fixing a crime), by connecting criminals/victims in other ways than empathy thought experiments (like trading criminal/victim positions, progressively applying more punishments rather than applying the same crime, connecting criminals with other victims of the same crime rather than their victim, etc)
          - the reason the 'preventative' solution works is its interaction with 'empathy' or the 'immune system', and this cause can be re-applied in other problem-solving intent solution structures than 'prevention'
        - generalization: this can be generalized to re-applying any problem/solution structures across different problem/solution variables (like different problem-solving intents) that have an important structure in common (like 'success cause'), indicating there is reason to re-use one structure in another context

      - apply useful structures (like opposite structures) once applied to interfaces to fulfill functions of relevant types (like problem-solving intents, core interaction functions, interim functions, general functions) & organize these 'useful structures for function types' to find other useful structures connecting the useful structures (like useful structure sequences, hubs, overlaps, symmetries) in the 'useful structure network'
        - example: with the 'find a prediction function' problem, the function might be verifiable as not a shape, a set of subset or conditional functions, a linear function, & other solution formats
          - this is applying the 'opposite' structure to various difference types in solution format structures to fulfill the 'filter solution space' problem-solving intent, applied to various interfaces ('opposite' applied to 'potential' interface to produce 'conditional alternative functions')
          - another example is how the 'reduce' function applied to 'distance' or 'difference' structures is a useful structure for the 'connect' function
        - 'format a problem in terms of an interface query that can be fulfilled with functions on this function type network or useful structures on the useful structure network to reduce computations required' is a solution automation workflow that can use either of these networks once defined

      - calculate how much certainty can be determined with input info & apply that as a filter of the solution space & the solution format
        - example: with the 'find a prediction function' problem, the function may only be determinable within a certain range of alternative functions or within a certain parameter range, which may form a solution format of an area rather than a line/curve
        - knowing that only so much certainty in a solution can be derived with given inputs, the solution space can be filtered with an interface query connecting to that certainty structure instead of the original solution structure

      - find/derive/generate specific structures that are useful for specific problem-solving intents, general/core/interim function intents, or interface query intents, to implement those intents automatically
        - this involves identifying the cause of useful structures' usefulness & applying as a generative function
        - example:
          - specific structures like 'maximizing differences' and 'input-output sequences' that are useful for problem-solving intents like 'filter solution space' & 'connect problem/solution', and other function intents bc of the useful structures they generate like 'adjacence to inputs of function intent'
            - maximized differences are more adjacent to the input of 'identify/filter' functions & may reduce the work required by those functions to reach the output
            - input-output sequences provide default possible solution or solution component structures to reduce the work of filtering the solution space, making the input to the 'filter solution space' function more similar to its required output (a reduced set of solutions)
            - useful structures can be found/derived/generated by which structures create differences (like a difference in the form of a 'reduction' in possible solutions) that happen to be useful for various required intents (like 'avoid errors' or 'identify difference')

      - derive functions connecting function interaction levels (general, core, interim functions) and all the routes on the function network that are particularly useful for a specific function that solves a problem, then identify the average implementation & its parameters to define a standard function to solve that problem (fulfill the specific function) which can be adjusted as needed for varying intents
        - example: 'remove similarities for comparison' and 'standardize to emphasize differences' are useful connecting paths on the function network for the 'find a prediction function' problem (or the 'predict' interim function) which can also be formatted as a path on the function network

      - apply ml with useful structures for a problem-solving intent (like 'generate code for a general function automatically') that combines specific features into general features to combine specific structural functions ('combine', 'sort', 'reduce') to generate general functions ('filter', 'identify', 'standardize')
        - the reason 'find a prediction function' is a standard problem format that any problem can be formatted as, is bc its adjacent to an interim function 'predict' ('find input-output sequence', 'identify causal variable', 'identify vertex variable')
        - other standard problem formats are adjacent to other core/interim/general functions
        - generalization: this can be generalized to 'find a solution with useful structures like 'similarities' in 'inputs/outputs' for a standard problem format like finding prediction functions that can be applied to the original problem once formatted according to the standard problem format'

      - apply interchangeable problem/solution & interface objects to each other, bc when there are interchangeable objects, that indicates they can be applied to each other in a useful way
        - example:
          - variables/functions are interchangeable formats, which can be applied to each other to generate useful objects ('variables of functions' like 'inputs/outputs/intents', and 'functions of variables' like 'determining/generating/causing')
          - find/build/apply can be applied to generate interim functions & common intents ('find a build method', 'apply a find method to derive a build method')
          - applying problem-solving intents to each other can direct the design of interface queries fulfilling each intent 'filter solution space' of problem of 'finding other problems to solve'
          - applying specific problem formats which any problem can be formatted as ('find a prediction function', 'apply sorting algorithm') can be applied to each other
          - core interaction functions can be applied to each other ('reduce connections', 'sort reductions', 'combine sorts')
        - these interchangeable objects tend to be on the same interaction level which can mean they are different useful variants of a core underlying base object, with overlapping definitions, and applying them to other objects on the same interaction level can produce more gains for an intent

      - identify useful structures for sub-intents of an interface query to use as default structures
        - example: for a sub-intent of 'find an example', structures of 'specificity' are more useful bc theyre 'more adjacent to attributes of inputs' of the sub-intent, 'more adjacent to input attributes' being a useful filter for useful structures
        - generalization: this can be generalized to 'find all the interface & problem/solution structures of useful structures', which would include 'useful filters' of useful structures for the 'filter solution space problem-solving intent'

      - identify the structures with highest impact on solution success
        - example: in the 'find a prediction function' problem, this would include standard 'contributing variables' & 'variable interactions', but also 'function structures' like 'averages', 'continuity', 'change rate patterns', 'waves/peaks/inflection points'
          - these have high impact on solution success bc theyre 'high variation', 'represent a standard', 'reflect the output of relevant variables like exponents or patterns', are 'relevant inputs like function component structures', or are defined to be useful 'patterns are defined to represent an abstraction of a change type'

      - identify the complete structures in a problem space & format the problem in terms of the complete structures for solution metrics like accuracy/robustness
        - example: variables arent a complete structure until some understanding rules are injected about their interaction structures such as cause & relationship to other variables, the context in which they are variable/constant, and their associated change types

      - derive which interface structures (like combinations/subsets) are relevant to useful structures (like variable interactions) using insight rules (like that 'adjacent features are likely to be dependent') & comparing possible usefulness structures
        - example: how to derive 'combinations' of 'variable interactions' as useful structures, given the insight rule 'adjacent variables are likely to be dependent'
          - 'adjacence' is 'similarity in position', and structures that are 'similar in position' are easier to fulfill intents like 'group', so 'combinations' are an 'adjacent' structure of this structure
            - the 'combination' structure also fulfills intents like 'isolate' for structures like 'dependent variables', and 'isolating related objects' or 'isolating objects of a type' are a useful function for various general/problem-solving/interim/core function intents
            - given that it can be adjacently used for various known useful intents, it can be considered a useful structure (after comparing it to the adjacently useful intent ratio of other possible useful structures)
        - workflow fit: this is similar to other workflows involving deriving useful/interface structures useful for other useful/interface structures or problem-solving intents, but with a filter for evaluating probability of usefulness compared to other structures

      - identify structures of determination (where once a structure is determined, the other structures dependent on it are also determined) & apply as 'reduction' structures of computation requirements in an interface query

      - generate maximally different perspectives to avoid over-incentivizing one perspective & its resulting error types, to apply as solution filters
        - example: in the 'find a prediction function' problem, maximally different perspectives would include:
          - 'find the right unique isolated variable interaction to equal the output variable'
          - 'check if the definition of objects is applicable'
            - if a 'variable' concept is not applicable to a particular structure, it will generate errors
              - example: 
                - if the 'sound' variable is only measurable by 'vibrations', it might be handled incorrectly, miss all the variation within the 'sound' variable, miss the fact that the 'sound' variable can act as an interface, and be a poor predictor of 'sound' variation & metadata like inputs/outputs
                  - the 'variable' concept refers to a 'unique change type', but it leaves out the 'related variable network' structure that all variables are nodes in & other structures relevant to that 'variable' definition, and would misidentify 'vibrations' as a change-determining variable rather than an attribute of the 'sound' variable, bc it would miss their interaction in the 'related variable network' inherent to a complete 'variable' definition, where usually a limited structural definition of 'variable' as 'unique change type' is applied
                - in the 'chihuahua/muffin' class identification problem, adjacent features arent isolatable bc they determine what adjacent features are possible (the structure of a skull determines what configurations of structures surrounding it are possible), but they are treated as isolatable (the correlation between bone/organs is treated as independent), whereas other variables are isolatable but are treated as one variable (damage to one eye/ear doesnt necessarily correlate with damage to the other)
                  - this is bc there is no 'requirement' structure requiring that any damage to one side be reflected in the other (the inherent symmetry can be distorted), but there are structures that 'can' require that (causes of organ damage)
                    - 'requirement' structures can be checked for using attributes of adjacent structures (does the skull seem to have a firm structure or would it necessarily change if another feature was removed)
              - not all variables treated as isolatable are actually isolatable, but with missing data they might seem isolatable
        - these perspective can be filtered by which would have the most impact on the solution success (solution success impact, as a variable that can limit or enable solution success)

      - find difference causes of interface structures (like concepts) and apply structures of them to create various solutions to filter as an initial solution space
        - example: find the reasons why data set points might differ (randomness, indicative of change in the underlying interaction, variation within expected/valid variable ranges) and create combinations of these reasons to explain the data set, by adjusting which points are included in the 'find a prediction function' problem input, which are excluded bc of reasons like 'random noise'
        - this is useful bc difference causes are a powerful structure in understanding why differences occur so they can be created/predicted as needed

      - find useful structures like units/ratios between change causes (reasons to change) vs. reasons not to change to justify changing a standard solution (like a linear function) to find an optimal solution (a better-fitting function)
        - example: 
          - the reasons to change may include reasons like that 'a data point would be better predicted if the change is applied'
          - the reasons not to change may include reasons like that 'patterns of changes of other functions that avoided this change type performed better' or 'the data point is an outlier'
          - structures like ratios between these change causes can be useful if each change cause contributes equivalent certainty so they can be treated like units
          - this is useful bc change causes from a standard solution are a powerful structure to help optimize a solution - if there is a reason to change a structure, its likelier to be reflective of reality

      - find target solution structures that lead to problem-solving processes even if they dont solve the original problem, like a target position that leads to change in a direction toward the original intended solution, even if the destination isnt reached

      - find structures of difference between 'false rewards' & other useful error structures of falsehood & the error structures they correct to apply as structure to fulfill the 'error-correcting' problem-solving intent
        - usually real rewards can be found to incentivize finding/generating/deriving a solution if its correct, so this shouldnt be necessary, but it can be more efficient than identifying/using real rewards to incentivize a solution/optimization

      - find the structures of primary default interface structures that are most useful across interface queries & workflows & apply those as default components
        - example: change + direction, priority + potential field, variable + concept type are examples of structures of interface structures, but some in particular are more useful than others, like 'perspectives' (filter with priorities) bc they fulfill structures of usefulness like 'capturing high variation' and 'reducing complexity' and 'applying importance structures' which are useful for various interim & core functions like 'find important objects' and 'understand a system quickly' and 'find hub variables', so apply these metrics as filters of these structures of primary interface structures
        - workflow fit: this is similar to other workflows involving finding useful structures, but specifically filters them by which are useful for fulfilling intents of interim/core functions that are commonly used in interface queries' sub-intents

      - combine a partially implemented interface query with gaps in implementation left for variation, where the sections implemented are known to be optimal for various sub-intents of the interface query
        - the pieces that are implemented can be on different interaction levels of the interface query
        - generalization: 
          - this can be generalized to other interactions between problem/solution structures which have clearly optimal implementations of sections of the interaction
          - it can be generalized further to other structures than 'partial subset', such as known optimal 'sequences' of problem/solution interactions or known optimal 'combinations' of problem/solution interactions
        - simplification: this can be simplified to adding a variable, allowing variation in which subsets or other structures are implemented & which can be changed for various implementations

      - interface structures that are adjacent (immediately preceding/following) to a solution so as to be causative or indicative of a solution can be identified as predictors or generators or identifiers of solution structures
        - if there's a perspective, function, change, pattern, etc that is often found around solutions, those can be used according to their position as predictors/generators/identifiers
        - this is similar to 'applying the solution as a symmetry or interface around which changes are applied while still qualifying as a solution', but applying the solution as a base or center where other objects relevant to it are adjacent, which may or may not be solutions, as a merged interface structure involving a combination of multiple interfaces, although the surrounding structures may also qualify as solutions
        - adjacence can be determined by number of steps separating the structures (for example, separating a question/perspective/useful structure & a solution), number of interface structures separating them, distance determined by some similarity metric, or other definition
      
      - find a structure (such as a perspective/function or network with nodes arranged by a certain distance or similarity metric) that would make solving a problem much quicker (or fulfilling another solution metric, like using available resources) and aim for that structure as the solution target to generate (so the problem becomes 'generate this useful structure' instead of 'solve the original problem')
        - for example, when a function network is organized by similarity in impact, its easier to see which nodes are higher impact
        - this can be extended by applying filters to find useful 'solution-adjacent' or 'adjacently solution-finding' structures that make a solution obvious or guaranteed/inevitable
          - structures like a particular way of organizing a network by some distance metric can make solving a set of problems trivial, which makes it more useful than a network organized in a way that solves one problem, other things being equal
          - structures that 'make solving multiple problems trivial' are useful targets for solution automation workflows, as a problem-solving intent of 'find structures that make solving the problem trivial'
      
      - store the optimal interface queries associated with a particular solution automation workflow to convert the 'build interface query' task into a 'find interface query in database' task, or store generative functions to find the optimal interface queries if any are stored, or derive the interface query in a more efficient way than interface query design logic
        - generalization: can be generalized to associations between any problem/solution structures

      - identify structures of error structures & their interface structures like meaning, for use in 'predicting structures', which is an interim function, or 'predicting error/solution structures', which is a problem-solving intent
        - example: when an extreme set of errors of a particular type usually precedes finding an interface, that can be used to predict which error structures mean that 'an interface is about to be found' 
